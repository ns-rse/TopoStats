{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to TopoStats's documentation","text":"<p>TopoStats batch processes scans from Atomic Force Microscopy. Please read through the various documentation sections listed below to find out more.</p> <ul> <li>Introduction</li> <li>Installation</li> <li>Usage</li> <li>Configuration</li> <li>Notebooks</li> <li>Workflow</li> <li>Data Dictionary</li> <li>Advanced</li> <li>Contributing</li> <li>Related Software</li> <li>Glossary</li> <li>FAQ</li> </ul>"},{"location":"faq/","title":"Frequently Asked Questions","text":"<p>This is a collection of questions (and answers) to problems that arise with using TopoStats software for processing Atomic Force Microscopy images.</p> <p>If you have questions that are not answered here please consider starting a new discussion in the TopoStats Discussion section of the GitHub repository. Developers will endeavour to help you resolve your problem and it may get added to this page.</p>"},{"location":"faq/#general-questions","title":"General Questions","text":""},{"location":"faq/#my-files-image-files-are-on-a-mounted-google-drive-can-i-process-them-there","title":"My files image files are on a mounted Google Drive, can I process them there?","text":"<p>Maybe! We have had mixed success with processing images that are located on Google Drive and mounted on your local computer. If you find you are encountering errors such as <code>FileExistsError</code> (see #201) then please copy your files to a local drive on your computer for processing and then copy the results back to the network drive.</p>"},{"location":"faq/#common-errors","title":"Common Errors","text":"<p>Common errors that are encountered along with explanations are listed below.</p>"},{"location":"glossary/","title":"Glossary","text":""},{"location":"glossary/#a","title":"A","text":""},{"location":"glossary/#alignment","title":"alignment","text":""},{"location":"glossary/#b","title":"B","text":""},{"location":"glossary/#c","title":"C","text":""},{"location":"glossary/#csv","title":"csv","text":"<p>Comma Separated Values (CSV) is an ASCII plain-text file format where columns of data are separated by commas.</p>"},{"location":"glossary/#d","title":"D","text":""},{"location":"glossary/#dna","title":"DNA","text":"<p>Deoxyribonucleic acid (DNA) is a double-helix polymer of four molecules Cytosine, Guanine, Adenine and Thymine. It is the genetic material of the vast majority of organisms (some viruses use Ribonucleic Acid (RNA) as their genetic material).</p>"},{"location":"glossary/#e","title":"E","text":""},{"location":"glossary/#f","title":"F","text":""},{"location":"glossary/#flattening","title":"flattening","text":"<p>The process of removing tilt from an image.</p>"},{"location":"glossary/#g","title":"G","text":""},{"location":"glossary/#git","title":"Git","text":"<p>Git is a free, open source version control system for managing software projects and development.</p>"},{"location":"glossary/#github","title":"GitHub","text":"<p>GitHub is a website for sharing and collaboratively working on software that is version controlled using Git.</p>"},{"location":"glossary/#grain","title":"Grain","text":"<p>The name given to DNA/RNA/protein structures observed in scans.</p>"},{"location":"glossary/#h","title":"H","text":""},{"location":"glossary/#i","title":"I","text":""},{"location":"glossary/#j","title":"J","text":""},{"location":"glossary/#k","title":"K","text":""},{"location":"glossary/#l","title":"L","text":""},{"location":"glossary/#m","title":"M","text":""},{"location":"glossary/#n","title":"N","text":""},{"location":"glossary/#o","title":"O","text":""},{"location":"glossary/#p","title":"P","text":""},{"location":"glossary/#python","title":"Python","text":"<p>Python is the high-level interpreted programming language in which TopoStats is written.</p>"},{"location":"glossary/#q","title":"Q","text":""},{"location":"glossary/#r","title":"R","text":""},{"location":"glossary/#s","title":"S","text":""},{"location":"glossary/#scars","title":"scars","text":"<p>Artefacts seen in some scans that can be removed during processing. Typically they appear as horizontal high bands. These are removed and the missing values interpolated.</p>"},{"location":"glossary/#skeleton","title":"skeleton","text":"<p>The single-pixel width outline of a molecule after a grain has undergone tracing.</p>"},{"location":"glossary/#t","title":"T","text":""},{"location":"glossary/#tilt","title":"tilt","text":""},{"location":"glossary/#tracing","title":"tracing","text":"<p>The processing step where by a grain is reduced to a single pixel or skeleton. Typically a number of statistics on the shape, length and curvature are calculated after molecules have been traced.</p>"},{"location":"glossary/#u","title":"U","text":""},{"location":"glossary/#v","title":"V","text":""},{"location":"glossary/#w","title":"W","text":""},{"location":"glossary/#x","title":"X","text":""},{"location":"glossary/#y","title":"Y","text":""},{"location":"glossary/#z","title":"Z","text":""},{"location":"introduction/","title":"Introduction","text":"<p>TopoStats is a Python package that aims to simplify batch processing Atomic Force Microscopy (AFM) images.</p> <p>Input directories are recursively searched for files of a given type. Each image is then loaded and processed. Multiple images can be processed in parallel.</p> <p>Once an image has been loaded the specified channel of data extracted along with the pixel to nanometre scaling. This data is then aligned and the tilt is removed. Configurable thresholds are then used to generate masks and a second round of tilt removal and row alignment is performed.</p> <p>Molecules/regions of interest known as Grains are then detected based on user specified thresholds and the detected regions are labelled and have preliminary statistics calculated. The labelled regions of each grain then have individual statistics calculated capturing the height, volume, radius and the location of the centroid.</p> <p>Optionally DNA Tracing is then performed, which traces the backbone of the DNA molecules to calculate further statistics such as whether grains are linear or circular, their contour length and end-to-end distances etc.</p> <p>The resulting statistics are written to a CSV file and optionally plots are then generated from various stages of the processing as well as cropped images of each grain. The amount of images produced is also configurable.</p> <p>An schematic overview of the classes and methods that are run in processing files can be found in the workflow page along with more detailed information on installation, usage, configuration and contributing.</p> <p>If you have questions, please post them on the discussion, if you think you've encountered a bug whilst running the code or suggestions for improvements please create an issue in the GitHub project page.</p>"},{"location":"related_software/","title":"Related Software","text":"<p>TopoStats is one of many pieces of software available for working with Atomic Force Microscopy data, other packages are detailed here. If you know of another package please consider making a pull request to add it to the list.</p>"},{"location":"related_software/#python","title":"Python","text":"<ul> <li>afmformats reading common AFM file formats.</li> <li>AFMReader library developed by TopoStats team for loading different AFM   images.</li> <li>gwyfile a pure Python interface to reading and writing Gwyddion files.</li> <li>magni compressive sampling and reconstruction of Atomic Force Microscopy images.</li> <li>nanite loading, fitting and rating AFM force-distance data.</li> <li>nanoforce import and analyse AFM force curves produced using Nanoscope 5 &amp; 6   and Nanosurf <code>.nid</code> files.</li> <li>nanoscope read data files collected using Bruker, Veeco, and Digital   Instruments Atomic Force Microscopes (AFMs) using Nanoscope v5.12 - v10.00 acquisition software</li> <li>NSFOpen Read data and parameters from Nanosurf NID files.</li> <li>pycroscopy Python Package for scientific analysis of nanoscience   data.</li> <li>pySPM read, handle and plot Scanning Probme Microscopy (SPM) images and ToF-SIMS data.</li> </ul>"},{"location":"related_software/#c","title":"C++","text":"<ul> <li>libasd library for reading asd files, includes Python 3 bindings.</li> </ul>"},{"location":"related_software/#other","title":"Other","text":"<ul> <li>gwyddion a modular program for Scanning Probe Microscopy (SPM) data visualisation and analysis.</li> </ul>"},{"location":"advanced/","title":"Overview","text":"<p>You can read more detailed information about the methods implemented in TopoStats in the pages below.</p> <ul> <li>Flattening</li> <li>Grain Finding</li> <li>Thresholding</li> <li>Grain Stats</li> <li>Disordered Tracing</li> <li>Nodestats</li> <li>Ordered Tracing</li> <li>Splining</li> </ul>"},{"location":"advanced/disordered_tracing/","title":"Disordered Tracing","text":"<p>This section gives an in-depth overview of the steps taken in the disordered tracing module.</p>"},{"location":"advanced/disordered_tracing/#at-a-glance-simple-representations","title":"At a Glance : Simple Representations","text":"<p>The <code>disordered_tracing.py</code> module handles all the functions associated with obtaining single-pixel wide, line representations of masked objects.</p> <p>The quality and likeness of the resultant pruned skeleton thus depends on the quality of the mask, the effectiveness of smoothing parameters, the method of skeletonisation, and the quality of automating the pruning of incorrect skeletal branches.</p> <p></p> <p>This module measures the number of junctions and endpoints for each pruned skeleton object and appends these columns to the <code>all_statistics.csv</code>. In addition, the <code>all_disordered_segment_statistics.csv</code> file is produced which measures the length, type, connections, and pixel value (typically height); minimum, middle, median, mean and standard deviation for each skeleton segment between junctions using Skan. The branch types are given by:</p> <ul> <li>0: Endpoint-to-endpoint</li> <li>1: Endpoint-to-junction</li> <li>2: Junction-to-junction</li> <li>3: Isolated cycle</li> </ul> <p>Some useful points to bear in mind:</p> <ul> <li>Bad mask, bad skeleton - If the mask closes holes seen in the image, all skeletonisation methods will produce a   single line for this region.</li> <li>No skeletons in image - The disordered trace <code>core</code> image may not show the resultant skeletons if the plotting   <code>dpi</code> value is too low (varies based on image size).</li> <li>Hard to remove branches - If there are still spurious branches to prune after modifying the   <code>mask_smoothing_params</code> and <code>pruning_params</code>, try increasing the <code>filters.gaussian_size</code> value to smooth the image the   mask is created from.</li> <li>Masked colours are relative - Any mask colours that may be produced by plots are relative to the mask values in   that image as they will always span the masked colourmap, and will not compare well across images if the range of mask   values differ.</li> </ul>"},{"location":"advanced/disordered_tracing/#processing-steps","title":"Processing Steps","text":""},{"location":"advanced/disordered_tracing/#1-smoothing-the-mask","title":"1. Smoothing the Mask","text":"<p>Generated masks can be quite jagged which causes a large increase in spurious skeletal branches which do not best represent the image. This can be resolved by first smoothing the incoming mask.</p> <p></p> <p>Smoothing uses either binary dilation (expanding the borders of the mask <code>dilation_iterations</code> times) or an otsu threshold applied to a gaussian filtered mask (with a smoothing factor of <code>gaussian_sigma</code>). If both values are provided an input in the configuration file, they will compete, and the winning result is the one with the smallest number of added pixels.</p> <p>The reason for the competition is an attempt to conserve mask topology i.e. any small holes it has which may become closed upon dilation / gaussian blurring. The dilation method seems to work best for larger masks where there are more mask pixels, and the gaussian smoothing better when there are small holes.</p> <p>In addition, this smoothing step also tries to preserve mask topology by re-adding any holes back into the mask that lie within the <code>holearea_min_max</code> threshold. This has the resulting effect of only smoothing the outer edge of the mask.</p> <p>If required, the function can also take <code>null</code> values for both <code>dilation_iteration</code> and <code>gaussian_sigma</code> values to return the original grain. This is useful for retaining the sample topology when the masking / segmentation is good enough, for example when you use finely-trained deep learning models.</p>"},{"location":"advanced/disordered_tracing/#2-skeletonisation","title":"2. Skeletonisation","text":"<p>Skeletonisation is the process of reducing a binary image to a single-pixel wide representation. This can be done using the algorithms provided by scikit-image such as <code>zhang</code> (rule based + erosion), <code>lee</code> (connectivity preserving), <code>medial_axis</code> (pixels with &gt;1 closest boundary pixels), or <code>topostats</code> - a modification of Zhang's algorithm which uses the underlying height information to order and then remove only a percentage of the pixels marked for removal on each skeletonisation iteration. The skeletonisation methods are handled by the <code>tracing/skeletonize.py</code> module.</p> <p></p> <p>We have found that by including the height information into the skeletonisation process and removing the lowest <code>height_bias</code> percent, we can bias the skeleton to lie on the DNA backbone and generate a better representation of the molecule, especially at crossing points and regions where the mask is less accurate.</p> <p></p>"},{"location":"advanced/disordered_tracing/#3-pruning","title":"3. Pruning","text":"<p>Pruning is the act of removing spurious branches from a skeleton which does not follow the underlying masks' shape. To this end, TopoStats provides a variety of methods and parameters to help clean up the skeletons.</p> <p></p> <p>Pruning can be done by branch length (using the <code>max_length</code> configuration parameter) and / or the branch height (using the <code>height_threshold</code>, <code>method_values</code> and <code>method_outliers</code> configuration parameters).</p> <p>Length pruning is the simplest, iteratively comparing the length (in nm) of each branch containing an endpoint with the <code>max_length</code> parameter. If it's length is below this value, it is deemed as a spurious branch and removed, along with any junction pixels until a single-pixel skeleton remains.</p> <p>Height pruning also iteratively compares the branches pixel values (height) to a <code>height_threshold</code> parameter, again, any branch heights which are below this value are pruned. However, as there are multiple pixels in a branch, we provide different methods to obtain a single branch height value for comparison i.e. <code>method_values</code>:</p> <ul> <li><code>min</code> - the minimum value of all the branch pixel values.</li> <li><code>median</code>- the median value of all the branch pixel values.</li> <li><code>mid</code> - the middle value (averaged if two) of the ordered branch pixels. This is particularly useful for pruning false   bridges where the height dips in the middle of the branch.</li> </ul> <p>Additionally, how these branch height values compare to the <code>height_threshold</code> is also considered i.e <code>method_outliers</code>:</p> <ul> <li><code>abs</code> - prunes branch values below the absolute value of the <code>height_threshold</code>.</li> <li><code>mean_abs</code> - prunes branch values below the whole skeleton mean pixel value - absolute threshold. This is useful for   non-surface samples or periodic structures e.g. in DNA we expect the mean height to be around 2nm, but high resolution   imaging may cause this to dip to 0.8nm (the depth of a major groove), so we'd want to prune branch heights below this.</li> <li><code>iqr</code> - prunes branch values below 1.5x inter-quartile range (IQR) of all the branches. Height pruning cannot produce   more than one skeleton and so avoids breaking up the skeleton into multiple parts.</li> </ul>"},{"location":"advanced/disordered_tracing/#outputs","title":"Outputs","text":"<p>The <code>&lt;image&gt;_&lt;threshold&gt;_disordered_trace</code> image shows the pruned skeletons that are used to obtain the below metrics and passed onto future processing stages.</p> <p>For each grain, the following new columns are added to the <code>grainstats.csv</code> file:</p> Column Name Description Data Type <code>grain_endpoints</code> The number of pixels designated as endpoints (only 1 neighbour) in the pruned skeleton. <code>integer</code> <code>grain_junctions</code> The number of pixels designated as junctions (&gt;2 neighbours) in the pruned skeleton. <code>integer</code> <code>total_branch_length</code> The sum of all branch lengths in the pruned skeleton. <code>float</code> <p> </p> <p></p>"},{"location":"advanced/disordered_tracing/#disordered-segment-statistics","title":"Disordered Segment Statistics","text":"<p>An <code>all_disordered_segment_statistics.csv</code> file is produced for each image which measures the following metrics from each segment in each pruned skeleton:</p> Column Name Description Data Type <code>image</code> The image name being processed. <code>string</code> <code>threshold</code> The direction of the grain threshold being applied. <code>string</code> <code>grain_number</code> The number of the grain being processed in the image. <code>integer</code> <code>index</code> The branch index. <code>integer</code> <code>branch-distance</code> The distance (in nm) of the branch. <code>float</code> <code>branch-type</code> Branch classification of endpoint-to-endpoint (0), endpoint-to-junction (1), junction-to-junction (2), isolated cycle (3). <code>integer</code> <code>connected_segments</code> The index of the branch segments that this current branch is connected to via a junction point. <code>list</code> <code>mean-pixel-value</code> The mean of the branch pixel values (height), in nm. <code>float</code> <code>stdev-pixel-value</code> The standard deviation of the branch pixel values (height), in nm. <code>float</code> <code>min-value</code> The minimum value of the branch pixel values (height), in nm. <code>float</code> <code>median-value</code> The median value of the branch pixel values (height), in nm. <code>float</code> <code>mid-value</code> The value of a pixel halfway along the ordered branch (height), in nm. <code>float</code> <code>basename</code> The directory path containing the image. <code>string</code> <p> </p> <p></p>"},{"location":"advanced/disordered_tracing/#diagnostic-images","title":"Diagnostic Images","text":"<p>Images produced by the <code>plotting.image_set: all</code> for this module are:</p> <ul> <li><code>21-smoothed_grains</code> - The smoothed mask, used to check that the image topology is retained (holes) before   skeletonisation.</li> <li><code>22-original_skeletons</code> - Skeletonised mask, used to ensure the skeletons follow the underlying structures. Used to   check if the skeletonisation parameters are suitable.</li> <li><code>23-branch_indexes</code> - An integer mask of the pruned skeleton with branch pixel values matching the index value in the   data. Used to cross reference the <code>all_disordered_segment_statistics.csv</code> data with an image. Using the default   colourmap for this (viridris), darker (purple) colours are lower indexes, and brighter (yellow) colours are higher.</li> <li><code>24-branch_types</code> - An integer mask of the pruned skeleton with branch pixel values matching the <code>branch-type</code>   (numbers and definitions in the \"At a Glance\" section). This can be used to count and check if the skeletonisation   process correctly identifies the different branch types. Using the default colourmap for this (viridris), darker   (purple) colours are lower indexes, and brighter (yellow) colours are higher.</li> </ul> <p></p>"},{"location":"advanced/disordered_tracing/#possible-uses","title":"Possible Uses","text":"<p>This module would lend itself to measuring branched structures and may aid the identification of particular regions by filtering-out segments based on their branch type.</p> <p>We have used this module to identify and measure the length of reverse forks in stalled DNA replication intermediates as these structures should produce closed loops, however, the reverse forks can be identified as branches with endpoints and their metrics identified from the data. It has also been used as part of the pipeline to obtain ordered traces along topologically complex DNA molecules and topological classifications in our paper; Under or Over? Tracing Complex DNA Topologies with High Resolution Atomic Force Microscopy.</p>"},{"location":"advanced/flattening/","title":"Flattening","text":"<p>Flattening is the process of taking a raw AFM image, and removing the image artefacts that are present due to the scanning probe microscopy (SPM) and AFM imaging. These encompass, but are not limited to; row alignment from the raster scanning motion, and polynomial flattening of a surface from piezoelectric bowing. For surface based samples, such as DNA on Mica, this results in an image where the background mica is flat and the sample is clearly visible resting on the surface.</p> <p>Here is a raw, unprocessed AFM image:</p> <p></p> <p>You can see there is a large tilt in the image from the bottom right to the top left, as well as lots of horizontal banding throughout the rows in the image. These artefacts are removed during the flattening process in TopoStats knows as <code>Filters</code>.</p>"},{"location":"advanced/flattening/#at-a-glance-removing-afm-imaging-artefacts","title":"At a Glance - Removing AFM Imaging Artefacts","text":"<p>Images are processed by:</p> <ul> <li>Row alignment (make each row median the same height)</li> <li>Tilt &amp; polynomial removal (fit a plane and quadratic polynomial to the image and subtract)</li> <li>Scar removal (remove long, thin, bright streaks in the data)</li> <li>Zero the average height (lower the image by the mean height) to make the background roughly centred at zero nm</li> <li>Masking (detect objects on the surface and flatten the image again, ignoring the data on the surface)</li> <li>Secondary flattening (re-process the data using the mask to tell us where the background is, and zero the data using   the mean of the background mask)</li> <li>Gaussian filter (to smooth pixel differences / high-gain noise)</li> </ul> <p></p>"},{"location":"advanced/flattening/#row-alignment","title":"Row alignment","text":"<p>The first step in the flattening process is row alignment. Row alignment is a process that adjusts the height of each row of the image so that they all share the same median height value. This \"median\" value is set by the <code>row_alignment_quartile</code> where the default of 0.5 is the median value, but can be adjusted depending on how much data is considered background. This gets rid of some of the horizontal banding and produces an image where the rows are aligned, but the image still has a clear tilt.</p> <p></p>"},{"location":"advanced/flattening/#tilt-removal","title":"Tilt removal","text":"<p>After row alignment, tilt removal is applied. This is a simple process of fitting and subtracting a plane to the image, resulting in a mostly flat image. However as you can see in the following image, it's not perfect and there still exists \"shadows\" on rows with lots of non-background data. Two images are provided here, one with the full z-range and one with an adjusted height range (z-range) to show the remaining artefacts better, such as the low regions or \"shadows\" on rows with lots of non-background data.</p> <p></p> <p></p>"},{"location":"advanced/flattening/#polynomial-removal","title":"Polynomial removal","text":"<p>After the tilt, we remove the polynomial trends. In some images, there is also quadratic or occasionally cubic bowing to the image too. We remove this by fitting a two dimensional quadratic polynomial to the image (in the horizontal direction), and subtracting it from the image. We then do the same for a nonlinear polynomial (z = axy) to eliminate \u201csaddle\u201d trends in the data. We could do all of these at the same time, but we like to be able to see the iterative differences.</p>"},{"location":"advanced/flattening/#scar-removal-optional","title":"Scar removal (optional)","text":"<p>We then optionally run scar removal on the image. This is a special function that detects scars - long, thin, bright / dark streaks in the data, caused by physical problems in the AFM process. They are found by the parameters; <code>threshold_low</code> and <code>threshold_high</code> identifying great height changes between rows, and filtered for scars via <code>max_scar_width</code> and <code>min_scar_length</code> in pixel lengths. We are using a different image here as an example since our lovely minicircles.spm image doesn\u2019t have any scars.</p> <p></p> <p></p> <p>Note that scar removal can distort data, and it\u2019s best to take data without scars if you can.</p>"},{"location":"advanced/flattening/#zero-the-average-height","title":"Zero the average height","text":"<p>We then lower the image by its mean height which causes the background of the image to be roughly centred at zero nm. If this function is provided a foreground mask such as in the second iteration of flattening, this function zeros the data only on the background data. Data zeroing is important since the raw AFM heights are relative, and these processing steps can shift the background height away from zero, so this makes it easier to obtain comparative height metrics.</p>"},{"location":"advanced/flattening/#masking","title":"Masking","text":"<p>Now consider that all the processing we have done has assumed that every pixel of the image is background. We assumed that there were no objects on the surface, messing up our fitting, and row alignment. If there was a large amount of DNA on one side of the image, then the slope will be affected by it, and so flatten the image poorly.</p> <p>Because of this, once we have done our initial flattening, we detect our objects on the surface, and then flatten the image again! But this time, ignoring the data on the surface, and only considering the background.</p> <p>How do we do that? Well first, we need to find the data on the surface. We do this by thresholding. The type of threshold (standard deviation - <code>std_dev</code>, absolute - <code>absolute</code>, otsu - <code>otsu</code>), and the threshold values are set by the config file (have a look!). Any pixels that are below the threshold, are considered background (sample surface). Any pixels that are above the threshold are considered to be data (useful sample objects). This binary classification allows us to make a binary mask of where is foreground data, and where is background.</p> <p>For more information on thresholding and how to set it, see the thresholding page.</p> <p>Here is the binary mask for minicircle.spm:</p> <p></p> <p>So you can see how all the interesting foreground (high) regions are now masked in white, and the background is in black.</p> <p>This allows TopoStats to use only the background (black pixels) in its calculations for slope removal, row alignment etc.</p> <p>So we re-do all the previous processing, but with this new useful binary mask to guide us.</p>"},{"location":"advanced/flattening/#secondary-flattening","title":"Secondary flattening","text":"<p>After re-processing the data using the mask to tell us where the background is, we get a better, more accurately flattened image. We can see the \"shadows\" on rows with lots of data have now been flattened correctly.</p> <p>From here, we can go on to do things like finding our objects of interest (grains) and get stats about them.</p> <p></p>"},{"location":"advanced/flattening/#gaussian-filter","title":"Gaussian filter","text":"<p>Finally, we apply a Gaussian filter to the image to smooth height differences and remove high-gain noise. This allows you to get smoother data but will start to blur out important features if you apply it too strongly. The default strength is a sigma of 1.0, but you can adjust this in the config file under <code>gaussian_size</code>. The <code>gaussian_mode</code> parameter suggests how values at the border should be handled, see skimage.filters.gaussian for more details.</p> <p>Here are some examples of different gaussian sizes:</p> <p></p>"},{"location":"advanced/grain_finding/","title":"Grain finding","text":""},{"location":"advanced/grain_finding/#at-a-glance-identifying-objects-of-interest","title":"At a Glance - Identifying Objects of Interest","text":"<p>TopoStats automatically tries to find grains (objects of interest) in your AFM images. There are several steps to this.</p> <ul> <li>Height thresholding: We find grains based on their height in the image.</li> <li>Remove edge grains: We remove grains that intersect the image border.</li> <li>Size thresholding: We remove grains that are too small or too large.</li> <li>Optional: U-Net mask improvement: We can use a U-Net to improve the mask of each grain.</li> </ul>"},{"location":"advanced/grain_finding/#height-thresholding","title":"Height thresholding","text":"<p>Grain finding is the process of detecting useful objects in your AFM images. This might be DNA, proteins, holes in a surface or ridges on a surface. In the standard operation of TopoStats, the way we find objects is based on a height threshold. This means that we detect where things are based on how high up they are.</p> <p>For example, with our example minicircles.spm image, we have DNA that is poking up from the sample surface, represented by bright regions in the image, alongside impurities and proteins, also above the surface:</p> <p></p> <p>If we want to select the DNA, then we can take only the regions of the image that are above a certain height threshold (standard deviation - <code>std_dev</code>, absolute - <code>absolute</code>, otsu - <code>otsu</code>).</p> <p>Here are several thresholds to show you what happens as we increase the absolute height threshold:</p> <p></p> <p>Notice that the amount of data decreases, until we are only left with the very highest points.</p> <p>The aim is to choose a threshold that keeps the data you want, while removing the background and other low objects that you don\u2019t want including. So in this example, a threshold of 0.5 would be best, since it keeps the DNA while removing the background.</p> <p>There are lots of objects in this mask that we don't want to analyse, but we can remove those using area thresholds in the next steps. These objects have been detectd because while they are small, they are still high up and above the background.</p> <p>For more information on the types of thresholding, and how to set them, see the thresholding page.</p>"},{"location":"advanced/grain_finding/#remove-edge-grains","title":"Remove edge grains","text":"<p>Some grains may intersect the image border. In these cases, the grain will not be able to have accuracte statistics calculated for it, since it is not fully in the image. Because of this, we have the option of removing grains that intersect the image border with the <code>remove_edge_intersecting_grains</code> flag in the config file. This simply removes any grains that intersect the image border.</p> <p>Here is a before and after example of removing edge grains:</p> <p></p>"},{"location":"advanced/grain_finding/#size-thresholding","title":"Size thresholding","text":"<p>In our thresholded image, you will notice that we have a lot of small grains that we do not want to analyse in our image. We can get rid of those with size thresholding. This is where TopoStats will remove grains based on their area, leaving only the right size of molecules. You will need to play around with the thresholds to get the right results.</p> <p>You can set the size threshold using the <code>absolute_area_threshold</code> in the config file. This sets the minimum and maximum area of the grains that you want to keep, in nanometers squared. Eg if you want to keep grains that are between 10nm^2 and 100nm^2, you would set <code>absolute_area_threshold</code> to <code>[10, 100]</code>.</p> <p></p>"},{"location":"advanced/grain_finding/#optional-u-net-mask-improvement","title":"Optional: U-Net mask improvement","text":"<p>As an additional optional step, each grain that reaches this stage can be improved by using a U-Net to mask the grain again. This requires a U-Net model path to be supplied in the config file.</p> <p>The U-Net model will take the bounding box of each grain, makes it square, and passees it to a trained U-Net model which makes a prediction for a better mask, which then replaces the original mask.</p> <p>Here is an example comparing absolute height thresholding to U-Net masking for one of our projects. The white boxes indicate regions where the height threhsold performs poorly and is improved by the U-Net mask.</p> <p></p>"},{"location":"advanced/grain_finding/#multi-class-masking","title":"Multi-class masking","text":"<p>TopoStats supports masking with multiple classes. This means that you could use a U-Net to mask DNA and proteins separately.</p> <p>This requires a U-Net that has been trained on multiple classes.</p> <p>Here is an example of multi-class masking using a U-Net which was used for one of our projects.</p> <p></p>"},{"location":"advanced/grain_finding/#technical-details","title":"Technical details","text":""},{"location":"advanced/grain_finding/#details-multi-class-masking","title":"Details: Multi-class masking","text":"<p>Multi class masking is implemented by having each image be a tensor of shape N x N x C, where N is the image size, and C is the number of classes. Each class is a binary mask, where 1 is the class, and 0 is not the class. The first channel is background, where 1 is background, and 0 is not background. The rest of the channels are arbitrary, and defined by how the U-Net was trained, however we conventially recommend that the first class be for DNA (if applicable) and the next classes for other objects.</p>"},{"location":"advanced/grainstats/","title":"Grainstats","text":""},{"location":"advanced/grainstats/#at-a-glance-measures-objects","title":"At a Glance - Measures Objects","text":"<p>TopoStats automatically tries to measure the grains (objects of interest) found in the grain finding section, in your AFM images, and outputs them into the <code>all_statistics.csv</code> file.</p> <p>The metrics are briefly summarised in the table below:</p> Column Name Description Data Type <code>center_x/y</code> The center of the grain. <code>float</code> <code>radius_min/max/mean/median</code> The distance from the center to each pixel on the perimeter. <code>float</code> <code>height_min/max/mean/median</code> The pixel values underlying the grain mask. <code>float</code> <code>area</code> The area of the pixel-wise grain mask. <code>float</code> <code>volume</code> Volume of the pixel-wise grain mask. <code>float</code> <code>area_cartesian_bbox</code> The area of a box bounding the grain along cardinal directions. <code>float</code> <code>smallest_bounding_width/length</code> The shortest bounding box length and perpendicular width of the grain in non-cardinal directions. <code>float</code> <code>smallest_bounding_area</code> The area of the smallest possible box bounding the grain. <code>float</code> <code>aspect_ratio</code> Ratio of the smallest bounding width to smallest bounding length. <code>float</code> <code>max/min_feret</code> The largest and shortest distance of the calipers rotating the grain between calipers. See feret diameter. <code>float</code> <p> </p> <p></p>"},{"location":"advanced/nodestats/","title":"NodeStats","text":"<p>This section gives an in-depth overview of the steps taken in the NodeStats module.</p>"},{"location":"advanced/nodestats/#at-a-glance-crossing-analyses","title":"At a Glance : Crossing Analyses","text":"<p>The <code>nodestats.py</code> module handles all the functions associated with identifying and analysing the crossing regions (nodes) and crossing branches in pruned skeletons.</p> <p>The quality of the resultant metrics and over/underlying branch classifications depend on the quality of the pruned skeleton, the effectiveness of automating the joining of skeleton junction points through the parameters.</p> <p></p> <p>This module identifies crossing regions from nearby skeleton junctions and analyses each branch emanating out from the crossing to pair them, then determines the overlying and underlying strand using the full-width half-maximum from each height trace passing through the crossing. It adds the number of identified crossings and the minimum and average pseudo confidence values to the <code>all_statistics.csv</code>.</p> <p>Some quick FYI's:</p> <ul> <li>Bad skeletons, bad classifications - If the skeleton does not lie along the backbone of the structure, it's   resulting height trace and thus stacking order calculation may not be accurate.</li> <li>No skeletons in image - The NodeStats <code>all</code> images may not show the resultant skeletons if the plotting <code>dpi</code>   value is too low (varies based on image size) as these single pixel lines cannot be resolved by matplotlib.</li> <li>Incorrect pairing - Pairing of the branches emanating from a crossing is based on the assumption that the regions   being compared (<code>branch_pairing_length</code>) are below half the persistence length of the material, and as such they   should follow straight lines through the crossing region.</li> <li>Masked colours are relative - Any mask colours that may be produced by plots are relative to the mask values in   that image as they will always span the masked colourmap, and will not compare well across images if the range of mask   values differ.</li> <li>Odd numbered crossings - These can result from poor masking / pruning and are handled by looking further around   odd nodes to join them (<code>node_extend_dist</code>), and if they are still odd, the default behaviour results from the   <code>pair_odd_branches</code> parameter to pair as many as possible leaving one remaining, or to not pair any of them.</li> </ul>"},{"location":"advanced/nodestats/#processing-steps","title":"Processing Steps","text":""},{"location":"advanced/nodestats/#1-identify-skeleton-junctions","title":"1. Identify Skeleton Junctions","text":"<p>The pruned skeletons undergo a 2D convolution with a 3x3 kernel of 1's, and the skeleton is the remapped onto the resultant image. This produces a non-binary skeleton where the value of each skeleton pixel is the count of it's neighbours + 1. This is used to produce a new skeleton image in with pixels labelled as:</p> <ul> <li>1 - Endpoints</li> <li>2 - Skeleton segments</li> <li>3 - Junctions</li> </ul> <p></p> <p>This produces a skeleton mask (blue) where the junctions (green) and endpoints (pink) can be seen.</p>"},{"location":"advanced/nodestats/#2-clean-up-the-crossing-regions","title":"2. Clean-up the Crossing Regions","text":"<p>The alignment of the skeleton onto the crossing backbone is key to obtaining good analyses from this module, especially for accurate topological classifications and calculation of writhe signs. For this reason, a small area around the junctions points are re-filled with the mask and skeletonised again using the height biasing skeletonisation approach.</p> <p></p> <p>This has been useful to align the skeletons at branch crossing points however, the modification to the skeleton has also been known to cause problems as no additional pruning steps are done.</p>"},{"location":"advanced/nodestats/#3-connect-the-junctions","title":"3. Connect the Junctions","text":"<p>Skeleton segments which represent a crossing may not join up perfectly at a single pixel (junction) and as a result of the skeletonisation procedure, may be offset from one another and need to be combined to represent the crossing region or \"node\". Therefore, junctions closer than the <code>node_joining_length</code> of each other define a crossing region, and the pixels which span between the junctions along the skeleton are also labelled as part of the crossing.</p> <p></p> <p>Depending on the sample type or skeletonisation / pruning errors, there might exist an odd number of emanating branches after this initial pairing. In DNA samples, we typically see this where just before a crossing region, the two strands lie close to each other, creating an elongated crossing region in the skeletonisation representation. In order to capture these for analysis, the <code>node_extend_dist</code> tells only odd-branch crossing regions to look for and extend to other odd-branch crossing regions within this distance, using the shortest path possible along the skeleton. Coming after the initial connection, this means that closer crossing regions can be joined, and that 3-branch nodes can be joined through a 4-branch node to another 3-branch node.</p>"},{"location":"advanced/nodestats/#4-pair-the-branches","title":"4. Pair the Branches","text":"<p>For each of these crossing regions, the skeletons are reduced to solely a single crossing and their emanating branches. The part we are interested in, and obtain traces for are branch regions defined as extending upto the <code>branch_pairing_length</code> away from the central crossing region. This length should be below half the persistence length of the material, so that the branches should follow (roughly) straight lines through the crossing region.</p> <p></p> <p>This enables us to pair emanating branches based on the angles between their vectors using bipartite matching to obtain the best pairing combinations to use for subsequent steps.</p>"},{"location":"advanced/nodestats/#5-height-traces","title":"5. Height Traces","text":"<p>For each paired branch in the crossing region, we can use a series of dilations to obtain two more accompanying branches to average our traces across a few pixels and reduce the error in the skeleton position along the backbone at the crossing. Using the underlying height values, and calculating the distance radially (not along the path) from the highest point in the crossing (the node centre), a height trace of the topographic crossing can be used to find the full-width half-maximum (FWHM) value of the crossing peak and determine which crossing branch lies atop (largest value) or beneath (smallest value) the other.</p> <p></p> <p>From the FWHM of the height traces, a pseudo confidence value is obtained using the equation below. It calculates the ratio of the minimum to maximum value across all FWHM pairs of all crossing branches, N, (using combinatorics to pair crossing branches if &gt;2):</p> \\[ \\text{crossing confidence} = \\frac{1}{N} \\sum_{\\text{FWHM\\_pairs}} \\left(1 - \\frac{\\min(\\text{FWHM\\_pairs})}{\\max(\\text{FWHM\\_pairs})}\\right) \\]"},{"location":"advanced/nodestats/#outputs","title":"Outputs","text":"<p>The <code>&lt;image&gt;_&lt;threshold&gt;_nodes</code> image shows the crossing regions highlighted in green, skeleton segments in blue, and endpoints in pink.</p> <p>For each grain, the following new columns are added to the <code>grainstats.csv</code> file:</p> Column Name Description Data Type <code>num_crossings</code> The number of crossing regions found in the grain. Note: this will be equal to or lower than the number of junctions explained in the previous section. <code>integer</code> <code>avg_crossing_confidence</code> The average of all pseudo crossing confidences. Used to estimate quality of predictions. <code>integer</code> <code>min_crossing_confidence</code> The minimum of all pseudo crossing confidences. Used to estimate quality of predictions. <code>float</code> <p> </p> <p></p> <p>Note: Most information obtained during the NodeStats processing can be obtained from the <code>&lt;image_name&gt;.topostats</code> file found within the <code>processed</code> folder and contains a multitude of grain and branch statistics such as:</p> <ul> <li>number of nodes per grain</li> <li>node confidences</li> <li>node coordinates</li> <li>number of branches per node</li> <li>branch distance array</li> <li>branch height array</li> <li>branch FWHM dictionary containing the FWHM, half max, and peak values</li> <li>matched and unmatched branch angles</li> </ul> <p> Note: The writhe sign is identified in <code>ordered_traces.py</code>, not <code>nodestats</code> as the path needs directionality provided by the ordering. It is added to the NodeStats dictionary as this carries the node statistics.</p>"},{"location":"advanced/nodestats/#diagnostic-images","title":"Diagnostic Images","text":"<p>Images produced by the <code>plotting.image_set: all</code> for this module are:</p> <ul> <li><code>25-convolved_skeleton</code> - The result of the convolution operation described in 1. The default \"blue_green_pink\"   colourmap for this image represent skeleton segments, junctions, and endpoints respectively.</li> <li><code>26-node_centres</code> - The highest pixel in each crossing region (green) with the same colourmap as above. This is where   the '0' distance point corresponds to in the height traces.</li> <li><code>nodes</code> folder:</li> <li><code>grain_&lt;X&gt;_node_&lt;Y&gt;_node_area_skeleton&gt;</code> - Contains the reduced area of grain number X and node number Y which     consists of the node in question and only it's emanating branches.</li> <li><code>grain_&lt;X&gt;_node_&lt;Y&gt;_node_branch_mask&gt;</code> - Visualises the crossing branches where the length depends on     <code>branch_pairing_length</code>.</li> <li><code>grain_&lt;X&gt;_node_&lt;Y&gt;_node_avg_mask&gt;</code> - Visualises the dilated crossing branches used to obtain an average height     trace along the crossing branches.</li> <li><code>grain_&lt;X&gt;_node_&lt;Y&gt;_linetrace_halfmax&gt;</code> - Shows the height trace of each crossing branch, and was used to determine     the FWHM. The vertical lines show the location of where the half-maximum was taken from.</li> </ul> <p></p>"},{"location":"advanced/nodestats/#possible-uses","title":"Possible Uses","text":"<p>This module would lend itself useful for measuring and quantifying complex overlapping structures, and is a requirement for the <code>nodestats</code> method in <code>ordered_tracing</code> which orders the trace along a complex topology.</p> <p>We have used this module to broadly quantify conformational differences between relaxed and supercoiled DNA samples based on the number of crossing regions seen in samples of each grain. Additionally the FWHM results have been used to confirm the classification topologically complex molecules via the highest confidence. The branch statistics have been used to identify and quantify different conformations of topologically complex DNA and the effect of surface deposition. Finally, splitting the odd-branched nodes enabled us to identify and measure the replicated and unreplicated DNA segments in replication intermediates despite their complex writhed path. These analyses can be seen in our paper; Under or Over? Tracing Complex DNA Topologies with High Resolution Atomic Force Microscopy.</p>"},{"location":"advanced/ordered_tracing/","title":"Ordered Tracing","text":"<p>This section gives an in-depth overview of the steps taken in the ordered tracing module.</p>"},{"location":"advanced/ordered_tracing/#at-a-glance-traversing-a-path","title":"At a Glance : Traversing a Path","text":"<p>The <code>ordered_tracing.py</code> module handles all the functions associated with ordering the pixels one-after-another from the disordered trace (pruned skeleton).</p> <p>The quality of the resultant metrics and ordered coordinates will depend on the ordering method chosen, whether the skeleton matches the conformation, and if selected, the performance (pairing) of the branch crossing points in NodeStats.</p> <p></p> <p>This module orders the disordered trace pixel-by-pixel (<code>topostats</code> method) or segment-by-segment (<code>nodestats</code> method), giving direction to the trace and creating a path to follow. It adds the number of identified molecules (found by restarting the trace when using the <code>nodestats</code> method) and whether the trace contains endpoints and is therefore circular or not to the <code>all_statistics.csv</code>.</p> <p>Some quick FYI's:</p> <ul> <li>Multiple molecules - By design the <code>topostats</code> ordering method will only produce a single ordered trace per grain,   however, the <code>nodestats</code> method may identify multiple (useful for separating overlapping structures etc).</li> <li>No skeletons in image - The Ordered Traces <code>all</code> image set may not show the resultant skeletons if the plotting   <code>dpi</code> value is too low (varies based on image size) as these single pixel lines cannot be resolved by matplotlib.</li> <li>Circular field not circular - The grain stats (and molecule stats) field labelled \"circular\" does not check if the   path starts and ends at the same place. Instead, it is a True/False indicator of the presence of any endpoints.</li> <li>Failed NodeStats ordering - If the \"nodestats\" method is selected in the configurations file and an error occurs   in the NodeStats module for a particular grain, and that grain isn't added to the noodestats dictionary, it will   default to \"topostats\" ordering.</li> <li>Overlapping traces - Because the crossing region is shared by both crossing strands, the pixels in the mask may   show a discontinuity in one \"leg\" of the crossing in the ordered trace image, this is purely visual and does not   affect the underlying data.</li> </ul>"},{"location":"advanced/ordered_tracing/#processing-steps","title":"Processing Steps","text":""},{"location":"advanced/ordered_tracing/#nodestats-method","title":"NodeStats Method","text":""},{"location":"advanced/ordered_tracing/#1-compile-segments","title":"1. Compile Segments","text":"<p>The first stage is to use the branch coordinates and disordered trace skeleton to compile a labelled image and associated set of coordinates and their stacking orders. To do this, the crossing branch coordinates are removed from the disordered trace and all remaining segments labelled 1 to N. Then, branch-by-branch the crossing coordinates are replaced with following labels, resulting in an image where each skeleton and crossing segment are labelled.</p> <p></p>"},{"location":"advanced/ordered_tracing/#2-the-nodestats-tracing-loop","title":"2. The NodeStats Tracing Loop","text":"<p>The trace aims to use the labelled segments described above to link to the full set of coordinates and build, segment-by-segment, an ordered path.</p> <p>It starts by looking for any endpoints, and uses the index of the endpoint segment to start the trace, if there are no endpoints, the starting index will all ways be the first labelled index (1 in the image, 0 in the coordinate list) - this also has the advantage of starting from a non-crossing segment. The coordinates are added to the ordered trace and the currently indexed segment is then removed from the guide image containing all the segments. Then, the maximum value found in a 3x3 area around the final coordinate in the ordered trace is used to identify the following trace segment. This repeats until a segment terminates and the only values in that 3x3 area are 0's (background).</p> <p></p> <p>If there are no more remaining segments, the trace is finished. However, if any segments remain, a new ordered trace is started, again from an endpoint segment if possible, hence why this method is able to untangle two interlinked molecules such as DNA catenanes.</p> <p> *Skeletons dilated for visual aid</p>"},{"location":"advanced/ordered_tracing/#22-a-simple-trace","title":"2.2. A Simple Trace","text":"<p>While the above is happening, ordered trace segment coordinates are also being added to a simplified ordered trace to be used with the Topolypackage to determine it's topological species. A pseudo Z (height) is used to distinguish between skeleton segments (Z=0) and crossing segments (Z=-1, 1, 2...). However, these traces (N, X, Y, Z) can be too long and cause Topoly to hang, so they are reduced to ~100 coordinates. Each reduced points of each segments ensure the points capture the start and end of each segment.</p> <p></p> <p>Topoly then uses this NXYZ coordinate trace to produce a topological classification using Homfly polynomials. In addition, another trace is built up which flips the stacking order of the lowest confidence crossing to generate a secondary topology.</p> <ul> <li>Future work may aim to ensure these reduced segments don't accidentally cross.</li> </ul>"},{"location":"advanced/ordered_tracing/#23-writhe-sign","title":"2.3. Writhe Sign","text":"<p>The ordered trace and crossing branch coordinates are also used to calculate the writhe of each crossing via the cross product of the branches normalised vectors, with their direction following the path of the trace. The writhe sign is calculated as \"+\" or \"-\". If a crossing contains &gt; 2 crossing branches, the single crossing region is split into pairs and the writhe calculated in brackets i.e. \"+(-++)\"</p> <p></p> <p>For overlapping molecules, the writhe signs are still calculated but this is greatly dependent on the directionality of each molecule. In the case of DNA catenanes, a positive or negative writhe would depend on the relative direction of each trace. In these cases, the writhe string should only be used to observe relative writhe signs i.e. \"++-+\" equals \"--+-\", as directionality cannot be observed in AFM images.</p> <ul> <li>Future work may be to separate self and intra-molecule writhes.</li> </ul>"},{"location":"advanced/ordered_tracing/#topostats-method","title":"TopoStats Method","text":""},{"location":"advanced/ordered_tracing/#1-classifying-circularity","title":"1. Classifying Circularity","text":"<p>The TopoStats tracing algorithms slightly differ depending on whether the trace is circular or not. The disordered trace is defined as circular by counting the number of neighbours of each pixel in the skeleton. If a skeleton contains at least one skeleton with only one neighbour it is defined as non-circular.</p> <p></p>"},{"location":"advanced/ordered_tracing/#2-circular-and-linear-topostats-tracing","title":"2. Circular and Linear TopoStats Tracing","text":"<p>If the disordered trace is not deemed circular, the trace starts by first finding and selecting an endpoint (pixel with one neighbour).</p> <p>If the disordered trace is deemed circular, the trace starts by first finding and selecting a point with two neighbours. Then, the selected coordinate is added to the ordered path, and deleted from the skeleton. One of the neighbouring points are randomly selected.</p> <p>The selected point is then added to the path and deleted from the skeleton enabling the path to then follow the sole remaining pixel to traverse the path. However, above assumes there is always only one pixel to follow around the path, but if there are more, the trace will look up to 4 pixels earlier in the ordered trace, and try to identify the next pixel which has the lowest angular change.</p> <p></p>"},{"location":"advanced/ordered_tracing/#outputs","title":"Outputs","text":"<p>The <code>&lt;image&gt;_&lt;threshold&gt;_ordered_traces</code> image shows the direction of ordered coordinates.</p> <p>For each grain, the following new columns are added to the <code>grainstats.csv</code> file:</p> Column Name Description Data Type <code>num_molecules</code> The number of molecules found by following the tracing paths. Note: This will always be 1 for the TopoStats method. <code>integer</code> <code>circular</code> Whether the disordered trace contains an endpoint. <code>bool</code> <code>writhe_string</code> The writhe sign (+/-) which describes the crossing directionality. If a crossing contains &gt; 2 crossing branches, the single crossing region is split into pairs and the writhe calculated in brackets i.e. \"+(-++)\". <code>str</code> <p> </p> <p></p> <p>For each molecule found by the ordering algorithm(s), the following new columns are added to the <code>molstats.csv</code> file:</p> Column Name Description Data Type <code>circular</code> The number of molecules found by following the tracing paths. Note: This will always be 1 for the TopoStats method. <code>integer</code> <code>topology</code> Whether the disordered trace contains an endpoint. <code>bool</code> <code>topology_flip</code> The number of molecules found by following the tracing paths. Note: This will always be 1 for the TopoStats method. <code>integer</code> <code>processing</code> The method used for ordering. <code>str</code> <p> </p> <p></p> <p>Note: Most information obtained during the Ordered Tracing processing can be obtained from the <code>&lt;image_name&gt;.topostats</code> file found within the <code>processed</code> folder and contains a multitude of molecule related objects such as:</p> <ul> <li>bounding box</li> <li>cumulative distance along the trace</li> <li>height along the trace</li> <li>the ordered coordinates</li> <li>molecule statistics explained above</li> <li>The writhe sign for each crossing is added to the NodeStats dictionary.</li> </ul> <p></p>"},{"location":"advanced/ordered_tracing/#diagnostic-images","title":"Diagnostic Images","text":"<p>Images produced by the <code>plotting.image_set: all</code> for this module are:</p> <ul> <li><code>27-trace_segments</code> - The labelled skeleton and crossing segments that the NodeStats trace is built from.</li> <li><code>28-all_molecule_crossings</code> - The skeleton, underlying and overlying crossing segments in blue, pink and green   respectively. The colourmap used is three-tone meaning that middle crossing branches when there are more than two   branches will appear blue too.</li> <li><code>29-all_molecules</code> - A labelled image of all the identified molecules in the grain found by the ordering method. In   the default colourmap, only three traces will show - blue, green, and pink.</li> </ul> <p></p>"},{"location":"advanced/ordered_tracing/#possible-uses","title":"Possible Uses","text":"<p>This module would lend itself useful for separating overlapping or intertwined structures, and is a requirement for the <code>splining</code> module which smooths the ordered traces to obtain contour lengths of individual molecules.</p> <p>Additionally, you could use this module and the writhe string obtained to assess the supercoiling degree (via writhe only, not twist) in DNA samples as well as a preliminary step to obtaining the lengths of the individual molecules.</p>"},{"location":"advanced/splining/","title":"Splining","text":"<p>This section gives an in-depth overview of the steps taken in the splining module.</p>"},{"location":"advanced/splining/#at-a-glance-smoothing-pixelated-traces","title":"At a Glance : Smoothing Pixelated Traces","text":"<p>The <code>splining.py</code> module handles all the functions associated with smoothing the ordered pixel-wise trace from the \"ordered_tracing\" step, in order to produce curves which more closely follow the samples structure.</p> <p>The quality of the resultant metrics and smoothed coordinates will depend on the splining method chosen, whether the ordering worked successfully, and whether the skeleton matches the underlying sample conformation.</p> <p></p> <p>This smooths the ordered trace by using an average of splines through the ordered coordinates (<code>spline</code> method) or using the mean coordinate of a rolling window (<code>rolling_window</code> method), helping to resolve length errors in jagged in the skeletons. It adds the contour length and end-to-end euclidean distance to the <code>all_mol_statistics.csv</code> and the sum and average of these respectively to the <code>all_statistics.csv</code>.</p> <p>Some quick FYI's:</p> <ul> <li>Constricted Traces - Using the <code>rolling_window</code> method with a rolling window size that is not far below the   persistence length can result in over-smoothing where the spline is dragged away from regions of high curvature.</li> <li>Unrepresentative Splines - The <code>spline</code> method's parameters can be quite temperamental so it's recommended that   <code>spline_linear_smoothing</code>, <code>spline_circular_smoothing</code> and <code>spline_degree</code> are not changed unless understood.</li> <li>Unrepresentative Splines 2 - The <code>spline</code> method may produce unwanted results if the <code>spline_step_size</code> is too   long. This is because the way the splines are averaged assumes that each spline point is sampled close to that of   another's.</li> </ul>"},{"location":"advanced/splining/#processing-steps","title":"Processing Steps","text":""},{"location":"advanced/splining/#splining-method","title":"Splining Method","text":""},{"location":"advanced/splining/#1-trace-coordinate-subsets","title":"1. Trace Coordinate Subsets","text":"<p>The first stage is to use the ordered coordinates and the <code>spline_step_size</code> parameter to define how many splines we want to average together. As the <code>spline_step_size</code> is the distance (in nm) at which to take every i'th coordinate for its spline. This means the number of splines to average is calculated below:</p> \\[ N = max(\\text{spline step size} \\div \\text{px to nm}, 1) \\] <p>The coordinates used for each spline are then obtained from the initial ordered trace, i.e. the spline coordinate indexes: [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4], where spline 1 takes every 4th coordinate, starting at position 0, then spline 2 takes every 4th coordinate starting at position 1, etc.</p> <p></p>"},{"location":"advanced/splining/#2-obtaining-splines","title":"2. Obtaining Splines","text":"<p>For each of these coordinate subsets, we use the Sci-Py library to find the B-Spline representation of the 2D curve using the smoothness parameters <code>spline_linear_smoothing</code>, <code>spline_circular_smoothing</code>, and the <code>spline_degree</code>, found in the configuration file. The <code>spline_linear_smoothing</code> and <code>spline_circular_smoothing</code> define the degrees of smoothing for circular or linear molecules obtained in the Ordered Tracing step, which also tells TopoStats whether to make the spline periodic if circular. Larger smoothing values mean more smoothing and smaller values indicate less smoothing. The <code>spline_degree</code> should take odd values, or even with large smoothing. Read more on the Sci-Py documentation above.</p> <p></p> <p>These splines are then averaged together via their index i.e. first spline coordinates are averaged, then second etc... until a single averaged B-Spline remain. However, because the splined are averaged on their index, it is assumed that each index is within close proximity, thus, the <code>spline_step_size</code> must be small enough for this assumption to hold true and for the splining to work as intended.</p>"},{"location":"advanced/splining/#rolling-window-method","title":"Rolling Window Method","text":""},{"location":"advanced/splining/#1-rolling-average","title":"1. Rolling Average","text":"<p>This method simply uses a rolling average of the ordered trace coordinates within the <code>rolling_window_size</code> to produce the new smoothed trace. The rolling window will move one coordinate along each time, and continues until the start of the window returns back to its initial position.</p> <p></p> <p>For linear smooth traces, the same as above occurs however, the initial and final coordinates are also added to the smoothed trace as to not drastically reduce the length of the smoothed trace.</p> <p></p>"},{"location":"advanced/splining/#outputs","title":"Outputs","text":"<p>The <code>&lt;image&gt;_&lt;threshold&gt;_ordered_traces</code> image shows the direction of ordered coordinates.</p> <p>For each grain, the following new columns are added to the <code>grainstats.csv</code> file:</p> Column Name Description Data Type <code>total_contour_length</code> The total length along the splined trace of all identified molecules. <code>float</code> <code>average_end_to_end_distance</code> The average distance from two endpoints of the spline of all identified linear molecules. <code>float</code> <p> </p> <p></p> <p>For each molecule found by the ordering algorithm(s), the following new columns are added to the <code>molstats.csv</code> file:</p> Column Name Description Data Type <code>contour_length</code> The length along the splined trace of the molecule. <code>float</code> <code>end_to_end_distance</code> The distance from two endpoints of the spline of the linear molecule. <code>float</code> <p> </p> <p></p> <p>Note: Most information obtained during the Splining processing can be obtained from the <code>&lt;image_name&gt;.topostats</code> file found within the <code>processed</code> folder and contains a multitude of molecule related objects such as:</p> <ul> <li>bounding box</li> <li>spline coordinates</li> <li>tracing statistics of contour length and end to end distance</li> </ul> <p></p>"},{"location":"advanced/splining/#diagnostic-images","title":"Diagnostic Images","text":"<p>There are no diagnostic images produced in this step.</p>"},{"location":"advanced/splining/#possible-uses","title":"Possible Uses","text":"<p>This module would lend itself useful for accurately measuring the lengths of complex objects within samples, and obtaining an accurate representation of the underlying conformation of the sample.</p> <p>We have used this module to accurately measure the length of topologically complex DNA samples such as knots, catenanes, and theata-curves (replication intermediates). Additionally, we've used the end-to-end distance to measure the conformational variation of linear DNA in the presence of NDP-52 to show that it may also play a role in topological regulation. See more here..</p>"},{"location":"advanced/thresholding/","title":"Thresholding","text":"<p>When flattening images and finding grains, TopoStats uses thresholding to separate the background data from the foreground data. This is done by setting a threshold value, and classifying all pixels above this value as foreground, and all pixels below this value as background.</p> <p>There are several different types of thresholding that can be used, and each has its own advantages and disadvantages.</p> <p>Below is a histogram showing the heights of the pixels in minicircle.spm after flattening. You can see that most of the pixels are at a height of 0nm, which is the background. There is a second peak at 2.5nm which is around the height that we expect DNA to be. The rest of the pixels are noise.</p> <p>A threshold will select all pixels above a certain height, and ignore the rest, ie the pixels in the orange area.</p> <p></p>"},{"location":"advanced/thresholding/#note-thresholding-above-and-below-the-surface","title":"Note: Thresholding above and below the surface","text":"<p>TopoStats has the ability to threshold both above the sample surface and below it. This allows finding grains on the surface but also holes in the surface (useful for silicon wafer analysis). This can be configured by setting the corresponding \"above\" or \"below\" thresholds in the config file. Eg if you only want to find grains above the surface, only use the \"above\" threshold options, and vice-versa.</p>"},{"location":"advanced/thresholding/#thresholding-types","title":"Thresholding types","text":""},{"location":"advanced/thresholding/#standard-deviation-thresholding","title":"Standard deviation thresholding","text":"<p>Standard deviation thresholding is a simple method of thresholding that uses the standard deviation of the image to determine the threshold value. The threshold value is calculated as:</p> \\[ \\text{threshold} = \\text{mean} + \\text{std\\_dev} \\times \\text{factor} \\] <p>Where <code>mean</code> is the mean of the image, <code>std_dev</code> is the standard deviation of the image, and <code>factor</code> is a user-defined value that determines how many standard deviations above the mean the threshold should be.</p> <p>This method is useful when you don't know the exact threshold value you want to use, and when you have a bit of noise in your image.</p>"},{"location":"advanced/thresholding/#otsu-thresholding","title":"Otsu thresholding","text":"<p>Otsu thresholding is an automatic thresholding method that tries to find the threshold value that minimizes the intra-class variance of the foreground and background pixels.</p> <p>We have added a multiplier to the Otsu thresholding method to allow for a more flexible thresholding method. The threshold value is calculated as:</p> \\[ \\text{threshold} = \\text{otsu} \\times \\text{factor} \\] <p>Where <code>otsu</code> is the threshold value calculated by the Otsu method, and <code>factor</code> is a user-defined value that allows you to adjust the threshold value.</p> <p>This method is useful when you want to automatically find the threshold value, and when you have a clear binomial distribution of pixels (heights). I.e. separation between the foreground and background pixels in your image with little noise.</p>"},{"location":"advanced/thresholding/#absolute-thresholding","title":"Absolute thresholding","text":"<p>Absolute thresholding is a simple method of thresholding that uses a user-defined threshold value to separate the foreground and background pixels.</p> <p>This method is useful when you know the exact threshold value you want to use, for example if you know your DNA lies at 2nm above the surface you can set the threshold to 1.5nm to capture the DNA without capturing the background.</p>"},{"location":"api/","title":"API","text":"<ul> <li><code>entry_point.py</code></li> <li><code>filters.py</code></li> <li><code>grains.py</code></li> <li><code>grainstats.py</code></li> <li><code>io.py</code></li> <li><code>plotting</code></li> <li><code>plottingfuncs</code></li> <li><code>run_modules</code></li> <li><code>scars</code></li> <li><code>statistics</code></li> <li><code>theme</code></li> <li><code>thresholds</code></li> <li><code>utils</code></li> <li><code>validation</code></li> </ul>"},{"location":"api/entry_point/","title":"Entry Point Modules","text":"<p>Entry point for all TopoStats programs.</p> <p>Parses command-line arguments and passes input on to the relevant functions / modules.</p> <p>handler: python options: docstring_style: numpy rendering: show_signature_annotations: true</p>"},{"location":"api/entry_point/#topostats.entry_point.create_parser","title":"<code>create_parser()</code>","text":"<p>Create a parser for reading options.</p> <p>Creates a parser, with multiple sub-parsers for reading options to run 'topostats'.</p>"},{"location":"api/entry_point/#topostats.entry_point.create_parser--returns","title":"Returns","text":"<p>arg.ArgumentParser     Argument parser.</p> Source code in <code>topostats/entry_point.py</code> <pre><code>def create_parser() -&gt; arg.ArgumentParser:\n    \"\"\"\n    Create a parser for reading options.\n\n    Creates a parser, with multiple sub-parsers for reading options to run 'topostats'.\n\n    Returns\n    -------\n    arg.ArgumentParser\n        Argument parser.\n    \"\"\"\n    parser = arg.ArgumentParser(\n        description=\"Run various programs relating to AFM data. Add the name of the program you wish to run.\"\n    )\n    parser.add_argument(\n        \"-v\",\n        \"--version\",\n        action=\"version\",\n        version=f\"Installed version of TopoStats: {__version__}\",\n        help=\"Report the current version of TopoStats that is installed\",\n    )\n    parser.add_argument(\n        \"-c\",\n        \"--config-file\",\n        dest=\"config_file\",\n        type=Path,\n        required=False,\n        help=\"Path to a YAML configuration file.\",\n    )\n    parser.add_argument(\n        \"-s\",\n        \"--summary-config\",\n        dest=\"summary_config\",\n        required=False,\n        help=\"Path to a YAML configuration file for summary plots and statistics.\",\n    )\n    parser.add_argument(\n        \"--matplotlibrc\",\n        dest=\"matplotlibrc\",\n        type=Path,\n        required=False,\n        help=\"Path to a matplotlibrc file.\",\n    )\n    parser.add_argument(\n        \"-b\",\n        \"--base-dir\",\n        dest=\"base_dir\",\n        type=Path,\n        required=False,\n        help=\"Base directory to scan for images.\",\n    )\n    parser.add_argument(\n        \"-o\",\n        \"--output-dir\",\n        dest=\"output_dir\",\n        type=Path,\n        required=False,\n        help=\"Output directory to write results to.\",\n    )\n    parser.add_argument(\n        \"-l\",\n        \"--log-level\",\n        dest=\"log_level\",\n        type=str,\n        required=False,\n        help=\"Logging level to use, default is 'info' for verbose output use 'debug'.\",\n    )\n    parser.add_argument(\n        \"-j\",\n        \"--cores\",\n        dest=\"cores\",\n        type=int,\n        required=False,\n        help=\"Number of CPU cores to use when processing.\",\n    )\n    parser.add_argument(\n        \"-f\",\n        \"--file-ext\",\n        dest=\"file_ext\",\n        type=str,\n        required=False,\n        help=\"File extension to scan for.\",\n    )\n    parser.add_argument(\n        \"--channel\",\n        dest=\"channel\",\n        type=str,\n        required=False,\n        help=\"Channel to extract.\",\n    )\n    parser.add_argument(\n        \"--extract\", dest=\"extract\", type=str, required=False, help=\"Array to extract when loading '.topostats' files.\"\n    )\n    parser.add_argument(\n        \"--image-set\",\n        dest=\"image_set\",\n        type=str,\n        required=False,\n        help=\"Image set to generate, default is 'core' other option is 'all'.\",\n    )\n\n    subparsers = parser.add_subparsers(title=\"program\", description=\"Available programs, listed below:\", dest=\"program\")\n\n    # Create a sub-parsers for different stages of processing and tasks\n    process_parser = subparsers.add_parser(\n        \"process\",\n        description=\"Process AFM images. Additional arguments over-ride defaults or those in the configuration file.\",\n        help=\"Process AFM images. Additional arguments over-ride defaults or those in the configuration file.\",\n    )\n    # Filter options\n    process_parser.add_argument(\n        \"--filter-row-alignment-quantile\",\n        dest=\"filter_row_alignment_quantile\",\n        type=float,\n        required=False,\n        help=\"Lower values may improve flattening of larger features.\",\n    )\n    process_parser.add_argument(\n        \"--filter-threshold-method\",\n        dest=\"filter_threshold_method\",\n        type=str,\n        required=False,\n        help=\"Method for thresholding Filtering. Options are otsu, std_dev, absolute.\",\n    )\n    process_parser.add_argument(\n        \"--filter-otsu-threshold-multiplier\",\n        dest=\"filter_otsu_threshold_multiplier\",\n        type=float,\n        required=False,\n        help=\"Factor for scaling the Otsu threshold during Filtering.\",\n    )\n    process_parser.add_argument(\n        \"--filter-threshold-std-dev-below\",\n        dest=\"filter_threshold_std_dev_below\",\n        type=float,\n        required=False,\n        help=\"Threshold for data below the image background for std dev method during Filtering.\",\n    )\n    process_parser.add_argument(\n        \"--filter-threshold-std-dev-above\",\n        dest=\"filter_threshold_std_dev_above\",\n        type=float,\n        required=False,\n        help=\"Threshold for data above the image background for std dev method during Filtering.\",\n    )\n    process_parser.add_argument(\n        \"--filter-threshold-absolute-below\",\n        dest=\"filter_threshold_absolute_below\",\n        type=float,\n        required=False,\n        help=\"Threshold for data below the image bacnground dor absolute method during Filtering\",\n    )\n    process_parser.add_argument(\n        \"--filter-threshold-absolute-above\",\n        dest=\"filter_threshold_absolute_above\",\n        type=float,\n        required=False,\n        help=\"Threshold for data above the image bacnground dor absolute method during Filtering\",\n    )\n    process_parser.add_argument(\n        \"--filter-gaussian-size\",\n        dest=\"filter_gaussian_size\",\n        type=float,\n        required=False,\n        help=\"Gaussian blur intensity in pixels.\",\n    )\n    process_parser.add_argument(\n        \"--filter-gaussian-mode\",\n        dest=\"filter_gaussian_mode\",\n        type=str,\n        required=False,\n        help=\"Gaussian blur method. Options are 'nearest' (default), 'reflect', 'constant', 'mirror' or 'wrap'.\",\n    )\n    process_parser.add_argument(\n        \"--filter-remove-scars\", dest=\"filter_scars_run\", type=bool, required=False, help=\"Whether to remove scars.\"\n    )\n    process_parser.add_argument(\n        \"--filter-scars-removal-iterations\",\n        dest=\"filter_scars_removal_iterations\",\n        type=int,\n        required=False,\n        help=\"Number of times to run scar removal\",\n    )\n    process_parser.add_argument(\n        \"--filter-scars-threshold-low\",\n        dest=\"filter_scars_threshold_low\",\n        type=float,\n        required=False,\n        help=\"Lower values make scar removal more sensitive\",\n    )\n    process_parser.add_argument(\n        \"--filter-scars-threshold-high\",\n        dest=\"filter_scars_threshold_high\",\n        type=float,\n        required=False,\n        help=\"Lower values make scar removal more sensitive\",\n    )\n    process_parser.add_argument(\n        \"--filter-scars-max-scar-width\",\n        dest=\"filter_scars_max_scar_width\",\n        type=int,\n        required=False,\n        help=\"Maximum thickness of scars in pixels\",\n    )\n    process_parser.add_argument(\n        \"--filter-scars-max-scar-length\",\n        dest=\"filter_scars_max_scar_length\",\n        type=int,\n        required=False,\n        help=\"Maximum length of scars in pixels\",\n    )\n\n    # Grains\n    process_parser.add_argument(\n        \"--grains-threshold-method\",\n        dest=\"grains_threshold_method\",\n        type=str,\n        required=False,\n        help=\"Method for thresholding Grain finding. Options are otsu, std_dev, absolute.\",\n    )\n    process_parser.add_argument(\n        \"--grains-otsu-threshold-multiplier\",\n        dest=\"grains_otsu_threshold_multiplier\",\n        type=float,\n        required=False,\n        help=\"Factor for scaling the Otsu threshold during Grain finding.\",\n    )\n    process_parser.add_argument(\n        \"--grains-threshold-std-dev-below\",\n        dest=\"grains_threshold_std_dev_below\",\n        type=float,\n        required=False,\n        help=\"Threshold for data below the image background for std dev method during Grain finding.\",\n    )\n    process_parser.add_argument(\n        \"--grains-threshold-std-dev-above\",\n        dest=\"grains_threshold_std_dev_above\",\n        type=float,\n        required=False,\n        help=\"Threshold for data above the image background for std dev method during Grain finding.\",\n    )\n    process_parser.add_argument(\n        \"--grains-threshold-absolute-below\",\n        dest=\"grains_threshold_absolute_below\",\n        type=float,\n        required=False,\n        help=\"Threshold for data below the image bacnground dor absolute method during Grain finding\",\n    )\n    process_parser.add_argument(\n        \"--grains-threshold-absolute-above\",\n        dest=\"grains_threshold_absolute_above\",\n        type=float,\n        required=False,\n        help=\"Threshold for data above the image bacnground dor absolute method during Grain finding\",\n    )\n    process_parser.add_argument(\n        \"--grains-direction\",\n        dest=\"grains_direction\",\n        type=str,\n        required=False,\n        help=\"Whether to look for grains 'above' pr 'below' thresholds of 'both'\",\n    )\n    process_parser.add_argument(\n        \"--grains-smallest-grain-size-nm2\",\n        dest=\"grains_smallest_grain_size_nm2\",\n        type=float,\n        required=False,\n        help=\"Size in nm^2 of tiny grains/blobs to remove, must be &gt; 0.0\",\n    )\n    process_parser.add_argument(\n        \"--grains-absolute-area-threshold-above\",\n        dest=\"grains_absolute_area_threshold_above\",\n        type=float,\n        required=False,\n        nargs=2,\n        help=\"Above surface (low, high) in nm^2, both low and high should be specified\",\n    )\n    process_parser.add_argument(\n        \"--grains-absolute-area-threshold-below\",\n        dest=\"grains_absolute_area_threshold_below\",\n        type=float,\n        required=False,\n        nargs=2,\n        help=\"Below surface (low, high) in nm^2, both low and high should be specified\",\n    )\n    process_parser.add_argument(\n        \"--grains-remove-edge-intersecting-grains\",\n        dest=\"grains_remove_edge_intersecting_grains\",\n        type=bool,\n        required=False,\n        help=\"Whether or not to remove grains that touch the image border\",\n    )\n    # Unet\n    process_parser.add_argument(\n        \"--unet-model-path\", dest=\"unet_model_path\", type=Path, required=False, help=\"Path to a trained U-net model\"\n    )\n    process_parser.add_argument(\n        \"--unet-grain-crop-padding\",\n        dest=\"unet_grain_crop_padding\",\n        type=int,\n        required=False,\n        help=\"Padding to apply to the grain crop bounding box\",\n    )\n    process_parser.add_argument(\n        \"--unet-upper-norm-bound\",\n        dest=\"unet_upper_norm_bound\",\n        type=float,\n        required=False,\n        help=\"Upper bound for normalisation of input data. This should be slightly higher than the maximum desired\"\n        \"/expected height of grains\",\n    )\n    process_parser.add_argument(\n        \"--unet-lower-norm-bound\",\n        dest=\"unet_lower_norm_bound\",\n        type=float,\n        required=False,\n        help=\"Lower bound for normalisation of input data. This should be slightly lower than the minimum desired\"\n        \"/expected height of the background\",\n    )\n\n    # Grainstats\n    process_parser.add_argument(\n        \"--grainstats-edge-detection-method\",\n        dest=\"grainstats_edge_detection_method\",\n        type=str,\n        required=False,\n        help=\"Method of edge detection, do NOT change this unless you are sure of what it will do. Options 'canny' and\"\n        \"'binary_erosion (default)\",\n    )\n    process_parser.add_argument(\n        \"--grainstats-cropped-size\",\n        dest=\"grainstats_cropped_size\",\n        type=float,\n        required=False,\n        help=\"Length (in nm) of square cropped images (can take -1 for grain-sized box)\",\n    )\n    process_parser.add_argument(\n        \"--grainstats-extract-height-profile\",\n        dest=\"grainstats_extract_height_profile\",\n        type=bool,\n        required=False,\n        help=\"Extract height profiles along maximum feret of molecules\",\n    )\n\n    # Disordered Tracing\n    process_parser.add_argument(\n        \"--disordered-min-skeleton-size\",\n        dest=\"disordered_min_skeleton_size\",\n        type=float,\n        required=False,\n        help=\"Minimum number of pixels in a skeleton for it to be retained\",\n    )\n    process_parser.add_argument(\n        \"--disordered-pad-width\",\n        dest=\"disordered_pad_width\",\n        type=int,\n        required=False,\n        help=\"Pixels to pad grains by when tracing\",\n    )\n    process_parser.add_argument(\n        \"--disordered-mask-smoothing-params-gaussian-sigma\",\n        dest=\"disordered_mask_smoothing_params_gaussian_sigma\",\n        type=float,\n        required=False,\n        help=\"Gaussian smoothing parameter 'sigma' in pixels\",\n    )\n    process_parser.add_argument(\n        \"--disordered-mask-smoothing-params-dilation-iterations\",\n        dest=\"disordered_mask_smoothing_params_dilation_iterations\",\n        type=int,\n        required=False,\n        help=\"Number of dilation iterations to use for grain smoothing\",\n    )\n    process_parser.add_argument(\n        \"--disordered-mask-smoothing-params-holearea-min-max\",\n        dest=\"disordered_mask_smoothing_params_holearea_min_max\",\n        type=float,\n        required=False,\n        nargs=2,\n        help=\"Range (min, max) of a hole area in nm to refil in the smoothed masks\",\n    )\n    process_parser.add_argument(\n        \"--disordered-skeletonisation-params-method\",\n        dest=\"disordered_skeletonisation_params_method\",\n        type=str,\n        required=False,\n        help=\"Skeletonisation method. Options : zhang | lee | thin | topostats\",\n    )\n    process_parser.add_argument(\n        \"--disordered-skeletonisation-height-bias\",\n        dest=\"disordered_skeletonisation_height_bias\",\n        type=float,\n        required=False,\n        help=\"Percentage of lowest pixels to remove each skeletonisation iteration. 1.0 equates to Zhang method\",\n    )\n    process_parser.add_argument(\n        \"--disordered-pruning-params-method\",\n        dest=\"disordered_pruning_params_method\",\n        type=str,\n        required=False,\n        help=\"Method to clean branches from the skeleton: Options : 'topostats'\",\n    )\n    process_parser.add_argument(\n        \"--disordered-pruning-params-max-length\",\n        dest=\"disordered_pruning_params_max_length\",\n        type=float,\n        required=False,\n        help=\"Maximum length in nm to remove a branch containing an endpoint\",\n    )\n    process_parser.add_argument(\n        \"--disordered-pruning-params-height-threshold\",\n        dest=\"disordered_pruning_params_height_threshold\",\n        type=float,\n        required=False,\n        help=\"The height to remove branches below\",\n    )\n    process_parser.add_argument(\n        \"--disordered-pruning-params-method-values\",\n        dest=\"disordered_pruning_params_method_values\",\n        type=str,\n        required=False,\n        help=\"Method to obtain a branch's height for pruning. Options : 'min' | 'median', 'mid'\",\n    )\n    process_parser.add_argument(\n        \"--disordered-pruning-params-method-outlier\",\n        dest=\"disordered_pruning_params_method_outlier\",\n        type=str,\n        required=False,\n        help=\"Method to prune branches based on height. Options : 'abs' | 'mean_abs' | 'iqr'\",\n    )\n\n    # Nodestats\n    process_parser.add_argument(\n        \"--nodestats-node-joining-length\",\n        dest=\"nodestats_node_joining_length\",\n        type=float,\n        required=False,\n        help=\"The distance over which to join nearby crossing points\",\n    )\n    process_parser.add_argument(\n        \"--nodestats-node-extend-dist\",\n        dest=\"nodestats_node_extend_dist\",\n        type=float,\n        required=False,\n        help=\"The distance over which to join nearby odd-branched nodes\",\n    )\n    process_parser.add_argument(\n        \"--nodestats-branch-pairing-length\",\n        dest=\"nodestats_branch_pairing_length\",\n        type=float,\n        required=False,\n        help=\"The length from the crossing point to pair and trace, obtaining FWHM's\",\n    )\n    process_parser.add_argument(\n        \"--nodestats-pair-odd-branches\",\n        dest=\"nodestats_pair_odd_branches\",\n        type=bool,\n        required=False,\n        help=\"Whether to try and pair odd-branched nodes\",\n    )\n    process_parser.add_argument(\n        \"--nodestats-pad-width\",\n        dest=\"nodestats_pad_width\",\n        type=int,\n        required=False,\n        help=\"Pixels to pad grains by when tracing (should be the same as --disordered-pad-width)\",\n    )\n\n    # Ordered Tracing\n    process_parser.add_argument(\n        \"--ordered-ordering-method\",\n        dest=\"ordered_ordering_method\",\n        type=str,\n        required=False,\n        help=\"Ordering method for ordering disordered traces. Option 'nodestats'\",\n    )\n    process_parser.add_argument(\n        \"--ordered-pad-width\",\n        dest=\"ordered_pad_width\",\n        type=int,\n        required=False,\n        help=\"Pixels to pad grains by when tracing (should be the same as --disordered-pad-width)\",\n    )\n\n    # Splining\n    process_parser.add_argument(\n        \"--splining-method\",\n        dest=\"splining_method\",\n        type=str,\n        required=False,\n        help=\"Method for splining. Options 'spline' or 'rolling_window\",\n    )\n    process_parser.add_argument(\n        \"--splining-window-size\",\n        dest=\"splining_window_size\",\n        type=float,\n        required=False,\n        help=\"Size in nm of the rolling window\",\n    )\n    process_parser.add_argument(\n        \"--splining-step-size\",\n        dest=\"splining_step_size\",\n        type=float,\n        required=False,\n        help=\"The sampling rate of the spline in metres\",\n    )\n    process_parser.add_argument(\n        \"--splining-linear-smoothing\",\n        dest=\"splining_linear_smoothing\",\n        type=float,\n        required=False,\n        help=\"The amount of smoothing to apply to linear features\",\n    )\n    process_parser.add_argument(\n        \"--splining-circular-smoothing\",\n        dest=\"splining_circular_smoothing\",\n        type=float,\n        required=False,\n        help=\"The amount of smoothing to apply to circular features\",\n    )\n    process_parser.add_argument(\n        \"--splining-degree\",\n        dest=\"splining_degree\",\n        type=int,\n        required=False,\n        help=\"The polynomial degree of the spline\",\n    )\n\n    # Plotting\n    process_parser.add_argument(\n        \"--save-plots\",\n        dest=\"save_plots\",\n        type=bool,\n        required=False,\n        help=\"Whether to save plots.\",\n    )\n    process_parser.add_argument(\n        \"--savefig-format\",\n        dest=\"savefig_format\",\n        type=str,\n        required=False,\n        help=\"Format for saving figures to, options are 'png', 'svg', or other valid Matplotlib supported formats.\",\n    )\n    process_parser.add_argument(\n        \"--savefig-dpi\",\n        dest=\"savefig_dpi\",\n        type=int,\n        required=False,\n        help=\"Dots Per Inch for plots, should be integer for dots per inch.\",\n    )\n    process_parser.add_argument(\n        \"--cmap\",\n        dest=\"cmap\",\n        type=str,\n        required=False,\n        help=\"Colormap to use, options include 'nanoscope', 'afmhot' or any valid Matplotlib colormap.\",\n    )\n    process_parser.add_argument(\"-m\", \"--mask\", dest=\"mask\", type=bool, required=False, help=\"Mask the image.\")\n    process_parser.add_argument(\n        \"-w\",\n        \"--warnings\",\n        dest=\"warnings\",\n        type=bool,\n        required=False,\n        help=\"Whether to ignore warnings.\",\n    )\n    # Run the relevant function with the arguments\n    process_parser.set_defaults(func=run_modules.process)\n\n    load_parser = subparsers.add_parser(\n        \"load\",\n        description=\"Load and save all images as .topostats files for subsequent processing.\",\n        help=\"Load and save all images as .topostats files for subsequent processing.\",\n    )\n    # Run the relevant function with the arguments\n    load_parser.set_defaults(func=run_modules.process)\n\n    # Filter\n    filter_parser = subparsers.add_parser(\n        \"filter\",\n        description=\"Load and filter images, saving as .topostats files for subsequent processing.\",\n        help=\"Load and filter images, saving as .topostats files for subsequent processing.\",\n    )\n    filter_parser.add_argument(\n        \"--row-alignment-quantile\",\n        dest=\"row_alignment_quantile\",\n        type=float,\n        required=False,\n        help=\"Lower values may improve flattening of larger features.\",\n    )\n    filter_parser.add_argument(\n        \"--threshold-method\",\n        dest=\"threshold_method\",\n        type=str,\n        required=False,\n        help=\"Method for thresholding Filtering. Options are otsu, std_dev, absolute.\",\n    )\n    filter_parser.add_argument(\n        \"--otsu-threshold-multiplier\",\n        dest=\"otsu_threshold_multiplier\",\n        type=float,\n        required=False,\n        help=\"Factor for scaling the Otsu threshold during Filtering.\",\n    )\n    filter_parser.add_argument(\n        \"--threshold-std-dev-below\",\n        dest=\"threshold_std_dev_below\",\n        type=float,\n        required=False,\n        help=\"Threshold for data below the image background for std dev method during Filtering.\",\n    )\n    filter_parser.add_argument(\n        \"--threshold-std-dev-above\",\n        dest=\"threshold_std_dev_above\",\n        type=float,\n        required=False,\n        help=\"Threshold for data above the image background for std dev method during Filtering.\",\n    )\n    filter_parser.add_argument(\n        \"--threshold-absolute-below\",\n        dest=\"threshold_absolute_below\",\n        type=float,\n        required=False,\n        help=\"Threshold for data below the image bacnground dor absolute method during Filtering\",\n    )\n    filter_parser.add_argument(\n        \"--threshold-absolute-above\",\n        dest=\"threshold_absolute_above\",\n        type=float,\n        required=False,\n        help=\"Threshold for data above the image bacnground dor absolute method during Filtering\",\n    )\n    filter_parser.add_argument(\n        \"--gaussian-size\", dest=\"gaussian_size\", type=float, required=False, help=\"Gaussian blur intensity in pixels.\"\n    )\n    filter_parser.add_argument(\n        \"--gaussian-mode\",\n        dest=\"gaussian_mode\",\n        type=str,\n        required=False,\n        help=\"Gaussian blur method. Options are 'nearest' (default), 'reflect', 'constant', 'mirror' or 'wrap'.\",\n    )\n    filter_parser.add_argument(\n        \"--remove-scars\", dest=\"scars_run\", type=bool, required=False, help=\"Whether to remove scars.\"\n    )\n    filter_parser.add_argument(\n        \"--scars-removal-iterations\",\n        dest=\"scars_removal_iterations\",\n        type=int,\n        required=False,\n        help=\"Number of times to run scar removal\",\n    )\n    filter_parser.add_argument(\n        \"--scars-threshold-low\",\n        dest=\"scars_threshold_low\",\n        type=float,\n        required=False,\n        help=\"Lower values make scar removal more sensitive\",\n    )\n    filter_parser.add_argument(\n        \"--scars-threshold-high\",\n        dest=\"scars_threshold_high\",\n        type=float,\n        required=False,\n        help=\"Lower values make scar removal more sensitive\",\n    )\n    filter_parser.add_argument(\n        \"--scars-max-scar-width\",\n        dest=\"scars_max_scar_width\",\n        type=int,\n        required=False,\n        help=\"Maximum thickness of scars in pixels\",\n    )\n    filter_parser.add_argument(\n        \"--scars-max-scar-length\",\n        dest=\"scars_max_scar_length\",\n        type=int,\n        required=False,\n        help=\"Maximum length of scars in pixels\",\n    )\n    # Run the relevant function with the arguments\n    filter_parser.set_defaults(func=run_modules.filters)\n\n    grains_parser = subparsers.add_parser(\n        \"grains\",\n        description=\"Load filtered images from '.topostats' files and detect grains.\",\n        help=\"Load filtered images from '.topostats' files and detect grains.\",\n    )\n    grains_parser.add_argument(\n        \"--threshold-method\",\n        dest=\"threshold_method\",\n        type=str,\n        required=False,\n        help=\"Method for thresholding Grain finding. Options are otsu, std_dev, absolute.\",\n    )\n    grains_parser.add_argument(\n        \"--otsu-threshold-multiplier\",\n        dest=\"otsu_threshold_multiplier\",\n        type=float,\n        required=False,\n        help=\"Factor for scaling the Otsu threshold during Grain finding.\",\n    )\n    grains_parser.add_argument(\n        \"--threshold-std-dev-below\",\n        dest=\"threshold_std_dev_below\",\n        type=float,\n        required=False,\n        help=\"Threshold for data below the image background for std dev method during Grain finding.\",\n    )\n    grains_parser.add_argument(\n        \"--threshold-std-dev-above\",\n        dest=\"threshold_std_dev_above\",\n        type=float,\n        required=False,\n        help=\"Threshold for data above the image background for std dev method during Grain finding.\",\n    )\n    grains_parser.add_argument(\n        \"--threshold-absolute-below\",\n        dest=\"threshold_absolute_below\",\n        type=float,\n        required=False,\n        help=\"Threshold for data below the image bacnground dor absolute method during Grain finding\",\n    )\n    grains_parser.add_argument(\n        \"--threshold-absolute-above\",\n        dest=\"threshold_absolute_above\",\n        type=float,\n        required=False,\n        help=\"Threshold for data above the image bacnground dor absolute method during Grain finding\",\n    )\n    grains_parser.add_argument(\n        \"--direction\",\n        dest=\"direction\",\n        type=str,\n        required=False,\n        help=\"Whether to look for grains 'above' pr 'below' thresholds of 'both'\",\n    )\n    grains_parser.add_argument(\n        \"--smallest-grain-size-nm2\",\n        dest=\"smallest_grain_size_nm2\",\n        type=float,\n        required=False,\n        help=\"Size in nm^2 of tiny grains/blobs to remove, must be &gt; 0.0\",\n    )\n    grains_parser.add_argument(\n        \"--absolute-area-threshold-above\",\n        dest=\"absolute_area_threshold_above\",\n        type=float,\n        required=False,\n        nargs=2,\n        help=\"Above surface (low, high) in nm^2, both low and high should be specified\",\n    )\n    grains_parser.add_argument(\n        \"--absolute-area-threshold-below\",\n        dest=\"absolute_area_threshold_below\",\n        type=float,\n        required=False,\n        nargs=2,\n        help=\"Below surface (low, high) in nm^2, both low and high should be specified\",\n    )\n    grains_parser.add_argument(\n        \"--remove-edge-intersecting-grains\",\n        dest=\"remove_edge_intersecting_grains\",\n        type=bool,\n        required=False,\n        help=\"Whether or not to remove grains that touch the image border\",\n    )\n    # Unet\n    grains_parser.add_argument(\n        \"--unet-model-path\", dest=\"unet_model_path\", type=Path, required=False, help=\"Path to a trained U-net model\"\n    )\n    grains_parser.add_argument(\n        \"--unet-grain-crop-padding\",\n        dest=\"unet_grain_crop_padding\",\n        type=int,\n        required=False,\n        help=\"Padding to apply to the grain crop bounding box\",\n    )\n    grains_parser.add_argument(\n        \"--unet-upper-norm-bound\",\n        dest=\"unet_upper_norm_bound\",\n        type=float,\n        required=False,\n        help=\"Upper bound for normalisation of input data. This should be slightly higher than the maximum desired\"\n        \"/expected height of grains\",\n    )\n    grains_parser.add_argument(\n        \"--unet-lower-norm-bound\",\n        dest=\"unet_lower_norm_bound\",\n        type=float,\n        required=False,\n        help=\"Lower bound for normalisation of input data. This should be slightly lower than the minimum desired\"\n        \"/expected height of the background\",\n    )\n    # Run the relevant function with the arguments\n    grains_parser.set_defaults(func=run_modules.grains)\n\n    grainstats_parser = subparsers.add_parser(\n        \"grainstats\",\n        description=\"Load images with grains from '.topostats' files and calculate statistics.\",\n        help=\"Load images with grains from '.topostats' files and calculate statistics.\",\n    )\n    grainstats_parser.add_argument(\n        \"--edge-detection-method\",\n        dest=\"edge_detection_method\",\n        type=str,\n        required=False,\n        help=\"Method of edge detection, do NOT change this unless you are sure of what it will do. Options 'canny' and\"\n        \"'binary_erosion (default)\",\n    )\n    grainstats_parser.add_argument(\n        \"--cropped-size\",\n        dest=\"cropped_size\",\n        type=float,\n        required=False,\n        help=\"Length (in nm) of square cropped images (can take -1 for grain-sized box)\",\n    )\n    grainstats_parser.add_argument(\n        \"--extract-height-profile\",\n        dest=\"extract_height_profile\",\n        type=bool,\n        required=False,\n        help=\"Extract height profiles along maximum feret of molecules\",\n    )\n    # Run the relevant function with the arguments\n    grainstats_parser.set_defaults(func=run_modules.grainstats)\n\n    # Disordered\n    disordered_tracing_parser = subparsers.add_parser(\n        \"disordered-tracing\",\n        description=\"WIP DO NOT USE - Skeletonise and prune objects to disordered traces.\",\n        help=\"WIP DO NOT USE - Skeletonise and prune objects to disordered traces.\",\n    )\n    disordered_tracing_parser.add_argument(\n        \"--min-skeleton-size\",\n        dest=\"min_skeleton_size\",\n        type=float,\n        required=False,\n        help=\"Minimum number of pixels in a skeleton for it to be retained\",\n    )\n    disordered_tracing_parser.add_argument(\n        \"--pad-width\",\n        dest=\"pad_width\",\n        type=int,\n        required=False,\n        help=\"Pixels to pad grains by when tracing\",\n    )\n    disordered_tracing_parser.add_argument(\n        \"--mask-smoothing-params-gaussian-sigma\",\n        dest=\"mask_smoothing_params_gaussian_sigma\",\n        type=float,\n        required=False,\n        help=\"Gaussian smoothing parameter 'sigma' in pixels\",\n    )\n    disordered_tracing_parser.add_argument(\n        \"--mask-smoothing-params-dilation-iterations\",\n        dest=\"mask_smoothing_params_dilation_iterations\",\n        type=int,\n        required=False,\n        help=\"Number of dilation iterations to use for grain smoothing\",\n    )\n    disordered_tracing_parser.add_argument(\n        \"--mask-smoothing-params-holearea-min-max\",\n        dest=\"mask_smoothing_params_holearea_min_max\",\n        type=float,\n        required=False,\n        nargs=2,\n        help=\"Range (min, max) of a hole area in nm to refil in the smoothed masks\",\n    )\n    disordered_tracing_parser.add_argument(\n        \"--skeletonisation-params-method\",\n        dest=\"skeletonisation_params_method\",\n        type=str,\n        required=False,\n        help=\"Skeletonisation method. Options : zhang | lee | thin | topostats\",\n    )\n    disordered_tracing_parser.add_argument(\n        \"--skeletonisation-height-bias\",\n        dest=\"skeletonisation_height_bias\",\n        type=float,\n        required=False,\n        help=\"Percentage of lowest pixels to remove each skeletonisation iteration. 1.0 equates to Zhang method\",\n    )\n    disordered_tracing_parser.add_argument(\n        \"--pruning-params-method\",\n        dest=\"pruning_params_method\",\n        type=str,\n        required=False,\n        help=\"Method to clean branches from the skeleton: Options : 'topostats'\",\n    )\n    disordered_tracing_parser.add_argument(\n        \"--pruning-params-max-length\",\n        dest=\"pruning_params_max_length\",\n        type=float,\n        required=False,\n        help=\"Maximum length in nm to remove a branch containing an endpoint\",\n    )\n    disordered_tracing_parser.add_argument(\n        \"--pruning-params-height-threshold\",\n        dest=\"pruning_params_height_threshold\",\n        type=float,\n        required=False,\n        help=\"The height to remove branches below\",\n    )\n    disordered_tracing_parser.add_argument(\n        \"--pruning-params-method-values\",\n        dest=\"pruning_params_method_values\",\n        type=str,\n        required=False,\n        help=\"Method to obtain a branch's height for pruning. Options : 'min' | 'median' | 'mid'\",\n    )\n    disordered_tracing_parser.add_argument(\n        \"--pruning-params-method-outlier\",\n        dest=\"pruning_params_method_outlier\",\n        type=str,\n        required=False,\n        help=\"Method to prune branches based on height. Options : 'abs' | 'mean_abs' | 'iqr'\",\n    )\n    # Run the relevant function with the arguments\n    disordered_tracing_parser.set_defaults(func=run_modules.disordered_tracing)\n\n    # Nodestats\n    nodestats_parser = subparsers.add_parser(\n        \"nodestats\",\n        description=\"WIP DO NOT USE - Calculate node statistics and disentangle molecules.\",\n        help=\"WIP DO NOT USE - Calculate node statistics and disentangle molecules.\",\n    )\n    nodestats_parser.add_argument(\n        \"--node-joining-length\",\n        dest=\"node_joining_length\",\n        type=float,\n        required=False,\n        help=\"The distance over which to join nearby crossing points\",\n    )\n    nodestats_parser.add_argument(\n        \"--node-extend-dist\",\n        dest=\"node_extend_dist\",\n        type=float,\n        required=False,\n        help=\"The distance over which to join nearby odd-branched nodes\",\n    )\n    nodestats_parser.add_argument(\n        \"--branch-pairing-length\",\n        dest=\"branch_pairing_length\",\n        type=float,\n        required=False,\n        help=\"The length from the crossing point to pair and trace, obtaining FWHM's\",\n    )\n    nodestats_parser.add_argument(\n        \"--pair-odd-branches\",\n        dest=\"pair_odd_branches\",\n        type=bool,\n        required=False,\n        help=\"Whether to try and pair odd-branched nodes\",\n    )\n    nodestats_parser.add_argument(\n        \"--pad-width\",\n        dest=\"pad_width\",\n        type=int,\n        required=False,\n        help=\"Pixels to pad grains by when tracing (should be the same as --disordered-pad-width)\",\n    )\n    # Run the relevant function with the arguments\n    nodestats_parser.set_defaults(func=run_modules.nodestats)\n\n    # Ordered Tracing\n    ordered_tracing_parser = subparsers.add_parser(\n        \"ordered-tracing\",\n        description=\"WIP DO NOT USE - Ordered traces of pruned skeletons.\",\n        help=\"WIP DO NOT USE - Ordered traces of pruned skeletons.\",\n    )\n    ordered_tracing_parser.add_argument(\n        \"--ordering-method\",\n        dest=\"ordering_method\",\n        type=str,\n        required=False,\n        help=\"Ordering method for ordering disordered traces. Option 'nodestats'\",\n    )\n    ordered_tracing_parser.add_argument(\n        \"--pad-width\",\n        dest=\"pad_width\",\n        type=int,\n        required=False,\n        help=\"Pixels to pad grains by when tracing (should be the same as --disordered-pad-width)\",\n    )\n    # Run the relevant function with the arguments\n    ordered_tracing_parser.set_defaults(func=run_modules.ordered_tracing)\n\n    # Splining\n    splining_parser = subparsers.add_parser(\n        \"splining\",\n        description=\"WIP DO NOT USE - Splining of traced molecules to produce smooth curves.\",\n        help=\"WIP DO NOT USE - Splining of traced molecules to produce smooth curves.\",\n    )\n    splining_parser.add_argument(\n        \"--method\",\n        dest=\"method\",\n        type=str,\n        required=False,\n        help=\"Method for splining. Options 'spline' or 'rolling_window\",\n    )\n    splining_parser.add_argument(\n        \"--window-size\",\n        dest=\"window_size\",\n        type=float,\n        required=False,\n        help=\"Size in nm of the rolling window\",\n    )\n    splining_parser.add_argument(\n        \"--step-size\",\n        dest=\"step_size\",\n        type=float,\n        required=False,\n        help=\"The sampling rate of the spline in metres\",\n    )\n    splining_parser.add_argument(\n        \"--linear-smoothing\",\n        dest=\"linear_smoothing\",\n        type=float,\n        required=False,\n        help=\"The amount of smoothing to apply to linear features\",\n    )\n    splining_parser.add_argument(\n        \"--circular-smoothing\",\n        dest=\"circular_smoothing\",\n        type=float,\n        required=False,\n        help=\"The amount of smoothing to apply to circular features\",\n    )\n    splining_parser.add_argument(\n        \"--degree\",\n        dest=\"degree\",\n        type=int,\n        required=False,\n        help=\"The polynomial degree of the spline\",\n    )\n    # Run the relevant function with the arguments\n    splining_parser.set_defaults(func=run_modules.splining)\n\n    summary_parser = subparsers.add_parser(\n        \"summary\",\n        description=\"Plotting and summary of TopoStats output statistics.\",\n        help=\"Plotting and summary of TopoStats output statistics.\",\n    )\n    summary_parser.add_argument(\n        \"--input-csv\",\n        dest=\"input_csv\",\n        type=Path,\n        required=False,\n        help=\"Path to CSV file to plot.\",\n    )\n    summary_parser.add_argument(\n        \"--config-file\",\n        dest=\"config_file\",\n        type=Path,\n        required=False,\n        help=\"Path to a YAML plotting dictionary that maps variable names to labels.\",\n    )\n    summary_parser.add_argument(\n        \"--var-to-label\",\n        dest=\"var_to_label\",\n        type=Path,\n        required=False,\n        help=\"Path to a YAML plotting dictionary that maps variable names to labels.\",\n    )\n    summary_parser.add_argument(\n        \"--create-config-file\",\n        dest=\"create_config_file\",\n        type=Path,\n        required=False,\n        help=\"Filename to write a sample YAML configuration file to (should end in '.yaml').\",\n    )\n    summary_parser.add_argument(\n        \"--create-label-file\",\n        dest=\"create_label_file\",\n        type=Path,\n        required=False,\n        help=\"Filename to write a sample YAML label file to (should end in '.yaml').\",\n    )\n    summary_parser.add_argument(\n        \"--savefig-format\",\n        dest=\"savefig_format\",\n        type=str,\n        required=False,\n        help=\"Format for saving figures to, options are 'png', 'svg', or other valid Matplotlib supported formats.\",\n    )\n    summary_parser.set_defaults(func=run_toposum)\n\n    create_config_parser = subparsers.add_parser(\n        \"create-config\",\n        description=\"Create a configuration file using the defaults.\",\n        help=\"Create a configuration file using the defaults.\",\n    )\n    create_config_parser.add_argument(\n        \"-f\",\n        \"--filename\",\n        dest=\"filename\",\n        type=Path,\n        required=False,\n        default=\"config.yaml\",\n        help=\"Name of YAML file to save configuration to (default 'config.yaml').\",\n    )\n    create_config_parser.add_argument(\n        \"-o\",\n        \"--output-dir\",\n        dest=\"output_dir\",\n        type=Path,\n        required=False,\n        default=\"./\",\n        help=\"Path to where the YAML file should be saved (default './' the current directory).\",\n    )\n    create_config_parser.add_argument(\n        \"-c\",\n        \"--config\",\n        dest=\"config\",\n        type=str,\n        default=None,\n        help=\"Configuration to use, currently only one is supported, the 'default'.\",\n    )\n    create_config_parser.add_argument(\n        \"-s\",\n        \"--simple\",\n        dest=\"simple\",\n        action=\"store_true\",\n        help=\"Create a simple configuration file with only the most common options.\",\n    )\n    create_config_parser.set_defaults(func=write_config_with_comments)\n\n    create_matplotlibrc_parser = subparsers.add_parser(\n        \"create-matplotlibrc\",\n        description=\"Create a Matplotlibrc parameters file.\",\n        help=\"Create a Matplotlibrc parameters file using the defaults.\",\n    )\n    create_matplotlibrc_parser.add_argument(\n        \"-f\",\n        \"--filename\",\n        dest=\"filename\",\n        type=Path,\n        required=False,\n        default=\"topostats.mplstyle\",\n        help=\"Name of file to save Matplotlibrc configuration to (default 'topostats.mplstyle').\",\n    )\n    create_matplotlibrc_parser.add_argument(\n        \"-o\",\n        \"--output-dir\",\n        dest=\"output_dir\",\n        type=Path,\n        required=False,\n        default=\"./\",\n        help=\"Path to where the YAML file should be saved (default './' the current directory).\",\n    )\n    create_matplotlibrc_parser.add_argument(\n        \"-c\",\n        \"--config\",\n        dest=\"config\",\n        default=\"topostats.mplstyle\",\n        help=\"Matplotlibrc style file to use, currently only one is supported, the 'topostats.mplstyle'.\",\n    )\n    create_matplotlibrc_parser.set_defaults(func=write_config_with_comments)\n\n    return parser\n</code></pre>"},{"location":"api/entry_point/#topostats.entry_point.entry_point","title":"<code>entry_point(manually_provided_args=None, testing=False)</code>","text":"<p>Entry point for all TopoStats programs.</p> <p>Main entry point for running 'topostats' which allows the different processing steps ('process', 'filter', 'create_config' etc.) to be run.</p>"},{"location":"api/entry_point/#topostats.entry_point.entry_point--parameters","title":"Parameters","text":"<p>manually_provided_args : None     Manually provided arguments. testing : bool     Whether testing is being carried out.</p>"},{"location":"api/entry_point/#topostats.entry_point.entry_point--returns","title":"Returns","text":"<p>None     Does not return anything.</p> Source code in <code>topostats/entry_point.py</code> <pre><code>def entry_point(manually_provided_args=None, testing=False) -&gt; None:\n    \"\"\"\n    Entry point for all TopoStats programs.\n\n    Main entry point for running 'topostats' which allows the different processing steps ('process', 'filter',\n    'create_config' etc.) to be run.\n\n    Parameters\n    ----------\n    manually_provided_args : None\n        Manually provided arguments.\n    testing : bool\n        Whether testing is being carried out.\n\n    Returns\n    -------\n    None\n        Does not return anything.\n    \"\"\"\n    # Parse command line options, load config (or default) and update with command line options\n    parser = create_parser()\n    args = parser.parse_args() if manually_provided_args is None else parser.parse_args(manually_provided_args)\n\n    # No program specified, print help and exit\n    if not args.program:\n        parser.print_help()\n        sys.exit()\n\n    if testing:\n        return args\n\n    # call the relevant function\n    args.func(args)\n\n    return None\n</code></pre>"},{"location":"api/filters/","title":"Filters Modules","text":"<p>Module for filtering 2D Numpy arrays.</p> <p>handler: python options: docstring_style: numpy rendering: show_signature_annotations: true</p>"},{"location":"api/filters/#topostats.filters.Filters","title":"<code>Filters</code>","text":"<p>Class for filtering scans.</p>"},{"location":"api/filters/#topostats.filters.Filters--parameters","title":"Parameters","text":"<p>image : npt.NDArray     The raw image from the Atomic Force Microscopy machine. filename : str     The filename (used in logging only). pixel_to_nm_scaling : float     Value for converting pixels to nanometers. row_alignment_quantile : float     Quantile (0.0 to 1.0) to be used to determine the average background for the image below values may improve     flattening of large features. threshold_method : str     Method for thresholding, default 'otsu', valid options 'otsu', 'std_dev' and 'absolute'. otsu_threshold_multiplier : float     Value for scaling the derived Otsu threshold. threshold_std_dev : dict     If using the 'std_dev' threshold method. Dictionary that contains above and below threshold values for the     number of standard deviations from the mean to threshold. threshold_absolute : dict     If using the 'absolute' threshold method. Dictionary that contains above and below absolute threshold values     for flattening. gaussian_size : float     If using the 'absolute' threshold method. Dictionary that contains above and below absolute threshold values     for flattening. gaussian_mode : str     Method passed to 'skimage.filters.gaussian(mode = gaussian_mode)'. remove_scars : dict     Dictionary containing configuration parameters for the scar removal function.</p> Source code in <code>topostats/filters.py</code> <pre><code>class Filters:\n    \"\"\"\n    Class for filtering scans.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        The raw image from the Atomic Force Microscopy machine.\n    filename : str\n        The filename (used in logging only).\n    pixel_to_nm_scaling : float\n        Value for converting pixels to nanometers.\n    row_alignment_quantile : float\n        Quantile (0.0 to 1.0) to be used to determine the average background for the image below values may improve\n        flattening of large features.\n    threshold_method : str\n        Method for thresholding, default 'otsu', valid options 'otsu', 'std_dev' and 'absolute'.\n    otsu_threshold_multiplier : float\n        Value for scaling the derived Otsu threshold.\n    threshold_std_dev : dict\n        If using the 'std_dev' threshold method. Dictionary that contains above and below threshold values for the\n        number of standard deviations from the mean to threshold.\n    threshold_absolute : dict\n        If using the 'absolute' threshold method. Dictionary that contains above and below absolute threshold values\n        for flattening.\n    gaussian_size : float\n        If using the 'absolute' threshold method. Dictionary that contains above and below absolute threshold values\n        for flattening.\n    gaussian_mode : str\n        Method passed to 'skimage.filters.gaussian(mode = gaussian_mode)'.\n    remove_scars : dict\n        Dictionary containing configuration parameters for the scar removal function.\n    \"\"\"  # numpydoc: ignore=PR01\n\n    def __init__(\n        self,\n        image: npt.NDArray,\n        filename: str,\n        pixel_to_nm_scaling: float,\n        row_alignment_quantile: float = 0.5,\n        threshold_method: str = \"otsu\",\n        otsu_threshold_multiplier: float = 1.7,\n        threshold_std_dev: dict = None,\n        threshold_absolute: dict = None,\n        gaussian_size: float = None,\n        gaussian_mode: str = \"nearest\",\n        remove_scars: dict = None,\n    ):\n        \"\"\"\n        Initialise the class.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            The raw image from the Atomic Force Microscopy machine.\n        filename : str\n            The filename (used in logging only).\n        pixel_to_nm_scaling : float\n            Value for converting pixels to nanometers.\n        row_alignment_quantile : float\n            Quantile (0.0 to 1.0) to be used to determine the average background for the image below values may improve\n            flattening of large features.\n        threshold_method : str\n            Method for thresholding, default 'otsu', valid options 'otsu', 'std_dev' and 'absolute'.\n        otsu_threshold_multiplier : float\n            Value for scaling the derived Otsu threshold.\n        threshold_std_dev : dict\n            If using the 'std_dev' threshold method. Dictionary that contains above and below threshold values for the\n            number of standard deviations from the mean to threshold.\n        threshold_absolute : dict\n            If using the 'absolute' threshold method. Dictionary that contains above and below absolute threshold values\n            for flattening.\n        gaussian_size : float\n            If using the 'absolute' threshold method. Dictionary that contains above and below absolute threshold values\n            for flattening.\n        gaussian_mode : str\n            Method passed to 'skimage.filters.gaussian(mode = gaussian_mode)'.\n        remove_scars : dict\n            Dictionary containing configuration parameters for the scar removal function.\n        \"\"\"\n        self.filename = filename\n        self.pixel_to_nm_scaling = pixel_to_nm_scaling\n        self.gaussian_size = gaussian_size\n        self.gaussian_mode = gaussian_mode\n        self.row_alignment_quantile = row_alignment_quantile\n        self.threshold_method = threshold_method\n        self.otsu_threshold_multiplier = otsu_threshold_multiplier\n        self.threshold_std_dev = threshold_std_dev\n        self.threshold_absolute = threshold_absolute\n        self.remove_scars_config = remove_scars\n        self.images = {\n            \"pixels\": image,\n            \"initial_median_flatten\": None,\n            \"initial_tilt_removal\": None,\n            \"initial_quadratic_removal\": None,\n            \"initial_scar_removal\": None,\n            \"initial_zero_average_background\": None,\n            \"masked_median_flatten\": None,\n            \"masked_tilt_removal\": None,\n            \"masked_quadratic_removal\": None,\n            \"secondary_scar_removal\": None,\n            \"scar_mask\": None,\n            \"mask\": None,\n            \"final_zero_average_background\": None,\n            \"gaussian_filtered\": None,\n        }\n        self.thresholds = None\n        self.medians = {\"rows\": None, \"cols\": None}\n        self.results = {\n            \"diff\": None,\n            \"median_row_height\": None,\n            \"x_gradient\": None,\n            \"y_gradient\": None,\n            \"threshold\": None,\n        }\n\n    def median_flatten(\n        self, image: npt.NDArray, mask: npt.NDArray = None, row_alignment_quantile: float = 0.5\n    ) -&gt; npt.NDArray:\n        \"\"\"\n        Flatten images using median differences.\n\n        Flatten the rows of an image, aligning the rows and centering the median around zero. When used with a mask,\n        this has the effect of centering the background data on zero.\n\n        Note this function does not handle scars.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            2-D image of the data to align the rows of.\n        mask : npt.NDArray\n            Boolean array of points to mask (ignore).\n        row_alignment_quantile : float\n            Quantile (in the range 0.0 to 1.0) used for defining the average background.\n\n        Returns\n        -------\n        npt.NDArray\n            Copy of the input image with rows aligned.\n        \"\"\"\n        image = image.copy()\n        if mask is not None:\n            read_matrix = np.ma.masked_array(image, mask=mask, fill_value=np.nan).filled()\n            LOGGER.debug(f\"[{self.filename}] : Median flattening with mask\")\n        else:\n            read_matrix = image\n            LOGGER.debug(f\"[{self.filename}] : Median flattening without mask\")\n\n        for row in range(image.shape[0]):\n            # Get the median of the row\n            m = np.nanquantile(read_matrix[row, :], row_alignment_quantile)\n            if not np.isnan(m):\n                image[row, :] -= m\n            else:\n                LOGGER.warning(\n                    \"\"\"f[{self.filename}] Large grain detected image can not be\nprocessed, please refer to https://github.com/AFM-SPM/TopoStats/discussions for more information.\"\"\"\n                )\n\n        return image\n\n    def remove_tilt(self, image: npt.NDArray, mask: npt.NDArray = None) -&gt; npt.NDArray:\n        \"\"\"\n        Remove the planar tilt from an image (linear in 2D spaces).\n\n        Uses a linear fit of the medians of the rows and columns to determine the linear slants in x and y directions\n        and then subtracts the fit from the columns.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            2-D image of the data to remove the planar tilt from.\n        mask : npt.NDArray\n            Boolean array of points to mask (ignore).\n\n        Returns\n        -------\n        npt.NDArray\n            Numpy array of image with tilt removed.\n        \"\"\"\n        image = image.copy()\n        if mask is not None:\n            read_matrix = np.ma.masked_array(image, mask=mask, fill_value=np.nan).filled()\n            LOGGER.debug(f\"[{self.filename}] : Plane tilt removal with mask\")\n        else:\n            read_matrix = image\n            LOGGER.debug(f\"[{self.filename}] : Plane tilt removal without mask\")\n\n        # Line of best fit\n        # Calculate medians\n        medians_x = [np.nanmedian(read_matrix[:, i]) for i in range(read_matrix.shape[1])]\n        medians_y = [np.nanmedian(read_matrix[j, :]) for j in range(read_matrix.shape[0])]\n        LOGGER.debug(f\"[{self.filename}] [remove_tilt] medians_x   : {medians_x}\")\n        LOGGER.debug(f\"[{self.filename}] [remove_tilt] medians_y   : {medians_y}\")\n\n        # Fit linear x\n        px = np.polyfit(range(0, len(medians_x)), medians_x, 1)\n        LOGGER.debug(f\"[{self.filename}] : x-polyfit 1st order: {px}\")\n        py = np.polyfit(range(0, len(medians_y)), medians_y, 1)\n        LOGGER.debug(f\"[{self.filename}] : y-polyfit 1st order: {py}\")\n\n        if px[0] != 0:\n            if not np.isnan(px[0]):\n                LOGGER.debug(f\"[{self.filename}] : Removing x plane tilt\")\n                for row in range(0, image.shape[0]):\n                    for col in range(0, image.shape[1]):\n                        image[row, col] -= px[0] * (col)\n            else:\n                LOGGER.debug(f\"[{self.filename}] : x gradient is nan, skipping plane tilt x removal\")\n        else:\n            LOGGER.debug(\"[{self.filename}] : x gradient is zero, skipping plane tilt x removal\")\n\n        if py[0] != 0:\n            if not np.isnan(py[0]):\n                LOGGER.debug(f\"[{self.filename}] : removing y plane tilt\")\n                for row in range(0, image.shape[0]):\n                    for col in range(0, image.shape[1]):\n                        image[row, col] -= py[0] * (row)\n            else:\n                LOGGER.debug(\"[{self.filename}] : y gradient is nan, skipping plane tilt y removal\")\n        else:\n            LOGGER.debug(\"[{self.filename}] : y gradient is zero, skipping plane tilt y removal\")\n\n        return image\n\n    def remove_nonlinear_polynomial(self, image: npt.NDArray, mask: npt.NDArray | None = None) -&gt; npt.NDArray:\n        \"\"\"\n        Fit and remove a \"saddle\" shaped nonlinear polynomial from the image.\n\n        \"Saddles\" with the form a + b * x * y - c * x - d * y from the supplied image. AFM images sometimes contain a\n        \"saddle\" shape trend to their background, and so to remove them we fit a nonlinear polynomial of x and y and\n        then subtract the fit from the image.\n\n        If these trends are not removed, then the image will not flatten properly and will leave opposite diagonal\n        corners raised or lowered.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            2-D numpy height-map array of floats with a polynomial trend to remove.\n        mask : npt.NDArray, optional\n            2-D Numpy boolean array used to mask any points in the image that are deemed not to be part of the\n            height-map's background data.\n\n        Returns\n        -------\n        npt.NDArray\n            Image with the polynomial trend subtracted.\n        \"\"\"\n        # Script has a lot of locals but I feel this is necessary for readability?\n        # pylint: disable=too-many-locals\n\n        # Define the polynomial function to fit to the image\n        def model_func(x: float, y: float, a: float, b: float, c: float, d: float) -&gt; float:\n            \"\"\"\n            Polynomial function to fit to the image.\n\n            Parameters\n            ----------\n            x : float\n                X.\n            y : float\n                Y.\n            a : float\n                A.\n            b : float\n                B.\n            c : float\n                C.\n            d : float\n                D.\n\n            Returns\n            -------\n            float\n                Result of applying the polynomial a + (b * x * y) - (c * x) - (d * y).\n            \"\"\"\n            return a + b * x * y - c * x - d * y\n\n        image = image.copy()\n        if mask is not None:\n            read_matrix = np.ma.masked_array(image, mask=mask, fill_value=np.nan).filled()\n        else:\n            read_matrix = image\n\n        # Construct a meshgrid of x and y points for fitting to the z heights\n        xdata, ydata = np.meshgrid(np.arange(read_matrix.shape[1]), np.arange(read_matrix.shape[0]))\n        zdata = read_matrix\n\n        # Only use data that is not nan. Nans may be in the image from the\n        # masked array. Curve fitting cannot handle nans.\n        nan_mask = ~np.isnan(zdata)\n        xdata_nans_removed = xdata[nan_mask]\n        ydata_nans_removed = ydata[nan_mask]\n        zdata_nans_removed = zdata[nan_mask]\n\n        # Convert the z data to a 1D array\n        zdata = zdata.ravel()\n        zdata_nans_removed = zdata_nans_removed.ravel()\n\n        # Stack the x, y meshgrid data after converting them to 1D\n        xy_data_stacked = np.vstack((xdata_nans_removed.ravel(), ydata_nans_removed.ravel()))\n\n        # Fit the model to the data\n        # Note: pylint is flagging the tuple unpacking regarding an internal line of scipy.optimize._minpack_py : 910.\n        # This isn't actually an issue though as the extended tuple output is only provided if the 'full_output' flag is\n        # provided as a kwarg in curve_fit.\n        popt, _pcov = curve_fit(  # pylint: disable=unbalanced-tuple-unpacking\n            lambda x, a, b, c, d: model_func(x[0], x[1], a, b, c, d),\n            xy_data_stacked,\n            zdata_nans_removed,\n        )\n\n        # Unpack the optimised parameters\n        a, b, c, d = popt\n        LOGGER.debug(\n            f\"[{self.filename}] : Nonlinear polynomial removal optimal params: const: {a} xy: {b} x: {c} y: {d}\"\n        )\n\n        # Use the optimised parameters to construct a prediction of the underlying surface\n        z_pred = model_func(xdata, ydata, a, b, c, d)\n        # Subtract the fitted nonlinear polynomial from the image\n        image -= z_pred\n\n        return image\n\n    def remove_quadratic(self, image: npt.NDArray, mask: npt.NDArray = None) -&gt; npt.NDArray:\n        \"\"\"\n        Remove the quadratic bowing that can be seen in some large-scale AFM images.\n\n        Use a simple quadratic fit on the medians of the columns of the image and then subtracts the calculated\n        quadratic from the columns.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            2-D image of the data to remove the quadratic from.\n        mask : npt.NDArray\n            Boolean array of points to mask (ignore).\n\n        Returns\n        -------\n        npt.NDArray\n            Image with the quadratic bowing removed.\n        \"\"\"\n        image = image.copy()\n        if mask is not None:\n            read_matrix = np.ma.masked_array(image, mask=mask, fill_value=np.nan).filled()\n            LOGGER.debug(f\"[{self.filename}] : Remove quadratic bow with mask\")\n        else:\n            read_matrix = image\n            LOGGER.debug(f\"[{self.filename}] : Remove quadratic bow without mask\")\n\n        # Calculate medians\n        medians_x = [np.nanmedian(read_matrix[:, i]) for i in range(read_matrix.shape[1])]\n\n        # Fit quadratic x\n        px = np.polyfit(range(0, len(medians_x)), medians_x, 2)\n        LOGGER.debug(f\"[{self.filename}] : x polyfit 2nd order: {px}\")\n\n        # Handle divide by zero\n        if px[0] != 0:\n            if not np.isnan(px[0]):\n                # Remove quadratic in x\n                cx = -px[1] / (2 * px[0])\n                for row in range(0, image.shape[0]):\n                    for col in range(0, image.shape[1]):\n                        image[row, col] -= px[0] * (col - cx) ** 2\n            else:\n                LOGGER.debug(f\"[{self.filename}] : Quadratic polyfit returns nan, skipping quadratic removal\")\n        else:\n            LOGGER.debug(f\"[{self.filename}] : Quadratic polyfit returns zero, skipping quadratic removal\")\n\n        return image\n\n    @staticmethod\n    def calc_diff(array: npt.NDArray) -&gt; npt.NDArray:\n        \"\"\"\n        Calculate the difference between the last and first rows of a 2-D array.\n\n        Parameters\n        ----------\n        array : npt.NDArray\n            A Numpy array.\n\n        Returns\n        -------\n        npt.NDArray\n            An array of the difference between the last and first rows of an array.\n        \"\"\"\n        return array[-1] - array[0]\n\n    def calc_gradient(self, array: npt.NDArray, shape: int) -&gt; npt.NDArray:\n        \"\"\"\n        Calculate the gradient of an array.\n\n        Parameters\n        ----------\n        array : npt.NDArray\n            Array for gradient to be calculated.\n        shape : int\n            Shape of the array.\n\n        Returns\n        -------\n        npt.NDArray\n            Gradient across the array.\n        \"\"\"\n        return self.calc_diff(array) / shape\n\n    def average_background(self, image: npt.NDArray, mask: npt.NDArray = None) -&gt; npt.NDArray:\n        \"\"\"\n        Zero the background by subtracting the non-masked mean from all pixels.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            Numpy array representing the image.\n        mask : npt.NDArray\n            Mask of the array, should have the same dimensions as image.\n\n        Returns\n        -------\n        npt.NDArray\n            Numpy array of image zero averaged.\n        \"\"\"\n        if mask is None:\n            mask = np.zeros_like(image)\n        mean = np.mean(image[mask == 0])\n        LOGGER.debug(f\"[{self.filename}] : Zero averaging background : {mean} nm\")\n        return image - mean\n\n    def gaussian_filter(self, image: npt.NDArray, **kwargs) -&gt; npt.NDArray:\n        \"\"\"\n        Apply Gaussian filter to an image.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            Numpy array representing the image.\n        **kwargs\n            Keyword arguments passed on to the skimage.filters.gaussian() function.\n\n        Returns\n        -------\n        npt.NDArray\n            Numpy array that represent the image after Gaussian filtering.\n        \"\"\"\n        LOGGER.debug(\n            f\"[{self.filename}] : Applying Gaussian filter (mode : {self.gaussian_mode};\"\n            f\" Gaussian blur (px) : {self.gaussian_size}).\"\n        )\n        return gaussian(\n            image,\n            sigma=(self.gaussian_size),\n            mode=self.gaussian_mode,\n            **kwargs,\n        )\n\n    def filter_image(self) -&gt; None:  # numpydoc: ignore=GL07\n        \"\"\"\n        Process a single image, filtering, finding grains and calculating their statistics.\n\n        Returns\n        -------\n        None\n            Does not return anything.\n\n        Examples\n        --------\n        from topostats.io import LoadScan\n        from topostats.topotracing import Filter, process_scan\n\n        filter = Filter(image=load_scan.image,\n        ...             pixel_to_nm_scaling=load_scan.pixel_to_nm_scaling,\n        ...             filename=load_scan.filename,\n        ...             threshold_method='otsu')\n        filter.filter_image()\n        \"\"\"\n        self.images[\"initial_median_flatten\"] = self.median_flatten(\n            self.images[\"pixels\"], mask=None, row_alignment_quantile=self.row_alignment_quantile\n        )\n        self.images[\"initial_tilt_removal\"] = self.remove_tilt(self.images[\"initial_median_flatten\"], mask=None)\n        self.images[\"initial_quadratic_removal\"] = self.remove_quadratic(self.images[\"initial_tilt_removal\"], mask=None)\n        self.images[\"initial_nonlinear_polynomial_removal\"] = self.remove_nonlinear_polynomial(\n            self.images[\"initial_quadratic_removal\"], mask=None\n        )\n\n        # Remove scars\n        run_scar_removal = self.remove_scars_config.pop(\"run\")\n        if run_scar_removal:\n            LOGGER.debug(f\"[{self.filename}] : Initial scar removal\")\n            self.images[\"initial_scar_removal\"], _ = scars.remove_scars(\n                self.images[\"initial_nonlinear_polynomial_removal\"],\n                filename=self.filename,\n                **self.remove_scars_config,\n            )\n        else:\n            LOGGER.debug(f\"[{self.filename}] : Skipping scar removal as requested from config\")\n            self.images[\"initial_scar_removal\"] = self.images[\"initial_nonlinear_polynomial_removal\"]\n\n        # Zero the data before thresholding, helps with absolute thresholding\n        self.images[\"initial_zero_average_background\"] = self.average_background(\n            self.images[\"initial_scar_removal\"], mask=None\n        )\n\n        # Get the thresholds\n        try:\n            self.thresholds = get_thresholds(\n                image=self.images[\"initial_zero_average_background\"],\n                threshold_method=self.threshold_method,\n                otsu_threshold_multiplier=self.otsu_threshold_multiplier,\n                threshold_std_dev=self.threshold_std_dev,\n                absolute=self.threshold_absolute,\n            )\n        except TypeError as type_error:\n            raise type_error\n        self.images[\"mask\"] = get_mask(\n            image=self.images[\"initial_zero_average_background\"],\n            thresholds=self.thresholds,\n            img_name=self.filename,\n        )\n        self.images[\"masked_median_flatten\"] = self.median_flatten(\n            self.images[\"initial_tilt_removal\"],\n            self.images[\"mask\"],\n            row_alignment_quantile=self.row_alignment_quantile,\n        )\n        self.images[\"masked_tilt_removal\"] = self.remove_tilt(self.images[\"masked_median_flatten\"], self.images[\"mask\"])\n        self.images[\"masked_quadratic_removal\"] = self.remove_quadratic(\n            self.images[\"masked_tilt_removal\"], self.images[\"mask\"]\n        )\n        self.images[\"masked_nonlinear_polynomial_removal\"] = self.remove_nonlinear_polynomial(\n            self.images[\"masked_quadratic_removal\"], self.images[\"mask\"]\n        )\n        # Remove scars\n        if run_scar_removal:\n            LOGGER.debug(f\"[{self.filename}] : Secondary scar removal\")\n            self.images[\"secondary_scar_removal\"], scar_mask = scars.remove_scars(\n                self.images[\"masked_nonlinear_polynomial_removal\"],\n                filename=self.filename,\n                **self.remove_scars_config,\n            )\n            self.images[\"scar_mask\"] = scar_mask\n        else:\n            LOGGER.debug(f\"[{self.filename}] : Skipping scar removal as requested from config\")\n            self.images[\"secondary_scar_removal\"] = self.images[\"masked_nonlinear_polynomial_removal\"]\n        self.images[\"final_zero_average_background\"] = self.average_background(\n            self.images[\"secondary_scar_removal\"], self.images[\"mask\"]\n        )\n        self.images[\"gaussian_filtered\"] = self.gaussian_filter(self.images[\"final_zero_average_background\"])\n</code></pre>"},{"location":"api/filters/#topostats.filters.Filters.__init__","title":"<code>__init__(image, filename, pixel_to_nm_scaling, row_alignment_quantile=0.5, threshold_method='otsu', otsu_threshold_multiplier=1.7, threshold_std_dev=None, threshold_absolute=None, gaussian_size=None, gaussian_mode='nearest', remove_scars=None)</code>","text":"<p>Initialise the class.</p>"},{"location":"api/filters/#topostats.filters.Filters.__init__--parameters","title":"Parameters","text":"<p>image : npt.NDArray     The raw image from the Atomic Force Microscopy machine. filename : str     The filename (used in logging only). pixel_to_nm_scaling : float     Value for converting pixels to nanometers. row_alignment_quantile : float     Quantile (0.0 to 1.0) to be used to determine the average background for the image below values may improve     flattening of large features. threshold_method : str     Method for thresholding, default 'otsu', valid options 'otsu', 'std_dev' and 'absolute'. otsu_threshold_multiplier : float     Value for scaling the derived Otsu threshold. threshold_std_dev : dict     If using the 'std_dev' threshold method. Dictionary that contains above and below threshold values for the     number of standard deviations from the mean to threshold. threshold_absolute : dict     If using the 'absolute' threshold method. Dictionary that contains above and below absolute threshold values     for flattening. gaussian_size : float     If using the 'absolute' threshold method. Dictionary that contains above and below absolute threshold values     for flattening. gaussian_mode : str     Method passed to 'skimage.filters.gaussian(mode = gaussian_mode)'. remove_scars : dict     Dictionary containing configuration parameters for the scar removal function.</p> Source code in <code>topostats/filters.py</code> <pre><code>def __init__(\n    self,\n    image: npt.NDArray,\n    filename: str,\n    pixel_to_nm_scaling: float,\n    row_alignment_quantile: float = 0.5,\n    threshold_method: str = \"otsu\",\n    otsu_threshold_multiplier: float = 1.7,\n    threshold_std_dev: dict = None,\n    threshold_absolute: dict = None,\n    gaussian_size: float = None,\n    gaussian_mode: str = \"nearest\",\n    remove_scars: dict = None,\n):\n    \"\"\"\n    Initialise the class.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        The raw image from the Atomic Force Microscopy machine.\n    filename : str\n        The filename (used in logging only).\n    pixel_to_nm_scaling : float\n        Value for converting pixels to nanometers.\n    row_alignment_quantile : float\n        Quantile (0.0 to 1.0) to be used to determine the average background for the image below values may improve\n        flattening of large features.\n    threshold_method : str\n        Method for thresholding, default 'otsu', valid options 'otsu', 'std_dev' and 'absolute'.\n    otsu_threshold_multiplier : float\n        Value for scaling the derived Otsu threshold.\n    threshold_std_dev : dict\n        If using the 'std_dev' threshold method. Dictionary that contains above and below threshold values for the\n        number of standard deviations from the mean to threshold.\n    threshold_absolute : dict\n        If using the 'absolute' threshold method. Dictionary that contains above and below absolute threshold values\n        for flattening.\n    gaussian_size : float\n        If using the 'absolute' threshold method. Dictionary that contains above and below absolute threshold values\n        for flattening.\n    gaussian_mode : str\n        Method passed to 'skimage.filters.gaussian(mode = gaussian_mode)'.\n    remove_scars : dict\n        Dictionary containing configuration parameters for the scar removal function.\n    \"\"\"\n    self.filename = filename\n    self.pixel_to_nm_scaling = pixel_to_nm_scaling\n    self.gaussian_size = gaussian_size\n    self.gaussian_mode = gaussian_mode\n    self.row_alignment_quantile = row_alignment_quantile\n    self.threshold_method = threshold_method\n    self.otsu_threshold_multiplier = otsu_threshold_multiplier\n    self.threshold_std_dev = threshold_std_dev\n    self.threshold_absolute = threshold_absolute\n    self.remove_scars_config = remove_scars\n    self.images = {\n        \"pixels\": image,\n        \"initial_median_flatten\": None,\n        \"initial_tilt_removal\": None,\n        \"initial_quadratic_removal\": None,\n        \"initial_scar_removal\": None,\n        \"initial_zero_average_background\": None,\n        \"masked_median_flatten\": None,\n        \"masked_tilt_removal\": None,\n        \"masked_quadratic_removal\": None,\n        \"secondary_scar_removal\": None,\n        \"scar_mask\": None,\n        \"mask\": None,\n        \"final_zero_average_background\": None,\n        \"gaussian_filtered\": None,\n    }\n    self.thresholds = None\n    self.medians = {\"rows\": None, \"cols\": None}\n    self.results = {\n        \"diff\": None,\n        \"median_row_height\": None,\n        \"x_gradient\": None,\n        \"y_gradient\": None,\n        \"threshold\": None,\n    }\n</code></pre>"},{"location":"api/filters/#topostats.filters.Filters.average_background","title":"<code>average_background(image, mask=None)</code>","text":"<p>Zero the background by subtracting the non-masked mean from all pixels.</p>"},{"location":"api/filters/#topostats.filters.Filters.average_background--parameters","title":"Parameters","text":"<p>image : npt.NDArray     Numpy array representing the image. mask : npt.NDArray     Mask of the array, should have the same dimensions as image.</p>"},{"location":"api/filters/#topostats.filters.Filters.average_background--returns","title":"Returns","text":"<p>npt.NDArray     Numpy array of image zero averaged.</p> Source code in <code>topostats/filters.py</code> <pre><code>def average_background(self, image: npt.NDArray, mask: npt.NDArray = None) -&gt; npt.NDArray:\n    \"\"\"\n    Zero the background by subtracting the non-masked mean from all pixels.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        Numpy array representing the image.\n    mask : npt.NDArray\n        Mask of the array, should have the same dimensions as image.\n\n    Returns\n    -------\n    npt.NDArray\n        Numpy array of image zero averaged.\n    \"\"\"\n    if mask is None:\n        mask = np.zeros_like(image)\n    mean = np.mean(image[mask == 0])\n    LOGGER.debug(f\"[{self.filename}] : Zero averaging background : {mean} nm\")\n    return image - mean\n</code></pre>"},{"location":"api/filters/#topostats.filters.Filters.calc_diff","title":"<code>calc_diff(array)</code>  <code>staticmethod</code>","text":"<p>Calculate the difference between the last and first rows of a 2-D array.</p>"},{"location":"api/filters/#topostats.filters.Filters.calc_diff--parameters","title":"Parameters","text":"<p>array : npt.NDArray     A Numpy array.</p>"},{"location":"api/filters/#topostats.filters.Filters.calc_diff--returns","title":"Returns","text":"<p>npt.NDArray     An array of the difference between the last and first rows of an array.</p> Source code in <code>topostats/filters.py</code> <pre><code>@staticmethod\ndef calc_diff(array: npt.NDArray) -&gt; npt.NDArray:\n    \"\"\"\n    Calculate the difference between the last and first rows of a 2-D array.\n\n    Parameters\n    ----------\n    array : npt.NDArray\n        A Numpy array.\n\n    Returns\n    -------\n    npt.NDArray\n        An array of the difference between the last and first rows of an array.\n    \"\"\"\n    return array[-1] - array[0]\n</code></pre>"},{"location":"api/filters/#topostats.filters.Filters.calc_gradient","title":"<code>calc_gradient(array, shape)</code>","text":"<p>Calculate the gradient of an array.</p>"},{"location":"api/filters/#topostats.filters.Filters.calc_gradient--parameters","title":"Parameters","text":"<p>array : npt.NDArray     Array for gradient to be calculated. shape : int     Shape of the array.</p>"},{"location":"api/filters/#topostats.filters.Filters.calc_gradient--returns","title":"Returns","text":"<p>npt.NDArray     Gradient across the array.</p> Source code in <code>topostats/filters.py</code> <pre><code>def calc_gradient(self, array: npt.NDArray, shape: int) -&gt; npt.NDArray:\n    \"\"\"\n    Calculate the gradient of an array.\n\n    Parameters\n    ----------\n    array : npt.NDArray\n        Array for gradient to be calculated.\n    shape : int\n        Shape of the array.\n\n    Returns\n    -------\n    npt.NDArray\n        Gradient across the array.\n    \"\"\"\n    return self.calc_diff(array) / shape\n</code></pre>"},{"location":"api/filters/#topostats.filters.Filters.filter_image","title":"<code>filter_image()</code>","text":"<p>Process a single image, filtering, finding grains and calculating their statistics.</p>"},{"location":"api/filters/#topostats.filters.Filters.filter_image--returns","title":"Returns","text":"<p>None     Does not return anything.</p>"},{"location":"api/filters/#topostats.filters.Filters.filter_image--examples","title":"Examples","text":"<p>from topostats.io import LoadScan from topostats.topotracing import Filter, process_scan</p> <p>filter = Filter(image=load_scan.image, ...             pixel_to_nm_scaling=load_scan.pixel_to_nm_scaling, ...             filename=load_scan.filename, ...             threshold_method='otsu') filter.filter_image()</p> Source code in <code>topostats/filters.py</code> <pre><code>def filter_image(self) -&gt; None:  # numpydoc: ignore=GL07\n    \"\"\"\n    Process a single image, filtering, finding grains and calculating their statistics.\n\n    Returns\n    -------\n    None\n        Does not return anything.\n\n    Examples\n    --------\n    from topostats.io import LoadScan\n    from topostats.topotracing import Filter, process_scan\n\n    filter = Filter(image=load_scan.image,\n    ...             pixel_to_nm_scaling=load_scan.pixel_to_nm_scaling,\n    ...             filename=load_scan.filename,\n    ...             threshold_method='otsu')\n    filter.filter_image()\n    \"\"\"\n    self.images[\"initial_median_flatten\"] = self.median_flatten(\n        self.images[\"pixels\"], mask=None, row_alignment_quantile=self.row_alignment_quantile\n    )\n    self.images[\"initial_tilt_removal\"] = self.remove_tilt(self.images[\"initial_median_flatten\"], mask=None)\n    self.images[\"initial_quadratic_removal\"] = self.remove_quadratic(self.images[\"initial_tilt_removal\"], mask=None)\n    self.images[\"initial_nonlinear_polynomial_removal\"] = self.remove_nonlinear_polynomial(\n        self.images[\"initial_quadratic_removal\"], mask=None\n    )\n\n    # Remove scars\n    run_scar_removal = self.remove_scars_config.pop(\"run\")\n    if run_scar_removal:\n        LOGGER.debug(f\"[{self.filename}] : Initial scar removal\")\n        self.images[\"initial_scar_removal\"], _ = scars.remove_scars(\n            self.images[\"initial_nonlinear_polynomial_removal\"],\n            filename=self.filename,\n            **self.remove_scars_config,\n        )\n    else:\n        LOGGER.debug(f\"[{self.filename}] : Skipping scar removal as requested from config\")\n        self.images[\"initial_scar_removal\"] = self.images[\"initial_nonlinear_polynomial_removal\"]\n\n    # Zero the data before thresholding, helps with absolute thresholding\n    self.images[\"initial_zero_average_background\"] = self.average_background(\n        self.images[\"initial_scar_removal\"], mask=None\n    )\n\n    # Get the thresholds\n    try:\n        self.thresholds = get_thresholds(\n            image=self.images[\"initial_zero_average_background\"],\n            threshold_method=self.threshold_method,\n            otsu_threshold_multiplier=self.otsu_threshold_multiplier,\n            threshold_std_dev=self.threshold_std_dev,\n            absolute=self.threshold_absolute,\n        )\n    except TypeError as type_error:\n        raise type_error\n    self.images[\"mask\"] = get_mask(\n        image=self.images[\"initial_zero_average_background\"],\n        thresholds=self.thresholds,\n        img_name=self.filename,\n    )\n    self.images[\"masked_median_flatten\"] = self.median_flatten(\n        self.images[\"initial_tilt_removal\"],\n        self.images[\"mask\"],\n        row_alignment_quantile=self.row_alignment_quantile,\n    )\n    self.images[\"masked_tilt_removal\"] = self.remove_tilt(self.images[\"masked_median_flatten\"], self.images[\"mask\"])\n    self.images[\"masked_quadratic_removal\"] = self.remove_quadratic(\n        self.images[\"masked_tilt_removal\"], self.images[\"mask\"]\n    )\n    self.images[\"masked_nonlinear_polynomial_removal\"] = self.remove_nonlinear_polynomial(\n        self.images[\"masked_quadratic_removal\"], self.images[\"mask\"]\n    )\n    # Remove scars\n    if run_scar_removal:\n        LOGGER.debug(f\"[{self.filename}] : Secondary scar removal\")\n        self.images[\"secondary_scar_removal\"], scar_mask = scars.remove_scars(\n            self.images[\"masked_nonlinear_polynomial_removal\"],\n            filename=self.filename,\n            **self.remove_scars_config,\n        )\n        self.images[\"scar_mask\"] = scar_mask\n    else:\n        LOGGER.debug(f\"[{self.filename}] : Skipping scar removal as requested from config\")\n        self.images[\"secondary_scar_removal\"] = self.images[\"masked_nonlinear_polynomial_removal\"]\n    self.images[\"final_zero_average_background\"] = self.average_background(\n        self.images[\"secondary_scar_removal\"], self.images[\"mask\"]\n    )\n    self.images[\"gaussian_filtered\"] = self.gaussian_filter(self.images[\"final_zero_average_background\"])\n</code></pre>"},{"location":"api/filters/#topostats.filters.Filters.gaussian_filter","title":"<code>gaussian_filter(image, **kwargs)</code>","text":"<p>Apply Gaussian filter to an image.</p>"},{"location":"api/filters/#topostats.filters.Filters.gaussian_filter--parameters","title":"Parameters","text":"<p>image : npt.NDArray     Numpy array representing the image. **kwargs     Keyword arguments passed on to the skimage.filters.gaussian() function.</p>"},{"location":"api/filters/#topostats.filters.Filters.gaussian_filter--returns","title":"Returns","text":"<p>npt.NDArray     Numpy array that represent the image after Gaussian filtering.</p> Source code in <code>topostats/filters.py</code> <pre><code>def gaussian_filter(self, image: npt.NDArray, **kwargs) -&gt; npt.NDArray:\n    \"\"\"\n    Apply Gaussian filter to an image.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        Numpy array representing the image.\n    **kwargs\n        Keyword arguments passed on to the skimage.filters.gaussian() function.\n\n    Returns\n    -------\n    npt.NDArray\n        Numpy array that represent the image after Gaussian filtering.\n    \"\"\"\n    LOGGER.debug(\n        f\"[{self.filename}] : Applying Gaussian filter (mode : {self.gaussian_mode};\"\n        f\" Gaussian blur (px) : {self.gaussian_size}).\"\n    )\n    return gaussian(\n        image,\n        sigma=(self.gaussian_size),\n        mode=self.gaussian_mode,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/filters/#topostats.filters.Filters.median_flatten","title":"<code>median_flatten(image, mask=None, row_alignment_quantile=0.5)</code>","text":"<p>Flatten images using median differences.</p> <p>Flatten the rows of an image, aligning the rows and centering the median around zero. When used with a mask, this has the effect of centering the background data on zero.</p> <p>Note this function does not handle scars.</p>"},{"location":"api/filters/#topostats.filters.Filters.median_flatten--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D image of the data to align the rows of. mask : npt.NDArray     Boolean array of points to mask (ignore). row_alignment_quantile : float     Quantile (in the range 0.0 to 1.0) used for defining the average background.</p>"},{"location":"api/filters/#topostats.filters.Filters.median_flatten--returns","title":"Returns","text":"<p>npt.NDArray     Copy of the input image with rows aligned.</p> Source code in <code>topostats/filters.py</code> <pre><code>    def median_flatten(\n        self, image: npt.NDArray, mask: npt.NDArray = None, row_alignment_quantile: float = 0.5\n    ) -&gt; npt.NDArray:\n        \"\"\"\n        Flatten images using median differences.\n\n        Flatten the rows of an image, aligning the rows and centering the median around zero. When used with a mask,\n        this has the effect of centering the background data on zero.\n\n        Note this function does not handle scars.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            2-D image of the data to align the rows of.\n        mask : npt.NDArray\n            Boolean array of points to mask (ignore).\n        row_alignment_quantile : float\n            Quantile (in the range 0.0 to 1.0) used for defining the average background.\n\n        Returns\n        -------\n        npt.NDArray\n            Copy of the input image with rows aligned.\n        \"\"\"\n        image = image.copy()\n        if mask is not None:\n            read_matrix = np.ma.masked_array(image, mask=mask, fill_value=np.nan).filled()\n            LOGGER.debug(f\"[{self.filename}] : Median flattening with mask\")\n        else:\n            read_matrix = image\n            LOGGER.debug(f\"[{self.filename}] : Median flattening without mask\")\n\n        for row in range(image.shape[0]):\n            # Get the median of the row\n            m = np.nanquantile(read_matrix[row, :], row_alignment_quantile)\n            if not np.isnan(m):\n                image[row, :] -= m\n            else:\n                LOGGER.warning(\n                    \"\"\"f[{self.filename}] Large grain detected image can not be\nprocessed, please refer to https://github.com/AFM-SPM/TopoStats/discussions for more information.\"\"\"\n                )\n\n        return image\n</code></pre>"},{"location":"api/filters/#topostats.filters.Filters.remove_nonlinear_polynomial","title":"<code>remove_nonlinear_polynomial(image, mask=None)</code>","text":"<p>Fit and remove a \"saddle\" shaped nonlinear polynomial from the image.</p> <p>\"Saddles\" with the form a + b * x * y - c * x - d * y from the supplied image. AFM images sometimes contain a \"saddle\" shape trend to their background, and so to remove them we fit a nonlinear polynomial of x and y and then subtract the fit from the image.</p> <p>If these trends are not removed, then the image will not flatten properly and will leave opposite diagonal corners raised or lowered.</p>"},{"location":"api/filters/#topostats.filters.Filters.remove_nonlinear_polynomial--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D numpy height-map array of floats with a polynomial trend to remove. mask : npt.NDArray, optional     2-D Numpy boolean array used to mask any points in the image that are deemed not to be part of the     height-map's background data.</p>"},{"location":"api/filters/#topostats.filters.Filters.remove_nonlinear_polynomial--returns","title":"Returns","text":"<p>npt.NDArray     Image with the polynomial trend subtracted.</p> Source code in <code>topostats/filters.py</code> <pre><code>def remove_nonlinear_polynomial(self, image: npt.NDArray, mask: npt.NDArray | None = None) -&gt; npt.NDArray:\n    \"\"\"\n    Fit and remove a \"saddle\" shaped nonlinear polynomial from the image.\n\n    \"Saddles\" with the form a + b * x * y - c * x - d * y from the supplied image. AFM images sometimes contain a\n    \"saddle\" shape trend to their background, and so to remove them we fit a nonlinear polynomial of x and y and\n    then subtract the fit from the image.\n\n    If these trends are not removed, then the image will not flatten properly and will leave opposite diagonal\n    corners raised or lowered.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2-D numpy height-map array of floats with a polynomial trend to remove.\n    mask : npt.NDArray, optional\n        2-D Numpy boolean array used to mask any points in the image that are deemed not to be part of the\n        height-map's background data.\n\n    Returns\n    -------\n    npt.NDArray\n        Image with the polynomial trend subtracted.\n    \"\"\"\n    # Script has a lot of locals but I feel this is necessary for readability?\n    # pylint: disable=too-many-locals\n\n    # Define the polynomial function to fit to the image\n    def model_func(x: float, y: float, a: float, b: float, c: float, d: float) -&gt; float:\n        \"\"\"\n        Polynomial function to fit to the image.\n\n        Parameters\n        ----------\n        x : float\n            X.\n        y : float\n            Y.\n        a : float\n            A.\n        b : float\n            B.\n        c : float\n            C.\n        d : float\n            D.\n\n        Returns\n        -------\n        float\n            Result of applying the polynomial a + (b * x * y) - (c * x) - (d * y).\n        \"\"\"\n        return a + b * x * y - c * x - d * y\n\n    image = image.copy()\n    if mask is not None:\n        read_matrix = np.ma.masked_array(image, mask=mask, fill_value=np.nan).filled()\n    else:\n        read_matrix = image\n\n    # Construct a meshgrid of x and y points for fitting to the z heights\n    xdata, ydata = np.meshgrid(np.arange(read_matrix.shape[1]), np.arange(read_matrix.shape[0]))\n    zdata = read_matrix\n\n    # Only use data that is not nan. Nans may be in the image from the\n    # masked array. Curve fitting cannot handle nans.\n    nan_mask = ~np.isnan(zdata)\n    xdata_nans_removed = xdata[nan_mask]\n    ydata_nans_removed = ydata[nan_mask]\n    zdata_nans_removed = zdata[nan_mask]\n\n    # Convert the z data to a 1D array\n    zdata = zdata.ravel()\n    zdata_nans_removed = zdata_nans_removed.ravel()\n\n    # Stack the x, y meshgrid data after converting them to 1D\n    xy_data_stacked = np.vstack((xdata_nans_removed.ravel(), ydata_nans_removed.ravel()))\n\n    # Fit the model to the data\n    # Note: pylint is flagging the tuple unpacking regarding an internal line of scipy.optimize._minpack_py : 910.\n    # This isn't actually an issue though as the extended tuple output is only provided if the 'full_output' flag is\n    # provided as a kwarg in curve_fit.\n    popt, _pcov = curve_fit(  # pylint: disable=unbalanced-tuple-unpacking\n        lambda x, a, b, c, d: model_func(x[0], x[1], a, b, c, d),\n        xy_data_stacked,\n        zdata_nans_removed,\n    )\n\n    # Unpack the optimised parameters\n    a, b, c, d = popt\n    LOGGER.debug(\n        f\"[{self.filename}] : Nonlinear polynomial removal optimal params: const: {a} xy: {b} x: {c} y: {d}\"\n    )\n\n    # Use the optimised parameters to construct a prediction of the underlying surface\n    z_pred = model_func(xdata, ydata, a, b, c, d)\n    # Subtract the fitted nonlinear polynomial from the image\n    image -= z_pred\n\n    return image\n</code></pre>"},{"location":"api/filters/#topostats.filters.Filters.remove_quadratic","title":"<code>remove_quadratic(image, mask=None)</code>","text":"<p>Remove the quadratic bowing that can be seen in some large-scale AFM images.</p> <p>Use a simple quadratic fit on the medians of the columns of the image and then subtracts the calculated quadratic from the columns.</p>"},{"location":"api/filters/#topostats.filters.Filters.remove_quadratic--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D image of the data to remove the quadratic from. mask : npt.NDArray     Boolean array of points to mask (ignore).</p>"},{"location":"api/filters/#topostats.filters.Filters.remove_quadratic--returns","title":"Returns","text":"<p>npt.NDArray     Image with the quadratic bowing removed.</p> Source code in <code>topostats/filters.py</code> <pre><code>def remove_quadratic(self, image: npt.NDArray, mask: npt.NDArray = None) -&gt; npt.NDArray:\n    \"\"\"\n    Remove the quadratic bowing that can be seen in some large-scale AFM images.\n\n    Use a simple quadratic fit on the medians of the columns of the image and then subtracts the calculated\n    quadratic from the columns.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2-D image of the data to remove the quadratic from.\n    mask : npt.NDArray\n        Boolean array of points to mask (ignore).\n\n    Returns\n    -------\n    npt.NDArray\n        Image with the quadratic bowing removed.\n    \"\"\"\n    image = image.copy()\n    if mask is not None:\n        read_matrix = np.ma.masked_array(image, mask=mask, fill_value=np.nan).filled()\n        LOGGER.debug(f\"[{self.filename}] : Remove quadratic bow with mask\")\n    else:\n        read_matrix = image\n        LOGGER.debug(f\"[{self.filename}] : Remove quadratic bow without mask\")\n\n    # Calculate medians\n    medians_x = [np.nanmedian(read_matrix[:, i]) for i in range(read_matrix.shape[1])]\n\n    # Fit quadratic x\n    px = np.polyfit(range(0, len(medians_x)), medians_x, 2)\n    LOGGER.debug(f\"[{self.filename}] : x polyfit 2nd order: {px}\")\n\n    # Handle divide by zero\n    if px[0] != 0:\n        if not np.isnan(px[0]):\n            # Remove quadratic in x\n            cx = -px[1] / (2 * px[0])\n            for row in range(0, image.shape[0]):\n                for col in range(0, image.shape[1]):\n                    image[row, col] -= px[0] * (col - cx) ** 2\n        else:\n            LOGGER.debug(f\"[{self.filename}] : Quadratic polyfit returns nan, skipping quadratic removal\")\n    else:\n        LOGGER.debug(f\"[{self.filename}] : Quadratic polyfit returns zero, skipping quadratic removal\")\n\n    return image\n</code></pre>"},{"location":"api/filters/#topostats.filters.Filters.remove_tilt","title":"<code>remove_tilt(image, mask=None)</code>","text":"<p>Remove the planar tilt from an image (linear in 2D spaces).</p> <p>Uses a linear fit of the medians of the rows and columns to determine the linear slants in x and y directions and then subtracts the fit from the columns.</p>"},{"location":"api/filters/#topostats.filters.Filters.remove_tilt--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D image of the data to remove the planar tilt from. mask : npt.NDArray     Boolean array of points to mask (ignore).</p>"},{"location":"api/filters/#topostats.filters.Filters.remove_tilt--returns","title":"Returns","text":"<p>npt.NDArray     Numpy array of image with tilt removed.</p> Source code in <code>topostats/filters.py</code> <pre><code>def remove_tilt(self, image: npt.NDArray, mask: npt.NDArray = None) -&gt; npt.NDArray:\n    \"\"\"\n    Remove the planar tilt from an image (linear in 2D spaces).\n\n    Uses a linear fit of the medians of the rows and columns to determine the linear slants in x and y directions\n    and then subtracts the fit from the columns.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2-D image of the data to remove the planar tilt from.\n    mask : npt.NDArray\n        Boolean array of points to mask (ignore).\n\n    Returns\n    -------\n    npt.NDArray\n        Numpy array of image with tilt removed.\n    \"\"\"\n    image = image.copy()\n    if mask is not None:\n        read_matrix = np.ma.masked_array(image, mask=mask, fill_value=np.nan).filled()\n        LOGGER.debug(f\"[{self.filename}] : Plane tilt removal with mask\")\n    else:\n        read_matrix = image\n        LOGGER.debug(f\"[{self.filename}] : Plane tilt removal without mask\")\n\n    # Line of best fit\n    # Calculate medians\n    medians_x = [np.nanmedian(read_matrix[:, i]) for i in range(read_matrix.shape[1])]\n    medians_y = [np.nanmedian(read_matrix[j, :]) for j in range(read_matrix.shape[0])]\n    LOGGER.debug(f\"[{self.filename}] [remove_tilt] medians_x   : {medians_x}\")\n    LOGGER.debug(f\"[{self.filename}] [remove_tilt] medians_y   : {medians_y}\")\n\n    # Fit linear x\n    px = np.polyfit(range(0, len(medians_x)), medians_x, 1)\n    LOGGER.debug(f\"[{self.filename}] : x-polyfit 1st order: {px}\")\n    py = np.polyfit(range(0, len(medians_y)), medians_y, 1)\n    LOGGER.debug(f\"[{self.filename}] : y-polyfit 1st order: {py}\")\n\n    if px[0] != 0:\n        if not np.isnan(px[0]):\n            LOGGER.debug(f\"[{self.filename}] : Removing x plane tilt\")\n            for row in range(0, image.shape[0]):\n                for col in range(0, image.shape[1]):\n                    image[row, col] -= px[0] * (col)\n        else:\n            LOGGER.debug(f\"[{self.filename}] : x gradient is nan, skipping plane tilt x removal\")\n    else:\n        LOGGER.debug(\"[{self.filename}] : x gradient is zero, skipping plane tilt x removal\")\n\n    if py[0] != 0:\n        if not np.isnan(py[0]):\n            LOGGER.debug(f\"[{self.filename}] : removing y plane tilt\")\n            for row in range(0, image.shape[0]):\n                for col in range(0, image.shape[1]):\n                    image[row, col] -= py[0] * (row)\n        else:\n            LOGGER.debug(\"[{self.filename}] : y gradient is nan, skipping plane tilt y removal\")\n    else:\n        LOGGER.debug(\"[{self.filename}] : y gradient is zero, skipping plane tilt y removal\")\n\n    return image\n</code></pre>"},{"location":"api/grains/","title":"Grains Modules","text":"<p>Find grains in an image.</p> <p>handler: python options: docstring_style: numpy rendering: show_signature_annotations: true</p>"},{"location":"api/grains/#topostats.grains.Grains","title":"<code>Grains</code>","text":"<p>Find grains in an image.</p>"},{"location":"api/grains/#topostats.grains.Grains--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D Numpy array of image. filename : str     File being processed (used in logging). pixel_to_nm_scaling : float     Scaling of pixels to nanometres. unet_config : dict[str, str | int | float | tuple[int | None, int, int, int] | None]     Configuration for the UNet model.     model_path: str         Path to the UNet model.     grain_crop_padding: int         Padding to add to the bounding box of the grain before cropping.     upper_norm_bound: float         Upper bound for normalising the image.     lower_norm_bound: float         Lower bound for normalising the image. threshold_method : str     Method for determining thershold to mask values, default is 'otsu'. otsu_threshold_multiplier : float     Factor by which the below threshold is to be scaled prior to masking. threshold_std_dev : dict     Dictionary of 'below' and 'above' factors by which standard deviation is multiplied to derive the threshold     if threshold_method is 'std_dev'. threshold_absolute : dict     Dictionary of absolute 'below' and 'above' thresholds for grain finding. absolute_area_threshold : dict     Dictionary of above and below grain's area thresholds. direction : str     Direction for which grains are to be detected, valid values are 'above', 'below' and 'both'. smallest_grain_size_nm2 : float     Whether or not to remove grains that intersect the edge of the image. remove_edge_intersecting_grains : bool     Direction for which grains are to be detected, valid values are 'above', 'below' and 'both'. classes_to_merge : list[tuple[int, int]] | None     List of tuples of classes to merge. vetting : dict | None     Dictionary of vetting parameters.</p> Source code in <code>topostats/grains.py</code> <pre><code>class Grains:\n    \"\"\"\n    Find grains in an image.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2-D Numpy array of image.\n    filename : str\n        File being processed (used in logging).\n    pixel_to_nm_scaling : float\n        Scaling of pixels to nanometres.\n    unet_config : dict[str, str | int | float | tuple[int | None, int, int, int] | None]\n        Configuration for the UNet model.\n        model_path: str\n            Path to the UNet model.\n        grain_crop_padding: int\n            Padding to add to the bounding box of the grain before cropping.\n        upper_norm_bound: float\n            Upper bound for normalising the image.\n        lower_norm_bound: float\n            Lower bound for normalising the image.\n    threshold_method : str\n        Method for determining thershold to mask values, default is 'otsu'.\n    otsu_threshold_multiplier : float\n        Factor by which the below threshold is to be scaled prior to masking.\n    threshold_std_dev : dict\n        Dictionary of 'below' and 'above' factors by which standard deviation is multiplied to derive the threshold\n        if threshold_method is 'std_dev'.\n    threshold_absolute : dict\n        Dictionary of absolute 'below' and 'above' thresholds for grain finding.\n    absolute_area_threshold : dict\n        Dictionary of above and below grain's area thresholds.\n    direction : str\n        Direction for which grains are to be detected, valid values are 'above', 'below' and 'both'.\n    smallest_grain_size_nm2 : float\n        Whether or not to remove grains that intersect the edge of the image.\n    remove_edge_intersecting_grains : bool\n        Direction for which grains are to be detected, valid values are 'above', 'below' and 'both'.\n    classes_to_merge : list[tuple[int, int]] | None\n        List of tuples of classes to merge.\n    vetting : dict | None\n        Dictionary of vetting parameters.\n    \"\"\"\n\n    def __init__(\n        self,\n        image: npt.NDArray,\n        filename: str,\n        pixel_to_nm_scaling: float,\n        unet_config: dict[str, str | int | float | tuple[int | None, int, int, int] | None] | None = None,\n        threshold_method: str | None = None,\n        otsu_threshold_multiplier: float | None = None,\n        threshold_std_dev: dict | None = None,\n        threshold_absolute: dict | None = None,\n        absolute_area_threshold: dict | None = None,\n        direction: str | None = None,\n        smallest_grain_size_nm2: float | None = None,\n        remove_edge_intersecting_grains: bool = True,\n        classes_to_merge: list[tuple[int, int]] | None = None,\n        vetting: dict | None = None,\n    ):\n        \"\"\"\n        Initialise the class.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            2-D Numpy array of image.\n        filename : str\n            File being processed (used in logging).\n        pixel_to_nm_scaling : float\n            Scaling of pixels to nanometres.\n        unet_config : dict[str, str | int | float | tuple[int | None, int, int, int] | None]\n            Configuration for the UNet model which is a dictionary with the following keys and values.\n            model_path : str\n                Path to the UNet model.\n            grain_crop_padding : int\n                Padding to add to the bounding box of the grain before cropping.\n            upper_norm_bound : float\n                Upper bound for normalising the image.\n            lower_norm_bound : float\n                Lower bound for normalising the image.\n        threshold_method : str\n            Method for determining thershold to mask values, default is 'otsu'.\n        otsu_threshold_multiplier : float\n            Factor by which the below threshold is to be scaled prior to masking.\n        threshold_std_dev : dict\n            Dictionary of 'below' and 'above' factors by which standard deviation is multiplied to derive the threshold\n            if threshold_method is 'std_dev'.\n        threshold_absolute : dict\n            Dictionary of absolute 'below' and 'above' thresholds for grain finding.\n        absolute_area_threshold : dict\n            Dictionary of above and below grain's area thresholds.\n        direction : str\n            Direction for which grains are to be detected, valid values are 'above', 'below' and 'both'.\n        smallest_grain_size_nm2 : float\n            Whether or not to remove grains that intersect the edge of the image.\n        remove_edge_intersecting_grains : bool\n            Direction for which grains are to be detected, valid values are 'above', 'below' and 'both'.\n        classes_to_merge : list[tuple[int, int]] | None\n            List of tuples of classes to merge.\n        vetting : dict | None\n            Dictionary of vetting parameters.\n        \"\"\"\n        if unet_config is None:\n            unet_config = {\n                \"model_path\": None,\n                \"grain_crop_padding\": 0,\n                \"upper_norm_bound\": 1.0,\n                \"lower_norm_bound\": 0.0,\n            }\n        if absolute_area_threshold is None:\n            absolute_area_threshold = {\"above\": [None, None], \"below\": [None, None]}\n        self.image = image\n        self.filename = filename\n        self.pixel_to_nm_scaling = pixel_to_nm_scaling\n        self.threshold_method = threshold_method\n        self.otsu_threshold_multiplier = otsu_threshold_multiplier\n        self.threshold_std_dev = threshold_std_dev\n        self.threshold_absolute = threshold_absolute\n        self.absolute_area_threshold = absolute_area_threshold\n        # Only detect grains for the desired direction\n        self.direction = [direction] if direction != \"both\" else [\"above\", \"below\"]\n        self.smallest_grain_size_nm2 = smallest_grain_size_nm2\n        self.remove_edge_intersecting_grains = remove_edge_intersecting_grains\n        self.thresholds = None\n        self.images = {\n            \"mask_grains\": None,\n            \"tidied_border\": None,\n            \"tiny_objects_removed\": None,\n            \"objects_removed\": None,\n            # \"labelled_regions\": None,\n            # \"coloured_regions\": None,\n        }\n        self.directions = defaultdict()\n        self.minimum_grain_size = None\n        self.region_properties = defaultdict()\n        self.bounding_boxes = defaultdict()\n        self.grainstats = None\n        self.unet_config = unet_config\n        self.vetting = vetting\n        self.classes_to_merge = classes_to_merge\n\n        # Hardcoded minimum pixel size for grains. This should not be able to be changed by the user as this is\n        # determined by what is processable by the rest of the pipeline.\n        self.minimum_grain_size_px = 10\n        self.minimum_bbox_size_px = 5\n\n    def tidy_border(self, image: npt.NDArray, **kwargs) -&gt; npt.NDArray:\n        \"\"\"\n        Remove grains touching the border.\n\n        Parameters\n        ----------\n        image : npt.NDarray\n            2-D Numpy array representing the image.\n        **kwargs\n            Arguments passed to 'skimage.segmentation.clear_border(**kwargs)'.\n\n        Returns\n        -------\n        npt.NDarray\n            2-D Numpy array of image without objects touching the border.\n        \"\"\"\n        LOGGER.debug(f\"[{self.filename}] : Tidying borders\")\n        return clear_border(image, **kwargs)\n\n    @staticmethod\n    def label_regions(image: npt.NDArray, background: int = 0) -&gt; npt.NDArray:\n        \"\"\"\n        Label regions.\n\n        This method is used twice, once prior to removal of small regions and again afterwards which is why an image\n        must be supplied rather than using 'self'.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            2-D Numpy array of image.\n        background : int\n            Value used to indicate background of image. Default = 0.\n\n        Returns\n        -------\n        npt.NDArray\n            2-D Numpy array of image with regions numbered.\n        \"\"\"\n        return morphology.label(image, background)\n\n    def calc_minimum_grain_size(self, image: npt.NDArray) -&gt; float:\n        \"\"\"\n        Calculate the minimum grain size in pixels squared.\n\n        Very small objects are first removed via thresholding before calculating the below extreme.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            2-D Numpy image from which to calculate the minimum grain size.\n\n        Returns\n        -------\n        float\n            Minimum grains size in pixels squared. If there are areas a value of -1 is returned.\n        \"\"\"\n        region_properties = self.get_region_properties(image)\n        grain_areas = np.array([grain.area for grain in region_properties])\n        if len(grain_areas &gt; 0):\n            # Exclude small objects less than a given threshold first\n            grain_areas = grain_areas[\n                grain_areas &gt;= threshold(grain_areas, method=\"otsu\", otsu_threshold_multiplier=1.0)\n            ]\n            self.minimum_grain_size = np.median(grain_areas) - (\n                1.5 * (np.quantile(grain_areas, 0.75) - np.quantile(grain_areas, 0.25))\n            )\n        else:\n            self.minimum_grain_size = -1\n\n    def remove_noise(self, image: npt.NDArray, **kwargs) -&gt; npt.NDArray:\n        \"\"\"\n        Remove noise which are objects smaller than the 'smallest_grain_size_nm2'.\n\n        This ensures that the smallest objects ~1px are removed regardless of the size distribution of the grains.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            2-D Numpy array to be cleaned.\n        **kwargs\n            Arguments passed to 'skimage.morphology.remove_small_objects(**kwargs)'.\n\n        Returns\n        -------\n        npt.NDArray\n            2-D Numpy array of image with objects &lt; smallest_grain_size_nm2 removed.\n        \"\"\"\n        LOGGER.debug(\n            f\"[{self.filename}] : Removing noise (&lt; {self.smallest_grain_size_nm2} nm^2\"\n            \"{self.smallest_grain_size_nm2 / (self.pixel_to_nm_scaling**2):.2f} px^2)\"\n        )\n        return morphology.remove_small_objects(\n            image, min_size=self.smallest_grain_size_nm2 / (self.pixel_to_nm_scaling**2), **kwargs\n        )\n\n    def remove_small_objects(self, image: np.array, **kwargs) -&gt; npt.NDArray:\n        \"\"\"\n        Remove small objects from the input image.\n\n        Threshold determined by the minimum grain size, in pixels squared, of the classes initialisation.\n\n        Parameters\n        ----------\n        image : np.array\n            2-D Numpy array to remove small objects from.\n        **kwargs\n            Arguments passed to 'skimage.morphology.remove_small_objects(**kwargs)'.\n\n        Returns\n        -------\n        npt.NDArray\n            2-D Numpy array of image with objects &lt; minimumm_grain_size removed.\n        \"\"\"\n        # If self.minimum_grain_size is -1, then this means that\n        # there were no grains to calculate the minimum grian size from.\n        if self.minimum_grain_size != -1:\n            small_objects_removed = morphology.remove_small_objects(\n                image.astype(bool),\n                min_size=self.minimum_grain_size,  # minimum_grain_size is in pixels squared\n                **kwargs,\n            )\n            LOGGER.debug(\n                f\"[{self.filename}] : Removed small objects (&lt; \\\n{self.minimum_grain_size} px^2 / {self.minimum_grain_size / (self.pixel_to_nm_scaling)**2} nm^2)\"\n            )\n            return small_objects_removed &gt; 0.0\n        return image\n\n    def remove_objects_too_small_to_process(\n        self, image: npt.NDArray, minimum_size_px: int, minimum_bbox_size_px: int\n    ) -&gt; npt.NDArray[np.bool_]:\n        \"\"\"\n        Remove objects whose dimensions in pixels are too small to process.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            2-D Numpy array of image.\n        minimum_size_px : int\n            Minimum number of pixels for an object.\n        minimum_bbox_size_px : int\n            Limit for the minimum dimension of an object in pixels. Eg: 5 means the object's bounding box must be at\n            least 5x5.\n\n        Returns\n        -------\n        npt.NDArray\n            2-D Numpy array of image with objects removed that are too small to process.\n        \"\"\"\n        labelled_image = label(image)\n        region_properties = self.get_region_properties(labelled_image)\n        for region in region_properties:\n            # If the number of true pixels in the region is less than the minimum number of pixels, remove the region\n            if region.area &lt; minimum_size_px:\n                labelled_image[labelled_image == region.label] = 0\n            bbox_width = region.bbox[2] - region.bbox[0]\n            bbox_height = region.bbox[3] - region.bbox[1]\n            # If the minimum dimension of the bounding box is less than the minimum dimension, remove the region\n            if min(bbox_width, bbox_height) &lt; minimum_bbox_size_px:\n                labelled_image[labelled_image == region.label] = 0\n\n        return labelled_image.astype(bool)\n\n    def area_thresholding(self, image: npt.NDArray, area_thresholds: tuple) -&gt; npt.NDArray:\n        \"\"\"\n        Remove objects larger and smaller than the specified thresholds.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            Image array where the background == 0 and grains are labelled as integers &gt;0.\n        area_thresholds : tuple\n            List of area thresholds (in nanometres squared, not pixels squared), first is the lower limit for size,\n            second is the upper.\n\n        Returns\n        -------\n        npt.NDArray\n            Array with small and large objects removed.\n        \"\"\"\n        image_cp = image.copy()\n        lower_size_limit, upper_size_limit = area_thresholds\n        # if one value is None adjust for comparison\n        if upper_size_limit is None:\n            upper_size_limit = image.size * self.pixel_to_nm_scaling**2\n        if lower_size_limit is None:\n            lower_size_limit = 0\n        # Get array of grain numbers (discounting zero)\n        uniq = np.delete(np.unique(image), 0)\n        grain_count = 0\n        LOGGER.debug(\n            f\"[{self.filename}] : Area thresholding grains | Thresholds: L: {(lower_size_limit / self.pixel_to_nm_scaling**2):.2f},\"\n            f\"U: {(upper_size_limit / self.pixel_to_nm_scaling**2):.2f} px^2, L: {lower_size_limit:.2f}, U: {upper_size_limit:.2f} nm^2.\"\n        )\n        for grain_no in uniq:  # Calculate grian area in nm^2\n            grain_area = np.sum(image_cp == grain_no) * (self.pixel_to_nm_scaling**2)\n            # Compare area in nm^2 to area thresholds\n            if grain_area &gt; upper_size_limit or grain_area &lt; lower_size_limit:\n                image_cp[image_cp == grain_no] = 0\n            else:\n                grain_count += 1\n                image_cp[image_cp == grain_no] = grain_count\n        return image_cp\n\n    def colour_regions(self, image: npt.NDArray, **kwargs) -&gt; npt.NDArray:\n        \"\"\"\n        Colour the regions.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            2-D array of labelled regions to be coloured.\n        **kwargs\n            Arguments passed to 'skimage.color.label2rgb(**kwargs)'.\n\n        Returns\n        -------\n        np.array\n            Numpy array of image with objects coloured.\n        \"\"\"\n        coloured_regions = label2rgb(image, **kwargs)\n        LOGGER.debug(f\"[{self.filename}] : Coloured regions\")\n        return coloured_regions\n\n    @staticmethod\n    def get_region_properties(image: np.array, **kwargs) -&gt; list:\n        \"\"\"\n        Extract the properties of each region.\n\n        Parameters\n        ----------\n        image : np.array\n            Numpy array representing image.\n        **kwargs :\n            Arguments passed to 'skimage.measure.regionprops(**kwargs)'.\n\n        Returns\n        -------\n        list\n            List of region property objects.\n        \"\"\"\n        return regionprops(image, **kwargs)\n\n    def get_bounding_boxes(self, direction: str) -&gt; dict:\n        \"\"\"\n        Derive a list of bounding boxes for each region from the derived region_properties.\n\n        Parameters\n        ----------\n        direction : str\n            Direction of threshold for which bounding boxes are being calculated.\n\n        Returns\n        -------\n        dict\n            Dictionary of bounding boxes indexed by region area.\n        \"\"\"\n        return {region.area: region.area_bbox for region in self.region_properties[direction]}\n\n    def find_grains(self):\n        \"\"\"Find grains.\"\"\"\n        LOGGER.debug(f\"[{self.filename}] : Thresholding method (grains) : {self.threshold_method}\")\n        self.thresholds = get_thresholds(\n            image=self.image,\n            threshold_method=self.threshold_method,\n            otsu_threshold_multiplier=self.otsu_threshold_multiplier,\n            threshold_std_dev=self.threshold_std_dev,\n            absolute=self.threshold_absolute,\n        )\n\n        for direction in self.direction:\n            LOGGER.debug(f\"[{self.filename}] : Finding {direction} grains, threshold: ({self.thresholds[direction]})\")\n            self.directions[direction] = {}\n            self.directions[direction][\"mask_grains\"] = _get_mask(\n                self.image,\n                thresh=self.thresholds[direction],\n                threshold_direction=direction,\n                img_name=self.filename,\n            )\n            self.directions[direction][\"labelled_regions_01\"] = self.label_regions(\n                self.directions[direction][\"mask_grains\"]\n            )\n\n            if self.remove_edge_intersecting_grains:\n                self.directions[direction][\"tidied_border\"] = self.tidy_border(\n                    self.directions[direction][\"labelled_regions_01\"]\n                )\n            else:\n                self.directions[direction][\"tidied_border\"] = self.directions[direction][\"labelled_regions_01\"]\n\n            LOGGER.debug(f\"[{self.filename}] : Removing noise ({direction})\")\n            self.directions[direction][\"removed_noise\"] = self.area_thresholding(\n                self.directions[direction][\"tidied_border\"],\n                [self.smallest_grain_size_nm2, None],\n            )\n\n            LOGGER.debug(f\"[{self.filename}] : Removing small / large grains ({direction})\")\n            # if no area thresholds specified, use otsu\n            if self.absolute_area_threshold[direction].count(None) == 2:\n                self.calc_minimum_grain_size(self.directions[direction][\"removed_noise\"])\n                self.directions[direction][\"removed_small_objects\"] = self.remove_small_objects(\n                    self.directions[direction][\"removed_noise\"]\n                )\n            else:\n                self.directions[direction][\"removed_small_objects\"] = self.area_thresholding(\n                    self.directions[direction][\"removed_noise\"],\n                    self.absolute_area_threshold[direction],\n                )\n            self.directions[direction][\"removed_objects_too_small_to_process\"] = (\n                self.remove_objects_too_small_to_process(\n                    image=self.directions[direction][\"removed_small_objects\"],\n                    minimum_size_px=self.minimum_grain_size_px,\n                    minimum_bbox_size_px=self.minimum_bbox_size_px,\n                )\n            )\n            self.directions[direction][\"labelled_regions_02\"] = self.label_regions(\n                self.directions[direction][\"removed_objects_too_small_to_process\"]\n            )\n\n            self.region_properties[direction] = self.get_region_properties(\n                self.directions[direction][\"labelled_regions_02\"]\n            )\n            LOGGER.debug(f\"[{self.filename}] : Region properties calculated ({direction})\")\n            self.directions[direction][\"coloured_regions\"] = self.colour_regions(\n                self.directions[direction][\"labelled_regions_02\"]\n            )\n            self.bounding_boxes[direction] = self.get_bounding_boxes(direction=direction)\n            LOGGER.debug(f\"[{self.filename}] : Extracted bounding boxes ({direction})\")\n            thresholding_grain_count = self.directions[direction][\"labelled_regions_02\"].max()\n\n            # Force labelled_regions_02 to be of shape NxNx2, where the two classes are a binary background mask and the second is a binary grain mask.\n            # This is because we want to support multiple classes, and so we standardise so that the first layer is background mask, then feature mask 1, then feature mask 2 etc.\n\n            # Get a binary mask where 1s are background and 0s are grains\n            labelled_regions_background_mask = np.where(self.directions[direction][\"labelled_regions_02\"] == 0, 1, 0)\n            # keep only the largest region\n            labelled_regions_background_mask = label(labelled_regions_background_mask)\n            areas = [region.area for region in regionprops(labelled_regions_background_mask)]\n            labelled_regions_background_mask = np.where(\n                labelled_regions_background_mask == np.argmax(areas) + 1, labelled_regions_background_mask, 0\n            )\n\n            self.directions[direction][\"labelled_regions_02\"] = np.stack(\n                [\n                    labelled_regions_background_mask,\n                    self.directions[direction][\"labelled_regions_02\"],\n                ],\n                axis=-1,\n            ).astype(\n                np.int32\n            )  # Will produce an NxNx2 array\n\n            # Do the same for removed_small_objects, using the same labelled_regions_backgroudn_mask as the background since they will be the same\n            self.directions[direction][\"removed_small_objects\"] = np.stack(\n                [\n                    labelled_regions_background_mask,\n                    self.directions[direction][\"removed_small_objects\"],\n                ],\n                axis=-1,\n            ).astype(\n                np.int32\n            )  # Will produce an NxNx2 array\n\n            # Check whether to run the UNet model\n            if self.unet_config[\"model_path\"] is not None:\n\n                # Run unet segmentation on only the class 1 layer of the labelled_regions_02. Need to make this configurable\n                # later on along with all the other hardcoded class 1s.\n                unet_mask, unet_labelled_regions = Grains.improve_grain_segmentation_unet(\n                    filename=self.filename,\n                    direction=direction,\n                    unet_config=self.unet_config,\n                    image=self.image,\n                    labelled_grain_regions=self.directions[direction][\"labelled_regions_02\"][:, :, 1],\n                )\n\n                # Update the image masks to be the unet masks instead\n                self.directions[direction][\"removed_small_objects\"] = unet_mask\n                self.directions[direction][\"labelled_regions_02\"] = unet_labelled_regions\n\n                class_counts = [\n                    unet_labelled_regions[class_idx].max() for class_idx in range(unet_labelled_regions.shape[2])\n                ]\n                LOGGER.info(\n                    f\"[{self.filename}] : Overridden {thresholding_grain_count} grains with {class_counts} UNet predictions ({direction})\"\n                )\n\n            # Vet the grains\n            if self.vetting is not None:\n                vetted_grains = Grains.vet_grains(\n                    grain_mask_tensor=self.directions[direction][\"labelled_regions_02\"].astype(bool),\n                    pixel_to_nm_scaling=self.pixel_to_nm_scaling,\n                    **self.vetting,\n                )\n            else:\n                vetted_grains = self.directions[direction][\"labelled_regions_02\"].astype(bool)\n\n            # Merge classes if necessary\n            merged_classes = Grains.merge_classes(\n                vetted_grains,\n                self.classes_to_merge,\n            )\n\n            # Update the background class\n            final_grains = Grains.update_background_class(grain_mask_tensor=merged_classes)\n\n            # Label each class in the tensor\n            labelled_final_grains = np.zeros_like(final_grains).astype(int)\n            # The background class will be the same as the binary mask\n            labelled_final_grains[:, :, 0] = final_grains[:, :, 0]\n            # Iterate over each class and label the regions\n            for class_index in range(final_grains.shape[2]):\n                labelled_final_grains[:, :, class_index] = Grains.label_regions(final_grains[:, :, class_index])\n\n            self.directions[direction][\"removed_small_objects\"] = labelled_final_grains.astype(bool)\n            self.directions[direction][\"labelled_regions_02\"] = labelled_final_grains.astype(np.int32)\n\n    # pylint: disable=too-many-locals\n    @staticmethod\n    def improve_grain_segmentation_unet(\n        filename: str,\n        direction: str,\n        unet_config: dict[str, str | int | float | tuple[int | None, int, int, int] | None],\n        image: npt.NDArray,\n        labelled_grain_regions: npt.NDArray,\n    ) -&gt; tuple[npt.NDArray, npt.NDArray]:\n        \"\"\"\n        Use a UNet model to re-segment existing grains to improve their accuracy.\n\n        Parameters\n        ----------\n        filename : str\n            File being processed (used in logging).\n        direction : str\n            Direction of threshold for which bounding boxes are being calculated.\n        unet_config : dict[str, str | int | float | tuple[int | None, int, int, int] | None]\n            Configuration for the UNet model.\n            model_path: str\n                Path to the UNet model.\n            grain_crop_padding: int\n                Padding to add to the bounding box of the grain before cropping.\n            upper_norm_bound: float\n                Upper bound for normalising the image.\n            lower_norm_bound: float\n                Lower bound for normalising the image.\n        image : npt.NDArray\n            2-D Numpy array of image.\n        labelled_grain_regions : npt.NDArray\n            2-D Numpy array of labelled grain regions.\n\n        Returns\n        -------\n        npt.NDArray\n            NxNxC Numpy array of the UNet mask.\n        npt.NDArray\n            NxNxC Numpy array of the labelled regions from the UNet mask.\n        \"\"\"\n        LOGGER.debug(f\"[{filename}] : Running UNet model on {direction} grains\")\n\n        # When debugging, you might find that the custom_objects are incorrect. This is entirely based on what the model used\n        # for its loss during training and so this will need to be changed a lot.\n        # Once the group has gotten used to training models, this can be made configurable, but currently it's too changeable.\n        # unet_model = keras.models.load_model(\n        #     self.unet_config[\"model_path\"], custom_objects={\"dice_loss\": dice_loss, \"iou_loss\": iou_loss}\n        # )\n        # You may also get an error referencing a \"group_1\" parameter, this is discussed in this issue:\n        # https://github.com/keras-team/keras/issues/19441 which also has an experimental fix that we can try but\n        # I haven't tested it yet.\n\n        try:\n            unet_model = keras.models.load_model(\n                unet_config[\"model_path\"], custom_objects={\"mean_iou\": mean_iou, \"iou_loss\": iou_loss}, compile=False\n            )\n        except Exception as e:\n            LOGGER.debug(f\"Python executable: {sys.executable}\")\n            LOGGER.debug(f\"Keras version: {keras.__version__}\")\n            LOGGER.debug(f\"Model path: {unet_config['model_path']}\")\n            raise e\n\n        # unet_model = keras.models.load_model(unet_config[\"model_path\"], custom_objects={\"mean_iou\": mean_iou})\n        LOGGER.debug(f\"Output shape of UNet model: {unet_model.output_shape}\")\n\n        # Initialise an empty mask to iteratively add to for each grain, with the correct number of class channels based on\n        # the loaded model's output shape\n        # Note that the minimum number of classes is 2, as even for binary outputs, we will force categorical type\n        # data, so we have a class for background.\n        unet_mask = np.zeros((image.shape[0], image.shape[1], np.max([2, unet_model.output_shape[-1]]))).astype(\n            np.bool_\n        )\n        # Set the background class to be all 1s by default since not all of the image will be covered by the\n        # u-net predictions.\n        unet_mask[:, :, 0] = 1\n        # Labelled regions will be the same by default, but will be overwritten if there are any grains present.\n        unet_labelled_regions = np.zeros_like(unet_mask).astype(np.int32)\n        # For each detected molecule, create an image of just that molecule and run the UNet\n        # on that image to segment it\n        grain_region_properties = regionprops(labelled_grain_regions)\n        for grain_number, region in enumerate(grain_region_properties):\n            LOGGER.debug(f\"Unet predicting mask for grain {grain_number} of {len(grain_region_properties)}\")\n\n            # Get the bounding box for the region\n            bounding_box: tuple[int, int, int, int] = tuple(region.bbox)  # min_row, min_col, max_row, max_col\n\n            # Pad the bounding box\n            bounding_box = pad_bounding_box(\n                crop_min_row=bounding_box[0],\n                crop_min_col=bounding_box[1],\n                crop_max_row=bounding_box[2],\n                crop_max_col=bounding_box[3],\n                image_shape=(image.shape[0], image.shape[1]),\n                padding=unet_config[\"grain_crop_padding\"],\n            )\n\n            # Make the bounding box square within the confines of the image\n            if (bounding_box[2] - bounding_box[0]) != (bounding_box[3] - bounding_box[1]):\n                bounding_box = make_bounding_box_square(\n                    crop_min_row=bounding_box[0],\n                    crop_min_col=bounding_box[1],\n                    crop_max_row=bounding_box[2],\n                    crop_max_col=bounding_box[3],\n                    image_shape=(image.shape[0], image.shape[1]),\n                )\n\n            # Grab the cropped image. Using slice since the bounding box from skimage is\n            # half-open, so the max_row and max_col are not included in the region.\n            region_image = image[\n                bounding_box[0] : bounding_box[2],\n                bounding_box[1] : bounding_box[3],\n            ]\n\n            # Run the UNet on the region. This is allowed to be a single channel\n            # as we can add a background channel afterwards if needed.\n            # Remember that this region is cropped from the original image, so it's not\n            # the same size as the original image.\n            predicted_mask = predict_unet(\n                image=region_image,\n                model=unet_model,\n                confidence=0.1,\n                model_input_shape=unet_model.input_shape,\n                upper_norm_bound=unet_config[\"upper_norm_bound\"],\n                lower_norm_bound=unet_config[\"lower_norm_bound\"],\n            )\n\n            assert len(predicted_mask.shape) == 3\n            LOGGER.debug(f\"Predicted mask shape: {predicted_mask.shape}\")\n\n            # Add each class of the predicted mask to the overall full image mask\n            for class_index in range(unet_mask.shape[2]):\n                # Grab the unet mask for the class\n                unet_predicted_mask_labelled = morphology.label(predicted_mask[:, :, class_index])\n\n                # Directly set the background to be equal instead of logical or since they are by default\n                # 1, and should be turned off if any other class is on\n                if class_index == 0:\n                    unet_mask[\n                        bounding_box[0] : bounding_box[2],\n                        bounding_box[1] : bounding_box[3],\n                        class_index,\n                    ] = unet_predicted_mask_labelled\n                else:\n                    unet_mask[\n                        bounding_box[0] : bounding_box[2],\n                        bounding_box[1] : bounding_box[3],\n                        class_index,\n                    ] = np.logical_or(\n                        unet_mask[\n                            bounding_box[0] : bounding_box[2],\n                            bounding_box[1] : bounding_box[3],\n                            class_index,\n                        ],\n                        unet_predicted_mask_labelled,\n                    )\n\n            assert len(unet_mask.shape) == 3, f\"Unet mask shape: {unet_mask.shape}\"\n            assert unet_mask.shape[-1] &gt;= 2, f\"Unet mask shape: {unet_mask.shape}\"\n\n            # For each class in the unet mask tensor, label the mask and add to unet_labelled_regions\n            # The labelled background class will be identical to the binary one from the unet mask.\n            unet_labelled_regions[:, :, 0] = unet_mask[:, :, 0]\n            # Iterate over each class and label the regions\n            for class_index in range(unet_mask.shape[2]):\n                unet_labelled_regions[:, :, class_index] = Grains.label_regions(unet_mask[:, :, class_index])\n\n        return unet_mask, unet_labelled_regions\n\n    @staticmethod\n    def keep_largest_labelled_region(\n        labelled_image: npt.NDArray[np.int32],\n    ) -&gt; npt.NDArray[np.bool_]:\n        \"\"\"\n        Keep only the largest region in a labelled image.\n\n        Parameters\n        ----------\n        labelled_image : npt.NDArray\n            2-D Numpy array of labelled regions.\n\n        Returns\n        -------\n        npt.NDArray\n            2-D Numpy boolean array of labelled regions with only the largest region.\n        \"\"\"\n        # Check if there are any labelled regions\n        if labelled_image.max() == 0:\n            return np.zeros_like(labelled_image).astype(np.bool_)\n        # Get the sizes of the regions\n        sizes = np.array([(labelled_image == label).sum() for label in range(1, labelled_image.max() + 1)])\n        # Keep only the largest region\n        return np.where(labelled_image == sizes.argmax() + 1, labelled_image, 0).astype(bool)\n\n    @staticmethod\n    def flatten_multi_class_tensor(grain_mask_tensor: npt.NDArray) -&gt; npt.NDArray:\n        \"\"\"\n        Flatten a multi-class image tensor to a single binary mask.\n\n        The returned tensor is of boolean type in case there are multiple hits in the same pixel. We dont want to have\n        2s, 3s etc because this would cause issues in labelling and cause erroneous grains within grains.\n\n        Parameters\n        ----------\n        grain_mask_tensor : npt.NDArray\n            Multi class grain mask tensor tensor of shape (N, N, C).\n\n        Returns\n        -------\n        npt.NDArray\n            Combined binary mask of all but the background class (:, :, 0).\n        \"\"\"\n        assert len(grain_mask_tensor.shape) == 3, f\"Tensor not 3D: {grain_mask_tensor.shape}\"\n        return np.sum(grain_mask_tensor[:, :, 1:], axis=-1).astype(bool)\n\n    @staticmethod\n    def get_multi_class_grain_bounding_boxes(grain_mask_tensor: npt.NDArray) -&gt; dict:\n        \"\"\"\n        Get the bounding boxes for each grain in a multi-class image tensor.\n\n        Finds the bounding boxes for each grain in a multi-class image tensor. Grains can span multiple classes, so the\n        bounding boxes are found for the combined binary mask of contiguous grains across all classes.\n\n        Parameters\n        ----------\n        grain_mask_tensor : npt.NDArray\n            3-D Numpy array of grain mask tensor.\n\n        Returns\n        -------\n        dict\n            Dictionary of bounding boxes indexed by grain number.\n        \"\"\"\n        flattened_mask = Grains.flatten_multi_class_tensor(grain_mask_tensor)\n        labelled_regions = Grains.label_regions(flattened_mask)\n        region_properties = Grains.get_region_properties(labelled_regions)\n        bounding_boxes = {index: region.bbox for index, region in enumerate(region_properties)}\n        return {\n            index: pad_bounding_box(\n                crop_min_row=bbox[0],\n                crop_min_col=bbox[1],\n                crop_max_row=bbox[2],\n                crop_max_col=bbox[3],\n                image_shape=(grain_mask_tensor.shape[0], grain_mask_tensor.shape[1]),\n                padding=1,\n            )\n            for index, bbox in bounding_boxes.items()\n        }\n\n    @staticmethod\n    def update_background_class(\n        grain_mask_tensor: npt.NDArray,\n    ) -&gt; npt.NDArray:\n        \"\"\"\n        Update the background class to reflect the other classes.\n\n        Parameters\n        ----------\n        grain_mask_tensor : npt.NDArray\n            3-D Numpy array of the grain mask tensor.\n\n        Returns\n        -------\n        npt.NDArray\n            3-D Numpy array of image tensor with updated background class.\n        \"\"\"\n        flattened_mask = Grains.flatten_multi_class_tensor(grain_mask_tensor)\n        new_background = np.where(flattened_mask == 0, 1, 0)\n        grain_mask_tensor[:, :, 0] = new_background\n        return grain_mask_tensor.astype(bool)\n\n    @staticmethod\n    def vet_class_sizes_single_grain(\n        single_grain_mask_tensor: npt.NDArray,\n        pixel_to_nm_scaling: float,\n        class_size_thresholds: list[tuple[int, int, int]] | None,\n    ) -&gt; tuple[npt.NDArray, bool]:\n        \"\"\"\n        Remove regions of particular classes based on size thresholds.\n\n        Regions of classes that are too large or small may need to be removed for many reasons (eg removing noise\n        erroneously detected by the model or larger-than-expected molecules that are obviously erroneous), this method\n        allows for the removal of these regions based on size thresholds.\n\n        Parameters\n        ----------\n        single_grain_mask_tensor : npt.NDArray\n            3-D Numpy array of the mask tensor.\n        pixel_to_nm_scaling : float\n            Scaling of pixels to nanometres.\n        class_size_thresholds : list[list[int, int, int]] | None\n            List of class size thresholds. Structure is [(class_index, lower, upper)].\n\n        Returns\n        -------\n        npt.NDArray\n            3-D Numpy array of the mask tensor with grains removed based on size thresholds.\n        bool\n            True if the grain passes the vetting, False if it fails.\n        \"\"\"\n        if class_size_thresholds is None:\n            return single_grain_mask_tensor, True\n\n        # Iterate over the classes and check the sizes\n        for class_index in range(1, single_grain_mask_tensor.shape[2]):\n            class_size = np.sum(single_grain_mask_tensor[:, :, class_index]) * pixel_to_nm_scaling**2\n            # Check the size against the thresholds\n\n            classes_to_vet = [vetting_criteria[0] for vetting_criteria in class_size_thresholds]\n\n            if class_index not in classes_to_vet:\n                continue\n\n            lower_threshold, upper_threshold = [\n                vetting_criteria[1:] for vetting_criteria in class_size_thresholds if vetting_criteria[0] == class_index\n            ][0]\n\n            if lower_threshold is not None:\n                if class_size &lt; lower_threshold:\n                    # Return empty tensor\n                    empty_crop_tensor = np.zeros_like(single_grain_mask_tensor)\n                    # Fill the background class with 1s\n                    empty_crop_tensor[:, :, 0] = 1\n                    return empty_crop_tensor, False\n            if upper_threshold is not None:\n                if class_size &gt; upper_threshold:\n                    # Return empty tensor\n                    empty_crop_tensor = np.zeros_like(single_grain_mask_tensor)\n                    # Fill the background class with 1s\n                    empty_crop_tensor[:, :, 0] = 1\n                    return empty_crop_tensor, False\n\n        return single_grain_mask_tensor, True\n\n    @staticmethod\n    def get_individual_grain_crops(\n        grain_mask_tensor: npt.NDArray,\n        padding: int = 1,\n    ) -&gt; tuple[list[npt.NDArray], list[npt.NDArray], int]:\n        \"\"\"\n        Get individual grain crops from an image tensor.\n\n        Fetches individual grain crops from an image tensor, but zeros any non-connected grains\n        in the crop region. This is to ensure that other grains do not affect further processing\n        steps.\n\n        Parameters\n        ----------\n        grain_mask_tensor : npt.NDArray\n            3-D Numpy array of image tensor.\n        padding : int\n            Padding to add to the bounding box of the grain before cropping. Default is 1.\n\n        Returns\n        -------\n        list[npt.NDArray]\n            List of individual grain crops.\n        list[npt.NDArray]\n            List of bounding boxes for each grain.\n        int\n            Padding used for the bounding boxes.\n        \"\"\"\n        grain_crops = []\n        bounding_boxes = []\n\n        # Label the regions\n        flattened_multi_class_mask = Grains.flatten_multi_class_tensor(grain_mask_tensor)\n        labelled_regions = Grains.label_regions(flattened_multi_class_mask)\n\n        # Iterate over the regions and return the crop, but zero any non-connected grains\n        for region in Grains.get_region_properties(labelled_regions):\n            binary_labelled_regions = labelled_regions == region.label\n\n            # Zero any non-connected grains\n            # For each class, set all pixels to zero that are not in the current region\n            this_region_only_grain_tensor = np.copy(grain_mask_tensor)\n            # Iterate over the non-background classes\n            for class_index in range(1, grain_mask_tensor.shape[2]):\n                # Set all pixels to zero that are not in the current region\n                this_region_only_grain_tensor[:, :, class_index] = (\n                    binary_labelled_regions * grain_mask_tensor[:, :, class_index]\n                )\n\n            # Update background class to reflect the removal of any non-connected grains\n            this_region_only_grain_tensor = Grains.update_background_class(\n                grain_mask_tensor=this_region_only_grain_tensor\n            )\n\n            # Get the bounding box\n            bounding_box = region.bbox\n\n            # Pad the bounding box\n            bounding_box = pad_bounding_box(\n                crop_min_row=bounding_box[0],\n                crop_min_col=bounding_box[1],\n                crop_max_row=bounding_box[2],\n                crop_max_col=bounding_box[3],\n                image_shape=(grain_mask_tensor.shape[0], grain_mask_tensor.shape[1]),\n                padding=padding,\n            )\n\n            # Crop the grain\n            grain_crop = this_region_only_grain_tensor[\n                bounding_box[0] : bounding_box[2],\n                bounding_box[1] : bounding_box[3],\n                :,\n            ]\n\n            # Add the crop to the list\n            grain_crops.append(grain_crop.astype(bool))\n            bounding_boxes.append(bounding_box)\n\n        return grain_crops, bounding_boxes, padding\n\n    @staticmethod\n    def vet_numbers_of_regions_single_grain(\n        grain_mask_tensor: npt.NDArray,\n        class_region_number_thresholds: list[tuple[int, int, int]] | None,\n    ) -&gt; tuple[npt.NDArray, bool]:\n        \"\"\"\n        Check if the number of regions of different classes for a single grain is within thresholds.\n\n        Parameters\n        ----------\n        grain_mask_tensor : npt.NDArray\n            3-D Numpy array of the grain mask tensor, should be of only one grain.\n        class_region_number_thresholds : list[list[int, int, int]]\n            List of class region number thresholds. Structure is [(class_index, lower, upper)].\n\n        Returns\n        -------\n        npt.NDArray\n            3-D Numpy array of the grain mask tensor with grains removed based on region number thresholds.\n        bool\n            True if the grain passes the vetting, False if it fails.\n        \"\"\"\n        if class_region_number_thresholds is None:\n            return grain_mask_tensor, True\n\n        # Iterate over the classes and check the number of regions\n        for class_index in range(1, grain_mask_tensor.shape[2]):\n            # Get the number of regions\n            class_labelled_regions = Grains.label_regions(grain_mask_tensor[:, :, class_index])\n            number_of_regions = np.unique(class_labelled_regions).shape[0] - 1\n            # Check the number of regions against the thresholds, skip if no thresholds provided\n            # Get the classes we are trying to vet (the first element of each tuple)\n            classes_to_vet = [vetting_criteria[0] for vetting_criteria in class_region_number_thresholds]\n\n            if class_index not in classes_to_vet:\n                continue\n\n            lower_threshold, upper_threshold = [\n                vetting_criteria[1:]\n                for vetting_criteria in class_region_number_thresholds\n                if vetting_criteria[0] == class_index\n            ][0]\n\n            # Check the number of regions against the thresholds\n            if lower_threshold is not None:\n                if number_of_regions &lt; lower_threshold:\n                    # Return empty tensor\n                    empty_crop_tensor = np.zeros_like(grain_mask_tensor)\n                    # Fill the background class with 1s\n                    empty_crop_tensor[:, :, 0] = 1\n                    return empty_crop_tensor, False\n            if upper_threshold is not None:\n                if number_of_regions &gt; upper_threshold:\n                    # Return empty tensor\n                    empty_crop_tensor = np.zeros_like(grain_mask_tensor)\n                    # Fill the background class with 1s\n                    empty_crop_tensor[:, :, 0] = 1\n                    return empty_crop_tensor, False\n\n        return grain_mask_tensor, True\n\n    @staticmethod\n    def convert_classes_to_nearby_classes(\n        grain_mask_tensor: npt.NDArray,\n        classes_to_convert: list[tuple[int, int]] | None,\n        class_touching_threshold: int = 1,\n    ) -&gt; npt.NDArray:\n        \"\"\"\n        Convert all but the largest regions of one class into another class provided the former touches the latter.\n\n        Specifically, it takes a list of tuples of two integers (dubbed class A and class B). For each class A, class B\n        pair, it will find the largest region of class A and flag it to be ignored. Then for each non-largest region of\n        class A, it will check if it touches any class B region (within the ``class_touching_threshold`` distance). If it\n        does, it will convert the region to class B.\n\n        This is useful for situations where you want just one region of class A and the model has a habit of producing\n        small regions of class A interspersed in the class B regions, which should be class B instead.\n\n        Parameters\n        ----------\n        grain_mask_tensor : npt.NDArray\n            3-D Numpy array of the grain mask tensor.\n        classes_to_convert : list\n            List of tuples of classes to convert. Structure is [(class_a, class_b)].\n        class_touching_threshold : int\n            Number of dilation passes to do to determine class A connectivity with class B.\n\n        Returns\n        -------\n        npt.NDArray\n            3-D Numpy array of the grain mask tensor with classes converted.\n        \"\"\"\n        # If no classes to convert, return the original tensor\n        if not classes_to_convert:\n            return grain_mask_tensor\n\n        # Iterate over class pairs\n        for class_a, class_b in classes_to_convert:\n            # Get the binary mask for class A and class B\n            class_a_mask = grain_mask_tensor[:, :, class_a]\n            class_b_mask = grain_mask_tensor[:, :, class_b]\n\n            # Skip if no regions of class A\n            if np.max(class_a_mask) == 0:\n                continue\n\n            # Find the largest region of class A\n            class_a_labelled_regions = Grains.label_regions(class_a_mask)\n            class_a_region_properties = Grains.get_region_properties(class_a_labelled_regions)\n            class_a_areas = [region.area for region in class_a_region_properties]\n            largest_class_a_region = class_a_region_properties[np.argmax(class_a_areas)]\n\n            # For all other regions, check if they touch the class B region\n            for region in class_a_region_properties:\n                if region.label == largest_class_a_region.label:\n                    continue\n                # Get only the pixels in the region\n                region_mask = class_a_labelled_regions == region.label\n                # Dilate the region\n                dilated_region_mask = region_mask\n                for _ in range(class_touching_threshold):\n                    dilated_region_mask = binary_dilation(dilated_region_mask)\n                # Get the intersection with the class B mask\n                intersection = dilated_region_mask &amp; class_b_mask\n                # If there is any intersection, turn the region into class B\n                if np.any(intersection):\n                    # Add to the class B mask\n                    class_b_mask = np.where(region_mask, class_b, class_b_mask)\n                    # Remove from the class A mask\n                    class_a_mask = np.where(region_mask, 0, class_a_mask)\n\n            # Update the tensor\n            grain_mask_tensor[:, :, class_a] = class_a_mask\n            grain_mask_tensor[:, :, class_b] = class_b_mask\n\n        return grain_mask_tensor.astype(bool)\n\n    @staticmethod\n    def keep_largest_labelled_region_classes(\n        single_grain_mask_tensor: npt.NDArray,\n        keep_largest_labelled_regions_classes: list[int] | None,\n    ) -&gt; npt.NDArray:\n        \"\"\"\n        Keep only the largest region in specific classes.\n\n        Parameters\n        ----------\n        single_grain_mask_tensor : npt.NDArray\n            3-D Numpy array of the grain mask tensor.\n        keep_largest_labelled_regions_classes : list[int]\n            List of classes to keep only the largest region.\n\n        Returns\n        -------\n        npt.NDArray\n            3-D Numpy array of the grain mask tensor with only the largest regions in specific classes.\n        \"\"\"\n        if keep_largest_labelled_regions_classes is None:\n            return single_grain_mask_tensor\n\n        # Iterate over the classes\n        for class_index in keep_largest_labelled_regions_classes:\n            # Get the binary mask for the class\n            class_mask = single_grain_mask_tensor[:, :, class_index]\n\n            # Skip if no regions\n            if np.max(class_mask) == 0:\n                continue\n\n            # Label the regions\n            labelled_regions = Grains.label_regions(class_mask)\n            # Get the region properties\n            region_properties = Grains.get_region_properties(labelled_regions)\n            # Get the region areas\n            region_areas = [region.area for region in region_properties]\n            # Keep only the largest region\n            largest_region = region_properties[np.argmax(region_areas)]\n            class_mask_largest_only = np.where(labelled_regions == largest_region.label, labelled_regions, 0)\n            # Update the tensor\n            single_grain_mask_tensor[:, :, class_index] = class_mask_largest_only.astype(bool)\n\n        # Update the background class\n        return Grains.update_background_class(single_grain_mask_tensor)\n\n    @staticmethod\n    def calculate_region_connection_regions(\n        grain_mask_tensor: npt.NDArray,\n        classes: tuple[int, int],\n    ) -&gt; tuple[int, npt.NDArray, dict[int, npt.NDArray[int]]]:\n        \"\"\"\n        Get a list of connection regions between two classes.\n\n        Parameters\n        ----------\n        grain_mask_tensor : npt.NDArray\n            3-D Numpy array of the grain mask tensor.\n        classes : tuple[int, int]\n            Tuple pair of classes to calculate the connection regions.\n\n        Returns\n        -------\n        int\n            Number of connection regions.\n        npt.NDArray\n            2-D Numpy array of the intersection labels.\n        dict\n            Dictionary of connection points indexed by region label.\n        \"\"\"\n        # Get the binary masks for the classes\n        class_a_mask = grain_mask_tensor[:, :, classes[0]]\n        class_b_mask = grain_mask_tensor[:, :, classes[1]]\n\n        # Dilate class A mask\n        dilated_class_a_mask = binary_dilation(class_a_mask)\n        # Get the intersection with the class B mask\n        intersection = dilated_class_a_mask &amp; class_b_mask\n\n        # Get number of separate intersection regions\n        intersection_labels = label(intersection)\n        intersection_regions = regionprops(intersection_labels)\n        num_connection_regions = len(intersection_regions)\n        # Create a dictionary of the connection points\n        intersection_points = {region.label: region.coords for region in intersection_regions}\n\n        return num_connection_regions, intersection_labels, intersection_points\n\n    @staticmethod\n    def vet_class_connection_points(\n        grain_mask_tensor: npt.NDArray,\n        class_connection_point_thresholds: list[tuple[tuple[int, int], tuple[int, int]]] | None,\n    ) -&gt; bool:\n        \"\"\"\n        Vet the number of connection points between regions in specific classes.\n\n        Parameters\n        ----------\n        grain_mask_tensor : npt.NDArray\n            3-D Numpy array of the grain mask tensor.\n        class_connection_point_thresholds : list[tuple[tuple[int, int], tuple[int, int]]] | None\n            List of tuples of classes and connection point thresholds. Structure is [(class_pair, (lower, upper))].\n\n        Returns\n        -------\n        bool\n            True if the grain passes the vetting, False if it fails.\n        \"\"\"\n        if class_connection_point_thresholds is None:\n            return True\n\n        # Iterate over the class pairs\n        for class_pair, connection_point_thresholds in class_connection_point_thresholds:\n            # Get the connection regions\n            num_connection_regions, _, _ = Grains.calculate_region_connection_regions(\n                grain_mask_tensor=grain_mask_tensor,\n                classes=class_pair,\n            )\n            # Check the number of connection regions against the thresholds\n            lower_threshold, upper_threshold = connection_point_thresholds\n            if lower_threshold is not None:\n                if num_connection_regions &lt; lower_threshold:\n                    return False\n            if upper_threshold is not None:\n                if num_connection_regions &gt; upper_threshold:\n                    return False\n\n        return True\n\n    @staticmethod\n    def assemble_grain_mask_tensor_from_crops(\n        grain_mask_tensor_shape: tuple[int, int, int],\n        grain_crops_and_bounding_boxes: list[dict[str, npt.NDArray]],\n    ) -&gt; npt.NDArray:\n        \"\"\"\n        Combine individual grain crops into a single grain mask tensor.\n\n        Parameters\n        ----------\n        grain_mask_tensor_shape : tuple\n            Shape of the grain mask tensor.\n        grain_crops_and_bounding_boxes : list\n            List of dictionaries containing the grain crops and bounding boxes.\n            Structure: [{\"grain_tensor\": npt.NDArray, \"bounding_box\": tuple, \"padding\": int}].\n\n        Returns\n        -------\n        npt.NDArray\n            3-D Numpy array of the grain mask tensor.\n        \"\"\"\n        # Initialise the grain mask tensor\n        grain_mask_tensor = np.zeros(grain_mask_tensor_shape).astype(np.int32)\n\n        # Iterate over the grain crops\n        for grain_crop_and_bounding_box in grain_crops_and_bounding_boxes:\n            # Get the grain crop and bounding box\n            grain_crop = grain_crop_and_bounding_box[\"grain_tensor\"]\n            bounding_box = grain_crop_and_bounding_box[\"bounding_box\"]\n            padding = grain_crop_and_bounding_box[\"padding\"]\n\n            # Get the bounding box coordinates\n            min_row, min_col, max_row, max_col = bounding_box\n\n            # Crop the grain\n            cropped_grain = grain_crop[\n                padding:-padding,\n                padding:-padding,\n                :,\n            ]\n\n            # Update the grain mask tensor\n            grain_mask_tensor[min_row + padding : max_row - padding, min_col + padding : max_col - padding, :] = (\n                np.maximum(\n                    grain_mask_tensor[min_row + padding : max_row - padding, min_col + padding : max_col - padding, :],\n                    cropped_grain,\n                )\n            )\n\n        # Update the background class\n        grain_mask_tensor = Grains.update_background_class(grain_mask_tensor)\n\n        return grain_mask_tensor.astype(bool)\n\n    # Ignore too complex, to break the function down into smaller functions would make it more complex.\n    # ruff: noqa: C901\n    @staticmethod\n    def convert_classes_when_too_big_or_small(\n        grain_mask_tensor: npt.NDArray,\n        pixel_to_nm_scaling: float,\n        class_conversion_size_thresholds: list[tuple[tuple[int, int, int], tuple[int, int]]] | None,\n    ) -&gt; npt.NDArray:\n        \"\"\"\n        Convert classes when they are too big or too small based on size thresholds.\n\n        Parameters\n        ----------\n        grain_mask_tensor : npt.NDArray\n            3-D Numpy array of the grain mask tensor.\n        pixel_to_nm_scaling : float\n            Scaling of pixels to nanometres.\n        class_conversion_size_thresholds : list\n            List of class conversion size thresholds.\n            Structure is [(class_index, class_to_convert_to_if_to_small, class_to_convert_to_if_too_big),\n            (lower_threshold, upper_threshold)].\n\n        Returns\n        -------\n        npt.NDArray\n            3-D Numpy array of the grain mask tensor with classes converted based on size thresholds.\n        \"\"\"\n        if class_conversion_size_thresholds is None:\n            return grain_mask_tensor\n\n        new_grain_mask_tensor = np.copy(grain_mask_tensor)\n        classes_to_vet = [vetting_criteria[0][0] for vetting_criteria in class_conversion_size_thresholds]\n        for class_index in range(1, grain_mask_tensor.shape[2]):\n            if class_index not in classes_to_vet:\n                continue\n\n            lower_threshold, upper_threshold = [\n                vetting_criteria[1]\n                for vetting_criteria in class_conversion_size_thresholds\n                if vetting_criteria[0][0] == class_index\n            ][0]\n\n            class_to_convert_to_if_too_small, class_to_convert_to_if_too_big = [\n                vetting_criteria[0][1:]\n                for vetting_criteria in class_conversion_size_thresholds\n                if vetting_criteria[0][0] == class_index\n            ][0]\n\n            # For each region in the class, check its size and convert if needed\n            labelled_regions = Grains.label_regions(grain_mask_tensor[:, :, class_index])\n            region_properties = Grains.get_region_properties(labelled_regions)\n            for region in region_properties:\n                region_mask = labelled_regions == region.label\n                region_size = np.sum(region_mask) * pixel_to_nm_scaling**2\n                if lower_threshold is not None:\n                    if region_size &lt; lower_threshold:\n                        if class_to_convert_to_if_too_small is not None:\n                            # Add the region to the class to convert to in the new tensor\n                            new_grain_mask_tensor[:, :, class_to_convert_to_if_too_small] = np.where(\n                                region_mask,\n                                class_to_convert_to_if_too_small,\n                                new_grain_mask_tensor[:, :, class_to_convert_to_if_too_small],\n                            )\n                        # Remove the region from the original class\n                        new_grain_mask_tensor[:, :, class_index] = np.where(\n                            region_mask,\n                            0,\n                            new_grain_mask_tensor[:, :, class_index],\n                        )\n                if upper_threshold is not None:\n                    if region_size &gt; upper_threshold:\n                        if class_to_convert_to_if_too_big is not None:\n                            # Add the region to the class to convert to in the new tensor\n                            new_grain_mask_tensor[:, :, class_to_convert_to_if_too_big] = np.where(\n                                region_mask,\n                                class_to_convert_to_if_too_big,\n                                new_grain_mask_tensor[:, :, class_to_convert_to_if_too_big],\n                            )\n                        # Remove the region from the original class\n                        new_grain_mask_tensor[:, :, class_index] = np.where(\n                            region_mask,\n                            0,\n                            new_grain_mask_tensor[:, :, class_index],\n                        )\n\n        # Update the background class\n        new_grain_mask_tensor = Grains.update_background_class(new_grain_mask_tensor)\n\n        return new_grain_mask_tensor.astype(bool)\n\n    @staticmethod\n    def vet_grains(\n        grain_mask_tensor: npt.NDArray,\n        pixel_to_nm_scaling: float,\n        class_conversion_size_thresholds: list[tuple[tuple[int, int, int], tuple[int, int]]] | None,\n        class_size_thresholds: list[tuple[int, int, int]] | None,\n        class_region_number_thresholds: list[tuple[int, int, int]] | None,\n        nearby_conversion_classes_to_convert: list[tuple[int, int]] | None,\n        class_touching_threshold: int,\n        keep_largest_labelled_regions_classes: list[int] | None,\n        class_connection_point_thresholds: list[tuple[tuple[int, int], tuple[int, int]]] | None,\n    ) -&gt; npt.NDArray:\n        \"\"\"\n        Vet grains in a grain mask tensor based on a variety of criteria.\n\n        Parameters\n        ----------\n        grain_mask_tensor : npt.NDArray\n            3-D Numpy array of the grain mask tensor.\n        pixel_to_nm_scaling : float\n            Scaling of pixels to nanometres.\n        class_conversion_size_thresholds : list\n            List of class conversion size thresholds. Structure is [(class_index, class_to_convert_to_if_too_small,\n            class_to_convert_to_if_too_big), (lower_threshold, upper_threshold)].\n        class_size_thresholds : list\n            List of class size thresholds. Structure is [(class_index, lower, upper)].\n        class_region_number_thresholds : list\n            List of class region number thresholds. Structure is [(class_index, lower, upper)].\n        nearby_conversion_classes_to_convert : list\n            List of tuples of classes to convert. Structure is [(class_a, class_b)].\n        class_touching_threshold : int\n            Number of dilation passes to do to determine class A connectivity with class B.\n        keep_largest_labelled_regions_classes : list\n            List of classes to keep only the largest region.\n        class_connection_point_thresholds : list\n            List of tuples of classes and connection point thresholds. Structure is [(class_pair, (lower, upper))].\n\n        Returns\n        -------\n        npt.NDArray\n            3-D Numpy array of the vetted grain mask tensor.\n        \"\"\"\n        # Get individual grain crops\n        grain_tensor_crops, bounding_boxes, padding = Grains.get_individual_grain_crops(grain_mask_tensor)\n\n        passed_grain_crops_and_bounding_boxes = []\n\n        # Iterate over the grain crops\n        for _, (single_grain_mask_tensor, bounding_box) in enumerate(zip(grain_tensor_crops, bounding_boxes)):\n            # Convert small / big areas to other classes\n            single_grain_mask_tensor = Grains.convert_classes_when_too_big_or_small(\n                grain_mask_tensor=single_grain_mask_tensor,\n                pixel_to_nm_scaling=pixel_to_nm_scaling,\n                class_conversion_size_thresholds=class_conversion_size_thresholds,\n            )\n\n            # Vet number of regions (foreground and background)\n            _, passed = Grains.vet_numbers_of_regions_single_grain(\n                grain_mask_tensor=single_grain_mask_tensor,\n                class_region_number_thresholds=class_region_number_thresholds,\n            )\n            if not passed:\n                continue\n\n            # Vet size of regions (foreground and background)\n            _, passed = Grains.vet_class_sizes_single_grain(\n                single_grain_mask_tensor=single_grain_mask_tensor,\n                pixel_to_nm_scaling=pixel_to_nm_scaling,\n                class_size_thresholds=class_size_thresholds,\n            )\n            if not passed:\n                continue\n\n            # Turn all but largest region of class A into class B provided that the class A region touched a class B\n            # region\n            converted_single_grain_mask_tensor = Grains.convert_classes_to_nearby_classes(\n                grain_mask_tensor=single_grain_mask_tensor,\n                classes_to_convert=nearby_conversion_classes_to_convert,\n                class_touching_threshold=class_touching_threshold,\n            )\n\n            # Remove all but largest region in specific classes\n            largest_only_single_grain_mask_tensor = Grains.keep_largest_labelled_region_classes(\n                single_grain_mask_tensor=converted_single_grain_mask_tensor,\n                keep_largest_labelled_regions_classes=keep_largest_labelled_regions_classes,\n            )\n\n            # Vet number of connection points between regions in specific classes\n            if not Grains.vet_class_connection_points(\n                grain_mask_tensor=largest_only_single_grain_mask_tensor,\n                class_connection_point_thresholds=class_connection_point_thresholds,\n            ):\n                continue\n\n            # If passed all vetting steps, add to the list of passed grain crops\n            passed_grain_crops_and_bounding_boxes.append(\n                {\n                    \"grain_tensor\": largest_only_single_grain_mask_tensor,\n                    \"bounding_box\": bounding_box,\n                    \"padding\": padding,\n                }\n            )\n\n        # Construct a new grain mask tensor from the passed grains\n        return Grains.assemble_grain_mask_tensor_from_crops(\n            grain_mask_tensor_shape=(\n                grain_mask_tensor.shape[0],\n                grain_mask_tensor.shape[1],\n                grain_mask_tensor.shape[2],\n            ),\n            grain_crops_and_bounding_boxes=passed_grain_crops_and_bounding_boxes,\n        )\n\n    @staticmethod\n    def merge_classes(\n        grain_mask_tensor: npt.NDArray,\n        classes_to_merge: list[tuple[int]] | None,\n    ) -&gt; npt.NDArray:\n        \"\"\"\n        Merge classes in a grain mask tensor and add them to the grain tensor.\n\n        Parameters\n        ----------\n        grain_mask_tensor : npt.NDArray\n            3-D Numpy array of the grain mask tensor.\n        classes_to_merge : list | None\n            List of tuples for classes to merge, can be any number of classes.\n\n        Returns\n        -------\n        npt.NDArray\n            3-D Numpy array of the grain mask tensor with classes merged.\n        \"\"\"\n        if classes_to_merge is None:\n            return grain_mask_tensor\n        # For each set of classes to merge:\n        for classes in classes_to_merge:\n            # Get the binary masks for all the classes\n            class_masks = [grain_mask_tensor[:, :, class_index] for class_index in classes]\n            # Combine the masks\n            combined_mask = np.logical_or.reduce(class_masks)\n\n            # Add new class to the grain tensor with the combined mask\n            grain_mask_tensor = np.dstack([grain_mask_tensor, combined_mask])\n\n        return grain_mask_tensor.astype(bool)\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.__init__","title":"<code>__init__(image, filename, pixel_to_nm_scaling, unet_config=None, threshold_method=None, otsu_threshold_multiplier=None, threshold_std_dev=None, threshold_absolute=None, absolute_area_threshold=None, direction=None, smallest_grain_size_nm2=None, remove_edge_intersecting_grains=True, classes_to_merge=None, vetting=None)</code>","text":"<p>Initialise the class.</p>"},{"location":"api/grains/#topostats.grains.Grains.__init__--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D Numpy array of image. filename : str     File being processed (used in logging). pixel_to_nm_scaling : float     Scaling of pixels to nanometres. unet_config : dict[str, str | int | float | tuple[int | None, int, int, int] | None]     Configuration for the UNet model which is a dictionary with the following keys and values.     model_path : str         Path to the UNet model.     grain_crop_padding : int         Padding to add to the bounding box of the grain before cropping.     upper_norm_bound : float         Upper bound for normalising the image.     lower_norm_bound : float         Lower bound for normalising the image. threshold_method : str     Method for determining thershold to mask values, default is 'otsu'. otsu_threshold_multiplier : float     Factor by which the below threshold is to be scaled prior to masking. threshold_std_dev : dict     Dictionary of 'below' and 'above' factors by which standard deviation is multiplied to derive the threshold     if threshold_method is 'std_dev'. threshold_absolute : dict     Dictionary of absolute 'below' and 'above' thresholds for grain finding. absolute_area_threshold : dict     Dictionary of above and below grain's area thresholds. direction : str     Direction for which grains are to be detected, valid values are 'above', 'below' and 'both'. smallest_grain_size_nm2 : float     Whether or not to remove grains that intersect the edge of the image. remove_edge_intersecting_grains : bool     Direction for which grains are to be detected, valid values are 'above', 'below' and 'both'. classes_to_merge : list[tuple[int, int]] | None     List of tuples of classes to merge. vetting : dict | None     Dictionary of vetting parameters.</p> Source code in <code>topostats/grains.py</code> <pre><code>def __init__(\n    self,\n    image: npt.NDArray,\n    filename: str,\n    pixel_to_nm_scaling: float,\n    unet_config: dict[str, str | int | float | tuple[int | None, int, int, int] | None] | None = None,\n    threshold_method: str | None = None,\n    otsu_threshold_multiplier: float | None = None,\n    threshold_std_dev: dict | None = None,\n    threshold_absolute: dict | None = None,\n    absolute_area_threshold: dict | None = None,\n    direction: str | None = None,\n    smallest_grain_size_nm2: float | None = None,\n    remove_edge_intersecting_grains: bool = True,\n    classes_to_merge: list[tuple[int, int]] | None = None,\n    vetting: dict | None = None,\n):\n    \"\"\"\n    Initialise the class.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2-D Numpy array of image.\n    filename : str\n        File being processed (used in logging).\n    pixel_to_nm_scaling : float\n        Scaling of pixels to nanometres.\n    unet_config : dict[str, str | int | float | tuple[int | None, int, int, int] | None]\n        Configuration for the UNet model which is a dictionary with the following keys and values.\n        model_path : str\n            Path to the UNet model.\n        grain_crop_padding : int\n            Padding to add to the bounding box of the grain before cropping.\n        upper_norm_bound : float\n            Upper bound for normalising the image.\n        lower_norm_bound : float\n            Lower bound for normalising the image.\n    threshold_method : str\n        Method for determining thershold to mask values, default is 'otsu'.\n    otsu_threshold_multiplier : float\n        Factor by which the below threshold is to be scaled prior to masking.\n    threshold_std_dev : dict\n        Dictionary of 'below' and 'above' factors by which standard deviation is multiplied to derive the threshold\n        if threshold_method is 'std_dev'.\n    threshold_absolute : dict\n        Dictionary of absolute 'below' and 'above' thresholds for grain finding.\n    absolute_area_threshold : dict\n        Dictionary of above and below grain's area thresholds.\n    direction : str\n        Direction for which grains are to be detected, valid values are 'above', 'below' and 'both'.\n    smallest_grain_size_nm2 : float\n        Whether or not to remove grains that intersect the edge of the image.\n    remove_edge_intersecting_grains : bool\n        Direction for which grains are to be detected, valid values are 'above', 'below' and 'both'.\n    classes_to_merge : list[tuple[int, int]] | None\n        List of tuples of classes to merge.\n    vetting : dict | None\n        Dictionary of vetting parameters.\n    \"\"\"\n    if unet_config is None:\n        unet_config = {\n            \"model_path\": None,\n            \"grain_crop_padding\": 0,\n            \"upper_norm_bound\": 1.0,\n            \"lower_norm_bound\": 0.0,\n        }\n    if absolute_area_threshold is None:\n        absolute_area_threshold = {\"above\": [None, None], \"below\": [None, None]}\n    self.image = image\n    self.filename = filename\n    self.pixel_to_nm_scaling = pixel_to_nm_scaling\n    self.threshold_method = threshold_method\n    self.otsu_threshold_multiplier = otsu_threshold_multiplier\n    self.threshold_std_dev = threshold_std_dev\n    self.threshold_absolute = threshold_absolute\n    self.absolute_area_threshold = absolute_area_threshold\n    # Only detect grains for the desired direction\n    self.direction = [direction] if direction != \"both\" else [\"above\", \"below\"]\n    self.smallest_grain_size_nm2 = smallest_grain_size_nm2\n    self.remove_edge_intersecting_grains = remove_edge_intersecting_grains\n    self.thresholds = None\n    self.images = {\n        \"mask_grains\": None,\n        \"tidied_border\": None,\n        \"tiny_objects_removed\": None,\n        \"objects_removed\": None,\n        # \"labelled_regions\": None,\n        # \"coloured_regions\": None,\n    }\n    self.directions = defaultdict()\n    self.minimum_grain_size = None\n    self.region_properties = defaultdict()\n    self.bounding_boxes = defaultdict()\n    self.grainstats = None\n    self.unet_config = unet_config\n    self.vetting = vetting\n    self.classes_to_merge = classes_to_merge\n\n    # Hardcoded minimum pixel size for grains. This should not be able to be changed by the user as this is\n    # determined by what is processable by the rest of the pipeline.\n    self.minimum_grain_size_px = 10\n    self.minimum_bbox_size_px = 5\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.area_thresholding","title":"<code>area_thresholding(image, area_thresholds)</code>","text":"<p>Remove objects larger and smaller than the specified thresholds.</p>"},{"location":"api/grains/#topostats.grains.Grains.area_thresholding--parameters","title":"Parameters","text":"<p>image : npt.NDArray     Image array where the background == 0 and grains are labelled as integers &gt;0. area_thresholds : tuple     List of area thresholds (in nanometres squared, not pixels squared), first is the lower limit for size,     second is the upper.</p>"},{"location":"api/grains/#topostats.grains.Grains.area_thresholding--returns","title":"Returns","text":"<p>npt.NDArray     Array with small and large objects removed.</p> Source code in <code>topostats/grains.py</code> <pre><code>def area_thresholding(self, image: npt.NDArray, area_thresholds: tuple) -&gt; npt.NDArray:\n    \"\"\"\n    Remove objects larger and smaller than the specified thresholds.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        Image array where the background == 0 and grains are labelled as integers &gt;0.\n    area_thresholds : tuple\n        List of area thresholds (in nanometres squared, not pixels squared), first is the lower limit for size,\n        second is the upper.\n\n    Returns\n    -------\n    npt.NDArray\n        Array with small and large objects removed.\n    \"\"\"\n    image_cp = image.copy()\n    lower_size_limit, upper_size_limit = area_thresholds\n    # if one value is None adjust for comparison\n    if upper_size_limit is None:\n        upper_size_limit = image.size * self.pixel_to_nm_scaling**2\n    if lower_size_limit is None:\n        lower_size_limit = 0\n    # Get array of grain numbers (discounting zero)\n    uniq = np.delete(np.unique(image), 0)\n    grain_count = 0\n    LOGGER.debug(\n        f\"[{self.filename}] : Area thresholding grains | Thresholds: L: {(lower_size_limit / self.pixel_to_nm_scaling**2):.2f},\"\n        f\"U: {(upper_size_limit / self.pixel_to_nm_scaling**2):.2f} px^2, L: {lower_size_limit:.2f}, U: {upper_size_limit:.2f} nm^2.\"\n    )\n    for grain_no in uniq:  # Calculate grian area in nm^2\n        grain_area = np.sum(image_cp == grain_no) * (self.pixel_to_nm_scaling**2)\n        # Compare area in nm^2 to area thresholds\n        if grain_area &gt; upper_size_limit or grain_area &lt; lower_size_limit:\n            image_cp[image_cp == grain_no] = 0\n        else:\n            grain_count += 1\n            image_cp[image_cp == grain_no] = grain_count\n    return image_cp\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.assemble_grain_mask_tensor_from_crops","title":"<code>assemble_grain_mask_tensor_from_crops(grain_mask_tensor_shape, grain_crops_and_bounding_boxes)</code>  <code>staticmethod</code>","text":"<p>Combine individual grain crops into a single grain mask tensor.</p>"},{"location":"api/grains/#topostats.grains.Grains.assemble_grain_mask_tensor_from_crops--parameters","title":"Parameters","text":"<p>grain_mask_tensor_shape : tuple     Shape of the grain mask tensor. grain_crops_and_bounding_boxes : list     List of dictionaries containing the grain crops and bounding boxes.     Structure: [{\"grain_tensor\": npt.NDArray, \"bounding_box\": tuple, \"padding\": int}].</p>"},{"location":"api/grains/#topostats.grains.Grains.assemble_grain_mask_tensor_from_crops--returns","title":"Returns","text":"<p>npt.NDArray     3-D Numpy array of the grain mask tensor.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef assemble_grain_mask_tensor_from_crops(\n    grain_mask_tensor_shape: tuple[int, int, int],\n    grain_crops_and_bounding_boxes: list[dict[str, npt.NDArray]],\n) -&gt; npt.NDArray:\n    \"\"\"\n    Combine individual grain crops into a single grain mask tensor.\n\n    Parameters\n    ----------\n    grain_mask_tensor_shape : tuple\n        Shape of the grain mask tensor.\n    grain_crops_and_bounding_boxes : list\n        List of dictionaries containing the grain crops and bounding boxes.\n        Structure: [{\"grain_tensor\": npt.NDArray, \"bounding_box\": tuple, \"padding\": int}].\n\n    Returns\n    -------\n    npt.NDArray\n        3-D Numpy array of the grain mask tensor.\n    \"\"\"\n    # Initialise the grain mask tensor\n    grain_mask_tensor = np.zeros(grain_mask_tensor_shape).astype(np.int32)\n\n    # Iterate over the grain crops\n    for grain_crop_and_bounding_box in grain_crops_and_bounding_boxes:\n        # Get the grain crop and bounding box\n        grain_crop = grain_crop_and_bounding_box[\"grain_tensor\"]\n        bounding_box = grain_crop_and_bounding_box[\"bounding_box\"]\n        padding = grain_crop_and_bounding_box[\"padding\"]\n\n        # Get the bounding box coordinates\n        min_row, min_col, max_row, max_col = bounding_box\n\n        # Crop the grain\n        cropped_grain = grain_crop[\n            padding:-padding,\n            padding:-padding,\n            :,\n        ]\n\n        # Update the grain mask tensor\n        grain_mask_tensor[min_row + padding : max_row - padding, min_col + padding : max_col - padding, :] = (\n            np.maximum(\n                grain_mask_tensor[min_row + padding : max_row - padding, min_col + padding : max_col - padding, :],\n                cropped_grain,\n            )\n        )\n\n    # Update the background class\n    grain_mask_tensor = Grains.update_background_class(grain_mask_tensor)\n\n    return grain_mask_tensor.astype(bool)\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.calc_minimum_grain_size","title":"<code>calc_minimum_grain_size(image)</code>","text":"<p>Calculate the minimum grain size in pixels squared.</p> <p>Very small objects are first removed via thresholding before calculating the below extreme.</p>"},{"location":"api/grains/#topostats.grains.Grains.calc_minimum_grain_size--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D Numpy image from which to calculate the minimum grain size.</p>"},{"location":"api/grains/#topostats.grains.Grains.calc_minimum_grain_size--returns","title":"Returns","text":"<p>float     Minimum grains size in pixels squared. If there are areas a value of -1 is returned.</p> Source code in <code>topostats/grains.py</code> <pre><code>def calc_minimum_grain_size(self, image: npt.NDArray) -&gt; float:\n    \"\"\"\n    Calculate the minimum grain size in pixels squared.\n\n    Very small objects are first removed via thresholding before calculating the below extreme.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2-D Numpy image from which to calculate the minimum grain size.\n\n    Returns\n    -------\n    float\n        Minimum grains size in pixels squared. If there are areas a value of -1 is returned.\n    \"\"\"\n    region_properties = self.get_region_properties(image)\n    grain_areas = np.array([grain.area for grain in region_properties])\n    if len(grain_areas &gt; 0):\n        # Exclude small objects less than a given threshold first\n        grain_areas = grain_areas[\n            grain_areas &gt;= threshold(grain_areas, method=\"otsu\", otsu_threshold_multiplier=1.0)\n        ]\n        self.minimum_grain_size = np.median(grain_areas) - (\n            1.5 * (np.quantile(grain_areas, 0.75) - np.quantile(grain_areas, 0.25))\n        )\n    else:\n        self.minimum_grain_size = -1\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.calculate_region_connection_regions","title":"<code>calculate_region_connection_regions(grain_mask_tensor, classes)</code>  <code>staticmethod</code>","text":"<p>Get a list of connection regions between two classes.</p>"},{"location":"api/grains/#topostats.grains.Grains.calculate_region_connection_regions--parameters","title":"Parameters","text":"<p>grain_mask_tensor : npt.NDArray     3-D Numpy array of the grain mask tensor. classes : tuple[int, int]     Tuple pair of classes to calculate the connection regions.</p>"},{"location":"api/grains/#topostats.grains.Grains.calculate_region_connection_regions--returns","title":"Returns","text":"<p>int     Number of connection regions. npt.NDArray     2-D Numpy array of the intersection labels. dict     Dictionary of connection points indexed by region label.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef calculate_region_connection_regions(\n    grain_mask_tensor: npt.NDArray,\n    classes: tuple[int, int],\n) -&gt; tuple[int, npt.NDArray, dict[int, npt.NDArray[int]]]:\n    \"\"\"\n    Get a list of connection regions between two classes.\n\n    Parameters\n    ----------\n    grain_mask_tensor : npt.NDArray\n        3-D Numpy array of the grain mask tensor.\n    classes : tuple[int, int]\n        Tuple pair of classes to calculate the connection regions.\n\n    Returns\n    -------\n    int\n        Number of connection regions.\n    npt.NDArray\n        2-D Numpy array of the intersection labels.\n    dict\n        Dictionary of connection points indexed by region label.\n    \"\"\"\n    # Get the binary masks for the classes\n    class_a_mask = grain_mask_tensor[:, :, classes[0]]\n    class_b_mask = grain_mask_tensor[:, :, classes[1]]\n\n    # Dilate class A mask\n    dilated_class_a_mask = binary_dilation(class_a_mask)\n    # Get the intersection with the class B mask\n    intersection = dilated_class_a_mask &amp; class_b_mask\n\n    # Get number of separate intersection regions\n    intersection_labels = label(intersection)\n    intersection_regions = regionprops(intersection_labels)\n    num_connection_regions = len(intersection_regions)\n    # Create a dictionary of the connection points\n    intersection_points = {region.label: region.coords for region in intersection_regions}\n\n    return num_connection_regions, intersection_labels, intersection_points\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.colour_regions","title":"<code>colour_regions(image, **kwargs)</code>","text":"<p>Colour the regions.</p>"},{"location":"api/grains/#topostats.grains.Grains.colour_regions--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D array of labelled regions to be coloured. kwargs     Arguments passed to 'skimage.color.label2rgb(kwargs)'.</p>"},{"location":"api/grains/#topostats.grains.Grains.colour_regions--returns","title":"Returns","text":"<p>np.array     Numpy array of image with objects coloured.</p> Source code in <code>topostats/grains.py</code> <pre><code>def colour_regions(self, image: npt.NDArray, **kwargs) -&gt; npt.NDArray:\n    \"\"\"\n    Colour the regions.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2-D array of labelled regions to be coloured.\n    **kwargs\n        Arguments passed to 'skimage.color.label2rgb(**kwargs)'.\n\n    Returns\n    -------\n    np.array\n        Numpy array of image with objects coloured.\n    \"\"\"\n    coloured_regions = label2rgb(image, **kwargs)\n    LOGGER.debug(f\"[{self.filename}] : Coloured regions\")\n    return coloured_regions\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.convert_classes_to_nearby_classes","title":"<code>convert_classes_to_nearby_classes(grain_mask_tensor, classes_to_convert, class_touching_threshold=1)</code>  <code>staticmethod</code>","text":"<p>Convert all but the largest regions of one class into another class provided the former touches the latter.</p> <p>Specifically, it takes a list of tuples of two integers (dubbed class A and class B). For each class A, class B pair, it will find the largest region of class A and flag it to be ignored. Then for each non-largest region of class A, it will check if it touches any class B region (within the <code>class_touching_threshold</code> distance). If it does, it will convert the region to class B.</p> <p>This is useful for situations where you want just one region of class A and the model has a habit of producing small regions of class A interspersed in the class B regions, which should be class B instead.</p>"},{"location":"api/grains/#topostats.grains.Grains.convert_classes_to_nearby_classes--parameters","title":"Parameters","text":"<p>grain_mask_tensor : npt.NDArray     3-D Numpy array of the grain mask tensor. classes_to_convert : list     List of tuples of classes to convert. Structure is [(class_a, class_b)]. class_touching_threshold : int     Number of dilation passes to do to determine class A connectivity with class B.</p>"},{"location":"api/grains/#topostats.grains.Grains.convert_classes_to_nearby_classes--returns","title":"Returns","text":"<p>npt.NDArray     3-D Numpy array of the grain mask tensor with classes converted.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef convert_classes_to_nearby_classes(\n    grain_mask_tensor: npt.NDArray,\n    classes_to_convert: list[tuple[int, int]] | None,\n    class_touching_threshold: int = 1,\n) -&gt; npt.NDArray:\n    \"\"\"\n    Convert all but the largest regions of one class into another class provided the former touches the latter.\n\n    Specifically, it takes a list of tuples of two integers (dubbed class A and class B). For each class A, class B\n    pair, it will find the largest region of class A and flag it to be ignored. Then for each non-largest region of\n    class A, it will check if it touches any class B region (within the ``class_touching_threshold`` distance). If it\n    does, it will convert the region to class B.\n\n    This is useful for situations where you want just one region of class A and the model has a habit of producing\n    small regions of class A interspersed in the class B regions, which should be class B instead.\n\n    Parameters\n    ----------\n    grain_mask_tensor : npt.NDArray\n        3-D Numpy array of the grain mask tensor.\n    classes_to_convert : list\n        List of tuples of classes to convert. Structure is [(class_a, class_b)].\n    class_touching_threshold : int\n        Number of dilation passes to do to determine class A connectivity with class B.\n\n    Returns\n    -------\n    npt.NDArray\n        3-D Numpy array of the grain mask tensor with classes converted.\n    \"\"\"\n    # If no classes to convert, return the original tensor\n    if not classes_to_convert:\n        return grain_mask_tensor\n\n    # Iterate over class pairs\n    for class_a, class_b in classes_to_convert:\n        # Get the binary mask for class A and class B\n        class_a_mask = grain_mask_tensor[:, :, class_a]\n        class_b_mask = grain_mask_tensor[:, :, class_b]\n\n        # Skip if no regions of class A\n        if np.max(class_a_mask) == 0:\n            continue\n\n        # Find the largest region of class A\n        class_a_labelled_regions = Grains.label_regions(class_a_mask)\n        class_a_region_properties = Grains.get_region_properties(class_a_labelled_regions)\n        class_a_areas = [region.area for region in class_a_region_properties]\n        largest_class_a_region = class_a_region_properties[np.argmax(class_a_areas)]\n\n        # For all other regions, check if they touch the class B region\n        for region in class_a_region_properties:\n            if region.label == largest_class_a_region.label:\n                continue\n            # Get only the pixels in the region\n            region_mask = class_a_labelled_regions == region.label\n            # Dilate the region\n            dilated_region_mask = region_mask\n            for _ in range(class_touching_threshold):\n                dilated_region_mask = binary_dilation(dilated_region_mask)\n            # Get the intersection with the class B mask\n            intersection = dilated_region_mask &amp; class_b_mask\n            # If there is any intersection, turn the region into class B\n            if np.any(intersection):\n                # Add to the class B mask\n                class_b_mask = np.where(region_mask, class_b, class_b_mask)\n                # Remove from the class A mask\n                class_a_mask = np.where(region_mask, 0, class_a_mask)\n\n        # Update the tensor\n        grain_mask_tensor[:, :, class_a] = class_a_mask\n        grain_mask_tensor[:, :, class_b] = class_b_mask\n\n    return grain_mask_tensor.astype(bool)\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.convert_classes_when_too_big_or_small","title":"<code>convert_classes_when_too_big_or_small(grain_mask_tensor, pixel_to_nm_scaling, class_conversion_size_thresholds)</code>  <code>staticmethod</code>","text":"<p>Convert classes when they are too big or too small based on size thresholds.</p>"},{"location":"api/grains/#topostats.grains.Grains.convert_classes_when_too_big_or_small--parameters","title":"Parameters","text":"<p>grain_mask_tensor : npt.NDArray     3-D Numpy array of the grain mask tensor. pixel_to_nm_scaling : float     Scaling of pixels to nanometres. class_conversion_size_thresholds : list     List of class conversion size thresholds.     Structure is [(class_index, class_to_convert_to_if_to_small, class_to_convert_to_if_too_big),     (lower_threshold, upper_threshold)].</p>"},{"location":"api/grains/#topostats.grains.Grains.convert_classes_when_too_big_or_small--returns","title":"Returns","text":"<p>npt.NDArray     3-D Numpy array of the grain mask tensor with classes converted based on size thresholds.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef convert_classes_when_too_big_or_small(\n    grain_mask_tensor: npt.NDArray,\n    pixel_to_nm_scaling: float,\n    class_conversion_size_thresholds: list[tuple[tuple[int, int, int], tuple[int, int]]] | None,\n) -&gt; npt.NDArray:\n    \"\"\"\n    Convert classes when they are too big or too small based on size thresholds.\n\n    Parameters\n    ----------\n    grain_mask_tensor : npt.NDArray\n        3-D Numpy array of the grain mask tensor.\n    pixel_to_nm_scaling : float\n        Scaling of pixels to nanometres.\n    class_conversion_size_thresholds : list\n        List of class conversion size thresholds.\n        Structure is [(class_index, class_to_convert_to_if_to_small, class_to_convert_to_if_too_big),\n        (lower_threshold, upper_threshold)].\n\n    Returns\n    -------\n    npt.NDArray\n        3-D Numpy array of the grain mask tensor with classes converted based on size thresholds.\n    \"\"\"\n    if class_conversion_size_thresholds is None:\n        return grain_mask_tensor\n\n    new_grain_mask_tensor = np.copy(grain_mask_tensor)\n    classes_to_vet = [vetting_criteria[0][0] for vetting_criteria in class_conversion_size_thresholds]\n    for class_index in range(1, grain_mask_tensor.shape[2]):\n        if class_index not in classes_to_vet:\n            continue\n\n        lower_threshold, upper_threshold = [\n            vetting_criteria[1]\n            for vetting_criteria in class_conversion_size_thresholds\n            if vetting_criteria[0][0] == class_index\n        ][0]\n\n        class_to_convert_to_if_too_small, class_to_convert_to_if_too_big = [\n            vetting_criteria[0][1:]\n            for vetting_criteria in class_conversion_size_thresholds\n            if vetting_criteria[0][0] == class_index\n        ][0]\n\n        # For each region in the class, check its size and convert if needed\n        labelled_regions = Grains.label_regions(grain_mask_tensor[:, :, class_index])\n        region_properties = Grains.get_region_properties(labelled_regions)\n        for region in region_properties:\n            region_mask = labelled_regions == region.label\n            region_size = np.sum(region_mask) * pixel_to_nm_scaling**2\n            if lower_threshold is not None:\n                if region_size &lt; lower_threshold:\n                    if class_to_convert_to_if_too_small is not None:\n                        # Add the region to the class to convert to in the new tensor\n                        new_grain_mask_tensor[:, :, class_to_convert_to_if_too_small] = np.where(\n                            region_mask,\n                            class_to_convert_to_if_too_small,\n                            new_grain_mask_tensor[:, :, class_to_convert_to_if_too_small],\n                        )\n                    # Remove the region from the original class\n                    new_grain_mask_tensor[:, :, class_index] = np.where(\n                        region_mask,\n                        0,\n                        new_grain_mask_tensor[:, :, class_index],\n                    )\n            if upper_threshold is not None:\n                if region_size &gt; upper_threshold:\n                    if class_to_convert_to_if_too_big is not None:\n                        # Add the region to the class to convert to in the new tensor\n                        new_grain_mask_tensor[:, :, class_to_convert_to_if_too_big] = np.where(\n                            region_mask,\n                            class_to_convert_to_if_too_big,\n                            new_grain_mask_tensor[:, :, class_to_convert_to_if_too_big],\n                        )\n                    # Remove the region from the original class\n                    new_grain_mask_tensor[:, :, class_index] = np.where(\n                        region_mask,\n                        0,\n                        new_grain_mask_tensor[:, :, class_index],\n                    )\n\n    # Update the background class\n    new_grain_mask_tensor = Grains.update_background_class(new_grain_mask_tensor)\n\n    return new_grain_mask_tensor.astype(bool)\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.find_grains","title":"<code>find_grains()</code>","text":"<p>Find grains.</p> Source code in <code>topostats/grains.py</code> <pre><code>def find_grains(self):\n    \"\"\"Find grains.\"\"\"\n    LOGGER.debug(f\"[{self.filename}] : Thresholding method (grains) : {self.threshold_method}\")\n    self.thresholds = get_thresholds(\n        image=self.image,\n        threshold_method=self.threshold_method,\n        otsu_threshold_multiplier=self.otsu_threshold_multiplier,\n        threshold_std_dev=self.threshold_std_dev,\n        absolute=self.threshold_absolute,\n    )\n\n    for direction in self.direction:\n        LOGGER.debug(f\"[{self.filename}] : Finding {direction} grains, threshold: ({self.thresholds[direction]})\")\n        self.directions[direction] = {}\n        self.directions[direction][\"mask_grains\"] = _get_mask(\n            self.image,\n            thresh=self.thresholds[direction],\n            threshold_direction=direction,\n            img_name=self.filename,\n        )\n        self.directions[direction][\"labelled_regions_01\"] = self.label_regions(\n            self.directions[direction][\"mask_grains\"]\n        )\n\n        if self.remove_edge_intersecting_grains:\n            self.directions[direction][\"tidied_border\"] = self.tidy_border(\n                self.directions[direction][\"labelled_regions_01\"]\n            )\n        else:\n            self.directions[direction][\"tidied_border\"] = self.directions[direction][\"labelled_regions_01\"]\n\n        LOGGER.debug(f\"[{self.filename}] : Removing noise ({direction})\")\n        self.directions[direction][\"removed_noise\"] = self.area_thresholding(\n            self.directions[direction][\"tidied_border\"],\n            [self.smallest_grain_size_nm2, None],\n        )\n\n        LOGGER.debug(f\"[{self.filename}] : Removing small / large grains ({direction})\")\n        # if no area thresholds specified, use otsu\n        if self.absolute_area_threshold[direction].count(None) == 2:\n            self.calc_minimum_grain_size(self.directions[direction][\"removed_noise\"])\n            self.directions[direction][\"removed_small_objects\"] = self.remove_small_objects(\n                self.directions[direction][\"removed_noise\"]\n            )\n        else:\n            self.directions[direction][\"removed_small_objects\"] = self.area_thresholding(\n                self.directions[direction][\"removed_noise\"],\n                self.absolute_area_threshold[direction],\n            )\n        self.directions[direction][\"removed_objects_too_small_to_process\"] = (\n            self.remove_objects_too_small_to_process(\n                image=self.directions[direction][\"removed_small_objects\"],\n                minimum_size_px=self.minimum_grain_size_px,\n                minimum_bbox_size_px=self.minimum_bbox_size_px,\n            )\n        )\n        self.directions[direction][\"labelled_regions_02\"] = self.label_regions(\n            self.directions[direction][\"removed_objects_too_small_to_process\"]\n        )\n\n        self.region_properties[direction] = self.get_region_properties(\n            self.directions[direction][\"labelled_regions_02\"]\n        )\n        LOGGER.debug(f\"[{self.filename}] : Region properties calculated ({direction})\")\n        self.directions[direction][\"coloured_regions\"] = self.colour_regions(\n            self.directions[direction][\"labelled_regions_02\"]\n        )\n        self.bounding_boxes[direction] = self.get_bounding_boxes(direction=direction)\n        LOGGER.debug(f\"[{self.filename}] : Extracted bounding boxes ({direction})\")\n        thresholding_grain_count = self.directions[direction][\"labelled_regions_02\"].max()\n\n        # Force labelled_regions_02 to be of shape NxNx2, where the two classes are a binary background mask and the second is a binary grain mask.\n        # This is because we want to support multiple classes, and so we standardise so that the first layer is background mask, then feature mask 1, then feature mask 2 etc.\n\n        # Get a binary mask where 1s are background and 0s are grains\n        labelled_regions_background_mask = np.where(self.directions[direction][\"labelled_regions_02\"] == 0, 1, 0)\n        # keep only the largest region\n        labelled_regions_background_mask = label(labelled_regions_background_mask)\n        areas = [region.area for region in regionprops(labelled_regions_background_mask)]\n        labelled_regions_background_mask = np.where(\n            labelled_regions_background_mask == np.argmax(areas) + 1, labelled_regions_background_mask, 0\n        )\n\n        self.directions[direction][\"labelled_regions_02\"] = np.stack(\n            [\n                labelled_regions_background_mask,\n                self.directions[direction][\"labelled_regions_02\"],\n            ],\n            axis=-1,\n        ).astype(\n            np.int32\n        )  # Will produce an NxNx2 array\n\n        # Do the same for removed_small_objects, using the same labelled_regions_backgroudn_mask as the background since they will be the same\n        self.directions[direction][\"removed_small_objects\"] = np.stack(\n            [\n                labelled_regions_background_mask,\n                self.directions[direction][\"removed_small_objects\"],\n            ],\n            axis=-1,\n        ).astype(\n            np.int32\n        )  # Will produce an NxNx2 array\n\n        # Check whether to run the UNet model\n        if self.unet_config[\"model_path\"] is not None:\n\n            # Run unet segmentation on only the class 1 layer of the labelled_regions_02. Need to make this configurable\n            # later on along with all the other hardcoded class 1s.\n            unet_mask, unet_labelled_regions = Grains.improve_grain_segmentation_unet(\n                filename=self.filename,\n                direction=direction,\n                unet_config=self.unet_config,\n                image=self.image,\n                labelled_grain_regions=self.directions[direction][\"labelled_regions_02\"][:, :, 1],\n            )\n\n            # Update the image masks to be the unet masks instead\n            self.directions[direction][\"removed_small_objects\"] = unet_mask\n            self.directions[direction][\"labelled_regions_02\"] = unet_labelled_regions\n\n            class_counts = [\n                unet_labelled_regions[class_idx].max() for class_idx in range(unet_labelled_regions.shape[2])\n            ]\n            LOGGER.info(\n                f\"[{self.filename}] : Overridden {thresholding_grain_count} grains with {class_counts} UNet predictions ({direction})\"\n            )\n\n        # Vet the grains\n        if self.vetting is not None:\n            vetted_grains = Grains.vet_grains(\n                grain_mask_tensor=self.directions[direction][\"labelled_regions_02\"].astype(bool),\n                pixel_to_nm_scaling=self.pixel_to_nm_scaling,\n                **self.vetting,\n            )\n        else:\n            vetted_grains = self.directions[direction][\"labelled_regions_02\"].astype(bool)\n\n        # Merge classes if necessary\n        merged_classes = Grains.merge_classes(\n            vetted_grains,\n            self.classes_to_merge,\n        )\n\n        # Update the background class\n        final_grains = Grains.update_background_class(grain_mask_tensor=merged_classes)\n\n        # Label each class in the tensor\n        labelled_final_grains = np.zeros_like(final_grains).astype(int)\n        # The background class will be the same as the binary mask\n        labelled_final_grains[:, :, 0] = final_grains[:, :, 0]\n        # Iterate over each class and label the regions\n        for class_index in range(final_grains.shape[2]):\n            labelled_final_grains[:, :, class_index] = Grains.label_regions(final_grains[:, :, class_index])\n\n        self.directions[direction][\"removed_small_objects\"] = labelled_final_grains.astype(bool)\n        self.directions[direction][\"labelled_regions_02\"] = labelled_final_grains.astype(np.int32)\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.flatten_multi_class_tensor","title":"<code>flatten_multi_class_tensor(grain_mask_tensor)</code>  <code>staticmethod</code>","text":"<p>Flatten a multi-class image tensor to a single binary mask.</p> <p>The returned tensor is of boolean type in case there are multiple hits in the same pixel. We dont want to have 2s, 3s etc because this would cause issues in labelling and cause erroneous grains within grains.</p>"},{"location":"api/grains/#topostats.grains.Grains.flatten_multi_class_tensor--parameters","title":"Parameters","text":"<p>grain_mask_tensor : npt.NDArray     Multi class grain mask tensor tensor of shape (N, N, C).</p>"},{"location":"api/grains/#topostats.grains.Grains.flatten_multi_class_tensor--returns","title":"Returns","text":"<p>npt.NDArray     Combined binary mask of all but the background class (:, :, 0).</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef flatten_multi_class_tensor(grain_mask_tensor: npt.NDArray) -&gt; npt.NDArray:\n    \"\"\"\n    Flatten a multi-class image tensor to a single binary mask.\n\n    The returned tensor is of boolean type in case there are multiple hits in the same pixel. We dont want to have\n    2s, 3s etc because this would cause issues in labelling and cause erroneous grains within grains.\n\n    Parameters\n    ----------\n    grain_mask_tensor : npt.NDArray\n        Multi class grain mask tensor tensor of shape (N, N, C).\n\n    Returns\n    -------\n    npt.NDArray\n        Combined binary mask of all but the background class (:, :, 0).\n    \"\"\"\n    assert len(grain_mask_tensor.shape) == 3, f\"Tensor not 3D: {grain_mask_tensor.shape}\"\n    return np.sum(grain_mask_tensor[:, :, 1:], axis=-1).astype(bool)\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.get_bounding_boxes","title":"<code>get_bounding_boxes(direction)</code>","text":"<p>Derive a list of bounding boxes for each region from the derived region_properties.</p>"},{"location":"api/grains/#topostats.grains.Grains.get_bounding_boxes--parameters","title":"Parameters","text":"<p>direction : str     Direction of threshold for which bounding boxes are being calculated.</p>"},{"location":"api/grains/#topostats.grains.Grains.get_bounding_boxes--returns","title":"Returns","text":"<p>dict     Dictionary of bounding boxes indexed by region area.</p> Source code in <code>topostats/grains.py</code> <pre><code>def get_bounding_boxes(self, direction: str) -&gt; dict:\n    \"\"\"\n    Derive a list of bounding boxes for each region from the derived region_properties.\n\n    Parameters\n    ----------\n    direction : str\n        Direction of threshold for which bounding boxes are being calculated.\n\n    Returns\n    -------\n    dict\n        Dictionary of bounding boxes indexed by region area.\n    \"\"\"\n    return {region.area: region.area_bbox for region in self.region_properties[direction]}\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.get_individual_grain_crops","title":"<code>get_individual_grain_crops(grain_mask_tensor, padding=1)</code>  <code>staticmethod</code>","text":"<p>Get individual grain crops from an image tensor.</p> <p>Fetches individual grain crops from an image tensor, but zeros any non-connected grains in the crop region. This is to ensure that other grains do not affect further processing steps.</p>"},{"location":"api/grains/#topostats.grains.Grains.get_individual_grain_crops--parameters","title":"Parameters","text":"<p>grain_mask_tensor : npt.NDArray     3-D Numpy array of image tensor. padding : int     Padding to add to the bounding box of the grain before cropping. Default is 1.</p>"},{"location":"api/grains/#topostats.grains.Grains.get_individual_grain_crops--returns","title":"Returns","text":"<p>list[npt.NDArray]     List of individual grain crops. list[npt.NDArray]     List of bounding boxes for each grain. int     Padding used for the bounding boxes.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef get_individual_grain_crops(\n    grain_mask_tensor: npt.NDArray,\n    padding: int = 1,\n) -&gt; tuple[list[npt.NDArray], list[npt.NDArray], int]:\n    \"\"\"\n    Get individual grain crops from an image tensor.\n\n    Fetches individual grain crops from an image tensor, but zeros any non-connected grains\n    in the crop region. This is to ensure that other grains do not affect further processing\n    steps.\n\n    Parameters\n    ----------\n    grain_mask_tensor : npt.NDArray\n        3-D Numpy array of image tensor.\n    padding : int\n        Padding to add to the bounding box of the grain before cropping. Default is 1.\n\n    Returns\n    -------\n    list[npt.NDArray]\n        List of individual grain crops.\n    list[npt.NDArray]\n        List of bounding boxes for each grain.\n    int\n        Padding used for the bounding boxes.\n    \"\"\"\n    grain_crops = []\n    bounding_boxes = []\n\n    # Label the regions\n    flattened_multi_class_mask = Grains.flatten_multi_class_tensor(grain_mask_tensor)\n    labelled_regions = Grains.label_regions(flattened_multi_class_mask)\n\n    # Iterate over the regions and return the crop, but zero any non-connected grains\n    for region in Grains.get_region_properties(labelled_regions):\n        binary_labelled_regions = labelled_regions == region.label\n\n        # Zero any non-connected grains\n        # For each class, set all pixels to zero that are not in the current region\n        this_region_only_grain_tensor = np.copy(grain_mask_tensor)\n        # Iterate over the non-background classes\n        for class_index in range(1, grain_mask_tensor.shape[2]):\n            # Set all pixels to zero that are not in the current region\n            this_region_only_grain_tensor[:, :, class_index] = (\n                binary_labelled_regions * grain_mask_tensor[:, :, class_index]\n            )\n\n        # Update background class to reflect the removal of any non-connected grains\n        this_region_only_grain_tensor = Grains.update_background_class(\n            grain_mask_tensor=this_region_only_grain_tensor\n        )\n\n        # Get the bounding box\n        bounding_box = region.bbox\n\n        # Pad the bounding box\n        bounding_box = pad_bounding_box(\n            crop_min_row=bounding_box[0],\n            crop_min_col=bounding_box[1],\n            crop_max_row=bounding_box[2],\n            crop_max_col=bounding_box[3],\n            image_shape=(grain_mask_tensor.shape[0], grain_mask_tensor.shape[1]),\n            padding=padding,\n        )\n\n        # Crop the grain\n        grain_crop = this_region_only_grain_tensor[\n            bounding_box[0] : bounding_box[2],\n            bounding_box[1] : bounding_box[3],\n            :,\n        ]\n\n        # Add the crop to the list\n        grain_crops.append(grain_crop.astype(bool))\n        bounding_boxes.append(bounding_box)\n\n    return grain_crops, bounding_boxes, padding\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.get_multi_class_grain_bounding_boxes","title":"<code>get_multi_class_grain_bounding_boxes(grain_mask_tensor)</code>  <code>staticmethod</code>","text":"<p>Get the bounding boxes for each grain in a multi-class image tensor.</p> <p>Finds the bounding boxes for each grain in a multi-class image tensor. Grains can span multiple classes, so the bounding boxes are found for the combined binary mask of contiguous grains across all classes.</p>"},{"location":"api/grains/#topostats.grains.Grains.get_multi_class_grain_bounding_boxes--parameters","title":"Parameters","text":"<p>grain_mask_tensor : npt.NDArray     3-D Numpy array of grain mask tensor.</p>"},{"location":"api/grains/#topostats.grains.Grains.get_multi_class_grain_bounding_boxes--returns","title":"Returns","text":"<p>dict     Dictionary of bounding boxes indexed by grain number.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef get_multi_class_grain_bounding_boxes(grain_mask_tensor: npt.NDArray) -&gt; dict:\n    \"\"\"\n    Get the bounding boxes for each grain in a multi-class image tensor.\n\n    Finds the bounding boxes for each grain in a multi-class image tensor. Grains can span multiple classes, so the\n    bounding boxes are found for the combined binary mask of contiguous grains across all classes.\n\n    Parameters\n    ----------\n    grain_mask_tensor : npt.NDArray\n        3-D Numpy array of grain mask tensor.\n\n    Returns\n    -------\n    dict\n        Dictionary of bounding boxes indexed by grain number.\n    \"\"\"\n    flattened_mask = Grains.flatten_multi_class_tensor(grain_mask_tensor)\n    labelled_regions = Grains.label_regions(flattened_mask)\n    region_properties = Grains.get_region_properties(labelled_regions)\n    bounding_boxes = {index: region.bbox for index, region in enumerate(region_properties)}\n    return {\n        index: pad_bounding_box(\n            crop_min_row=bbox[0],\n            crop_min_col=bbox[1],\n            crop_max_row=bbox[2],\n            crop_max_col=bbox[3],\n            image_shape=(grain_mask_tensor.shape[0], grain_mask_tensor.shape[1]),\n            padding=1,\n        )\n        for index, bbox in bounding_boxes.items()\n    }\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.get_region_properties","title":"<code>get_region_properties(image, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Extract the properties of each region.</p>"},{"location":"api/grains/#topostats.grains.Grains.get_region_properties--parameters","title":"Parameters","text":"<p>image : np.array     Numpy array representing image. kwargs :     Arguments passed to 'skimage.measure.regionprops(kwargs)'.</p>"},{"location":"api/grains/#topostats.grains.Grains.get_region_properties--returns","title":"Returns","text":"<p>list     List of region property objects.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef get_region_properties(image: np.array, **kwargs) -&gt; list:\n    \"\"\"\n    Extract the properties of each region.\n\n    Parameters\n    ----------\n    image : np.array\n        Numpy array representing image.\n    **kwargs :\n        Arguments passed to 'skimage.measure.regionprops(**kwargs)'.\n\n    Returns\n    -------\n    list\n        List of region property objects.\n    \"\"\"\n    return regionprops(image, **kwargs)\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.improve_grain_segmentation_unet","title":"<code>improve_grain_segmentation_unet(filename, direction, unet_config, image, labelled_grain_regions)</code>  <code>staticmethod</code>","text":"<p>Use a UNet model to re-segment existing grains to improve their accuracy.</p>"},{"location":"api/grains/#topostats.grains.Grains.improve_grain_segmentation_unet--parameters","title":"Parameters","text":"<p>filename : str     File being processed (used in logging). direction : str     Direction of threshold for which bounding boxes are being calculated. unet_config : dict[str, str | int | float | tuple[int | None, int, int, int] | None]     Configuration for the UNet model.     model_path: str         Path to the UNet model.     grain_crop_padding: int         Padding to add to the bounding box of the grain before cropping.     upper_norm_bound: float         Upper bound for normalising the image.     lower_norm_bound: float         Lower bound for normalising the image. image : npt.NDArray     2-D Numpy array of image. labelled_grain_regions : npt.NDArray     2-D Numpy array of labelled grain regions.</p>"},{"location":"api/grains/#topostats.grains.Grains.improve_grain_segmentation_unet--returns","title":"Returns","text":"<p>npt.NDArray     NxNxC Numpy array of the UNet mask. npt.NDArray     NxNxC Numpy array of the labelled regions from the UNet mask.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef improve_grain_segmentation_unet(\n    filename: str,\n    direction: str,\n    unet_config: dict[str, str | int | float | tuple[int | None, int, int, int] | None],\n    image: npt.NDArray,\n    labelled_grain_regions: npt.NDArray,\n) -&gt; tuple[npt.NDArray, npt.NDArray]:\n    \"\"\"\n    Use a UNet model to re-segment existing grains to improve their accuracy.\n\n    Parameters\n    ----------\n    filename : str\n        File being processed (used in logging).\n    direction : str\n        Direction of threshold for which bounding boxes are being calculated.\n    unet_config : dict[str, str | int | float | tuple[int | None, int, int, int] | None]\n        Configuration for the UNet model.\n        model_path: str\n            Path to the UNet model.\n        grain_crop_padding: int\n            Padding to add to the bounding box of the grain before cropping.\n        upper_norm_bound: float\n            Upper bound for normalising the image.\n        lower_norm_bound: float\n            Lower bound for normalising the image.\n    image : npt.NDArray\n        2-D Numpy array of image.\n    labelled_grain_regions : npt.NDArray\n        2-D Numpy array of labelled grain regions.\n\n    Returns\n    -------\n    npt.NDArray\n        NxNxC Numpy array of the UNet mask.\n    npt.NDArray\n        NxNxC Numpy array of the labelled regions from the UNet mask.\n    \"\"\"\n    LOGGER.debug(f\"[{filename}] : Running UNet model on {direction} grains\")\n\n    # When debugging, you might find that the custom_objects are incorrect. This is entirely based on what the model used\n    # for its loss during training and so this will need to be changed a lot.\n    # Once the group has gotten used to training models, this can be made configurable, but currently it's too changeable.\n    # unet_model = keras.models.load_model(\n    #     self.unet_config[\"model_path\"], custom_objects={\"dice_loss\": dice_loss, \"iou_loss\": iou_loss}\n    # )\n    # You may also get an error referencing a \"group_1\" parameter, this is discussed in this issue:\n    # https://github.com/keras-team/keras/issues/19441 which also has an experimental fix that we can try but\n    # I haven't tested it yet.\n\n    try:\n        unet_model = keras.models.load_model(\n            unet_config[\"model_path\"], custom_objects={\"mean_iou\": mean_iou, \"iou_loss\": iou_loss}, compile=False\n        )\n    except Exception as e:\n        LOGGER.debug(f\"Python executable: {sys.executable}\")\n        LOGGER.debug(f\"Keras version: {keras.__version__}\")\n        LOGGER.debug(f\"Model path: {unet_config['model_path']}\")\n        raise e\n\n    # unet_model = keras.models.load_model(unet_config[\"model_path\"], custom_objects={\"mean_iou\": mean_iou})\n    LOGGER.debug(f\"Output shape of UNet model: {unet_model.output_shape}\")\n\n    # Initialise an empty mask to iteratively add to for each grain, with the correct number of class channels based on\n    # the loaded model's output shape\n    # Note that the minimum number of classes is 2, as even for binary outputs, we will force categorical type\n    # data, so we have a class for background.\n    unet_mask = np.zeros((image.shape[0], image.shape[1], np.max([2, unet_model.output_shape[-1]]))).astype(\n        np.bool_\n    )\n    # Set the background class to be all 1s by default since not all of the image will be covered by the\n    # u-net predictions.\n    unet_mask[:, :, 0] = 1\n    # Labelled regions will be the same by default, but will be overwritten if there are any grains present.\n    unet_labelled_regions = np.zeros_like(unet_mask).astype(np.int32)\n    # For each detected molecule, create an image of just that molecule and run the UNet\n    # on that image to segment it\n    grain_region_properties = regionprops(labelled_grain_regions)\n    for grain_number, region in enumerate(grain_region_properties):\n        LOGGER.debug(f\"Unet predicting mask for grain {grain_number} of {len(grain_region_properties)}\")\n\n        # Get the bounding box for the region\n        bounding_box: tuple[int, int, int, int] = tuple(region.bbox)  # min_row, min_col, max_row, max_col\n\n        # Pad the bounding box\n        bounding_box = pad_bounding_box(\n            crop_min_row=bounding_box[0],\n            crop_min_col=bounding_box[1],\n            crop_max_row=bounding_box[2],\n            crop_max_col=bounding_box[3],\n            image_shape=(image.shape[0], image.shape[1]),\n            padding=unet_config[\"grain_crop_padding\"],\n        )\n\n        # Make the bounding box square within the confines of the image\n        if (bounding_box[2] - bounding_box[0]) != (bounding_box[3] - bounding_box[1]):\n            bounding_box = make_bounding_box_square(\n                crop_min_row=bounding_box[0],\n                crop_min_col=bounding_box[1],\n                crop_max_row=bounding_box[2],\n                crop_max_col=bounding_box[3],\n                image_shape=(image.shape[0], image.shape[1]),\n            )\n\n        # Grab the cropped image. Using slice since the bounding box from skimage is\n        # half-open, so the max_row and max_col are not included in the region.\n        region_image = image[\n            bounding_box[0] : bounding_box[2],\n            bounding_box[1] : bounding_box[3],\n        ]\n\n        # Run the UNet on the region. This is allowed to be a single channel\n        # as we can add a background channel afterwards if needed.\n        # Remember that this region is cropped from the original image, so it's not\n        # the same size as the original image.\n        predicted_mask = predict_unet(\n            image=region_image,\n            model=unet_model,\n            confidence=0.1,\n            model_input_shape=unet_model.input_shape,\n            upper_norm_bound=unet_config[\"upper_norm_bound\"],\n            lower_norm_bound=unet_config[\"lower_norm_bound\"],\n        )\n\n        assert len(predicted_mask.shape) == 3\n        LOGGER.debug(f\"Predicted mask shape: {predicted_mask.shape}\")\n\n        # Add each class of the predicted mask to the overall full image mask\n        for class_index in range(unet_mask.shape[2]):\n            # Grab the unet mask for the class\n            unet_predicted_mask_labelled = morphology.label(predicted_mask[:, :, class_index])\n\n            # Directly set the background to be equal instead of logical or since they are by default\n            # 1, and should be turned off if any other class is on\n            if class_index == 0:\n                unet_mask[\n                    bounding_box[0] : bounding_box[2],\n                    bounding_box[1] : bounding_box[3],\n                    class_index,\n                ] = unet_predicted_mask_labelled\n            else:\n                unet_mask[\n                    bounding_box[0] : bounding_box[2],\n                    bounding_box[1] : bounding_box[3],\n                    class_index,\n                ] = np.logical_or(\n                    unet_mask[\n                        bounding_box[0] : bounding_box[2],\n                        bounding_box[1] : bounding_box[3],\n                        class_index,\n                    ],\n                    unet_predicted_mask_labelled,\n                )\n\n        assert len(unet_mask.shape) == 3, f\"Unet mask shape: {unet_mask.shape}\"\n        assert unet_mask.shape[-1] &gt;= 2, f\"Unet mask shape: {unet_mask.shape}\"\n\n        # For each class in the unet mask tensor, label the mask and add to unet_labelled_regions\n        # The labelled background class will be identical to the binary one from the unet mask.\n        unet_labelled_regions[:, :, 0] = unet_mask[:, :, 0]\n        # Iterate over each class and label the regions\n        for class_index in range(unet_mask.shape[2]):\n            unet_labelled_regions[:, :, class_index] = Grains.label_regions(unet_mask[:, :, class_index])\n\n    return unet_mask, unet_labelled_regions\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.keep_largest_labelled_region","title":"<code>keep_largest_labelled_region(labelled_image)</code>  <code>staticmethod</code>","text":"<p>Keep only the largest region in a labelled image.</p>"},{"location":"api/grains/#topostats.grains.Grains.keep_largest_labelled_region--parameters","title":"Parameters","text":"<p>labelled_image : npt.NDArray     2-D Numpy array of labelled regions.</p>"},{"location":"api/grains/#topostats.grains.Grains.keep_largest_labelled_region--returns","title":"Returns","text":"<p>npt.NDArray     2-D Numpy boolean array of labelled regions with only the largest region.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef keep_largest_labelled_region(\n    labelled_image: npt.NDArray[np.int32],\n) -&gt; npt.NDArray[np.bool_]:\n    \"\"\"\n    Keep only the largest region in a labelled image.\n\n    Parameters\n    ----------\n    labelled_image : npt.NDArray\n        2-D Numpy array of labelled regions.\n\n    Returns\n    -------\n    npt.NDArray\n        2-D Numpy boolean array of labelled regions with only the largest region.\n    \"\"\"\n    # Check if there are any labelled regions\n    if labelled_image.max() == 0:\n        return np.zeros_like(labelled_image).astype(np.bool_)\n    # Get the sizes of the regions\n    sizes = np.array([(labelled_image == label).sum() for label in range(1, labelled_image.max() + 1)])\n    # Keep only the largest region\n    return np.where(labelled_image == sizes.argmax() + 1, labelled_image, 0).astype(bool)\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.keep_largest_labelled_region_classes","title":"<code>keep_largest_labelled_region_classes(single_grain_mask_tensor, keep_largest_labelled_regions_classes)</code>  <code>staticmethod</code>","text":"<p>Keep only the largest region in specific classes.</p>"},{"location":"api/grains/#topostats.grains.Grains.keep_largest_labelled_region_classes--parameters","title":"Parameters","text":"<p>single_grain_mask_tensor : npt.NDArray     3-D Numpy array of the grain mask tensor. keep_largest_labelled_regions_classes : list[int]     List of classes to keep only the largest region.</p>"},{"location":"api/grains/#topostats.grains.Grains.keep_largest_labelled_region_classes--returns","title":"Returns","text":"<p>npt.NDArray     3-D Numpy array of the grain mask tensor with only the largest regions in specific classes.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef keep_largest_labelled_region_classes(\n    single_grain_mask_tensor: npt.NDArray,\n    keep_largest_labelled_regions_classes: list[int] | None,\n) -&gt; npt.NDArray:\n    \"\"\"\n    Keep only the largest region in specific classes.\n\n    Parameters\n    ----------\n    single_grain_mask_tensor : npt.NDArray\n        3-D Numpy array of the grain mask tensor.\n    keep_largest_labelled_regions_classes : list[int]\n        List of classes to keep only the largest region.\n\n    Returns\n    -------\n    npt.NDArray\n        3-D Numpy array of the grain mask tensor with only the largest regions in specific classes.\n    \"\"\"\n    if keep_largest_labelled_regions_classes is None:\n        return single_grain_mask_tensor\n\n    # Iterate over the classes\n    for class_index in keep_largest_labelled_regions_classes:\n        # Get the binary mask for the class\n        class_mask = single_grain_mask_tensor[:, :, class_index]\n\n        # Skip if no regions\n        if np.max(class_mask) == 0:\n            continue\n\n        # Label the regions\n        labelled_regions = Grains.label_regions(class_mask)\n        # Get the region properties\n        region_properties = Grains.get_region_properties(labelled_regions)\n        # Get the region areas\n        region_areas = [region.area for region in region_properties]\n        # Keep only the largest region\n        largest_region = region_properties[np.argmax(region_areas)]\n        class_mask_largest_only = np.where(labelled_regions == largest_region.label, labelled_regions, 0)\n        # Update the tensor\n        single_grain_mask_tensor[:, :, class_index] = class_mask_largest_only.astype(bool)\n\n    # Update the background class\n    return Grains.update_background_class(single_grain_mask_tensor)\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.label_regions","title":"<code>label_regions(image, background=0)</code>  <code>staticmethod</code>","text":"<p>Label regions.</p> <p>This method is used twice, once prior to removal of small regions and again afterwards which is why an image must be supplied rather than using 'self'.</p>"},{"location":"api/grains/#topostats.grains.Grains.label_regions--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D Numpy array of image. background : int     Value used to indicate background of image. Default = 0.</p>"},{"location":"api/grains/#topostats.grains.Grains.label_regions--returns","title":"Returns","text":"<p>npt.NDArray     2-D Numpy array of image with regions numbered.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef label_regions(image: npt.NDArray, background: int = 0) -&gt; npt.NDArray:\n    \"\"\"\n    Label regions.\n\n    This method is used twice, once prior to removal of small regions and again afterwards which is why an image\n    must be supplied rather than using 'self'.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2-D Numpy array of image.\n    background : int\n        Value used to indicate background of image. Default = 0.\n\n    Returns\n    -------\n    npt.NDArray\n        2-D Numpy array of image with regions numbered.\n    \"\"\"\n    return morphology.label(image, background)\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.merge_classes","title":"<code>merge_classes(grain_mask_tensor, classes_to_merge)</code>  <code>staticmethod</code>","text":"<p>Merge classes in a grain mask tensor and add them to the grain tensor.</p>"},{"location":"api/grains/#topostats.grains.Grains.merge_classes--parameters","title":"Parameters","text":"<p>grain_mask_tensor : npt.NDArray     3-D Numpy array of the grain mask tensor. classes_to_merge : list | None     List of tuples for classes to merge, can be any number of classes.</p>"},{"location":"api/grains/#topostats.grains.Grains.merge_classes--returns","title":"Returns","text":"<p>npt.NDArray     3-D Numpy array of the grain mask tensor with classes merged.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef merge_classes(\n    grain_mask_tensor: npt.NDArray,\n    classes_to_merge: list[tuple[int]] | None,\n) -&gt; npt.NDArray:\n    \"\"\"\n    Merge classes in a grain mask tensor and add them to the grain tensor.\n\n    Parameters\n    ----------\n    grain_mask_tensor : npt.NDArray\n        3-D Numpy array of the grain mask tensor.\n    classes_to_merge : list | None\n        List of tuples for classes to merge, can be any number of classes.\n\n    Returns\n    -------\n    npt.NDArray\n        3-D Numpy array of the grain mask tensor with classes merged.\n    \"\"\"\n    if classes_to_merge is None:\n        return grain_mask_tensor\n    # For each set of classes to merge:\n    for classes in classes_to_merge:\n        # Get the binary masks for all the classes\n        class_masks = [grain_mask_tensor[:, :, class_index] for class_index in classes]\n        # Combine the masks\n        combined_mask = np.logical_or.reduce(class_masks)\n\n        # Add new class to the grain tensor with the combined mask\n        grain_mask_tensor = np.dstack([grain_mask_tensor, combined_mask])\n\n    return grain_mask_tensor.astype(bool)\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.remove_noise","title":"<code>remove_noise(image, **kwargs)</code>","text":"<p>Remove noise which are objects smaller than the 'smallest_grain_size_nm2'.</p> <p>This ensures that the smallest objects ~1px are removed regardless of the size distribution of the grains.</p>"},{"location":"api/grains/#topostats.grains.Grains.remove_noise--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D Numpy array to be cleaned. kwargs     Arguments passed to 'skimage.morphology.remove_small_objects(kwargs)'.</p>"},{"location":"api/grains/#topostats.grains.Grains.remove_noise--returns","title":"Returns","text":"<p>npt.NDArray     2-D Numpy array of image with objects &lt; smallest_grain_size_nm2 removed.</p> Source code in <code>topostats/grains.py</code> <pre><code>def remove_noise(self, image: npt.NDArray, **kwargs) -&gt; npt.NDArray:\n    \"\"\"\n    Remove noise which are objects smaller than the 'smallest_grain_size_nm2'.\n\n    This ensures that the smallest objects ~1px are removed regardless of the size distribution of the grains.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2-D Numpy array to be cleaned.\n    **kwargs\n        Arguments passed to 'skimage.morphology.remove_small_objects(**kwargs)'.\n\n    Returns\n    -------\n    npt.NDArray\n        2-D Numpy array of image with objects &lt; smallest_grain_size_nm2 removed.\n    \"\"\"\n    LOGGER.debug(\n        f\"[{self.filename}] : Removing noise (&lt; {self.smallest_grain_size_nm2} nm^2\"\n        \"{self.smallest_grain_size_nm2 / (self.pixel_to_nm_scaling**2):.2f} px^2)\"\n    )\n    return morphology.remove_small_objects(\n        image, min_size=self.smallest_grain_size_nm2 / (self.pixel_to_nm_scaling**2), **kwargs\n    )\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.remove_objects_too_small_to_process","title":"<code>remove_objects_too_small_to_process(image, minimum_size_px, minimum_bbox_size_px)</code>","text":"<p>Remove objects whose dimensions in pixels are too small to process.</p>"},{"location":"api/grains/#topostats.grains.Grains.remove_objects_too_small_to_process--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D Numpy array of image. minimum_size_px : int     Minimum number of pixels for an object. minimum_bbox_size_px : int     Limit for the minimum dimension of an object in pixels. Eg: 5 means the object's bounding box must be at     least 5x5.</p>"},{"location":"api/grains/#topostats.grains.Grains.remove_objects_too_small_to_process--returns","title":"Returns","text":"<p>npt.NDArray     2-D Numpy array of image with objects removed that are too small to process.</p> Source code in <code>topostats/grains.py</code> <pre><code>def remove_objects_too_small_to_process(\n    self, image: npt.NDArray, minimum_size_px: int, minimum_bbox_size_px: int\n) -&gt; npt.NDArray[np.bool_]:\n    \"\"\"\n    Remove objects whose dimensions in pixels are too small to process.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2-D Numpy array of image.\n    minimum_size_px : int\n        Minimum number of pixels for an object.\n    minimum_bbox_size_px : int\n        Limit for the minimum dimension of an object in pixels. Eg: 5 means the object's bounding box must be at\n        least 5x5.\n\n    Returns\n    -------\n    npt.NDArray\n        2-D Numpy array of image with objects removed that are too small to process.\n    \"\"\"\n    labelled_image = label(image)\n    region_properties = self.get_region_properties(labelled_image)\n    for region in region_properties:\n        # If the number of true pixels in the region is less than the minimum number of pixels, remove the region\n        if region.area &lt; minimum_size_px:\n            labelled_image[labelled_image == region.label] = 0\n        bbox_width = region.bbox[2] - region.bbox[0]\n        bbox_height = region.bbox[3] - region.bbox[1]\n        # If the minimum dimension of the bounding box is less than the minimum dimension, remove the region\n        if min(bbox_width, bbox_height) &lt; minimum_bbox_size_px:\n            labelled_image[labelled_image == region.label] = 0\n\n    return labelled_image.astype(bool)\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.remove_small_objects","title":"<code>remove_small_objects(image, **kwargs)</code>","text":"<p>Remove small objects from the input image.</p> <p>Threshold determined by the minimum grain size, in pixels squared, of the classes initialisation.</p>"},{"location":"api/grains/#topostats.grains.Grains.remove_small_objects--parameters","title":"Parameters","text":"<p>image : np.array     2-D Numpy array to remove small objects from. kwargs     Arguments passed to 'skimage.morphology.remove_small_objects(kwargs)'.</p>"},{"location":"api/grains/#topostats.grains.Grains.remove_small_objects--returns","title":"Returns","text":"<p>npt.NDArray     2-D Numpy array of image with objects &lt; minimumm_grain_size removed.</p> Source code in <code>topostats/grains.py</code> <pre><code>    def remove_small_objects(self, image: np.array, **kwargs) -&gt; npt.NDArray:\n        \"\"\"\n        Remove small objects from the input image.\n\n        Threshold determined by the minimum grain size, in pixels squared, of the classes initialisation.\n\n        Parameters\n        ----------\n        image : np.array\n            2-D Numpy array to remove small objects from.\n        **kwargs\n            Arguments passed to 'skimage.morphology.remove_small_objects(**kwargs)'.\n\n        Returns\n        -------\n        npt.NDArray\n            2-D Numpy array of image with objects &lt; minimumm_grain_size removed.\n        \"\"\"\n        # If self.minimum_grain_size is -1, then this means that\n        # there were no grains to calculate the minimum grian size from.\n        if self.minimum_grain_size != -1:\n            small_objects_removed = morphology.remove_small_objects(\n                image.astype(bool),\n                min_size=self.minimum_grain_size,  # minimum_grain_size is in pixels squared\n                **kwargs,\n            )\n            LOGGER.debug(\n                f\"[{self.filename}] : Removed small objects (&lt; \\\n{self.minimum_grain_size} px^2 / {self.minimum_grain_size / (self.pixel_to_nm_scaling)**2} nm^2)\"\n            )\n            return small_objects_removed &gt; 0.0\n        return image\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.tidy_border","title":"<code>tidy_border(image, **kwargs)</code>","text":"<p>Remove grains touching the border.</p>"},{"location":"api/grains/#topostats.grains.Grains.tidy_border--parameters","title":"Parameters","text":"<p>image : npt.NDarray     2-D Numpy array representing the image. kwargs     Arguments passed to 'skimage.segmentation.clear_border(kwargs)'.</p>"},{"location":"api/grains/#topostats.grains.Grains.tidy_border--returns","title":"Returns","text":"<p>npt.NDarray     2-D Numpy array of image without objects touching the border.</p> Source code in <code>topostats/grains.py</code> <pre><code>def tidy_border(self, image: npt.NDArray, **kwargs) -&gt; npt.NDArray:\n    \"\"\"\n    Remove grains touching the border.\n\n    Parameters\n    ----------\n    image : npt.NDarray\n        2-D Numpy array representing the image.\n    **kwargs\n        Arguments passed to 'skimage.segmentation.clear_border(**kwargs)'.\n\n    Returns\n    -------\n    npt.NDarray\n        2-D Numpy array of image without objects touching the border.\n    \"\"\"\n    LOGGER.debug(f\"[{self.filename}] : Tidying borders\")\n    return clear_border(image, **kwargs)\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.update_background_class","title":"<code>update_background_class(grain_mask_tensor)</code>  <code>staticmethod</code>","text":"<p>Update the background class to reflect the other classes.</p>"},{"location":"api/grains/#topostats.grains.Grains.update_background_class--parameters","title":"Parameters","text":"<p>grain_mask_tensor : npt.NDArray     3-D Numpy array of the grain mask tensor.</p>"},{"location":"api/grains/#topostats.grains.Grains.update_background_class--returns","title":"Returns","text":"<p>npt.NDArray     3-D Numpy array of image tensor with updated background class.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef update_background_class(\n    grain_mask_tensor: npt.NDArray,\n) -&gt; npt.NDArray:\n    \"\"\"\n    Update the background class to reflect the other classes.\n\n    Parameters\n    ----------\n    grain_mask_tensor : npt.NDArray\n        3-D Numpy array of the grain mask tensor.\n\n    Returns\n    -------\n    npt.NDArray\n        3-D Numpy array of image tensor with updated background class.\n    \"\"\"\n    flattened_mask = Grains.flatten_multi_class_tensor(grain_mask_tensor)\n    new_background = np.where(flattened_mask == 0, 1, 0)\n    grain_mask_tensor[:, :, 0] = new_background\n    return grain_mask_tensor.astype(bool)\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.vet_class_connection_points","title":"<code>vet_class_connection_points(grain_mask_tensor, class_connection_point_thresholds)</code>  <code>staticmethod</code>","text":"<p>Vet the number of connection points between regions in specific classes.</p>"},{"location":"api/grains/#topostats.grains.Grains.vet_class_connection_points--parameters","title":"Parameters","text":"<p>grain_mask_tensor : npt.NDArray     3-D Numpy array of the grain mask tensor. class_connection_point_thresholds : list[tuple[tuple[int, int], tuple[int, int]]] | None     List of tuples of classes and connection point thresholds. Structure is [(class_pair, (lower, upper))].</p>"},{"location":"api/grains/#topostats.grains.Grains.vet_class_connection_points--returns","title":"Returns","text":"<p>bool     True if the grain passes the vetting, False if it fails.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef vet_class_connection_points(\n    grain_mask_tensor: npt.NDArray,\n    class_connection_point_thresholds: list[tuple[tuple[int, int], tuple[int, int]]] | None,\n) -&gt; bool:\n    \"\"\"\n    Vet the number of connection points between regions in specific classes.\n\n    Parameters\n    ----------\n    grain_mask_tensor : npt.NDArray\n        3-D Numpy array of the grain mask tensor.\n    class_connection_point_thresholds : list[tuple[tuple[int, int], tuple[int, int]]] | None\n        List of tuples of classes and connection point thresholds. Structure is [(class_pair, (lower, upper))].\n\n    Returns\n    -------\n    bool\n        True if the grain passes the vetting, False if it fails.\n    \"\"\"\n    if class_connection_point_thresholds is None:\n        return True\n\n    # Iterate over the class pairs\n    for class_pair, connection_point_thresholds in class_connection_point_thresholds:\n        # Get the connection regions\n        num_connection_regions, _, _ = Grains.calculate_region_connection_regions(\n            grain_mask_tensor=grain_mask_tensor,\n            classes=class_pair,\n        )\n        # Check the number of connection regions against the thresholds\n        lower_threshold, upper_threshold = connection_point_thresholds\n        if lower_threshold is not None:\n            if num_connection_regions &lt; lower_threshold:\n                return False\n        if upper_threshold is not None:\n            if num_connection_regions &gt; upper_threshold:\n                return False\n\n    return True\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.vet_class_sizes_single_grain","title":"<code>vet_class_sizes_single_grain(single_grain_mask_tensor, pixel_to_nm_scaling, class_size_thresholds)</code>  <code>staticmethod</code>","text":"<p>Remove regions of particular classes based on size thresholds.</p> <p>Regions of classes that are too large or small may need to be removed for many reasons (eg removing noise erroneously detected by the model or larger-than-expected molecules that are obviously erroneous), this method allows for the removal of these regions based on size thresholds.</p>"},{"location":"api/grains/#topostats.grains.Grains.vet_class_sizes_single_grain--parameters","title":"Parameters","text":"<p>single_grain_mask_tensor : npt.NDArray     3-D Numpy array of the mask tensor. pixel_to_nm_scaling : float     Scaling of pixels to nanometres. class_size_thresholds : list[list[int, int, int]] | None     List of class size thresholds. Structure is [(class_index, lower, upper)].</p>"},{"location":"api/grains/#topostats.grains.Grains.vet_class_sizes_single_grain--returns","title":"Returns","text":"<p>npt.NDArray     3-D Numpy array of the mask tensor with grains removed based on size thresholds. bool     True if the grain passes the vetting, False if it fails.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef vet_class_sizes_single_grain(\n    single_grain_mask_tensor: npt.NDArray,\n    pixel_to_nm_scaling: float,\n    class_size_thresholds: list[tuple[int, int, int]] | None,\n) -&gt; tuple[npt.NDArray, bool]:\n    \"\"\"\n    Remove regions of particular classes based on size thresholds.\n\n    Regions of classes that are too large or small may need to be removed for many reasons (eg removing noise\n    erroneously detected by the model or larger-than-expected molecules that are obviously erroneous), this method\n    allows for the removal of these regions based on size thresholds.\n\n    Parameters\n    ----------\n    single_grain_mask_tensor : npt.NDArray\n        3-D Numpy array of the mask tensor.\n    pixel_to_nm_scaling : float\n        Scaling of pixels to nanometres.\n    class_size_thresholds : list[list[int, int, int]] | None\n        List of class size thresholds. Structure is [(class_index, lower, upper)].\n\n    Returns\n    -------\n    npt.NDArray\n        3-D Numpy array of the mask tensor with grains removed based on size thresholds.\n    bool\n        True if the grain passes the vetting, False if it fails.\n    \"\"\"\n    if class_size_thresholds is None:\n        return single_grain_mask_tensor, True\n\n    # Iterate over the classes and check the sizes\n    for class_index in range(1, single_grain_mask_tensor.shape[2]):\n        class_size = np.sum(single_grain_mask_tensor[:, :, class_index]) * pixel_to_nm_scaling**2\n        # Check the size against the thresholds\n\n        classes_to_vet = [vetting_criteria[0] for vetting_criteria in class_size_thresholds]\n\n        if class_index not in classes_to_vet:\n            continue\n\n        lower_threshold, upper_threshold = [\n            vetting_criteria[1:] for vetting_criteria in class_size_thresholds if vetting_criteria[0] == class_index\n        ][0]\n\n        if lower_threshold is not None:\n            if class_size &lt; lower_threshold:\n                # Return empty tensor\n                empty_crop_tensor = np.zeros_like(single_grain_mask_tensor)\n                # Fill the background class with 1s\n                empty_crop_tensor[:, :, 0] = 1\n                return empty_crop_tensor, False\n        if upper_threshold is not None:\n            if class_size &gt; upper_threshold:\n                # Return empty tensor\n                empty_crop_tensor = np.zeros_like(single_grain_mask_tensor)\n                # Fill the background class with 1s\n                empty_crop_tensor[:, :, 0] = 1\n                return empty_crop_tensor, False\n\n    return single_grain_mask_tensor, True\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.vet_grains","title":"<code>vet_grains(grain_mask_tensor, pixel_to_nm_scaling, class_conversion_size_thresholds, class_size_thresholds, class_region_number_thresholds, nearby_conversion_classes_to_convert, class_touching_threshold, keep_largest_labelled_regions_classes, class_connection_point_thresholds)</code>  <code>staticmethod</code>","text":"<p>Vet grains in a grain mask tensor based on a variety of criteria.</p>"},{"location":"api/grains/#topostats.grains.Grains.vet_grains--parameters","title":"Parameters","text":"<p>grain_mask_tensor : npt.NDArray     3-D Numpy array of the grain mask tensor. pixel_to_nm_scaling : float     Scaling of pixels to nanometres. class_conversion_size_thresholds : list     List of class conversion size thresholds. Structure is [(class_index, class_to_convert_to_if_too_small,     class_to_convert_to_if_too_big), (lower_threshold, upper_threshold)]. class_size_thresholds : list     List of class size thresholds. Structure is [(class_index, lower, upper)]. class_region_number_thresholds : list     List of class region number thresholds. Structure is [(class_index, lower, upper)]. nearby_conversion_classes_to_convert : list     List of tuples of classes to convert. Structure is [(class_a, class_b)]. class_touching_threshold : int     Number of dilation passes to do to determine class A connectivity with class B. keep_largest_labelled_regions_classes : list     List of classes to keep only the largest region. class_connection_point_thresholds : list     List of tuples of classes and connection point thresholds. Structure is [(class_pair, (lower, upper))].</p>"},{"location":"api/grains/#topostats.grains.Grains.vet_grains--returns","title":"Returns","text":"<p>npt.NDArray     3-D Numpy array of the vetted grain mask tensor.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef vet_grains(\n    grain_mask_tensor: npt.NDArray,\n    pixel_to_nm_scaling: float,\n    class_conversion_size_thresholds: list[tuple[tuple[int, int, int], tuple[int, int]]] | None,\n    class_size_thresholds: list[tuple[int, int, int]] | None,\n    class_region_number_thresholds: list[tuple[int, int, int]] | None,\n    nearby_conversion_classes_to_convert: list[tuple[int, int]] | None,\n    class_touching_threshold: int,\n    keep_largest_labelled_regions_classes: list[int] | None,\n    class_connection_point_thresholds: list[tuple[tuple[int, int], tuple[int, int]]] | None,\n) -&gt; npt.NDArray:\n    \"\"\"\n    Vet grains in a grain mask tensor based on a variety of criteria.\n\n    Parameters\n    ----------\n    grain_mask_tensor : npt.NDArray\n        3-D Numpy array of the grain mask tensor.\n    pixel_to_nm_scaling : float\n        Scaling of pixels to nanometres.\n    class_conversion_size_thresholds : list\n        List of class conversion size thresholds. Structure is [(class_index, class_to_convert_to_if_too_small,\n        class_to_convert_to_if_too_big), (lower_threshold, upper_threshold)].\n    class_size_thresholds : list\n        List of class size thresholds. Structure is [(class_index, lower, upper)].\n    class_region_number_thresholds : list\n        List of class region number thresholds. Structure is [(class_index, lower, upper)].\n    nearby_conversion_classes_to_convert : list\n        List of tuples of classes to convert. Structure is [(class_a, class_b)].\n    class_touching_threshold : int\n        Number of dilation passes to do to determine class A connectivity with class B.\n    keep_largest_labelled_regions_classes : list\n        List of classes to keep only the largest region.\n    class_connection_point_thresholds : list\n        List of tuples of classes and connection point thresholds. Structure is [(class_pair, (lower, upper))].\n\n    Returns\n    -------\n    npt.NDArray\n        3-D Numpy array of the vetted grain mask tensor.\n    \"\"\"\n    # Get individual grain crops\n    grain_tensor_crops, bounding_boxes, padding = Grains.get_individual_grain_crops(grain_mask_tensor)\n\n    passed_grain_crops_and_bounding_boxes = []\n\n    # Iterate over the grain crops\n    for _, (single_grain_mask_tensor, bounding_box) in enumerate(zip(grain_tensor_crops, bounding_boxes)):\n        # Convert small / big areas to other classes\n        single_grain_mask_tensor = Grains.convert_classes_when_too_big_or_small(\n            grain_mask_tensor=single_grain_mask_tensor,\n            pixel_to_nm_scaling=pixel_to_nm_scaling,\n            class_conversion_size_thresholds=class_conversion_size_thresholds,\n        )\n\n        # Vet number of regions (foreground and background)\n        _, passed = Grains.vet_numbers_of_regions_single_grain(\n            grain_mask_tensor=single_grain_mask_tensor,\n            class_region_number_thresholds=class_region_number_thresholds,\n        )\n        if not passed:\n            continue\n\n        # Vet size of regions (foreground and background)\n        _, passed = Grains.vet_class_sizes_single_grain(\n            single_grain_mask_tensor=single_grain_mask_tensor,\n            pixel_to_nm_scaling=pixel_to_nm_scaling,\n            class_size_thresholds=class_size_thresholds,\n        )\n        if not passed:\n            continue\n\n        # Turn all but largest region of class A into class B provided that the class A region touched a class B\n        # region\n        converted_single_grain_mask_tensor = Grains.convert_classes_to_nearby_classes(\n            grain_mask_tensor=single_grain_mask_tensor,\n            classes_to_convert=nearby_conversion_classes_to_convert,\n            class_touching_threshold=class_touching_threshold,\n        )\n\n        # Remove all but largest region in specific classes\n        largest_only_single_grain_mask_tensor = Grains.keep_largest_labelled_region_classes(\n            single_grain_mask_tensor=converted_single_grain_mask_tensor,\n            keep_largest_labelled_regions_classes=keep_largest_labelled_regions_classes,\n        )\n\n        # Vet number of connection points between regions in specific classes\n        if not Grains.vet_class_connection_points(\n            grain_mask_tensor=largest_only_single_grain_mask_tensor,\n            class_connection_point_thresholds=class_connection_point_thresholds,\n        ):\n            continue\n\n        # If passed all vetting steps, add to the list of passed grain crops\n        passed_grain_crops_and_bounding_boxes.append(\n            {\n                \"grain_tensor\": largest_only_single_grain_mask_tensor,\n                \"bounding_box\": bounding_box,\n                \"padding\": padding,\n            }\n        )\n\n    # Construct a new grain mask tensor from the passed grains\n    return Grains.assemble_grain_mask_tensor_from_crops(\n        grain_mask_tensor_shape=(\n            grain_mask_tensor.shape[0],\n            grain_mask_tensor.shape[1],\n            grain_mask_tensor.shape[2],\n        ),\n        grain_crops_and_bounding_boxes=passed_grain_crops_and_bounding_boxes,\n    )\n</code></pre>"},{"location":"api/grains/#topostats.grains.Grains.vet_numbers_of_regions_single_grain","title":"<code>vet_numbers_of_regions_single_grain(grain_mask_tensor, class_region_number_thresholds)</code>  <code>staticmethod</code>","text":"<p>Check if the number of regions of different classes for a single grain is within thresholds.</p>"},{"location":"api/grains/#topostats.grains.Grains.vet_numbers_of_regions_single_grain--parameters","title":"Parameters","text":"<p>grain_mask_tensor : npt.NDArray     3-D Numpy array of the grain mask tensor, should be of only one grain. class_region_number_thresholds : list[list[int, int, int]]     List of class region number thresholds. Structure is [(class_index, lower, upper)].</p>"},{"location":"api/grains/#topostats.grains.Grains.vet_numbers_of_regions_single_grain--returns","title":"Returns","text":"<p>npt.NDArray     3-D Numpy array of the grain mask tensor with grains removed based on region number thresholds. bool     True if the grain passes the vetting, False if it fails.</p> Source code in <code>topostats/grains.py</code> <pre><code>@staticmethod\ndef vet_numbers_of_regions_single_grain(\n    grain_mask_tensor: npt.NDArray,\n    class_region_number_thresholds: list[tuple[int, int, int]] | None,\n) -&gt; tuple[npt.NDArray, bool]:\n    \"\"\"\n    Check if the number of regions of different classes for a single grain is within thresholds.\n\n    Parameters\n    ----------\n    grain_mask_tensor : npt.NDArray\n        3-D Numpy array of the grain mask tensor, should be of only one grain.\n    class_region_number_thresholds : list[list[int, int, int]]\n        List of class region number thresholds. Structure is [(class_index, lower, upper)].\n\n    Returns\n    -------\n    npt.NDArray\n        3-D Numpy array of the grain mask tensor with grains removed based on region number thresholds.\n    bool\n        True if the grain passes the vetting, False if it fails.\n    \"\"\"\n    if class_region_number_thresholds is None:\n        return grain_mask_tensor, True\n\n    # Iterate over the classes and check the number of regions\n    for class_index in range(1, grain_mask_tensor.shape[2]):\n        # Get the number of regions\n        class_labelled_regions = Grains.label_regions(grain_mask_tensor[:, :, class_index])\n        number_of_regions = np.unique(class_labelled_regions).shape[0] - 1\n        # Check the number of regions against the thresholds, skip if no thresholds provided\n        # Get the classes we are trying to vet (the first element of each tuple)\n        classes_to_vet = [vetting_criteria[0] for vetting_criteria in class_region_number_thresholds]\n\n        if class_index not in classes_to_vet:\n            continue\n\n        lower_threshold, upper_threshold = [\n            vetting_criteria[1:]\n            for vetting_criteria in class_region_number_thresholds\n            if vetting_criteria[0] == class_index\n        ][0]\n\n        # Check the number of regions against the thresholds\n        if lower_threshold is not None:\n            if number_of_regions &lt; lower_threshold:\n                # Return empty tensor\n                empty_crop_tensor = np.zeros_like(grain_mask_tensor)\n                # Fill the background class with 1s\n                empty_crop_tensor[:, :, 0] = 1\n                return empty_crop_tensor, False\n        if upper_threshold is not None:\n            if number_of_regions &gt; upper_threshold:\n                # Return empty tensor\n                empty_crop_tensor = np.zeros_like(grain_mask_tensor)\n                # Fill the background class with 1s\n                empty_crop_tensor[:, :, 0] = 1\n                return empty_crop_tensor, False\n\n    return grain_mask_tensor, True\n</code></pre>"},{"location":"api/grainstats/","title":"Grainstats Modules","text":"<p>Contains class for calculating the statistics of grains - 2d raster images.</p> <p>handler: python options: docstring_style: numpy rendering: show_signature_annotations: true</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats","title":"<code>GrainStats</code>","text":"<p>Class for calculating grain stats.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats--parameters","title":"Parameters","text":"<p>data : npt.NDArray     2D Numpy array containing the flattened afm image. Data in this 2D array is floating point. labelled_data : npt.NDArray     2D Numpy array containing all the grain masks in the image. Data in this 2D array is boolean. pixel_to_nanometre_scaling : float     Floating point value that defines the scaling factor between nanometres and pixels. direction : str     Direction for which grains have been detected (\"above\" or \"below\"). base_output_dir : Path     Path to the folder that will store the grain stats output images and data. image_name : str     The name of the file being processed. edge_detection_method : str     Method used for detecting the edges of grain masks before calculating statistics on them.     Do not change unless you know exactly what this is doing. Options: \"binary_erosion\", \"canny\". extract_height_profile : bool     Extract the height profile. cropped_size : float     Length of square side (in nm) to crop grains to. plot_opts : dict     Plotting options dictionary for the cropped grains. metre_scaling_factor : float     Multiplier to convert the current length scale to metres. Default: 1e-9 for the     usual AFM length scale of nanometres.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>class GrainStats:\n    \"\"\"\n    Class for calculating grain stats.\n\n    Parameters\n    ----------\n    data : npt.NDArray\n        2D Numpy array containing the flattened afm image. Data in this 2D array is floating point.\n    labelled_data : npt.NDArray\n        2D Numpy array containing all the grain masks in the image. Data in this 2D array is boolean.\n    pixel_to_nanometre_scaling : float\n        Floating point value that defines the scaling factor between nanometres and pixels.\n    direction : str\n        Direction for which grains have been detected (\"above\" or \"below\").\n    base_output_dir : Path\n        Path to the folder that will store the grain stats output images and data.\n    image_name : str\n        The name of the file being processed.\n    edge_detection_method : str\n        Method used for detecting the edges of grain masks before calculating statistics on them.\n        Do not change unless you know exactly what this is doing. Options: \"binary_erosion\", \"canny\".\n    extract_height_profile : bool\n        Extract the height profile.\n    cropped_size : float\n        Length of square side (in nm) to crop grains to.\n    plot_opts : dict\n        Plotting options dictionary for the cropped grains.\n    metre_scaling_factor : float\n        Multiplier to convert the current length scale to metres. Default: 1e-9 for the\n        usual AFM length scale of nanometres.\n    \"\"\"\n\n    def __init__(\n        self,\n        data: npt.NDArray,\n        labelled_data: npt.NDArray,\n        pixel_to_nanometre_scaling: float,\n        direction: str,\n        base_output_dir: str | Path,\n        image_name: str = None,\n        edge_detection_method: str = \"binary_erosion\",\n        extract_height_profile: bool = False,\n        cropped_size: float = -1,\n        plot_opts: dict = None,\n        metre_scaling_factor: float = 1e-9,\n    ):\n        \"\"\"\n        Initialise the class.\n\n        Parameters\n        ----------\n        data : npt.NDArray\n            2D Numpy array containing the flattened afm image. Data in this 2D array is floating point.\n        labelled_data : npt.NDArray\n            2D Numpy array containing all the grain masks in the image. Data in this 2D array is boolean.\n        pixel_to_nanometre_scaling : float\n            Floating point value that defines the scaling factor between nanometres and pixels.\n        direction : str\n            Direction for which grains have been detected (\"above\" or \"below\").\n        base_output_dir : Path\n            Path to the folder that will store the grain stats output images and data.\n        image_name : str\n            The name of the file being processed.\n        edge_detection_method : str\n            Method used for detecting the edges of grain masks before calculating statistics on them.\n            Do not change unless you know exactly what this is doing. Options: \"binary_erosion\", \"canny\".\n        extract_height_profile : bool\n            Extract the height profile.\n        cropped_size : float\n            Length of square side (in nm) to crop grains to.\n        plot_opts : dict\n            Plotting options dictionary for the cropped grains.\n        metre_scaling_factor : float\n            Multiplier to convert the current length scale to metres. Default: 1e-9 for the\n            usual AFM length scale of nanometres.\n        \"\"\"\n        self.data = data\n        self.labelled_data = labelled_data\n        self.pixel_to_nanometre_scaling = pixel_to_nanometre_scaling\n        self.direction = direction\n        self.base_output_dir = Path(base_output_dir)\n        self.start_point = None\n        self.image_name = image_name\n        self.edge_detection_method = edge_detection_method\n        self.extract_height_profile = extract_height_profile\n        self.cropped_size = cropped_size\n        self.plot_opts = plot_opts\n        self.metre_scaling_factor = metre_scaling_factor\n\n    @staticmethod\n    def get_angle(point_1: tuple, point_2: tuple) -&gt; float:\n        \"\"\"\n        Calculate the angle in radians between two points.\n\n        Parameters\n        ----------\n        point_1 : tuple\n            Coordinate vectors for the first point to find the angle between.\n        point_2 : tuple\n            Coordinate vectors for the second point to find the angle between.\n\n        Returns\n        -------\n        float\n            The angle in radians between the two input vectors.\n        \"\"\"\n        return np.arctan2(point_1[1] - point_2[1], point_1[0] - point_2[0])\n\n    @staticmethod\n    def is_clockwise(p_1: tuple, p_2: tuple, p_3: tuple) -&gt; bool:\n        \"\"\"\n        Determine if three points make a clockwise or counter-clockwise turn.\n\n        Parameters\n        ----------\n        p_1 : tuple\n            First point to be used to calculate turn.\n        p_2 : tuple\n            Second point to be used to calculate turn.\n        p_3 : tuple\n            Third point to be used to calculate turn.\n\n        Returns\n        -------\n        boolean\n            Indicator of whether turn is clockwise.\n        \"\"\"\n        # Determine if three points form a clockwise or counter-clockwise turn.\n        # I use the method of calculating the determinant of the following rotation matrix here. If the determinant\n        # is &gt; 0 then the rotation is counter-clockwise.\n        rotation_matrix = np.asarray(((p_1[0], p_1[1], 1), (p_2[0], p_2[1], 1), (p_3[0], p_3[1], 1)))\n        return not np.linalg.det(rotation_matrix) &gt; 0\n\n    def calculate_stats(self) -&gt; tuple(pd.DataFrame, dict):\n        \"\"\"\n        Calculate the stats of grains in the labelled image.\n\n        Returns\n        -------\n        tuple\n            Consists of a pd.DataFrame containing all the grain stats that have been calculated for the labelled image\n            and a list of dictionaries containing grain data to be plotted.\n        \"\"\"\n        grains_plot_data = []\n        all_height_profiles = {}\n        if self.labelled_data is None:\n            LOGGER.warning(\n                f\"[{self.image_name}] : No labelled regions for this image, grain statistics can not be calculated.\"\n            )\n            return pd.DataFrame(columns=GRAIN_STATS_COLUMNS), grains_plot_data, all_height_profiles\n\n        # Calculate region properties\n        region_properties = skimage_measure.regionprops(self.labelled_data)\n\n        # Iterate over all the grains in the image\n        stats_array = []\n        # List to hold all the plot data for all the grains. Each entry is a dictionary of plotting data.\n        # There are multiple entries for each grain.\n        for index, region in enumerate(region_properties):\n            LOGGER.debug(f\"[{self.image_name}] : Processing grain: {index}\")\n\n            # Skip grain if too small to calculate stats for\n            LOGGER.debug(f\"[{self.image_name}] : Grain size: {region.image.size}\")\n            if min(region.image.shape) &lt; 5:\n                LOGGER.debug(\n                    f\"[{self.image_name}] : Skipping grain due to being too small (size: {region.image.shape}) to calculate stats for.\"\n                )\n                continue\n\n            # Create directory for each grain's plots\n            output_grain = self.base_output_dir / self.direction\n            # Obtain cropped grain mask and image\n            minr, minc, maxr, maxc = region.bbox\n            grain_mask = np.array(region.image)\n            grain_image = self.data[minr:maxr, minc:maxc]\n            grain_mask_image = np.ma.masked_array(grain_image, mask=np.invert(grain_mask), fill_value=np.nan).filled()\n\n            if self.cropped_size == -1:\n                for name, image in {\n                    \"grain_image\": grain_image,\n                    \"grain_mask\": grain_mask,\n                    \"grain_mask_image\": grain_mask_image,\n                }.items():\n                    grains_plot_data.append(\n                        {\n                            \"data\": image,\n                            \"output_dir\": output_grain,\n                            \"filename\": f\"{self.image_name}_{name}_{index}\",\n                            \"name\": name,\n                        }\n                    )\n\n            else:\n                # Get cropped image and mask\n                grain_centre = int((minr + maxr) / 2), int((minc + maxc) / 2)\n                length = int(self.cropped_size / (2 * self.pixel_to_nanometre_scaling))\n                solo_mask = self.labelled_data.copy()\n                solo_mask[solo_mask != index + 1] = 0\n                solo_mask[solo_mask == index + 1] = 1\n                cropped_grain_image = self.get_cropped_region(self.data, length, np.asarray(grain_centre))\n                cropped_grain_mask = self.get_cropped_region(solo_mask, length, np.asarray(grain_centre)).astype(bool)\n                cropped_grain_mask_image = np.ma.masked_array(\n                    grain_image, mask=np.invert(grain_mask), fill_value=np.nan\n                ).filled()\n                for name, image in {\n                    \"grain_image\": cropped_grain_image,\n                    \"grain_mask\": cropped_grain_mask,\n                    \"grain_mask_image\": cropped_grain_mask_image,\n                }.items():\n                    grains_plot_data.append(\n                        {\n                            \"data\": image,\n                            \"output_dir\": output_grain,\n                            \"filename\": f\"{self.image_name}_{name}_{index}\",\n                            \"name\": name,\n                        }\n                    )\n\n            points = self.calculate_points(grain_mask)\n            edges = self.calculate_edges(grain_mask, edge_detection_method=self.edge_detection_method)\n            radius_stats = self.calculate_radius_stats(edges, points)\n            # hull, hull_indices, hull_simplexes = self.convex_hull(edges, output_grain)\n            _, _, hull_simplexes = self.convex_hull(edges, output_grain)\n            centroid = self._calculate_centroid(points)\n            # Centroids for the grains (minc and minr added because centroid returns values local to the cropped grain images)\n            centre_x = centroid[0] + minc\n            centre_y = centroid[1] + minr\n            (\n                smallest_bounding_width,\n                smallest_bounding_length,\n                aspect_ratio,\n            ) = self.calculate_aspect_ratio(\n                edges=edges,\n                hull_simplices=hull_simplexes,\n                path=output_grain,\n            )\n\n            # Calculate scaling factors\n            length_scaling_factor = self.pixel_to_nanometre_scaling * self.metre_scaling_factor\n            area_scaling_factor = length_scaling_factor**2\n\n            # Calculate minimum and maximum feret diameters and scale the distances\n            feret_statistics = feret.min_max_feret(points)\n            feret_statistics[\"min_feret\"] = feret_statistics[\"min_feret\"] * length_scaling_factor\n            feret_statistics[\"max_feret\"] = feret_statistics[\"max_feret\"] * length_scaling_factor\n\n            if self.extract_height_profile:\n                all_height_profiles[index] = height_profiles.interpolate_height_profile(\n                    img=grain_image, mask=grain_mask\n                )\n                LOGGER.debug(f\"[{self.image_name}] : Height profiles extracted.\")\n\n            # Save the stats to dictionary. Note that many of the stats are multiplied by a scaling factor to convert\n            # from pixel units to nanometres.\n            # Removed formatting, better to keep accurate until the end, including in CSV, then shorten display\n            stats = {\n                \"centre_x\": centre_x * length_scaling_factor,\n                \"centre_y\": centre_y * length_scaling_factor,\n                \"radius_min\": radius_stats[\"min\"] * length_scaling_factor,\n                \"radius_max\": radius_stats[\"max\"] * length_scaling_factor,\n                \"radius_mean\": radius_stats[\"mean\"] * length_scaling_factor,\n                \"radius_median\": radius_stats[\"median\"] * length_scaling_factor,\n                \"height_min\": np.nanmin(grain_mask_image) * self.metre_scaling_factor,\n                \"height_max\": np.nanmax(grain_mask_image) * self.metre_scaling_factor,\n                \"height_median\": np.nanmedian(grain_mask_image) * self.metre_scaling_factor,\n                \"height_mean\": np.nanmean(grain_mask_image) * self.metre_scaling_factor,\n                # [volume] = [pixel] * [pixel] * [height] = px * px * nm.\n                # To turn into m^3, multiply by pixel_to_nanometre_scaling^2 and metre_scaling_factor^3.\n                \"volume\": np.nansum(grain_mask_image)\n                * self.pixel_to_nanometre_scaling**2\n                * (self.metre_scaling_factor**3),\n                \"area\": region.area * area_scaling_factor,\n                \"area_cartesian_bbox\": region.area_bbox * area_scaling_factor,\n                \"smallest_bounding_width\": smallest_bounding_width * length_scaling_factor,\n                \"smallest_bounding_length\": smallest_bounding_length * length_scaling_factor,\n                \"smallest_bounding_area\": smallest_bounding_length * smallest_bounding_width * area_scaling_factor,\n                \"aspect_ratio\": aspect_ratio,\n                \"threshold\": self.direction,\n                \"max_feret\": feret_statistics[\"max_feret\"],\n                \"min_feret\": feret_statistics[\"min_feret\"],\n            }\n            stats_array.append(stats)\n        if len(stats_array) &gt; 0:\n            grainstats_df = pd.DataFrame(data=stats_array)\n        else:\n            grainstats_df = create_empty_dataframe()\n        grainstats_df.index.name = \"grain_number\"\n        grainstats_df[\"image\"] = self.image_name\n\n        return grainstats_df, grains_plot_data, all_height_profiles\n\n    @staticmethod\n    def calculate_points(grain_mask: npt.NDArray) -&gt; list:\n        \"\"\"\n        Convert a 2D boolean array to a list of coordinates.\n\n        Parameters\n        ----------\n        grain_mask : npt.NDArray\n            A 2D numpy array image of a grain. Data in the array must be boolean.\n\n        Returns\n        -------\n        list\n            A python list containing the coordinates of the pixels in the grain.\n        \"\"\"\n        nonzero_coordinates = grain_mask.nonzero()\n        points = []\n        for point in np.transpose(nonzero_coordinates):\n            points.append(list(point))\n\n        return points\n\n    @staticmethod\n    def calculate_edges(grain_mask: npt.NDArray, edge_detection_method: str) -&gt; list:\n        \"\"\"\n        Convert 2D boolean array to list of the coordinates of the edges of the grain.\n\n        Parameters\n        ----------\n        grain_mask : npt.NDArray\n            A 2D numpy array image of a grain. Data in the array must be boolean.\n        edge_detection_method : str\n            Method used for detecting the edges of grain masks before calculating statistics on them.\n            Do not change unless you know exactly what this is doing. Options: \"binary_erosion\", \"canny\".\n\n        Returns\n        -------\n        list\n            List containing the coordinates of the edges of the grain.\n        \"\"\"\n        # Fill any holes\n        filled_grain_mask = scipy.ndimage.binary_fill_holes(grain_mask)\n\n        if edge_detection_method == \"binary_erosion\":\n            # Add padding (needed for erosion)\n            padded = np.pad(filled_grain_mask, 1)\n            # Erode by 1 pixel\n            eroded = skimage_morphology.binary_erosion(padded)\n            # Remove padding\n            eroded = eroded[1:-1, 1:-1]\n\n            # Edges is equal to the difference between the\n            # original image and the eroded image.\n            edges = filled_grain_mask.astype(int) - eroded.astype(int)\n        else:\n            # Get outer edge using canny filtering\n            edges = skimage_feature.canny(filled_grain_mask, sigma=3)\n\n        nonzero_coordinates = edges.nonzero()\n        # Get vector representation of the points\n        # FIXME : Switched to list comprehension but should be unnecessary to create this as a list as we can use\n        # np.stack() to combine the arrays and use that...\n        # return np.stack(nonzero_coordinates, axis=1)\n        return [list(vector) for vector in np.transpose(nonzero_coordinates)]\n\n    def calculate_radius_stats(self, edges: list, points: list) -&gt; tuple[float]:\n        \"\"\"\n        Calculate the radius of grains.\n\n        The radius in this context is the distance from the centroid to points on the edge of the grain.\n\n        Parameters\n        ----------\n        edges : list\n            A 2D python list containing the coordinates of the edges of a grain.\n        points : list\n            A 2D python list containing the coordinates of the points in a grain.\n\n        Returns\n        -------\n        tuple[float]\n            A tuple of the minimum, maximum, mean and median radius of the grain.\n        \"\"\"\n        # Calculate the centroid of the grain\n        centroid = self._calculate_centroid(points)\n        # Calculate the displacement\n        displacements = self._calculate_displacement(edges, centroid)\n        # Calculate the radius of each point\n        radii = self._calculate_radius(displacements)\n        return {\n            \"min\": np.min(radii),\n            \"max\": np.max(radii),\n            \"mean\": np.mean(radii),\n            \"median\": np.median(radii),\n        }\n\n    @staticmethod\n    def _calculate_centroid(points: np.array) -&gt; tuple:\n        \"\"\"\n        Calculate the centroid of a bounding box.\n\n        Parameters\n        ----------\n        points : list\n            A 2D python list containing the coordinates of the points in a grain.\n\n        Returns\n        -------\n        tuple\n            The coordinates of the centroid.\n        \"\"\"\n        # FIXME : Remove once we have a numpy array returned by calculate_edges\n        points = np.array(points)\n        return (np.mean(points[:, 0]), np.mean(points[:, 1]))\n\n    @staticmethod\n    def _calculate_displacement(edges: npt.NDArray, centroid: tuple) -&gt; npt.NDArray:\n        \"\"\"\n        Calculate the displacement between the edges and centroid.\n\n        Parameters\n        ----------\n        edges : npt.NDArray\n            Coordinates of the edge points.\n        centroid : tuple\n            Coordinates of the centroid.\n\n        Returns\n        -------\n        npt.NDArray\n            Array of displacements.\n        \"\"\"\n        # FIXME : Remove once we have a numpy array returned by calculate_edges\n        return np.array(edges) - centroid\n\n    @staticmethod\n    def _calculate_radius(displacements: list[list]) -&gt; npt.NDarray:\n        \"\"\"\n        Calculate the radius of each point from the centroid.\n\n        Parameters\n        ----------\n        displacements : List[list]\n            A list of displacements.\n\n        Returns\n        -------\n        npt.NDarray\n            Array of radii of each point from the centroid.\n        \"\"\"\n        return np.array([np.sqrt(radius[0] ** 2 + radius[1] ** 2) for radius in displacements])\n\n    def convex_hull(self, edges: list, base_output_dir: Path, debug: bool = False) -&gt; tuple[list, list, list]:\n        \"\"\"\n        Calculate a grain's convex hull.\n\n        Based off of the Graham Scan algorithm and should ideally scale in time with O(nlog(n)).\n\n        Parameters\n        ----------\n        edges : list\n            A python list containing the coordinates of the edges of the grain.\n        base_output_dir : Path\n            Directory to save output to.\n        debug : bool\n            Default false. If true, debug information will be displayed to the terminal and plots for the convex hulls\n            and edges will be saved.\n\n        Returns\n        -------\n        tuple[list, list, list]\n            A hull (list) of the coordinates of each point on the hull. Hull indices providing a way to find the points\n            from the hill inside the edge list that was passed. Simplices (list) of tuples each representing a simplex\n            of the convex hull, these are sorted in a counter-clockwise order.\n        \"\"\"\n        hull, hull_indices, simplexes = self.graham_scan(edges)\n\n        # Debug information\n        if debug:\n            base_output_dir.mkdir(parents=True, exist_ok=True)\n            self.plot(edges, hull, base_output_dir / \"_points_hull.png\")\n            LOGGER.debug(f\"points: {edges}\")\n            LOGGER.debug(f\"hull: {hull}\")\n            LOGGER.debug(f\"hull indexes: {hull_indices}\")\n            LOGGER.debug(f\"simplexes: {simplexes}\")\n\n        return hull, hull_indices, simplexes\n\n    def calculate_squared_distance(self, point_2: tuple, point_1: tuple = None) -&gt; float:\n        \"\"\"\n        Calculate the squared distance between two points.\n\n        Used for distance sorting purposes and therefore does not perform a square root in the interests of efficiency.\n\n        Parameters\n        ----------\n        point_2 : tuple\n            The point to find the squared distance to.\n        point_1 : tuple\n            Optional - defaults to the starting point defined in the graham_scan() function. The point to find the\n            squared distance from.\n\n        Returns\n        -------\n        float\n            The squared distance between the two points.\n        \"\"\"\n        # Get the distance squared between two points. If the second point is not provided, use the starting point.\n        point_1 = self.start_point if point_1 is None else point_1\n        delta_x = point_2[0] - point_1[0]\n        delta_y = point_2[1] - point_1[1]\n        # Don't need the sqrt since just sorting for dist\n        return float(delta_x**2 + delta_y**2)\n\n    def sort_points(self, points: list) -&gt; list:\n        #    def sort_points(self, points: np.array) -&gt; List:\n        \"\"\"\n        Sort points in counter-clockwise order of angle made with the starting point.\n\n        Parameters\n        ----------\n        points : list\n            A python list of the coordinates to sort.\n\n        Returns\n        -------\n        list\n            Points (coordinates) sorted counter-clockwise.\n        \"\"\"\n        # Return if the list is length 1 or 0 (i.e. a single point).\n        if len(points) &lt;= 1:\n            return points\n        # Lists that allow sorting of points relative to a current comparison point\n        smaller, equal, larger = [], [], []\n        # Get a random point in the array to calculate the pivot angle from. This sorts the points relative to this point.\n        pivot_angle = self.get_angle(points[randint(0, len(points) - 1)], self.start_point)  # noqa: S311\n        for point in points:\n            point_angle = self.get_angle(point, self.start_point)\n            # If the\n            if point_angle &lt; pivot_angle:\n                smaller.append(point)\n            elif point_angle == pivot_angle:\n                equal.append(point)\n            else:\n                larger.append(point)\n        # Lets take a different approach and use arrays, we have a start point lets work out the angle of each point\n        # relative to that and _then_ sort it.\n        # pivot_angles = self.get_angle(points, self.start_point)\n        # Recursively sort the arrays until each point is sorted\n        return self.sort_points(smaller) + sorted(equal, key=self.calculate_squared_distance) + self.sort_points(larger)\n        # Return sorted array where equal angle points are sorted by distance\n\n    def get_start_point(self, edges: npt.NDArray) -&gt; None:\n        \"\"\"\n        Determine the index of the bottom most point of the hull when sorted by x-position.\n\n        Parameters\n        ----------\n        edges : npt.NDArray\n            Array of coordinates.\n        \"\"\"\n        min_y_index = np.argmin(edges[:, 1])\n        self.start_point = edges[min_y_index]\n\n    def graham_scan(self, edges: list) -&gt; tuple[list, list, list]:\n        \"\"\"\n        Construct the convex hull using the  Graham Scan algorithm.\n\n        Ideally this algorithm will take O( n * log(n) ) time.\n\n        Parameters\n        ----------\n        edges : list\n            A python list of coordinates that make up the edges of the grain.\n\n        Returns\n        -------\n        tuple[list, list, list]\n            A hull (list) of the coordinates of each point on the hull. Hull indices providing a way to find the points\n            from the hill inside the edge list that was passed. Simplices (list) of tuples each representing a simplex\n            of the convex hull, these are sorted in a counter-clockwise order.\n        \"\"\"\n        # FIXME : Make this an isolated method\n        # Find a point guaranteed to be on the hull. I find the bottom most point(s) and sort by x-position.\n        min_y_index = None\n        for index, point in enumerate(edges):\n            if min_y_index is None or point[1] &lt; edges[min_y_index][1]:\n                min_y_index = index\n            if point[1] == edges[min_y_index][1] and point[0] &lt; edges[min_y_index][0]:\n                min_y_index = index\n        self.start_point = edges[min_y_index]\n        # This does the same thing, but as a separate method and with Numpy Array rather than a list\n        # self.get_start_point(edges)\n        # Sort the points\n        points_sorted_by_angle = self.sort_points(edges)\n\n        # Remove starting point from the list so it's not added more than once to the hull\n        start_point_index = points_sorted_by_angle.index(self.start_point)\n        del points_sorted_by_angle[start_point_index]\n        # Add start point and the first point sorted by angle. Both of these points will always be on the hull.\n        hull = [self.start_point, points_sorted_by_angle[0]]\n\n        # Iterate through each point, checking if this point would cause a clockwise rotation if added to the hull, and\n        # if so, backtracking.\n        for _, point in enumerate(points_sorted_by_angle[1:]):\n            # Determine if the proposed point demands a clockwise rotation\n            while self.is_clockwise(hull[-2], hull[-1], point) is True:\n                # Delete the failed point\n                del hull[-1]\n                if len(hull) &lt; 2:\n                    break\n            # The point does not immediately cause a clockwise rotation.\n            hull.append(point)\n\n        # Get hull indices from original points array\n        hull_indices = []\n        for point in hull:\n            hull_indices.append(edges.index(point))\n\n        # Create simplices from the hull points\n        simplices = []\n        for index, value in enumerate(hull_indices):\n            simplices.append((hull_indices[index - 1], value))\n\n        return hull, hull_indices, simplices\n\n    @staticmethod\n    def plot(edges: list, convex_hull: list = None, file_path: Path = None) -&gt; None:\n        \"\"\"\n        Plot and save the coordinates of the edges in the grain and optionally the hull.\n\n        Parameters\n        ----------\n        edges : list\n            A list of points to be plotted.\n        convex_hull : list\n            Optional argument. A list of points that form the convex hull. Will be plotted with the coordinates if\n            provided.\n        file_path : Path\n            Path of the file to save the plot as.\n        \"\"\"\n        _, ax = plt.subplots(1, 1, figsize=(8, 8))\n        x_s, y_s = zip(*edges)\n        ax.scatter(x_s, y_s)\n        if convex_hull is not None:\n            for index in range(1, len(convex_hull) + 1):\n                # Loop on the final simplex of the hull to join the last and first points together.\n                if len(convex_hull) == index:\n                    index = 0\n                point2 = convex_hull[index]\n                point1 = convex_hull[index - 1]\n                # Plot a line between the two points\n                plt.plot((point1[0], point2[0]), (point1[1], point2[1]), \"#994400\")\n        plt.savefig(file_path)\n        plt.close()\n\n    def calculate_aspect_ratio(\n        self, edges: list, hull_simplices: npt.NDArray, path: Path, debug: bool = False\n    ) -&gt; tuple:\n        \"\"\"\n        Calculate the width, length and aspect ratio of the smallest bounding rectangle of a grain.\n\n        Parameters\n        ----------\n        edges : list\n            A python list of coordinates of the edge of the grain.\n        hull_simplices : npt.NDArray\n            A 2D numpy array of simplices that the hull is comprised of.\n        path : Path\n            Path to the save folder for the grain.\n        debug : bool\n            If true, various plots will be saved for diagnostic purposes.\n\n        Returns\n        -------\n        tuple:\n            The smallest_bouning_width (float) in pixels (not nanometres) of the smallest bounding rectangle for the\n            grain. The smallest_bounding_length (float) in pixels (not nanometres), of the smallest bounding rectangle\n            for the grain. And the aspect_ratio (float) the width divided by the length of the smallest bounding\n            rectangle for the grain. It will always be greater or equal to 1.\n        \"\"\"\n        # Ensure the edges are in the form of a numpy array.\n        edges = np.array(edges)\n\n        # Create a variable to store the smallest area in - this is to be able to compare whilst iterating\n        smallest_bounding_area = None\n        # FIXME : pylint complains that this is unused which looks like a false positive to me as it is used.\n        #         Probably does not need initiating here though (and code runs fine when doing so)\n        # smallest_bounding_rectangle = None\n\n        # Iterate through the simplices\n        for simplex_index, simplex in enumerate(hull_simplices):\n            p_1 = edges[simplex[0]]\n            p_2 = edges[simplex[1]]\n            delta = p_1 - p_2\n            angle = np.arctan2(delta[0], delta[1])\n\n            # Find the centroid of the points\n            centroid = (sum(edges[:, 0]) / len(edges), sum(edges[:, 1] / len(edges)))\n\n            # Map the coordinates such that the centroid is now centered on the origin. This is needed for the\n            # matrix rotation step coming up.\n            remapped_points = edges - centroid\n\n            # Rotate the coordinates using a rotation matrix\n            rotated_coordinates = np.array(((np.cos(angle), -np.sin(angle)), (np.sin(angle), np.cos(angle))))\n\n            # For each point in the set, rotate it using the above rotation matrix.\n            rotated_points = []\n            for _, point in enumerate(remapped_points):\n                newpoint = rotated_coordinates @ point\n                # FIXME : Can probably use np.append() here to append arrays directly, something like\n                # np.append(rotated_points, newpoint, axis=0) but doing so requires other areas to be modified\n                rotated_points.append(newpoint)\n            rotated_points = np.array(rotated_points)\n            # Find the cartesian extremities\n            extremes = self.find_cartesian_extremes(rotated_points)\n\n            if debug:\n                # Ensure directory is there\n                path.mkdir(parents=True, exist_ok=True)\n\n                # Create plot\n                # FIXME : Make this a method\n                fig = plt.figure(figsize=(8, 8))\n                ax = fig.add_subplot(111)\n\n                # Draw the points and the current simplex that is being tested\n                plt.scatter(x=remapped_points[:, 0], y=remapped_points[:, 1])\n                plt.plot(\n                    remapped_points[simplex, 0],\n                    remapped_points[simplex, 1],\n                    \"#444444\",\n                    linewidth=4,\n                )\n                plt.scatter(x=rotated_points[:, 0], y=rotated_points[:, 1])\n                plt.plot(\n                    rotated_points[simplex, 0],\n                    rotated_points[simplex, 1],\n                    \"k-\",\n                    linewidth=5,\n                )\n                LOGGER.debug(rotated_points[simplex, 0], rotated_points[simplex, 1])\n\n                # Draw the convex hulls\n                for _simplex in hull_simplices:\n                    plt.plot(\n                        remapped_points[_simplex, 0],\n                        remapped_points[_simplex, 1],\n                        \"#888888\",\n                    )\n                    plt.plot(\n                        rotated_points[_simplex, 0],\n                        rotated_points[_simplex, 1],\n                        \"#555555\",\n                    )\n\n                # Draw bounding box\n                plt.plot(\n                    [\n                        extremes[\"x_min\"],\n                        extremes[\"x_min\"],\n                        extremes[\"x_max\"],\n                        extremes[\"x_max\"],\n                        extremes[\"x_min\"],\n                    ],\n                    [\n                        extremes[\"y_min\"],\n                        extremes[\"y_max\"],\n                        extremes[\"y_max\"],\n                        extremes[\"y_min\"],\n                        extremes[\"y_min\"],\n                    ],\n                    \"#994400\",\n                )\n                plt.savefig(path / (\"bounding_rectangle_construction_simplex_\" + str(simplex_index) + \".png\"))\n\n            # Calculate the area of the proposed bounding rectangle\n            bounding_area = (extremes[\"x_max\"] - extremes[\"x_min\"]) * (extremes[\"y_max\"] - extremes[\"y_min\"])\n\n            # If current bounding rectangle is the smallest so far\n            if smallest_bounding_area is None or bounding_area &lt; smallest_bounding_area:\n                smallest_bounding_area = bounding_area\n                smallest_bounding_width = min(\n                    (extremes[\"x_max\"] - extremes[\"x_min\"]),\n                    (extremes[\"y_max\"] - extremes[\"y_min\"]),\n                )\n                smallest_bounding_length = max(\n                    (extremes[\"x_max\"] - extremes[\"x_min\"]),\n                    (extremes[\"y_max\"] - extremes[\"y_min\"]),\n                )\n                # aspect ratio bounded to be &lt;= 1\n                aspect_ratio = smallest_bounding_width / smallest_bounding_length\n\n        # Unrotate the bounding box vertices\n        r_inverse = rotated_coordinates.T\n        translated_rotated_bounding_rectangle_vertices = np.array(\n            (\n                [extremes[\"x_min\"], extremes[\"y_min\"]],\n                [extremes[\"x_max\"], extremes[\"y_min\"]],\n                [extremes[\"x_max\"], extremes[\"y_max\"]],\n                [extremes[\"x_min\"], extremes[\"y_max\"]],\n            )\n        )\n        translated_bounding_rectangle_vertices = []\n        for _, point in enumerate(translated_rotated_bounding_rectangle_vertices):\n            newpoint = r_inverse @ point\n            # FIXME : As above can likely use np.append(, axis=0) here\n            translated_bounding_rectangle_vertices.append(newpoint)\n        translated_bounding_rectangle_vertices = np.array(translated_bounding_rectangle_vertices)\n\n        if debug:\n            # Create plot\n            # FIXME : Make this a private method\n            fig = plt.figure(figsize=(8, 8))\n            ax = fig.add_subplot(111)\n            plt.scatter(x=edges[:, 0], y=edges[:, 1])\n            ax.plot(\n                np.append(\n                    translated_rotated_bounding_rectangle_vertices[:, 0],\n                    translated_rotated_bounding_rectangle_vertices[0, 0],\n                ),\n                np.append(\n                    translated_rotated_bounding_rectangle_vertices[:, 1],\n                    translated_rotated_bounding_rectangle_vertices[0, 1],\n                ),\n                \"#994400\",\n                label=\"rotated\",\n            )\n            ax.plot(\n                np.append(\n                    translated_bounding_rectangle_vertices[:, 0],\n                    translated_bounding_rectangle_vertices[0, 0],\n                ),\n                np.append(\n                    translated_bounding_rectangle_vertices[:, 1],\n                    translated_bounding_rectangle_vertices[0, 1],\n                ),\n                \"#004499\",\n                label=\"unrotated\",\n            )\n            ax.scatter(\n                x=remapped_points[:, 0],\n                y=remapped_points[:, 1],\n                color=\"#004499\",\n                label=\"translated\",\n            )\n            ax.scatter(x=rotated_points[:, 0], y=rotated_points[:, 1], label=\"rotated\")\n            ax.legend()\n            plt.savefig(path / \"hull_bounding_rectangle_extra\")\n\n        fig = plt.figure(figsize=(8, 8))\n        ax = fig.add_subplot(111)\n        bounding_rectangle_vertices = translated_bounding_rectangle_vertices + centroid\n        ax.plot(\n            np.append(bounding_rectangle_vertices[:, 0], bounding_rectangle_vertices[0, 0]),\n            np.append(bounding_rectangle_vertices[:, 1], bounding_rectangle_vertices[0, 1]),\n            \"#994400\",\n            label=\"unrotated\",\n        )\n        ax.scatter(x=edges[:, 0], y=edges[:, 1], label=\"original points\")\n        ax.set_aspect(1)\n        ax.legend()\n        plt.xlabel(\"Grain Length (nm)\")\n        plt.ylabel(\"Grain Width (nm)\")\n        # plt.savefig(path / \"minimum_bbox.png\")\n        plt.close()\n\n        return smallest_bounding_width, smallest_bounding_length, aspect_ratio\n\n    @staticmethod\n    def find_cartesian_extremes(rotated_points: npt.NDArray) -&gt; dict:\n        \"\"\"\n        Find the limits of x and y of rotated points.\n\n        Parameters\n        ----------\n        rotated_points : npt.NDArray\n            2-D array of rotated points.\n\n        Returns\n        -------\n        Dict\n            Dictionary of the x and y min and max.__annotations__.\n        \"\"\"\n        extremes = {}\n        extremes[\"x_min\"] = np.min(rotated_points[:, 0])\n        extremes[\"x_max\"] = np.max(rotated_points[:, 0])\n        extremes[\"y_min\"] = np.min(rotated_points[:, 1])\n        extremes[\"y_max\"] = np.max(rotated_points[:, 1])\n        return extremes\n\n    @staticmethod\n    def get_shift(coords: npt.NDArray, shape: npt.NDArray) -&gt; int:\n        \"\"\"\n        Obtain the coordinate shift to reflect the cropped image box for molecules near the edges of the image.\n\n        Parameters\n        ----------\n        coords : npt.NDArray\n            Value representing integer coordinates which may be outside of the image.\n        shape : npt.NDArray\n            Array of the shape of an image.\n\n        Returns\n        -------\n        np.int64\n            Max value of the shift to reflect the croped region so it stays within the image.\n        \"\"\"\n        shift = shape - coords[np.where(coords &gt; shape)]\n        shift = np.hstack((shift, -coords[np.where(coords &lt; 0)]))\n        if len(shift) == 0:\n            return 0\n        max_index = np.argmax(abs(shift))\n        return shift[max_index]\n\n    def get_cropped_region(self, image: npt.NDArray, length: int, centre: npt.NDArray) -&gt; npt.NDArray:\n        \"\"\"\n        Crop the image with respect to a given pixel length around the centre coordinates.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            The image array.\n        length : int\n            The length (in pixels) of the resultant cropped image.\n        centre : npt.NDArray\n            The centre of the object to crop.\n\n        Returns\n        -------\n        npt.NDArray\n            Cropped array of the image.\n        \"\"\"\n        shape = image.shape\n        xy1 = shape - (centre + length + 1)\n        xy2 = shape - (centre - length)\n        xy = np.stack((xy1, xy2))\n        shiftx = self.get_shift(xy[:, 0], shape[0])\n        shifty = self.get_shift(xy[:, 1], shape[1])\n        return image.copy()[\n            centre[0] - length - shiftx : centre[0] + length + 1 - shiftx,  # noqa: E203\n            centre[1] - length - shifty : centre[1] + length + 1 - shifty,  # noqa: E203\n        ]\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.__init__","title":"<code>__init__(data, labelled_data, pixel_to_nanometre_scaling, direction, base_output_dir, image_name=None, edge_detection_method='binary_erosion', extract_height_profile=False, cropped_size=-1, plot_opts=None, metre_scaling_factor=1e-09)</code>","text":"<p>Initialise the class.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.__init__--parameters","title":"Parameters","text":"<p>data : npt.NDArray     2D Numpy array containing the flattened afm image. Data in this 2D array is floating point. labelled_data : npt.NDArray     2D Numpy array containing all the grain masks in the image. Data in this 2D array is boolean. pixel_to_nanometre_scaling : float     Floating point value that defines the scaling factor between nanometres and pixels. direction : str     Direction for which grains have been detected (\"above\" or \"below\"). base_output_dir : Path     Path to the folder that will store the grain stats output images and data. image_name : str     The name of the file being processed. edge_detection_method : str     Method used for detecting the edges of grain masks before calculating statistics on them.     Do not change unless you know exactly what this is doing. Options: \"binary_erosion\", \"canny\". extract_height_profile : bool     Extract the height profile. cropped_size : float     Length of square side (in nm) to crop grains to. plot_opts : dict     Plotting options dictionary for the cropped grains. metre_scaling_factor : float     Multiplier to convert the current length scale to metres. Default: 1e-9 for the     usual AFM length scale of nanometres.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>def __init__(\n    self,\n    data: npt.NDArray,\n    labelled_data: npt.NDArray,\n    pixel_to_nanometre_scaling: float,\n    direction: str,\n    base_output_dir: str | Path,\n    image_name: str = None,\n    edge_detection_method: str = \"binary_erosion\",\n    extract_height_profile: bool = False,\n    cropped_size: float = -1,\n    plot_opts: dict = None,\n    metre_scaling_factor: float = 1e-9,\n):\n    \"\"\"\n    Initialise the class.\n\n    Parameters\n    ----------\n    data : npt.NDArray\n        2D Numpy array containing the flattened afm image. Data in this 2D array is floating point.\n    labelled_data : npt.NDArray\n        2D Numpy array containing all the grain masks in the image. Data in this 2D array is boolean.\n    pixel_to_nanometre_scaling : float\n        Floating point value that defines the scaling factor between nanometres and pixels.\n    direction : str\n        Direction for which grains have been detected (\"above\" or \"below\").\n    base_output_dir : Path\n        Path to the folder that will store the grain stats output images and data.\n    image_name : str\n        The name of the file being processed.\n    edge_detection_method : str\n        Method used for detecting the edges of grain masks before calculating statistics on them.\n        Do not change unless you know exactly what this is doing. Options: \"binary_erosion\", \"canny\".\n    extract_height_profile : bool\n        Extract the height profile.\n    cropped_size : float\n        Length of square side (in nm) to crop grains to.\n    plot_opts : dict\n        Plotting options dictionary for the cropped grains.\n    metre_scaling_factor : float\n        Multiplier to convert the current length scale to metres. Default: 1e-9 for the\n        usual AFM length scale of nanometres.\n    \"\"\"\n    self.data = data\n    self.labelled_data = labelled_data\n    self.pixel_to_nanometre_scaling = pixel_to_nanometre_scaling\n    self.direction = direction\n    self.base_output_dir = Path(base_output_dir)\n    self.start_point = None\n    self.image_name = image_name\n    self.edge_detection_method = edge_detection_method\n    self.extract_height_profile = extract_height_profile\n    self.cropped_size = cropped_size\n    self.plot_opts = plot_opts\n    self.metre_scaling_factor = metre_scaling_factor\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats._calculate_centroid","title":"<code>_calculate_centroid(points)</code>  <code>staticmethod</code>","text":"<p>Calculate the centroid of a bounding box.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats._calculate_centroid--parameters","title":"Parameters","text":"<p>points : list     A 2D python list containing the coordinates of the points in a grain.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats._calculate_centroid--returns","title":"Returns","text":"<p>tuple     The coordinates of the centroid.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>@staticmethod\ndef _calculate_centroid(points: np.array) -&gt; tuple:\n    \"\"\"\n    Calculate the centroid of a bounding box.\n\n    Parameters\n    ----------\n    points : list\n        A 2D python list containing the coordinates of the points in a grain.\n\n    Returns\n    -------\n    tuple\n        The coordinates of the centroid.\n    \"\"\"\n    # FIXME : Remove once we have a numpy array returned by calculate_edges\n    points = np.array(points)\n    return (np.mean(points[:, 0]), np.mean(points[:, 1]))\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats._calculate_displacement","title":"<code>_calculate_displacement(edges, centroid)</code>  <code>staticmethod</code>","text":"<p>Calculate the displacement between the edges and centroid.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats._calculate_displacement--parameters","title":"Parameters","text":"<p>edges : npt.NDArray     Coordinates of the edge points. centroid : tuple     Coordinates of the centroid.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats._calculate_displacement--returns","title":"Returns","text":"<p>npt.NDArray     Array of displacements.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>@staticmethod\ndef _calculate_displacement(edges: npt.NDArray, centroid: tuple) -&gt; npt.NDArray:\n    \"\"\"\n    Calculate the displacement between the edges and centroid.\n\n    Parameters\n    ----------\n    edges : npt.NDArray\n        Coordinates of the edge points.\n    centroid : tuple\n        Coordinates of the centroid.\n\n    Returns\n    -------\n    npt.NDArray\n        Array of displacements.\n    \"\"\"\n    # FIXME : Remove once we have a numpy array returned by calculate_edges\n    return np.array(edges) - centroid\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats._calculate_radius","title":"<code>_calculate_radius(displacements)</code>  <code>staticmethod</code>","text":"<p>Calculate the radius of each point from the centroid.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats._calculate_radius--parameters","title":"Parameters","text":"<p>displacements : List[list]     A list of displacements.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats._calculate_radius--returns","title":"Returns","text":"<p>npt.NDarray     Array of radii of each point from the centroid.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>@staticmethod\ndef _calculate_radius(displacements: list[list]) -&gt; npt.NDarray:\n    \"\"\"\n    Calculate the radius of each point from the centroid.\n\n    Parameters\n    ----------\n    displacements : List[list]\n        A list of displacements.\n\n    Returns\n    -------\n    npt.NDarray\n        Array of radii of each point from the centroid.\n    \"\"\"\n    return np.array([np.sqrt(radius[0] ** 2 + radius[1] ** 2) for radius in displacements])\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_aspect_ratio","title":"<code>calculate_aspect_ratio(edges, hull_simplices, path, debug=False)</code>","text":"<p>Calculate the width, length and aspect ratio of the smallest bounding rectangle of a grain.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_aspect_ratio--parameters","title":"Parameters","text":"<p>edges : list     A python list of coordinates of the edge of the grain. hull_simplices : npt.NDArray     A 2D numpy array of simplices that the hull is comprised of. path : Path     Path to the save folder for the grain. debug : bool     If true, various plots will be saved for diagnostic purposes.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_aspect_ratio--returns","title":"Returns","text":"<p>tuple:     The smallest_bouning_width (float) in pixels (not nanometres) of the smallest bounding rectangle for the     grain. The smallest_bounding_length (float) in pixels (not nanometres), of the smallest bounding rectangle     for the grain. And the aspect_ratio (float) the width divided by the length of the smallest bounding     rectangle for the grain. It will always be greater or equal to 1.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>def calculate_aspect_ratio(\n    self, edges: list, hull_simplices: npt.NDArray, path: Path, debug: bool = False\n) -&gt; tuple:\n    \"\"\"\n    Calculate the width, length and aspect ratio of the smallest bounding rectangle of a grain.\n\n    Parameters\n    ----------\n    edges : list\n        A python list of coordinates of the edge of the grain.\n    hull_simplices : npt.NDArray\n        A 2D numpy array of simplices that the hull is comprised of.\n    path : Path\n        Path to the save folder for the grain.\n    debug : bool\n        If true, various plots will be saved for diagnostic purposes.\n\n    Returns\n    -------\n    tuple:\n        The smallest_bouning_width (float) in pixels (not nanometres) of the smallest bounding rectangle for the\n        grain. The smallest_bounding_length (float) in pixels (not nanometres), of the smallest bounding rectangle\n        for the grain. And the aspect_ratio (float) the width divided by the length of the smallest bounding\n        rectangle for the grain. It will always be greater or equal to 1.\n    \"\"\"\n    # Ensure the edges are in the form of a numpy array.\n    edges = np.array(edges)\n\n    # Create a variable to store the smallest area in - this is to be able to compare whilst iterating\n    smallest_bounding_area = None\n    # FIXME : pylint complains that this is unused which looks like a false positive to me as it is used.\n    #         Probably does not need initiating here though (and code runs fine when doing so)\n    # smallest_bounding_rectangle = None\n\n    # Iterate through the simplices\n    for simplex_index, simplex in enumerate(hull_simplices):\n        p_1 = edges[simplex[0]]\n        p_2 = edges[simplex[1]]\n        delta = p_1 - p_2\n        angle = np.arctan2(delta[0], delta[1])\n\n        # Find the centroid of the points\n        centroid = (sum(edges[:, 0]) / len(edges), sum(edges[:, 1] / len(edges)))\n\n        # Map the coordinates such that the centroid is now centered on the origin. This is needed for the\n        # matrix rotation step coming up.\n        remapped_points = edges - centroid\n\n        # Rotate the coordinates using a rotation matrix\n        rotated_coordinates = np.array(((np.cos(angle), -np.sin(angle)), (np.sin(angle), np.cos(angle))))\n\n        # For each point in the set, rotate it using the above rotation matrix.\n        rotated_points = []\n        for _, point in enumerate(remapped_points):\n            newpoint = rotated_coordinates @ point\n            # FIXME : Can probably use np.append() here to append arrays directly, something like\n            # np.append(rotated_points, newpoint, axis=0) but doing so requires other areas to be modified\n            rotated_points.append(newpoint)\n        rotated_points = np.array(rotated_points)\n        # Find the cartesian extremities\n        extremes = self.find_cartesian_extremes(rotated_points)\n\n        if debug:\n            # Ensure directory is there\n            path.mkdir(parents=True, exist_ok=True)\n\n            # Create plot\n            # FIXME : Make this a method\n            fig = plt.figure(figsize=(8, 8))\n            ax = fig.add_subplot(111)\n\n            # Draw the points and the current simplex that is being tested\n            plt.scatter(x=remapped_points[:, 0], y=remapped_points[:, 1])\n            plt.plot(\n                remapped_points[simplex, 0],\n                remapped_points[simplex, 1],\n                \"#444444\",\n                linewidth=4,\n            )\n            plt.scatter(x=rotated_points[:, 0], y=rotated_points[:, 1])\n            plt.plot(\n                rotated_points[simplex, 0],\n                rotated_points[simplex, 1],\n                \"k-\",\n                linewidth=5,\n            )\n            LOGGER.debug(rotated_points[simplex, 0], rotated_points[simplex, 1])\n\n            # Draw the convex hulls\n            for _simplex in hull_simplices:\n                plt.plot(\n                    remapped_points[_simplex, 0],\n                    remapped_points[_simplex, 1],\n                    \"#888888\",\n                )\n                plt.plot(\n                    rotated_points[_simplex, 0],\n                    rotated_points[_simplex, 1],\n                    \"#555555\",\n                )\n\n            # Draw bounding box\n            plt.plot(\n                [\n                    extremes[\"x_min\"],\n                    extremes[\"x_min\"],\n                    extremes[\"x_max\"],\n                    extremes[\"x_max\"],\n                    extremes[\"x_min\"],\n                ],\n                [\n                    extremes[\"y_min\"],\n                    extremes[\"y_max\"],\n                    extremes[\"y_max\"],\n                    extremes[\"y_min\"],\n                    extremes[\"y_min\"],\n                ],\n                \"#994400\",\n            )\n            plt.savefig(path / (\"bounding_rectangle_construction_simplex_\" + str(simplex_index) + \".png\"))\n\n        # Calculate the area of the proposed bounding rectangle\n        bounding_area = (extremes[\"x_max\"] - extremes[\"x_min\"]) * (extremes[\"y_max\"] - extremes[\"y_min\"])\n\n        # If current bounding rectangle is the smallest so far\n        if smallest_bounding_area is None or bounding_area &lt; smallest_bounding_area:\n            smallest_bounding_area = bounding_area\n            smallest_bounding_width = min(\n                (extremes[\"x_max\"] - extremes[\"x_min\"]),\n                (extremes[\"y_max\"] - extremes[\"y_min\"]),\n            )\n            smallest_bounding_length = max(\n                (extremes[\"x_max\"] - extremes[\"x_min\"]),\n                (extremes[\"y_max\"] - extremes[\"y_min\"]),\n            )\n            # aspect ratio bounded to be &lt;= 1\n            aspect_ratio = smallest_bounding_width / smallest_bounding_length\n\n    # Unrotate the bounding box vertices\n    r_inverse = rotated_coordinates.T\n    translated_rotated_bounding_rectangle_vertices = np.array(\n        (\n            [extremes[\"x_min\"], extremes[\"y_min\"]],\n            [extremes[\"x_max\"], extremes[\"y_min\"]],\n            [extremes[\"x_max\"], extremes[\"y_max\"]],\n            [extremes[\"x_min\"], extremes[\"y_max\"]],\n        )\n    )\n    translated_bounding_rectangle_vertices = []\n    for _, point in enumerate(translated_rotated_bounding_rectangle_vertices):\n        newpoint = r_inverse @ point\n        # FIXME : As above can likely use np.append(, axis=0) here\n        translated_bounding_rectangle_vertices.append(newpoint)\n    translated_bounding_rectangle_vertices = np.array(translated_bounding_rectangle_vertices)\n\n    if debug:\n        # Create plot\n        # FIXME : Make this a private method\n        fig = plt.figure(figsize=(8, 8))\n        ax = fig.add_subplot(111)\n        plt.scatter(x=edges[:, 0], y=edges[:, 1])\n        ax.plot(\n            np.append(\n                translated_rotated_bounding_rectangle_vertices[:, 0],\n                translated_rotated_bounding_rectangle_vertices[0, 0],\n            ),\n            np.append(\n                translated_rotated_bounding_rectangle_vertices[:, 1],\n                translated_rotated_bounding_rectangle_vertices[0, 1],\n            ),\n            \"#994400\",\n            label=\"rotated\",\n        )\n        ax.plot(\n            np.append(\n                translated_bounding_rectangle_vertices[:, 0],\n                translated_bounding_rectangle_vertices[0, 0],\n            ),\n            np.append(\n                translated_bounding_rectangle_vertices[:, 1],\n                translated_bounding_rectangle_vertices[0, 1],\n            ),\n            \"#004499\",\n            label=\"unrotated\",\n        )\n        ax.scatter(\n            x=remapped_points[:, 0],\n            y=remapped_points[:, 1],\n            color=\"#004499\",\n            label=\"translated\",\n        )\n        ax.scatter(x=rotated_points[:, 0], y=rotated_points[:, 1], label=\"rotated\")\n        ax.legend()\n        plt.savefig(path / \"hull_bounding_rectangle_extra\")\n\n    fig = plt.figure(figsize=(8, 8))\n    ax = fig.add_subplot(111)\n    bounding_rectangle_vertices = translated_bounding_rectangle_vertices + centroid\n    ax.plot(\n        np.append(bounding_rectangle_vertices[:, 0], bounding_rectangle_vertices[0, 0]),\n        np.append(bounding_rectangle_vertices[:, 1], bounding_rectangle_vertices[0, 1]),\n        \"#994400\",\n        label=\"unrotated\",\n    )\n    ax.scatter(x=edges[:, 0], y=edges[:, 1], label=\"original points\")\n    ax.set_aspect(1)\n    ax.legend()\n    plt.xlabel(\"Grain Length (nm)\")\n    plt.ylabel(\"Grain Width (nm)\")\n    # plt.savefig(path / \"minimum_bbox.png\")\n    plt.close()\n\n    return smallest_bounding_width, smallest_bounding_length, aspect_ratio\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_edges","title":"<code>calculate_edges(grain_mask, edge_detection_method)</code>  <code>staticmethod</code>","text":"<p>Convert 2D boolean array to list of the coordinates of the edges of the grain.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_edges--parameters","title":"Parameters","text":"<p>grain_mask : npt.NDArray     A 2D numpy array image of a grain. Data in the array must be boolean. edge_detection_method : str     Method used for detecting the edges of grain masks before calculating statistics on them.     Do not change unless you know exactly what this is doing. Options: \"binary_erosion\", \"canny\".</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_edges--returns","title":"Returns","text":"<p>list     List containing the coordinates of the edges of the grain.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>@staticmethod\ndef calculate_edges(grain_mask: npt.NDArray, edge_detection_method: str) -&gt; list:\n    \"\"\"\n    Convert 2D boolean array to list of the coordinates of the edges of the grain.\n\n    Parameters\n    ----------\n    grain_mask : npt.NDArray\n        A 2D numpy array image of a grain. Data in the array must be boolean.\n    edge_detection_method : str\n        Method used for detecting the edges of grain masks before calculating statistics on them.\n        Do not change unless you know exactly what this is doing. Options: \"binary_erosion\", \"canny\".\n\n    Returns\n    -------\n    list\n        List containing the coordinates of the edges of the grain.\n    \"\"\"\n    # Fill any holes\n    filled_grain_mask = scipy.ndimage.binary_fill_holes(grain_mask)\n\n    if edge_detection_method == \"binary_erosion\":\n        # Add padding (needed for erosion)\n        padded = np.pad(filled_grain_mask, 1)\n        # Erode by 1 pixel\n        eroded = skimage_morphology.binary_erosion(padded)\n        # Remove padding\n        eroded = eroded[1:-1, 1:-1]\n\n        # Edges is equal to the difference between the\n        # original image and the eroded image.\n        edges = filled_grain_mask.astype(int) - eroded.astype(int)\n    else:\n        # Get outer edge using canny filtering\n        edges = skimage_feature.canny(filled_grain_mask, sigma=3)\n\n    nonzero_coordinates = edges.nonzero()\n    # Get vector representation of the points\n    # FIXME : Switched to list comprehension but should be unnecessary to create this as a list as we can use\n    # np.stack() to combine the arrays and use that...\n    # return np.stack(nonzero_coordinates, axis=1)\n    return [list(vector) for vector in np.transpose(nonzero_coordinates)]\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_points","title":"<code>calculate_points(grain_mask)</code>  <code>staticmethod</code>","text":"<p>Convert a 2D boolean array to a list of coordinates.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_points--parameters","title":"Parameters","text":"<p>grain_mask : npt.NDArray     A 2D numpy array image of a grain. Data in the array must be boolean.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_points--returns","title":"Returns","text":"<p>list     A python list containing the coordinates of the pixels in the grain.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>@staticmethod\ndef calculate_points(grain_mask: npt.NDArray) -&gt; list:\n    \"\"\"\n    Convert a 2D boolean array to a list of coordinates.\n\n    Parameters\n    ----------\n    grain_mask : npt.NDArray\n        A 2D numpy array image of a grain. Data in the array must be boolean.\n\n    Returns\n    -------\n    list\n        A python list containing the coordinates of the pixels in the grain.\n    \"\"\"\n    nonzero_coordinates = grain_mask.nonzero()\n    points = []\n    for point in np.transpose(nonzero_coordinates):\n        points.append(list(point))\n\n    return points\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_radius_stats","title":"<code>calculate_radius_stats(edges, points)</code>","text":"<p>Calculate the radius of grains.</p> <p>The radius in this context is the distance from the centroid to points on the edge of the grain.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_radius_stats--parameters","title":"Parameters","text":"<p>edges : list     A 2D python list containing the coordinates of the edges of a grain. points : list     A 2D python list containing the coordinates of the points in a grain.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_radius_stats--returns","title":"Returns","text":"<p>tuple[float]     A tuple of the minimum, maximum, mean and median radius of the grain.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>def calculate_radius_stats(self, edges: list, points: list) -&gt; tuple[float]:\n    \"\"\"\n    Calculate the radius of grains.\n\n    The radius in this context is the distance from the centroid to points on the edge of the grain.\n\n    Parameters\n    ----------\n    edges : list\n        A 2D python list containing the coordinates of the edges of a grain.\n    points : list\n        A 2D python list containing the coordinates of the points in a grain.\n\n    Returns\n    -------\n    tuple[float]\n        A tuple of the minimum, maximum, mean and median radius of the grain.\n    \"\"\"\n    # Calculate the centroid of the grain\n    centroid = self._calculate_centroid(points)\n    # Calculate the displacement\n    displacements = self._calculate_displacement(edges, centroid)\n    # Calculate the radius of each point\n    radii = self._calculate_radius(displacements)\n    return {\n        \"min\": np.min(radii),\n        \"max\": np.max(radii),\n        \"mean\": np.mean(radii),\n        \"median\": np.median(radii),\n    }\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_squared_distance","title":"<code>calculate_squared_distance(point_2, point_1=None)</code>","text":"<p>Calculate the squared distance between two points.</p> <p>Used for distance sorting purposes and therefore does not perform a square root in the interests of efficiency.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_squared_distance--parameters","title":"Parameters","text":"<p>point_2 : tuple     The point to find the squared distance to. point_1 : tuple     Optional - defaults to the starting point defined in the graham_scan() function. The point to find the     squared distance from.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_squared_distance--returns","title":"Returns","text":"<p>float     The squared distance between the two points.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>def calculate_squared_distance(self, point_2: tuple, point_1: tuple = None) -&gt; float:\n    \"\"\"\n    Calculate the squared distance between two points.\n\n    Used for distance sorting purposes and therefore does not perform a square root in the interests of efficiency.\n\n    Parameters\n    ----------\n    point_2 : tuple\n        The point to find the squared distance to.\n    point_1 : tuple\n        Optional - defaults to the starting point defined in the graham_scan() function. The point to find the\n        squared distance from.\n\n    Returns\n    -------\n    float\n        The squared distance between the two points.\n    \"\"\"\n    # Get the distance squared between two points. If the second point is not provided, use the starting point.\n    point_1 = self.start_point if point_1 is None else point_1\n    delta_x = point_2[0] - point_1[0]\n    delta_y = point_2[1] - point_1[1]\n    # Don't need the sqrt since just sorting for dist\n    return float(delta_x**2 + delta_y**2)\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_stats","title":"<code>calculate_stats()</code>","text":"<p>Calculate the stats of grains in the labelled image.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.calculate_stats--returns","title":"Returns","text":"<p>tuple     Consists of a pd.DataFrame containing all the grain stats that have been calculated for the labelled image     and a list of dictionaries containing grain data to be plotted.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>def calculate_stats(self) -&gt; tuple(pd.DataFrame, dict):\n    \"\"\"\n    Calculate the stats of grains in the labelled image.\n\n    Returns\n    -------\n    tuple\n        Consists of a pd.DataFrame containing all the grain stats that have been calculated for the labelled image\n        and a list of dictionaries containing grain data to be plotted.\n    \"\"\"\n    grains_plot_data = []\n    all_height_profiles = {}\n    if self.labelled_data is None:\n        LOGGER.warning(\n            f\"[{self.image_name}] : No labelled regions for this image, grain statistics can not be calculated.\"\n        )\n        return pd.DataFrame(columns=GRAIN_STATS_COLUMNS), grains_plot_data, all_height_profiles\n\n    # Calculate region properties\n    region_properties = skimage_measure.regionprops(self.labelled_data)\n\n    # Iterate over all the grains in the image\n    stats_array = []\n    # List to hold all the plot data for all the grains. Each entry is a dictionary of plotting data.\n    # There are multiple entries for each grain.\n    for index, region in enumerate(region_properties):\n        LOGGER.debug(f\"[{self.image_name}] : Processing grain: {index}\")\n\n        # Skip grain if too small to calculate stats for\n        LOGGER.debug(f\"[{self.image_name}] : Grain size: {region.image.size}\")\n        if min(region.image.shape) &lt; 5:\n            LOGGER.debug(\n                f\"[{self.image_name}] : Skipping grain due to being too small (size: {region.image.shape}) to calculate stats for.\"\n            )\n            continue\n\n        # Create directory for each grain's plots\n        output_grain = self.base_output_dir / self.direction\n        # Obtain cropped grain mask and image\n        minr, minc, maxr, maxc = region.bbox\n        grain_mask = np.array(region.image)\n        grain_image = self.data[minr:maxr, minc:maxc]\n        grain_mask_image = np.ma.masked_array(grain_image, mask=np.invert(grain_mask), fill_value=np.nan).filled()\n\n        if self.cropped_size == -1:\n            for name, image in {\n                \"grain_image\": grain_image,\n                \"grain_mask\": grain_mask,\n                \"grain_mask_image\": grain_mask_image,\n            }.items():\n                grains_plot_data.append(\n                    {\n                        \"data\": image,\n                        \"output_dir\": output_grain,\n                        \"filename\": f\"{self.image_name}_{name}_{index}\",\n                        \"name\": name,\n                    }\n                )\n\n        else:\n            # Get cropped image and mask\n            grain_centre = int((minr + maxr) / 2), int((minc + maxc) / 2)\n            length = int(self.cropped_size / (2 * self.pixel_to_nanometre_scaling))\n            solo_mask = self.labelled_data.copy()\n            solo_mask[solo_mask != index + 1] = 0\n            solo_mask[solo_mask == index + 1] = 1\n            cropped_grain_image = self.get_cropped_region(self.data, length, np.asarray(grain_centre))\n            cropped_grain_mask = self.get_cropped_region(solo_mask, length, np.asarray(grain_centre)).astype(bool)\n            cropped_grain_mask_image = np.ma.masked_array(\n                grain_image, mask=np.invert(grain_mask), fill_value=np.nan\n            ).filled()\n            for name, image in {\n                \"grain_image\": cropped_grain_image,\n                \"grain_mask\": cropped_grain_mask,\n                \"grain_mask_image\": cropped_grain_mask_image,\n            }.items():\n                grains_plot_data.append(\n                    {\n                        \"data\": image,\n                        \"output_dir\": output_grain,\n                        \"filename\": f\"{self.image_name}_{name}_{index}\",\n                        \"name\": name,\n                    }\n                )\n\n        points = self.calculate_points(grain_mask)\n        edges = self.calculate_edges(grain_mask, edge_detection_method=self.edge_detection_method)\n        radius_stats = self.calculate_radius_stats(edges, points)\n        # hull, hull_indices, hull_simplexes = self.convex_hull(edges, output_grain)\n        _, _, hull_simplexes = self.convex_hull(edges, output_grain)\n        centroid = self._calculate_centroid(points)\n        # Centroids for the grains (minc and minr added because centroid returns values local to the cropped grain images)\n        centre_x = centroid[0] + minc\n        centre_y = centroid[1] + minr\n        (\n            smallest_bounding_width,\n            smallest_bounding_length,\n            aspect_ratio,\n        ) = self.calculate_aspect_ratio(\n            edges=edges,\n            hull_simplices=hull_simplexes,\n            path=output_grain,\n        )\n\n        # Calculate scaling factors\n        length_scaling_factor = self.pixel_to_nanometre_scaling * self.metre_scaling_factor\n        area_scaling_factor = length_scaling_factor**2\n\n        # Calculate minimum and maximum feret diameters and scale the distances\n        feret_statistics = feret.min_max_feret(points)\n        feret_statistics[\"min_feret\"] = feret_statistics[\"min_feret\"] * length_scaling_factor\n        feret_statistics[\"max_feret\"] = feret_statistics[\"max_feret\"] * length_scaling_factor\n\n        if self.extract_height_profile:\n            all_height_profiles[index] = height_profiles.interpolate_height_profile(\n                img=grain_image, mask=grain_mask\n            )\n            LOGGER.debug(f\"[{self.image_name}] : Height profiles extracted.\")\n\n        # Save the stats to dictionary. Note that many of the stats are multiplied by a scaling factor to convert\n        # from pixel units to nanometres.\n        # Removed formatting, better to keep accurate until the end, including in CSV, then shorten display\n        stats = {\n            \"centre_x\": centre_x * length_scaling_factor,\n            \"centre_y\": centre_y * length_scaling_factor,\n            \"radius_min\": radius_stats[\"min\"] * length_scaling_factor,\n            \"radius_max\": radius_stats[\"max\"] * length_scaling_factor,\n            \"radius_mean\": radius_stats[\"mean\"] * length_scaling_factor,\n            \"radius_median\": radius_stats[\"median\"] * length_scaling_factor,\n            \"height_min\": np.nanmin(grain_mask_image) * self.metre_scaling_factor,\n            \"height_max\": np.nanmax(grain_mask_image) * self.metre_scaling_factor,\n            \"height_median\": np.nanmedian(grain_mask_image) * self.metre_scaling_factor,\n            \"height_mean\": np.nanmean(grain_mask_image) * self.metre_scaling_factor,\n            # [volume] = [pixel] * [pixel] * [height] = px * px * nm.\n            # To turn into m^3, multiply by pixel_to_nanometre_scaling^2 and metre_scaling_factor^3.\n            \"volume\": np.nansum(grain_mask_image)\n            * self.pixel_to_nanometre_scaling**2\n            * (self.metre_scaling_factor**3),\n            \"area\": region.area * area_scaling_factor,\n            \"area_cartesian_bbox\": region.area_bbox * area_scaling_factor,\n            \"smallest_bounding_width\": smallest_bounding_width * length_scaling_factor,\n            \"smallest_bounding_length\": smallest_bounding_length * length_scaling_factor,\n            \"smallest_bounding_area\": smallest_bounding_length * smallest_bounding_width * area_scaling_factor,\n            \"aspect_ratio\": aspect_ratio,\n            \"threshold\": self.direction,\n            \"max_feret\": feret_statistics[\"max_feret\"],\n            \"min_feret\": feret_statistics[\"min_feret\"],\n        }\n        stats_array.append(stats)\n    if len(stats_array) &gt; 0:\n        grainstats_df = pd.DataFrame(data=stats_array)\n    else:\n        grainstats_df = create_empty_dataframe()\n    grainstats_df.index.name = \"grain_number\"\n    grainstats_df[\"image\"] = self.image_name\n\n    return grainstats_df, grains_plot_data, all_height_profiles\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.convex_hull","title":"<code>convex_hull(edges, base_output_dir, debug=False)</code>","text":"<p>Calculate a grain's convex hull.</p> <p>Based off of the Graham Scan algorithm and should ideally scale in time with O(nlog(n)).</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.convex_hull--parameters","title":"Parameters","text":"<p>edges : list     A python list containing the coordinates of the edges of the grain. base_output_dir : Path     Directory to save output to. debug : bool     Default false. If true, debug information will be displayed to the terminal and plots for the convex hulls     and edges will be saved.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.convex_hull--returns","title":"Returns","text":"<p>tuple[list, list, list]     A hull (list) of the coordinates of each point on the hull. Hull indices providing a way to find the points     from the hill inside the edge list that was passed. Simplices (list) of tuples each representing a simplex     of the convex hull, these are sorted in a counter-clockwise order.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>def convex_hull(self, edges: list, base_output_dir: Path, debug: bool = False) -&gt; tuple[list, list, list]:\n    \"\"\"\n    Calculate a grain's convex hull.\n\n    Based off of the Graham Scan algorithm and should ideally scale in time with O(nlog(n)).\n\n    Parameters\n    ----------\n    edges : list\n        A python list containing the coordinates of the edges of the grain.\n    base_output_dir : Path\n        Directory to save output to.\n    debug : bool\n        Default false. If true, debug information will be displayed to the terminal and plots for the convex hulls\n        and edges will be saved.\n\n    Returns\n    -------\n    tuple[list, list, list]\n        A hull (list) of the coordinates of each point on the hull. Hull indices providing a way to find the points\n        from the hill inside the edge list that was passed. Simplices (list) of tuples each representing a simplex\n        of the convex hull, these are sorted in a counter-clockwise order.\n    \"\"\"\n    hull, hull_indices, simplexes = self.graham_scan(edges)\n\n    # Debug information\n    if debug:\n        base_output_dir.mkdir(parents=True, exist_ok=True)\n        self.plot(edges, hull, base_output_dir / \"_points_hull.png\")\n        LOGGER.debug(f\"points: {edges}\")\n        LOGGER.debug(f\"hull: {hull}\")\n        LOGGER.debug(f\"hull indexes: {hull_indices}\")\n        LOGGER.debug(f\"simplexes: {simplexes}\")\n\n    return hull, hull_indices, simplexes\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.find_cartesian_extremes","title":"<code>find_cartesian_extremes(rotated_points)</code>  <code>staticmethod</code>","text":"<p>Find the limits of x and y of rotated points.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.find_cartesian_extremes--parameters","title":"Parameters","text":"<p>rotated_points : npt.NDArray     2-D array of rotated points.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.find_cartesian_extremes--returns","title":"Returns","text":"<p>Dict     Dictionary of the x and y min and max.annotations.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>@staticmethod\ndef find_cartesian_extremes(rotated_points: npt.NDArray) -&gt; dict:\n    \"\"\"\n    Find the limits of x and y of rotated points.\n\n    Parameters\n    ----------\n    rotated_points : npt.NDArray\n        2-D array of rotated points.\n\n    Returns\n    -------\n    Dict\n        Dictionary of the x and y min and max.__annotations__.\n    \"\"\"\n    extremes = {}\n    extremes[\"x_min\"] = np.min(rotated_points[:, 0])\n    extremes[\"x_max\"] = np.max(rotated_points[:, 0])\n    extremes[\"y_min\"] = np.min(rotated_points[:, 1])\n    extremes[\"y_max\"] = np.max(rotated_points[:, 1])\n    return extremes\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.get_angle","title":"<code>get_angle(point_1, point_2)</code>  <code>staticmethod</code>","text":"<p>Calculate the angle in radians between two points.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.get_angle--parameters","title":"Parameters","text":"<p>point_1 : tuple     Coordinate vectors for the first point to find the angle between. point_2 : tuple     Coordinate vectors for the second point to find the angle between.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.get_angle--returns","title":"Returns","text":"<p>float     The angle in radians between the two input vectors.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>@staticmethod\ndef get_angle(point_1: tuple, point_2: tuple) -&gt; float:\n    \"\"\"\n    Calculate the angle in radians between two points.\n\n    Parameters\n    ----------\n    point_1 : tuple\n        Coordinate vectors for the first point to find the angle between.\n    point_2 : tuple\n        Coordinate vectors for the second point to find the angle between.\n\n    Returns\n    -------\n    float\n        The angle in radians between the two input vectors.\n    \"\"\"\n    return np.arctan2(point_1[1] - point_2[1], point_1[0] - point_2[0])\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.get_cropped_region","title":"<code>get_cropped_region(image, length, centre)</code>","text":"<p>Crop the image with respect to a given pixel length around the centre coordinates.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.get_cropped_region--parameters","title":"Parameters","text":"<p>image : npt.NDArray     The image array. length : int     The length (in pixels) of the resultant cropped image. centre : npt.NDArray     The centre of the object to crop.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.get_cropped_region--returns","title":"Returns","text":"<p>npt.NDArray     Cropped array of the image.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>def get_cropped_region(self, image: npt.NDArray, length: int, centre: npt.NDArray) -&gt; npt.NDArray:\n    \"\"\"\n    Crop the image with respect to a given pixel length around the centre coordinates.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        The image array.\n    length : int\n        The length (in pixels) of the resultant cropped image.\n    centre : npt.NDArray\n        The centre of the object to crop.\n\n    Returns\n    -------\n    npt.NDArray\n        Cropped array of the image.\n    \"\"\"\n    shape = image.shape\n    xy1 = shape - (centre + length + 1)\n    xy2 = shape - (centre - length)\n    xy = np.stack((xy1, xy2))\n    shiftx = self.get_shift(xy[:, 0], shape[0])\n    shifty = self.get_shift(xy[:, 1], shape[1])\n    return image.copy()[\n        centre[0] - length - shiftx : centre[0] + length + 1 - shiftx,  # noqa: E203\n        centre[1] - length - shifty : centre[1] + length + 1 - shifty,  # noqa: E203\n    ]\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.get_shift","title":"<code>get_shift(coords, shape)</code>  <code>staticmethod</code>","text":"<p>Obtain the coordinate shift to reflect the cropped image box for molecules near the edges of the image.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.get_shift--parameters","title":"Parameters","text":"<p>coords : npt.NDArray     Value representing integer coordinates which may be outside of the image. shape : npt.NDArray     Array of the shape of an image.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.get_shift--returns","title":"Returns","text":"<p>np.int64     Max value of the shift to reflect the croped region so it stays within the image.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>@staticmethod\ndef get_shift(coords: npt.NDArray, shape: npt.NDArray) -&gt; int:\n    \"\"\"\n    Obtain the coordinate shift to reflect the cropped image box for molecules near the edges of the image.\n\n    Parameters\n    ----------\n    coords : npt.NDArray\n        Value representing integer coordinates which may be outside of the image.\n    shape : npt.NDArray\n        Array of the shape of an image.\n\n    Returns\n    -------\n    np.int64\n        Max value of the shift to reflect the croped region so it stays within the image.\n    \"\"\"\n    shift = shape - coords[np.where(coords &gt; shape)]\n    shift = np.hstack((shift, -coords[np.where(coords &lt; 0)]))\n    if len(shift) == 0:\n        return 0\n    max_index = np.argmax(abs(shift))\n    return shift[max_index]\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.get_start_point","title":"<code>get_start_point(edges)</code>","text":"<p>Determine the index of the bottom most point of the hull when sorted by x-position.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.get_start_point--parameters","title":"Parameters","text":"<p>edges : npt.NDArray     Array of coordinates.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>def get_start_point(self, edges: npt.NDArray) -&gt; None:\n    \"\"\"\n    Determine the index of the bottom most point of the hull when sorted by x-position.\n\n    Parameters\n    ----------\n    edges : npt.NDArray\n        Array of coordinates.\n    \"\"\"\n    min_y_index = np.argmin(edges[:, 1])\n    self.start_point = edges[min_y_index]\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.graham_scan","title":"<code>graham_scan(edges)</code>","text":"<p>Construct the convex hull using the  Graham Scan algorithm.</p> <p>Ideally this algorithm will take O( n * log(n) ) time.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.graham_scan--parameters","title":"Parameters","text":"<p>edges : list     A python list of coordinates that make up the edges of the grain.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.graham_scan--returns","title":"Returns","text":"<p>tuple[list, list, list]     A hull (list) of the coordinates of each point on the hull. Hull indices providing a way to find the points     from the hill inside the edge list that was passed. Simplices (list) of tuples each representing a simplex     of the convex hull, these are sorted in a counter-clockwise order.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>def graham_scan(self, edges: list) -&gt; tuple[list, list, list]:\n    \"\"\"\n    Construct the convex hull using the  Graham Scan algorithm.\n\n    Ideally this algorithm will take O( n * log(n) ) time.\n\n    Parameters\n    ----------\n    edges : list\n        A python list of coordinates that make up the edges of the grain.\n\n    Returns\n    -------\n    tuple[list, list, list]\n        A hull (list) of the coordinates of each point on the hull. Hull indices providing a way to find the points\n        from the hill inside the edge list that was passed. Simplices (list) of tuples each representing a simplex\n        of the convex hull, these are sorted in a counter-clockwise order.\n    \"\"\"\n    # FIXME : Make this an isolated method\n    # Find a point guaranteed to be on the hull. I find the bottom most point(s) and sort by x-position.\n    min_y_index = None\n    for index, point in enumerate(edges):\n        if min_y_index is None or point[1] &lt; edges[min_y_index][1]:\n            min_y_index = index\n        if point[1] == edges[min_y_index][1] and point[0] &lt; edges[min_y_index][0]:\n            min_y_index = index\n    self.start_point = edges[min_y_index]\n    # This does the same thing, but as a separate method and with Numpy Array rather than a list\n    # self.get_start_point(edges)\n    # Sort the points\n    points_sorted_by_angle = self.sort_points(edges)\n\n    # Remove starting point from the list so it's not added more than once to the hull\n    start_point_index = points_sorted_by_angle.index(self.start_point)\n    del points_sorted_by_angle[start_point_index]\n    # Add start point and the first point sorted by angle. Both of these points will always be on the hull.\n    hull = [self.start_point, points_sorted_by_angle[0]]\n\n    # Iterate through each point, checking if this point would cause a clockwise rotation if added to the hull, and\n    # if so, backtracking.\n    for _, point in enumerate(points_sorted_by_angle[1:]):\n        # Determine if the proposed point demands a clockwise rotation\n        while self.is_clockwise(hull[-2], hull[-1], point) is True:\n            # Delete the failed point\n            del hull[-1]\n            if len(hull) &lt; 2:\n                break\n        # The point does not immediately cause a clockwise rotation.\n        hull.append(point)\n\n    # Get hull indices from original points array\n    hull_indices = []\n    for point in hull:\n        hull_indices.append(edges.index(point))\n\n    # Create simplices from the hull points\n    simplices = []\n    for index, value in enumerate(hull_indices):\n        simplices.append((hull_indices[index - 1], value))\n\n    return hull, hull_indices, simplices\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.is_clockwise","title":"<code>is_clockwise(p_1, p_2, p_3)</code>  <code>staticmethod</code>","text":"<p>Determine if three points make a clockwise or counter-clockwise turn.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.is_clockwise--parameters","title":"Parameters","text":"<p>p_1 : tuple     First point to be used to calculate turn. p_2 : tuple     Second point to be used to calculate turn. p_3 : tuple     Third point to be used to calculate turn.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.is_clockwise--returns","title":"Returns","text":"<p>boolean     Indicator of whether turn is clockwise.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>@staticmethod\ndef is_clockwise(p_1: tuple, p_2: tuple, p_3: tuple) -&gt; bool:\n    \"\"\"\n    Determine if three points make a clockwise or counter-clockwise turn.\n\n    Parameters\n    ----------\n    p_1 : tuple\n        First point to be used to calculate turn.\n    p_2 : tuple\n        Second point to be used to calculate turn.\n    p_3 : tuple\n        Third point to be used to calculate turn.\n\n    Returns\n    -------\n    boolean\n        Indicator of whether turn is clockwise.\n    \"\"\"\n    # Determine if three points form a clockwise or counter-clockwise turn.\n    # I use the method of calculating the determinant of the following rotation matrix here. If the determinant\n    # is &gt; 0 then the rotation is counter-clockwise.\n    rotation_matrix = np.asarray(((p_1[0], p_1[1], 1), (p_2[0], p_2[1], 1), (p_3[0], p_3[1], 1)))\n    return not np.linalg.det(rotation_matrix) &gt; 0\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.plot","title":"<code>plot(edges, convex_hull=None, file_path=None)</code>  <code>staticmethod</code>","text":"<p>Plot and save the coordinates of the edges in the grain and optionally the hull.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.plot--parameters","title":"Parameters","text":"<p>edges : list     A list of points to be plotted. convex_hull : list     Optional argument. A list of points that form the convex hull. Will be plotted with the coordinates if     provided. file_path : Path     Path of the file to save the plot as.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>@staticmethod\ndef plot(edges: list, convex_hull: list = None, file_path: Path = None) -&gt; None:\n    \"\"\"\n    Plot and save the coordinates of the edges in the grain and optionally the hull.\n\n    Parameters\n    ----------\n    edges : list\n        A list of points to be plotted.\n    convex_hull : list\n        Optional argument. A list of points that form the convex hull. Will be plotted with the coordinates if\n        provided.\n    file_path : Path\n        Path of the file to save the plot as.\n    \"\"\"\n    _, ax = plt.subplots(1, 1, figsize=(8, 8))\n    x_s, y_s = zip(*edges)\n    ax.scatter(x_s, y_s)\n    if convex_hull is not None:\n        for index in range(1, len(convex_hull) + 1):\n            # Loop on the final simplex of the hull to join the last and first points together.\n            if len(convex_hull) == index:\n                index = 0\n            point2 = convex_hull[index]\n            point1 = convex_hull[index - 1]\n            # Plot a line between the two points\n            plt.plot((point1[0], point2[0]), (point1[1], point2[1]), \"#994400\")\n    plt.savefig(file_path)\n    plt.close()\n</code></pre>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.sort_points","title":"<code>sort_points(points)</code>","text":"<p>Sort points in counter-clockwise order of angle made with the starting point.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.sort_points--parameters","title":"Parameters","text":"<p>points : list     A python list of the coordinates to sort.</p>"},{"location":"api/grainstats/#topostats.grainstats.GrainStats.sort_points--returns","title":"Returns","text":"<p>list     Points (coordinates) sorted counter-clockwise.</p> Source code in <code>topostats/grainstats.py</code> <pre><code>def sort_points(self, points: list) -&gt; list:\n    #    def sort_points(self, points: np.array) -&gt; List:\n    \"\"\"\n    Sort points in counter-clockwise order of angle made with the starting point.\n\n    Parameters\n    ----------\n    points : list\n        A python list of the coordinates to sort.\n\n    Returns\n    -------\n    list\n        Points (coordinates) sorted counter-clockwise.\n    \"\"\"\n    # Return if the list is length 1 or 0 (i.e. a single point).\n    if len(points) &lt;= 1:\n        return points\n    # Lists that allow sorting of points relative to a current comparison point\n    smaller, equal, larger = [], [], []\n    # Get a random point in the array to calculate the pivot angle from. This sorts the points relative to this point.\n    pivot_angle = self.get_angle(points[randint(0, len(points) - 1)], self.start_point)  # noqa: S311\n    for point in points:\n        point_angle = self.get_angle(point, self.start_point)\n        # If the\n        if point_angle &lt; pivot_angle:\n            smaller.append(point)\n        elif point_angle == pivot_angle:\n            equal.append(point)\n        else:\n            larger.append(point)\n    # Lets take a different approach and use arrays, we have a start point lets work out the angle of each point\n    # relative to that and _then_ sort it.\n    # pivot_angles = self.get_angle(points, self.start_point)\n    # Recursively sort the arrays until each point is sorted\n    return self.sort_points(smaller) + sorted(equal, key=self.calculate_squared_distance) + self.sort_points(larger)\n</code></pre>"},{"location":"api/io/","title":"IO Modules","text":"<p>Functions for reading and writing data.</p> <p>handler: python options: docstring_style: numpy rendering: show_signature_annotations: true</p>"},{"location":"api/io/#topostats.io.LoadScans","title":"<code>LoadScans</code>","text":"<p>Load the image and image parameters from a file path.</p>"},{"location":"api/io/#topostats.io.LoadScans--parameters","title":"Parameters","text":"<p>img_paths : list[str, Path]     Path to a valid AFM scan to load. channel : str     Image channel to extract from the scan. extract : str     What to extract from ''.topostats'' files, default is ''all'' which loads everything but if using in     ''run_topostats'' functions then specific subsets of data are required and this allows just those to be     loaded. Options include ''raw'' and ''filter'' at present.</p> Source code in <code>topostats/io.py</code> <pre><code>class LoadScans:\n    \"\"\"\n    Load the image and image parameters from a file path.\n\n    Parameters\n    ----------\n    img_paths : list[str, Path]\n        Path to a valid AFM scan to load.\n    channel : str\n        Image channel to extract from the scan.\n    extract : str\n        What to extract from ''.topostats'' files, default is ''all'' which loads everything but if using in\n        ''run_topostats'' functions then specific subsets of data are required and this allows just those to be\n        loaded. Options include ''raw'' and ''filter'' at present.\n    \"\"\"\n\n    def __init__(\n        self,\n        img_paths: list[str | Path],\n        channel: str,\n        extract: str = \"all\",\n    ):\n        \"\"\"\n        Initialise the class.\n\n        Parameters\n        ----------\n        img_paths : list[str | Path]\n            Path to a valid AFM scan to load.\n        channel : str\n            Image channel to extract from the scan.\n        extract : str\n            What to extract from ''.topostats'' files, default is ''all'' which loads everything but if using in\n            ''run_topostats'' functions then specific subsets of data are required and this allows just those to be\n            loaded. Options include ''raw'' and ''filter'' at present.\n        \"\"\"\n        self.img_paths = img_paths\n        self.img_path = None\n        self.channel = channel\n        self.channel_data = None\n        self.extract = extract\n        self.filename = None\n        self.suffix = None\n        self.image = None\n        self.pixel_to_nm_scaling = None\n        self.grain_masks = {}\n        self.grain_trace_data = {}\n        self.img_dict = {}\n        self.MINIMUM_IMAGE_SIZE = 10\n\n    def load_spm(self) -&gt; tuple[npt.NDArray, float]:\n        \"\"\"\n        Extract image and pixel to nm scaling from the Bruker .spm file.\n\n        Returns\n        -------\n        tuple[npt.NDArray, float]\n            A tuple containing the image and its pixel to nanometre scaling value.\n        \"\"\"\n        try:\n            LOGGER.debug(f\"Loading image from : {self.img_path}\")\n            return spm.load_spm(file_path=self.img_path, channel=self.channel)\n        except FileNotFoundError:\n            LOGGER.error(f\"File Not Found : {self.img_path}\")\n            raise\n\n    def load_topostats(self, extract: str = \"all\") -&gt; dict[str, Any] | tuple[npt.NDArray, float, Any]:\n        \"\"\"\n        Load a .topostats file (hdf5 format).\n\n        Loads and extracts the image, pixel to nanometre scaling factor and any grain masks.\n\n        Note that grain masks are stored via self.grain_masks rather than returned due to how we extract information for\n        all other file loading functions.\n\n        Parameters\n        ----------\n        extract : str\n            String of which image (Numpy array) and data to extract, default is 'all' which returns the cleaned\n            (post-Filter) image, `pixel_to_nm_scaling` and all `data`. It is possible to extract image arrays for other\n            stages of processing such as `raw` or 'filter'.\n\n        Returns\n        -------\n        dict[str, Any] | tuple[npt.NDArray, float, Any]\n            A dictionary of all previously processed data or tuple containing the image and its pixel to nanometre\n            scaling value. This is contingent on the ''extract'' option.\n        \"\"\"\n        try:\n            LOGGER.debug(f\"Loading image from : {self.img_path}\")\n            data = topostats.load_topostats(self.img_path)\n        except FileNotFoundError:\n            LOGGER.error(f\"File Not Found : {self.img_path}\")\n            raise\n        # We want everything if performing any step beyond filtering (or explicitly ask for None/\"all\")\n        if extract in [None, \"all\", \"grains\", \"grainstats\"]:\n            return data\n        # Otherwise we are re-running filtering we want the raw/image_original and scaling\n        return (data[\"image_original\"], data[\"pixel_to_nm_scaling\"])\n\n    def load_asd(self) -&gt; tuple[npt.NDArray, float]:\n        \"\"\"\n        Extract image and pixel to nm scaling from .asd files.\n\n        Returns\n        -------\n        tuple[npt.NDArray, float]\n            A tuple containing the image and its pixel to nanometre scaling value.\n        \"\"\"\n        try:\n            frames: np.ndarray\n            pixel_to_nm_scaling: float\n            _: dict\n            frames, pixel_to_nm_scaling, _ = asd.load_asd(file_path=self.img_path, channel=self.channel)\n            LOGGER.debug(f\"[{self.filename}] : Loaded image from : {self.img_path}\")\n        except FileNotFoundError:\n            LOGGER.error(f\"File not found. Path: {self.img_path}\")\n            raise\n\n        return (frames, pixel_to_nm_scaling)\n\n    def load_ibw(self) -&gt; tuple[npt.NDArray, float]:\n        \"\"\"\n        Load image from Asylum Research (Igor) .ibw files.\n\n        Returns\n        -------\n        tuple[npt.NDArray, float]\n            A tuple containing the image and its pixel to nanometre scaling value.\n        \"\"\"\n        try:\n            LOGGER.debug(f\"Loading image from : {self.img_path}\")\n            return ibw.load_ibw(file_path=self.img_path, channel=self.channel)\n        except FileNotFoundError:\n            LOGGER.error(f\"File not found : {self.img_path}\")\n            raise\n\n    def load_jpk(self) -&gt; tuple[npt.NDArray, float]:\n        \"\"\"\n        Load image from JPK Instruments .jpk files.\n\n        Returns\n        -------\n        tuple[npt.NDArray, float]\n            A tuple containing the image and its pixel to nanometre scaling value.\n        \"\"\"\n        try:\n            return jpk.load_jpk(file_path=self.img_path, channel=self.channel)\n        except FileNotFoundError:\n            LOGGER.error(f\"[{self.filename}] File not found : {self.img_path}\")\n            raise\n\n    def load_gwy(self) -&gt; tuple[npt.NDArray, float]:\n        \"\"\"\n        Extract image and pixel to nm scaling from the Gwyddion .gwy file.\n\n        Returns\n        -------\n        tuple[npt.NDArray, float]\n            A tuple containing the image and its pixel to nanometre scaling value.\n        \"\"\"\n        LOGGER.debug(f\"Loading image from : {self.img_path}\")\n        try:\n            return gwy.load_gwy(file_path=self.img_path, channel=self.channel)\n        except FileNotFoundError:\n            LOGGER.error(f\"File not found : {self.img_path}\")\n            raise\n\n    def get_data(self) -&gt; None:  # noqa: C901  # pylint: disable=too-many-branches\n        \"\"\"Extract image, filepath and pixel to nm scaling value, and append these to the img_dic object.\"\"\"\n        suffix_to_loader = {\n            \".spm\": self.load_spm,\n            \".jpk\": self.load_jpk,\n            \".ibw\": self.load_ibw,\n            \".gwy\": self.load_gwy,\n            \".topostats\": self.load_topostats,\n            \".asd\": self.load_asd,\n        }\n        for img_path in self.img_paths:\n            self.img_path = img_path\n            self.filename = img_path.stem\n            suffix = img_path.suffix\n            LOGGER.info(f\"Extracting image from {self.img_path}\")\n            LOGGER.debug(f\"File extension : {suffix}\")\n\n            # Check that the file extension is supported\n            if suffix in suffix_to_loader:\n                data = None\n                try:\n                    if suffix == \".topostats\" and self.extract in (None, \"all\", \"grains\", \"grainstats\"):\n                        data = self.load_topostats(extract=self.extract)\n                        self.image = data[\"image\"]\n                        self.pixel_to_nm_scaling = data[\"pixel_to_nm_scaling\"]\n                        # If we need the grain masks for processing we extract them\n                        if self.extract in (\"grainstats\"):\n                            self.grain_masks = data[\"grain_masks\"]\n                    elif suffix == \".topostats\" and self.extract in (\"filter\", \"raw\"):\n                        self.image, self.pixel_to_nm_scaling = self.load_topostats(extract=self.extract)\n                    else:\n                        self.image, self.pixel_to_nm_scaling = suffix_to_loader[suffix]()\n                except Exception as e:\n                    if \"Channel\" in str(e) and \"not found\" in str(e):\n                        LOGGER.warning(e)  # log the specific error message\n                        LOGGER.warning(f\"[{self.filename}] Channel {self.channel} not found, skipping image.\")\n                    else:\n                        raise\n                else:\n                    if suffix == \".asd\":\n                        for index, frame in enumerate(self.image):\n                            self._check_image_size_and_add_to_dict(image=frame, filename=f\"{self.filename}_{index}\")\n                    # If we have extracted the image dictionary (only possible with .topostats files) we add that to the\n                    # dictionary\n                    elif data is not None:\n                        data[\"img_path\"] = img_path.with_suffix(\"\")\n                        self.img_dict[self.filename] = self.clean_dict(img_dict=data)\n                    # Otherwise check the size and add image to dictionary\n                    else:\n                        self._check_image_size_and_add_to_dict(image=self.image, filename=self.filename)\n            else:\n                raise ValueError(\n                    f\"File type {suffix} not yet supported. Please make an issue at \\\n                https://github.com/AFM-SPM/TopoStats/issues, or email topostats@sheffield.ac.uk to request support for \\\n                this file type.\"\n                )\n\n    def _check_image_size_and_add_to_dict(self, image: npt.NDArray, filename: str) -&gt; None:\n        \"\"\"\n        Check the image is above a minimum size in both dimensions.\n\n        Images that do not meet the minimum size are not included for processing.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            An array of the extracted AFM image.\n        filename : str\n            The name of the file.\n        \"\"\"\n        if image.shape[0] &lt; self.MINIMUM_IMAGE_SIZE or image.shape[1] &lt; self.MINIMUM_IMAGE_SIZE:\n            LOGGER.warning(f\"[{filename}] Skipping, image too small: {image.shape}\")\n        else:\n            self.add_to_dict(image=image, filename=filename)\n            LOGGER.debug(f\"[{filename}] Image added to processing.\")\n\n    def add_to_dict(self, image: npt.NDArray, filename: str) -&gt; None:\n        \"\"\"\n        Add an image and metadata to the img_dict dictionary under the key filename.\n\n        Adds the image and associated metadata such as any grain masks, and pixel to nanometere\n        scaling factor to the img_dict dictionary which is used as a place to store the image\n        information for processing.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            An array of the extracted AFM image.\n        filename : str\n            The name of the file.\n        \"\"\"\n        self.img_dict[filename] = {\n            \"filename\": filename,\n            \"img_path\": self.img_path.with_name(filename),\n            \"pixel_to_nm_scaling\": self.pixel_to_nm_scaling,\n            \"image_original\": image,\n            \"image\": None,\n            \"grain_masks\": self.grain_masks,\n            \"grain_trace_data\": self.grain_trace_data,\n        }\n\n    def clean_dict(self, img_dict: dict[str, Any]) -&gt; dict[str, Any]:\n        \"\"\"\n        If we are loading .topostats files for reprocessing we already have the dictionary structure.\n\n        We therefore need to extract just the information that is required for the stage requested and remove everything\n        else.\n\n        Parameters\n        ----------\n        img_dict : dict[str, Any]\n            Original image dictionary from which data is to be extracted.\n\n        Returns\n        -------\n        dict[str, Any]\n            Returns the image dictionary with keys/values removed appropriate to the extraction stage.\n        \"\"\"\n        # Reverse order so we remove things in reverse order, splining removes what it doesn't need then ordered\n        # tracing removes what it doesn't need, then nodestats, then disordered, then grainstats then grains, should be\n        # more succinct code with less popping\n        if self.extract in [\"grains\"]:\n            img_dict.pop(\"disordered_traces\")\n            img_dict.pop(\"grain_curvature_stats\")\n            img_dict.pop(\"grain_masks\")\n            img_dict.pop(\"height_profiles\")\n            img_dict.pop(\"nodestats\")\n            img_dict.pop(\"ordered_traces\")\n            img_dict.pop(\"splining\")\n            return img_dict\n        if self.extract in [\"grainstats\"]:\n            img_dict.pop(\"disordered_traces\")\n            img_dict.pop(\"grain_curvature_stats\")\n            img_dict.pop(\"height_profiles\")\n            img_dict.pop(\"nodestats\")\n            img_dict.pop(\"ordered_traces\")\n            img_dict.pop(\"splining\")\n            return img_dict\n        if self.extract in [\"disordered_tracing\", \"nodestats\", \"ordered_tracing\"]:\n            img_dict.pop(\"disordered_traces\")\n            img_dict.pop(\"grain_curvature_stats\")\n            img_dict.pop(\"nodestats\")\n            img_dict.pop(\"ordered_tracing\")\n            img_dict.pop(\"splining\")\n            return img_dict\n        if self.extract in [\"splining\"]:\n            img_dict.pop(\"splining\")\n            img_dict.pop(\"grain_curvature_stats\")\n            return img_dict\n        return img_dict\n</code></pre>"},{"location":"api/io/#topostats.io.LoadScans.__init__","title":"<code>__init__(img_paths, channel, extract='all')</code>","text":"<p>Initialise the class.</p>"},{"location":"api/io/#topostats.io.LoadScans.__init__--parameters","title":"Parameters","text":"<p>img_paths : list[str | Path]     Path to a valid AFM scan to load. channel : str     Image channel to extract from the scan. extract : str     What to extract from ''.topostats'' files, default is ''all'' which loads everything but if using in     ''run_topostats'' functions then specific subsets of data are required and this allows just those to be     loaded. Options include ''raw'' and ''filter'' at present.</p> Source code in <code>topostats/io.py</code> <pre><code>def __init__(\n    self,\n    img_paths: list[str | Path],\n    channel: str,\n    extract: str = \"all\",\n):\n    \"\"\"\n    Initialise the class.\n\n    Parameters\n    ----------\n    img_paths : list[str | Path]\n        Path to a valid AFM scan to load.\n    channel : str\n        Image channel to extract from the scan.\n    extract : str\n        What to extract from ''.topostats'' files, default is ''all'' which loads everything but if using in\n        ''run_topostats'' functions then specific subsets of data are required and this allows just those to be\n        loaded. Options include ''raw'' and ''filter'' at present.\n    \"\"\"\n    self.img_paths = img_paths\n    self.img_path = None\n    self.channel = channel\n    self.channel_data = None\n    self.extract = extract\n    self.filename = None\n    self.suffix = None\n    self.image = None\n    self.pixel_to_nm_scaling = None\n    self.grain_masks = {}\n    self.grain_trace_data = {}\n    self.img_dict = {}\n    self.MINIMUM_IMAGE_SIZE = 10\n</code></pre>"},{"location":"api/io/#topostats.io.LoadScans._check_image_size_and_add_to_dict","title":"<code>_check_image_size_and_add_to_dict(image, filename)</code>","text":"<p>Check the image is above a minimum size in both dimensions.</p> <p>Images that do not meet the minimum size are not included for processing.</p>"},{"location":"api/io/#topostats.io.LoadScans._check_image_size_and_add_to_dict--parameters","title":"Parameters","text":"<p>image : npt.NDArray     An array of the extracted AFM image. filename : str     The name of the file.</p> Source code in <code>topostats/io.py</code> <pre><code>def _check_image_size_and_add_to_dict(self, image: npt.NDArray, filename: str) -&gt; None:\n    \"\"\"\n    Check the image is above a minimum size in both dimensions.\n\n    Images that do not meet the minimum size are not included for processing.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        An array of the extracted AFM image.\n    filename : str\n        The name of the file.\n    \"\"\"\n    if image.shape[0] &lt; self.MINIMUM_IMAGE_SIZE or image.shape[1] &lt; self.MINIMUM_IMAGE_SIZE:\n        LOGGER.warning(f\"[{filename}] Skipping, image too small: {image.shape}\")\n    else:\n        self.add_to_dict(image=image, filename=filename)\n        LOGGER.debug(f\"[{filename}] Image added to processing.\")\n</code></pre>"},{"location":"api/io/#topostats.io.LoadScans.add_to_dict","title":"<code>add_to_dict(image, filename)</code>","text":"<p>Add an image and metadata to the img_dict dictionary under the key filename.</p> <p>Adds the image and associated metadata such as any grain masks, and pixel to nanometere scaling factor to the img_dict dictionary which is used as a place to store the image information for processing.</p>"},{"location":"api/io/#topostats.io.LoadScans.add_to_dict--parameters","title":"Parameters","text":"<p>image : npt.NDArray     An array of the extracted AFM image. filename : str     The name of the file.</p> Source code in <code>topostats/io.py</code> <pre><code>def add_to_dict(self, image: npt.NDArray, filename: str) -&gt; None:\n    \"\"\"\n    Add an image and metadata to the img_dict dictionary under the key filename.\n\n    Adds the image and associated metadata such as any grain masks, and pixel to nanometere\n    scaling factor to the img_dict dictionary which is used as a place to store the image\n    information for processing.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        An array of the extracted AFM image.\n    filename : str\n        The name of the file.\n    \"\"\"\n    self.img_dict[filename] = {\n        \"filename\": filename,\n        \"img_path\": self.img_path.with_name(filename),\n        \"pixel_to_nm_scaling\": self.pixel_to_nm_scaling,\n        \"image_original\": image,\n        \"image\": None,\n        \"grain_masks\": self.grain_masks,\n        \"grain_trace_data\": self.grain_trace_data,\n    }\n</code></pre>"},{"location":"api/io/#topostats.io.LoadScans.clean_dict","title":"<code>clean_dict(img_dict)</code>","text":"<p>If we are loading .topostats files for reprocessing we already have the dictionary structure.</p> <p>We therefore need to extract just the information that is required for the stage requested and remove everything else.</p>"},{"location":"api/io/#topostats.io.LoadScans.clean_dict--parameters","title":"Parameters","text":"<p>img_dict : dict[str, Any]     Original image dictionary from which data is to be extracted.</p>"},{"location":"api/io/#topostats.io.LoadScans.clean_dict--returns","title":"Returns","text":"<p>dict[str, Any]     Returns the image dictionary with keys/values removed appropriate to the extraction stage.</p> Source code in <code>topostats/io.py</code> <pre><code>def clean_dict(self, img_dict: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"\n    If we are loading .topostats files for reprocessing we already have the dictionary structure.\n\n    We therefore need to extract just the information that is required for the stage requested and remove everything\n    else.\n\n    Parameters\n    ----------\n    img_dict : dict[str, Any]\n        Original image dictionary from which data is to be extracted.\n\n    Returns\n    -------\n    dict[str, Any]\n        Returns the image dictionary with keys/values removed appropriate to the extraction stage.\n    \"\"\"\n    # Reverse order so we remove things in reverse order, splining removes what it doesn't need then ordered\n    # tracing removes what it doesn't need, then nodestats, then disordered, then grainstats then grains, should be\n    # more succinct code with less popping\n    if self.extract in [\"grains\"]:\n        img_dict.pop(\"disordered_traces\")\n        img_dict.pop(\"grain_curvature_stats\")\n        img_dict.pop(\"grain_masks\")\n        img_dict.pop(\"height_profiles\")\n        img_dict.pop(\"nodestats\")\n        img_dict.pop(\"ordered_traces\")\n        img_dict.pop(\"splining\")\n        return img_dict\n    if self.extract in [\"grainstats\"]:\n        img_dict.pop(\"disordered_traces\")\n        img_dict.pop(\"grain_curvature_stats\")\n        img_dict.pop(\"height_profiles\")\n        img_dict.pop(\"nodestats\")\n        img_dict.pop(\"ordered_traces\")\n        img_dict.pop(\"splining\")\n        return img_dict\n    if self.extract in [\"disordered_tracing\", \"nodestats\", \"ordered_tracing\"]:\n        img_dict.pop(\"disordered_traces\")\n        img_dict.pop(\"grain_curvature_stats\")\n        img_dict.pop(\"nodestats\")\n        img_dict.pop(\"ordered_tracing\")\n        img_dict.pop(\"splining\")\n        return img_dict\n    if self.extract in [\"splining\"]:\n        img_dict.pop(\"splining\")\n        img_dict.pop(\"grain_curvature_stats\")\n        return img_dict\n    return img_dict\n</code></pre>"},{"location":"api/io/#topostats.io.LoadScans.get_data","title":"<code>get_data()</code>","text":"<p>Extract image, filepath and pixel to nm scaling value, and append these to the img_dic object.</p> Source code in <code>topostats/io.py</code> <pre><code>def get_data(self) -&gt; None:  # noqa: C901  # pylint: disable=too-many-branches\n    \"\"\"Extract image, filepath and pixel to nm scaling value, and append these to the img_dic object.\"\"\"\n    suffix_to_loader = {\n        \".spm\": self.load_spm,\n        \".jpk\": self.load_jpk,\n        \".ibw\": self.load_ibw,\n        \".gwy\": self.load_gwy,\n        \".topostats\": self.load_topostats,\n        \".asd\": self.load_asd,\n    }\n    for img_path in self.img_paths:\n        self.img_path = img_path\n        self.filename = img_path.stem\n        suffix = img_path.suffix\n        LOGGER.info(f\"Extracting image from {self.img_path}\")\n        LOGGER.debug(f\"File extension : {suffix}\")\n\n        # Check that the file extension is supported\n        if suffix in suffix_to_loader:\n            data = None\n            try:\n                if suffix == \".topostats\" and self.extract in (None, \"all\", \"grains\", \"grainstats\"):\n                    data = self.load_topostats(extract=self.extract)\n                    self.image = data[\"image\"]\n                    self.pixel_to_nm_scaling = data[\"pixel_to_nm_scaling\"]\n                    # If we need the grain masks for processing we extract them\n                    if self.extract in (\"grainstats\"):\n                        self.grain_masks = data[\"grain_masks\"]\n                elif suffix == \".topostats\" and self.extract in (\"filter\", \"raw\"):\n                    self.image, self.pixel_to_nm_scaling = self.load_topostats(extract=self.extract)\n                else:\n                    self.image, self.pixel_to_nm_scaling = suffix_to_loader[suffix]()\n            except Exception as e:\n                if \"Channel\" in str(e) and \"not found\" in str(e):\n                    LOGGER.warning(e)  # log the specific error message\n                    LOGGER.warning(f\"[{self.filename}] Channel {self.channel} not found, skipping image.\")\n                else:\n                    raise\n            else:\n                if suffix == \".asd\":\n                    for index, frame in enumerate(self.image):\n                        self._check_image_size_and_add_to_dict(image=frame, filename=f\"{self.filename}_{index}\")\n                # If we have extracted the image dictionary (only possible with .topostats files) we add that to the\n                # dictionary\n                elif data is not None:\n                    data[\"img_path\"] = img_path.with_suffix(\"\")\n                    self.img_dict[self.filename] = self.clean_dict(img_dict=data)\n                # Otherwise check the size and add image to dictionary\n                else:\n                    self._check_image_size_and_add_to_dict(image=self.image, filename=self.filename)\n        else:\n            raise ValueError(\n                f\"File type {suffix} not yet supported. Please make an issue at \\\n            https://github.com/AFM-SPM/TopoStats/issues, or email topostats@sheffield.ac.uk to request support for \\\n            this file type.\"\n            )\n</code></pre>"},{"location":"api/io/#topostats.io.LoadScans.load_asd","title":"<code>load_asd()</code>","text":"<p>Extract image and pixel to nm scaling from .asd files.</p>"},{"location":"api/io/#topostats.io.LoadScans.load_asd--returns","title":"Returns","text":"<p>tuple[npt.NDArray, float]     A tuple containing the image and its pixel to nanometre scaling value.</p> Source code in <code>topostats/io.py</code> <pre><code>def load_asd(self) -&gt; tuple[npt.NDArray, float]:\n    \"\"\"\n    Extract image and pixel to nm scaling from .asd files.\n\n    Returns\n    -------\n    tuple[npt.NDArray, float]\n        A tuple containing the image and its pixel to nanometre scaling value.\n    \"\"\"\n    try:\n        frames: np.ndarray\n        pixel_to_nm_scaling: float\n        _: dict\n        frames, pixel_to_nm_scaling, _ = asd.load_asd(file_path=self.img_path, channel=self.channel)\n        LOGGER.debug(f\"[{self.filename}] : Loaded image from : {self.img_path}\")\n    except FileNotFoundError:\n        LOGGER.error(f\"File not found. Path: {self.img_path}\")\n        raise\n\n    return (frames, pixel_to_nm_scaling)\n</code></pre>"},{"location":"api/io/#topostats.io.LoadScans.load_gwy","title":"<code>load_gwy()</code>","text":"<p>Extract image and pixel to nm scaling from the Gwyddion .gwy file.</p>"},{"location":"api/io/#topostats.io.LoadScans.load_gwy--returns","title":"Returns","text":"<p>tuple[npt.NDArray, float]     A tuple containing the image and its pixel to nanometre scaling value.</p> Source code in <code>topostats/io.py</code> <pre><code>def load_gwy(self) -&gt; tuple[npt.NDArray, float]:\n    \"\"\"\n    Extract image and pixel to nm scaling from the Gwyddion .gwy file.\n\n    Returns\n    -------\n    tuple[npt.NDArray, float]\n        A tuple containing the image and its pixel to nanometre scaling value.\n    \"\"\"\n    LOGGER.debug(f\"Loading image from : {self.img_path}\")\n    try:\n        return gwy.load_gwy(file_path=self.img_path, channel=self.channel)\n    except FileNotFoundError:\n        LOGGER.error(f\"File not found : {self.img_path}\")\n        raise\n</code></pre>"},{"location":"api/io/#topostats.io.LoadScans.load_ibw","title":"<code>load_ibw()</code>","text":"<p>Load image from Asylum Research (Igor) .ibw files.</p>"},{"location":"api/io/#topostats.io.LoadScans.load_ibw--returns","title":"Returns","text":"<p>tuple[npt.NDArray, float]     A tuple containing the image and its pixel to nanometre scaling value.</p> Source code in <code>topostats/io.py</code> <pre><code>def load_ibw(self) -&gt; tuple[npt.NDArray, float]:\n    \"\"\"\n    Load image from Asylum Research (Igor) .ibw files.\n\n    Returns\n    -------\n    tuple[npt.NDArray, float]\n        A tuple containing the image and its pixel to nanometre scaling value.\n    \"\"\"\n    try:\n        LOGGER.debug(f\"Loading image from : {self.img_path}\")\n        return ibw.load_ibw(file_path=self.img_path, channel=self.channel)\n    except FileNotFoundError:\n        LOGGER.error(f\"File not found : {self.img_path}\")\n        raise\n</code></pre>"},{"location":"api/io/#topostats.io.LoadScans.load_jpk","title":"<code>load_jpk()</code>","text":"<p>Load image from JPK Instruments .jpk files.</p>"},{"location":"api/io/#topostats.io.LoadScans.load_jpk--returns","title":"Returns","text":"<p>tuple[npt.NDArray, float]     A tuple containing the image and its pixel to nanometre scaling value.</p> Source code in <code>topostats/io.py</code> <pre><code>def load_jpk(self) -&gt; tuple[npt.NDArray, float]:\n    \"\"\"\n    Load image from JPK Instruments .jpk files.\n\n    Returns\n    -------\n    tuple[npt.NDArray, float]\n        A tuple containing the image and its pixel to nanometre scaling value.\n    \"\"\"\n    try:\n        return jpk.load_jpk(file_path=self.img_path, channel=self.channel)\n    except FileNotFoundError:\n        LOGGER.error(f\"[{self.filename}] File not found : {self.img_path}\")\n        raise\n</code></pre>"},{"location":"api/io/#topostats.io.LoadScans.load_spm","title":"<code>load_spm()</code>","text":"<p>Extract image and pixel to nm scaling from the Bruker .spm file.</p>"},{"location":"api/io/#topostats.io.LoadScans.load_spm--returns","title":"Returns","text":"<p>tuple[npt.NDArray, float]     A tuple containing the image and its pixel to nanometre scaling value.</p> Source code in <code>topostats/io.py</code> <pre><code>def load_spm(self) -&gt; tuple[npt.NDArray, float]:\n    \"\"\"\n    Extract image and pixel to nm scaling from the Bruker .spm file.\n\n    Returns\n    -------\n    tuple[npt.NDArray, float]\n        A tuple containing the image and its pixel to nanometre scaling value.\n    \"\"\"\n    try:\n        LOGGER.debug(f\"Loading image from : {self.img_path}\")\n        return spm.load_spm(file_path=self.img_path, channel=self.channel)\n    except FileNotFoundError:\n        LOGGER.error(f\"File Not Found : {self.img_path}\")\n        raise\n</code></pre>"},{"location":"api/io/#topostats.io.LoadScans.load_topostats","title":"<code>load_topostats(extract='all')</code>","text":"<p>Load a .topostats file (hdf5 format).</p> <p>Loads and extracts the image, pixel to nanometre scaling factor and any grain masks.</p> <p>Note that grain masks are stored via self.grain_masks rather than returned due to how we extract information for all other file loading functions.</p>"},{"location":"api/io/#topostats.io.LoadScans.load_topostats--parameters","title":"Parameters","text":"<p>extract : str     String of which image (Numpy array) and data to extract, default is 'all' which returns the cleaned     (post-Filter) image, <code>pixel_to_nm_scaling</code> and all <code>data</code>. It is possible to extract image arrays for other     stages of processing such as <code>raw</code> or 'filter'.</p>"},{"location":"api/io/#topostats.io.LoadScans.load_topostats--returns","title":"Returns","text":"<p>dict[str, Any] | tuple[npt.NDArray, float, Any]     A dictionary of all previously processed data or tuple containing the image and its pixel to nanometre     scaling value. This is contingent on the ''extract'' option.</p> Source code in <code>topostats/io.py</code> <pre><code>def load_topostats(self, extract: str = \"all\") -&gt; dict[str, Any] | tuple[npt.NDArray, float, Any]:\n    \"\"\"\n    Load a .topostats file (hdf5 format).\n\n    Loads and extracts the image, pixel to nanometre scaling factor and any grain masks.\n\n    Note that grain masks are stored via self.grain_masks rather than returned due to how we extract information for\n    all other file loading functions.\n\n    Parameters\n    ----------\n    extract : str\n        String of which image (Numpy array) and data to extract, default is 'all' which returns the cleaned\n        (post-Filter) image, `pixel_to_nm_scaling` and all `data`. It is possible to extract image arrays for other\n        stages of processing such as `raw` or 'filter'.\n\n    Returns\n    -------\n    dict[str, Any] | tuple[npt.NDArray, float, Any]\n        A dictionary of all previously processed data or tuple containing the image and its pixel to nanometre\n        scaling value. This is contingent on the ''extract'' option.\n    \"\"\"\n    try:\n        LOGGER.debug(f\"Loading image from : {self.img_path}\")\n        data = topostats.load_topostats(self.img_path)\n    except FileNotFoundError:\n        LOGGER.error(f\"File Not Found : {self.img_path}\")\n        raise\n    # We want everything if performing any step beyond filtering (or explicitly ask for None/\"all\")\n    if extract in [None, \"all\", \"grains\", \"grainstats\"]:\n        return data\n    # Otherwise we are re-running filtering we want the raw/image_original and scaling\n    return (data[\"image_original\"], data[\"pixel_to_nm_scaling\"])\n</code></pre>"},{"location":"api/io/#topostats.io.convert_basename_to_relative_paths","title":"<code>convert_basename_to_relative_paths(df)</code>","text":"<p>Convert paths in the 'basename' column of a dataframe to relative paths.</p> <p>If the 'basename' column has the following paths: ['/usr/topo/data/a/b', '/usr/topo/data/c/d'], the output will be: ['a/b', 'c/d'].</p>"},{"location":"api/io/#topostats.io.convert_basename_to_relative_paths--parameters","title":"Parameters","text":"<p>df : pd.DataFrame     A pandas dataframe containing a column 'basename' which contains the paths     indicating the locations of the image data files.</p>"},{"location":"api/io/#topostats.io.convert_basename_to_relative_paths--returns","title":"Returns","text":"<p>pd.DataFrame     A pandas dataframe where the 'basename' column has paths relative to a common     parent.</p> Source code in <code>topostats/io.py</code> <pre><code>def convert_basename_to_relative_paths(df: pd.DataFrame):\n    \"\"\"\n    Convert paths in the 'basename' column of a dataframe to relative paths.\n\n    If the 'basename' column has the following paths: ['/usr/topo/data/a/b', '/usr/topo/data/c/d'], the output will be:\n    ['a/b', 'c/d'].\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        A pandas dataframe containing a column 'basename' which contains the paths\n        indicating the locations of the image data files.\n\n    Returns\n    -------\n    pd.DataFrame\n        A pandas dataframe where the 'basename' column has paths relative to a common\n        parent.\n    \"\"\"\n    paths = df[\"basename\"].tolist()\n    paths = [Path(path) for path in paths]\n    relative_paths = get_relative_paths(paths=paths)\n    df[\"basename\"] = relative_paths\n\n    return df\n</code></pre>"},{"location":"api/io/#topostats.io.dict_almost_equal","title":"<code>dict_almost_equal(dict1, dict2, abs_tol=1e-09)</code>","text":"<p>Recursively check if two dictionaries are almost equal with a given absolute tolerance.</p>"},{"location":"api/io/#topostats.io.dict_almost_equal--parameters","title":"Parameters","text":"<p>dict1 : dict     First dictionary to compare. dict2 : dict     Second dictionary to compare. abs_tol : float     Absolute tolerance to check for equality.</p>"},{"location":"api/io/#topostats.io.dict_almost_equal--returns","title":"Returns","text":"<p>bool     True if the dictionaries are almost equal, False otherwise.</p> Source code in <code>topostats/io.py</code> <pre><code>def dict_almost_equal(dict1: dict, dict2: dict, abs_tol: float = 1e-9):  # noqa: C901\n    \"\"\"\n    Recursively check if two dictionaries are almost equal with a given absolute tolerance.\n\n    Parameters\n    ----------\n    dict1 : dict\n        First dictionary to compare.\n    dict2 : dict\n        Second dictionary to compare.\n    abs_tol : float\n        Absolute tolerance to check for equality.\n\n    Returns\n    -------\n    bool\n        True if the dictionaries are almost equal, False otherwise.\n    \"\"\"\n    if dict1.keys() != dict2.keys():\n        return False\n\n    LOGGER.debug(\"Comparing dictionaries\")\n\n    for key in dict1:\n        LOGGER.debug(f\"Comparing key {key}\")\n        if isinstance(dict1[key], dict) and isinstance(dict2[key], dict):\n            if not dict_almost_equal(dict1[key], dict2[key], abs_tol=abs_tol):\n                return False\n        elif isinstance(dict1[key], np.ndarray) and isinstance(dict2[key], np.ndarray):\n            if not np.allclose(dict1[key], dict2[key], atol=abs_tol):\n                LOGGER.debug(f\"Key {key} type: {type(dict1[key])} not equal: {dict1[key]} != {dict2[key]}\")\n                return False\n        elif isinstance(dict1[key], float) and isinstance(dict2[key], float):\n            # Skip if both values are NaN\n            if not (np.isnan(dict1[key]) and np.isnan(dict2[key])):\n                # Check if both values are close\n                if not np.isclose(dict1[key], dict2[key], atol=abs_tol):\n                    LOGGER.debug(f\"Key {key} type: {type(dict1[key])} not equal: {dict1[key]} != {dict2[key]}\")\n                    return False\n\n        elif dict1[key] != dict2[key]:\n            LOGGER.debug(f\"Key {key} not equal: {dict1[key]} != {dict2[key]}\")\n            return False\n\n    return True\n</code></pre>"},{"location":"api/io/#topostats.io.dict_to_hdf5","title":"<code>dict_to_hdf5(open_hdf5_file, group_path, dictionary)</code>","text":"<p>Recursively save a dictionary to an open hdf5 file.</p>"},{"location":"api/io/#topostats.io.dict_to_hdf5--parameters","title":"Parameters","text":"<p>open_hdf5_file : h5py.File     An open hdf5 file object. group_path : str     The path to the group in the hdf5 file to start saving data from. dictionary : dict     A dictionary of the data to save.</p> Source code in <code>topostats/io.py</code> <pre><code>def dict_to_hdf5(open_hdf5_file: h5py.File, group_path: str, dictionary: dict) -&gt; None:\n    \"\"\"\n    Recursively save a dictionary to an open hdf5 file.\n\n    Parameters\n    ----------\n    open_hdf5_file : h5py.File\n        An open hdf5 file object.\n    group_path : str\n        The path to the group in the hdf5 file to start saving data from.\n    dictionary : dict\n        A dictionary of the data to save.\n    \"\"\"\n    for key, item in dictionary.items():\n        # LOGGER.info(f\"Saving key: {key}\")\n\n        if item is None:\n            LOGGER.debug(f\"Item '{key}' is None. Skipping.\")\n        # Make sure the key is a string\n        key = str(key)\n\n        # Check if the item is a known datatype\n        # Ruff wants us to use the pipe operator here but it isn't supported by python 3.9\n        if isinstance(item, (list, str, int, float, np.ndarray, Path, dict)):  # noqa: UP038\n            # Lists need to be converted to numpy arrays\n            if isinstance(item, list):\n                item = np.array(item)\n                open_hdf5_file[group_path + key] = item\n            # Strings need to be encoded to bytes\n            elif isinstance(item, str):\n                open_hdf5_file[group_path + key] = item.encode(\"utf8\")\n            # Integers, floats and numpy arrays can be added directly to the hdf5 file\n            # Ruff wants us to use the pipe operator here but it isn't supported by python 3.9\n            elif isinstance(item, (int, float, np.ndarray)):  # noqa: UP038\n                open_hdf5_file[group_path + key] = item\n            # Path objects need to be encoded to bytes\n            elif isinstance(item, Path):\n                open_hdf5_file[group_path + key] = str(item).encode(\"utf8\")\n            # Dictionaries need to be recursively saved\n            elif isinstance(item, dict):  # a sub-dictionary, so we need to recurse\n                dict_to_hdf5(open_hdf5_file, group_path + key + \"/\", item)\n        else:  # attempt to save an item that is not a numpy array or a dictionary\n            try:\n                open_hdf5_file[group_path + key] = item\n            except Exception as e:\n                LOGGER.debug(f\"Cannot save key '{key}' to HDF5. Item type: {type(item)}. Skipping. {e}\")\n</code></pre>"},{"location":"api/io/#topostats.io.dict_to_json","title":"<code>dict_to_json(data, output_dir, filename, indent=4)</code>","text":"<p>Write a dictionary to a JSON file at the specified location with the given name.</p> The <code>NumpyEncoder</code> class is used as the default encoder to ensure Numpy dtypes are written as strings (they are <p>not serialisable to JSON using the default JSONEncoder).</p>"},{"location":"api/io/#topostats.io.dict_to_json--parameters","title":"Parameters","text":"<p>data : dict     Data as a dictionary that is to be written to file. output_dir : str | Path     Directory the file is to be written to. filename : str | Path     Name of output file. indent : int     Spaces to indent JSON with, default is 4.</p> Source code in <code>topostats/io.py</code> <pre><code>def dict_to_json(data: dict, output_dir: str | Path, filename: str | Path, indent: int = 4) -&gt; None:\n    \"\"\"\n    Write a dictionary to a JSON file at the specified location with the given name.\n\n    NB : The `NumpyEncoder` class is used as the default encoder to ensure Numpy dtypes are written as strings (they are\n         not serialisable to JSON using the default JSONEncoder).\n\n    Parameters\n    ----------\n    data : dict\n        Data as a dictionary that is to be written to file.\n    output_dir : str | Path\n        Directory the file is to be written to.\n    filename : str | Path\n        Name of output file.\n    indent : int\n        Spaces to indent JSON with, default is 4.\n    \"\"\"\n    output_file = output_dir / filename\n    with output_file.open(\"w\") as f:\n        json.dump(data, f, indent=indent, cls=NumpyEncoder)\n</code></pre>"},{"location":"api/io/#topostats.io.find_files","title":"<code>find_files(base_dir=None, file_ext='.spm')</code>","text":"<p>Recursively scan the specified directory for images with the given file extension.</p>"},{"location":"api/io/#topostats.io.find_files--parameters","title":"Parameters","text":"<p>base_dir : Union[str, Path]     Directory to recursively search for files, if not specified the current directory is scanned. file_ext : str     File extension to search for.</p>"},{"location":"api/io/#topostats.io.find_files--returns","title":"Returns","text":"<p>List     List of files found with the extension in the given directory.</p> Source code in <code>topostats/io.py</code> <pre><code>def find_files(base_dir: str | Path = None, file_ext: str = \".spm\") -&gt; list:\n    \"\"\"\n    Recursively scan the specified directory for images with the given file extension.\n\n    Parameters\n    ----------\n    base_dir : Union[str, Path]\n        Directory to recursively search for files, if not specified the current directory is scanned.\n    file_ext : str\n        File extension to search for.\n\n    Returns\n    -------\n    List\n        List of files found with the extension in the given directory.\n    \"\"\"\n    base_dir = Path(\"./\") if base_dir is None else Path(base_dir)\n    return list(base_dir.glob(\"**/*\" + file_ext))\n</code></pre>"},{"location":"api/io/#topostats.io.get_date_time","title":"<code>get_date_time()</code>","text":"<p>Get a date and time for adding to generated files or logging.</p>"},{"location":"api/io/#topostats.io.get_date_time--returns","title":"Returns","text":"<p>str     A string of the current date and time, formatted appropriately.</p> Source code in <code>topostats/io.py</code> <pre><code>def get_date_time() -&gt; str:\n    \"\"\"\n    Get a date and time for adding to generated files or logging.\n\n    Returns\n    -------\n    str\n        A string of the current date and time, formatted appropriately.\n    \"\"\"\n    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n</code></pre>"},{"location":"api/io/#topostats.io.get_out_path","title":"<code>get_out_path(image_path=None, base_dir=None, output_dir=None)</code>","text":"<p>Add the image path relative to the base directory to the output directory.</p>"},{"location":"api/io/#topostats.io.get_out_path--parameters","title":"Parameters","text":"<p>image_path : Path     The path of the current image. base_dir : Path     Directory to recursively search for files. output_dir : Path     The output directory specified in the configuration file.</p>"},{"location":"api/io/#topostats.io.get_out_path--returns","title":"Returns","text":"<p>Path     The output path that mirrors the input path structure.</p> Source code in <code>topostats/io.py</code> <pre><code>def get_out_path(image_path: str | Path = None, base_dir: str | Path = None, output_dir: str | Path = None) -&gt; Path:\n    \"\"\"\n    Add the image path relative to the base directory to the output directory.\n\n    Parameters\n    ----------\n    image_path : Path\n        The path of the current image.\n    base_dir : Path\n        Directory to recursively search for files.\n    output_dir : Path\n        The output directory specified in the configuration file.\n\n    Returns\n    -------\n    Path\n        The output path that mirrors the input path structure.\n    \"\"\"\n    # If image_path is relative and doesn't include base_dir then a ValueError is raised, in which\n    # case we just want to append the image_path to the output_dir\n    try:\n        # Remove the filename if there is a suffix, not always the case as\n        # get_out_path is called from save_folder_grainstats()\n        if image_path.suffix:\n            return output_dir / image_path.relative_to(base_dir).parent / image_path.stem\n        return output_dir / image_path.relative_to(base_dir)\n    except ValueError:\n        if image_path.suffix:\n            return output_dir / image_path.parent / image_path.stem\n        return Path(str(output_dir) + \"/\" + str(image_path))\n    # AttributeError is raised if image_path is a string (since it isn't a Path() object with a .suffix)\n    except AttributeError:\n        LOGGER.error(\"A string form of a Path has been passed to 'get_out_path()' for image_path\")\n        raise\n</code></pre>"},{"location":"api/io/#topostats.io.get_relative_paths","title":"<code>get_relative_paths(paths)</code>","text":"<p>Extract a list of relative paths, removing the common suffix.</p> <p>From a list of paths, create a list where each path is relative to all path's closest common parent. For example, ['a/b/c', 'a/b/d', 'a/b/e/f'] would return ['c', 'd', 'e/f'].</p>"},{"location":"api/io/#topostats.io.get_relative_paths--parameters","title":"Parameters","text":"<p>paths : list     List of string or pathlib paths.</p>"},{"location":"api/io/#topostats.io.get_relative_paths--returns","title":"Returns","text":"<p>list     List of string paths, relative to the common parent.</p> Source code in <code>topostats/io.py</code> <pre><code>def get_relative_paths(paths: list[Path]) -&gt; list[str]:\n    \"\"\"\n    Extract a list of relative paths, removing the common suffix.\n\n    From a list of paths, create a list where each path is relative to all path's closest common parent. For example,\n    ['a/b/c', 'a/b/d', 'a/b/e/f'] would return ['c', 'd', 'e/f'].\n\n    Parameters\n    ----------\n    paths : list\n        List of string or pathlib paths.\n\n    Returns\n    -------\n    list\n        List of string paths, relative to the common parent.\n    \"\"\"\n    # Ensure paths are all pathlib paths, and not strings\n    paths = [Path(path) for path in paths]\n\n    # If the paths list consists of all the same path, then the relative path will\n    # be '.', which we don't want. we want the relative path to be the full path probably.\n    # len(set(my_list)) == 1 determines if all the elements in a list are the same.\n    if len(set(paths)) == 1:\n        return [str(path.as_posix()) for path in paths]\n\n    deepest_common_path = os.path.commonpath(paths)\n    # Have to convert to strings else the dataframe values will be slightly different\n    # to what is expected.\n    return [str(path.relative_to(deepest_common_path).as_posix()) for path in paths]\n</code></pre>"},{"location":"api/io/#topostats.io.hdf5_to_dict","title":"<code>hdf5_to_dict(open_hdf5_file, group_path)</code>","text":"<p>Read a dictionary from an open hdf5 file.</p>"},{"location":"api/io/#topostats.io.hdf5_to_dict--parameters","title":"Parameters","text":"<p>open_hdf5_file : h5py.File     An open hdf5 file object. group_path : str     The path to the group in the hdf5 file to start reading data from.</p>"},{"location":"api/io/#topostats.io.hdf5_to_dict--returns","title":"Returns","text":"<p>dict     A dictionary of the hdf5 file data.</p> Source code in <code>topostats/io.py</code> <pre><code>def hdf5_to_dict(open_hdf5_file: h5py.File, group_path: str) -&gt; dict:\n    \"\"\"\n    Read a dictionary from an open hdf5 file.\n\n    Parameters\n    ----------\n    open_hdf5_file : h5py.File\n        An open hdf5 file object.\n    group_path : str\n        The path to the group in the hdf5 file to start reading data from.\n\n    Returns\n    -------\n    dict\n        A dictionary of the hdf5 file data.\n    \"\"\"\n    data_dict = {}\n    for key, item in open_hdf5_file[group_path].items():\n        LOGGER.debug(f\"Loading hdf5 key: {key}\")\n        if isinstance(item, h5py.Group):\n            LOGGER.debug(f\" {key} is a group\")\n            data_dict[key] = hdf5_to_dict(open_hdf5_file, group_path + key + \"/\")\n        # Decode byte strings to utf-8. The data type \"O\" is a byte string.\n        elif isinstance(item, h5py.Dataset) and item.dtype == \"O\":\n            LOGGER.debug(f\" {key} is a byte string\")\n            data_dict[key] = item[()].decode(\"utf-8\")\n            LOGGER.debug(f\" {key} type: {type(data_dict[key])}\")\n        else:\n            LOGGER.debug(f\" {key} is other type of dataset\")\n            data_dict[key] = item[()]\n            LOGGER.debug(f\" {key} type: {type(data_dict[key])}\")\n    return data_dict\n</code></pre>"},{"location":"api/io/#topostats.io.load_array","title":"<code>load_array(array_path)</code>","text":"<p>Load a Numpy array from file.</p> <p>Should have been saved using save_array() or numpy.save().</p>"},{"location":"api/io/#topostats.io.load_array--parameters","title":"Parameters","text":"<p>array_path : Union[str, Path]     Path to the Numpy array on disk.</p>"},{"location":"api/io/#topostats.io.load_array--returns","title":"Returns","text":"<p>npt.NDArray     Returns the loaded Numpy array.</p> Source code in <code>topostats/io.py</code> <pre><code>def load_array(array_path: str | Path) -&gt; npt.NDArray:\n    \"\"\"\n    Load a Numpy array from file.\n\n    Should have been saved using save_array() or numpy.save().\n\n    Parameters\n    ----------\n    array_path : Union[str, Path]\n        Path to the Numpy array on disk.\n\n    Returns\n    -------\n    npt.NDArray\n        Returns the loaded Numpy array.\n    \"\"\"\n    try:\n        return np.load(Path(array_path))\n    except FileNotFoundError as e:\n        raise e\n</code></pre>"},{"location":"api/io/#topostats.io.load_pkl","title":"<code>load_pkl(infile)</code>","text":"<p>Load data from a pickle.</p>"},{"location":"api/io/#topostats.io.load_pkl--parameters","title":"Parameters","text":"<p>infile : Path     Path to a valid pickle.</p>"},{"location":"api/io/#topostats.io.load_pkl--returns","title":"Returns","text":"<p>dict:     Dictionary of generated images.</p>"},{"location":"api/io/#topostats.io.load_pkl--examples","title":"Examples","text":"<p>from pathlib import Path from topostats.io import load_plots</p> <p>pkl_path = \"output/distribution_plots.pkl\" my_plots = load_pkl(pkl_path)</p> <p>Show the type of my_plots which is a dictionary of nested dictionaries</p> <p>type(my_plots)</p> <p>Show the keys are various levels of nesting.</p> <p>my_plots.keys() my_plots[\"area\"].keys() my_plots[\"area\"][\"dist\"].keys()</p> <p>Get the figure and axis object for a given metrics distribution plot</p> <p>figure, axis = my_plots[\"area\"][\"dist\"].values()</p> <p>Get the figure and axis object for a given metrics violin plot</p> <p>figure, axis = my_plots[\"area\"][\"violin\"].values()</p> Source code in <code>topostats/io.py</code> <pre><code>def load_pkl(infile: Path) -&gt; Any:\n    \"\"\"\n    Load data from a pickle.\n\n    Parameters\n    ----------\n    infile : Path\n        Path to a valid pickle.\n\n    Returns\n    -------\n    dict:\n        Dictionary of generated images.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; from topostats.io import load_plots\n\n    &gt;&gt;&gt; pkl_path = \"output/distribution_plots.pkl\"\n    &gt;&gt;&gt; my_plots = load_pkl(pkl_path)\n\n    Show the type of my_plots which is a dictionary of nested dictionaries\n\n    &gt;&gt;&gt; type(my_plots)\n\n    Show the keys are various levels of nesting.\n\n    &gt;&gt;&gt; my_plots.keys()\n    &gt;&gt;&gt; my_plots[\"area\"].keys()\n    &gt;&gt;&gt; my_plots[\"area\"][\"dist\"].keys()\n\n    Get the figure and axis object for a given metrics distribution plot\n\n    &gt;&gt;&gt; figure, axis = my_plots[\"area\"][\"dist\"].values()\n\n    Get the figure and axis object for a given metrics violin plot\n\n    &gt;&gt;&gt; figure, axis = my_plots[\"area\"][\"violin\"].values()\n    \"\"\"\n    with infile.open(\"rb\", encoding=None) as f:\n        return pkl.load(f)  # noqa: S301\n</code></pre>"},{"location":"api/io/#topostats.io.merge_mappings","title":"<code>merge_mappings(map1, map2)</code>","text":"<p>Merge two mappings (dictionaries), with priority given to the second mapping.</p> <p>Note: Using a Mapping should make this robust to any mapping type, not just dictionaries. MutableMapping was needed as Mapping is not a mutable type, and this function needs to be able to change the dictionaries.</p>"},{"location":"api/io/#topostats.io.merge_mappings--parameters","title":"Parameters","text":"<p>map1 : MutableMapping     First mapping to merge, with secondary priority. map2 : MutableMapping     Second mapping to merge, with primary priority.</p>"},{"location":"api/io/#topostats.io.merge_mappings--returns","title":"Returns","text":"<p>dict     Merged dictionary.</p> Source code in <code>topostats/io.py</code> <pre><code>def merge_mappings(map1: MutableMappingType, map2: MutableMappingType) -&gt; MutableMappingType:\n    \"\"\"\n    Merge two mappings (dictionaries), with priority given to the second mapping.\n\n    Note: Using a Mapping should make this robust to any mapping type, not just dictionaries. MutableMapping was needed\n    as Mapping is not a mutable type, and this function needs to be able to change the dictionaries.\n\n    Parameters\n    ----------\n    map1 : MutableMapping\n        First mapping to merge, with secondary priority.\n    map2 : MutableMapping\n        Second mapping to merge, with primary priority.\n\n    Returns\n    -------\n    dict\n        Merged dictionary.\n    \"\"\"\n    # Iterate over the second mapping\n    for key, value in map2.items():\n        # If the value is another mapping, then recurse\n        if isinstance(value, MutableMapping):\n            # If the key is not in the first mapping, add it as an empty dictionary before recursing\n            map1[key] = merge_mappings(map1.get(key, {}), value)\n        else:\n            # Else simply add / override the key value pair\n            map1[key] = value\n    return map1\n</code></pre>"},{"location":"api/io/#topostats.io.path_to_str","title":"<code>path_to_str(config)</code>","text":"<p>Recursively traverse a dictionary and convert any Path() objects to strings for writing to YAML.</p>"},{"location":"api/io/#topostats.io.path_to_str--parameters","title":"Parameters","text":"<p>config : dict     Dictionary to be converted.</p>"},{"location":"api/io/#topostats.io.path_to_str--returns","title":"Returns","text":"<p>Dict:     The same dictionary with any Path() objects converted to string.</p> Source code in <code>topostats/io.py</code> <pre><code>def path_to_str(config: dict) -&gt; dict:\n    \"\"\"\n    Recursively traverse a dictionary and convert any Path() objects to strings for writing to YAML.\n\n    Parameters\n    ----------\n    config : dict\n        Dictionary to be converted.\n\n    Returns\n    -------\n    Dict:\n        The same dictionary with any Path() objects converted to string.\n    \"\"\"\n    for key, value in config.items():\n        if isinstance(value, dict):\n            path_to_str(value)\n        elif isinstance(value, Path):\n            config[key] = str(value)\n\n    return config\n</code></pre>"},{"location":"api/io/#topostats.io.read_64d","title":"<code>read_64d(open_file)</code>","text":"<p>Read a 64-bit double from an open binary file.</p>"},{"location":"api/io/#topostats.io.read_64d--parameters","title":"Parameters","text":"<p>open_file : io.TextIOWrapper     An open file object.</p>"},{"location":"api/io/#topostats.io.read_64d--returns","title":"Returns","text":"<p>float     Python float type cast from the double.</p> Source code in <code>topostats/io.py</code> <pre><code>def read_64d(open_file: io.TextIOWrapper) -&gt; str:\n    \"\"\"\n    Read a 64-bit double from an open binary file.\n\n    Parameters\n    ----------\n    open_file : io.TextIOWrapper\n        An open file object.\n\n    Returns\n    -------\n    float\n        Python float type cast from the double.\n    \"\"\"\n    return float(struct.unpack(\"d\", open_file.read(8))[0])\n</code></pre>"},{"location":"api/io/#topostats.io.read_char","title":"<code>read_char(open_file)</code>","text":"<p>Read a character from an open binary file.</p>"},{"location":"api/io/#topostats.io.read_char--parameters","title":"Parameters","text":"<p>open_file : io.TextIOWrapper     An open file object.</p>"},{"location":"api/io/#topostats.io.read_char--returns","title":"Returns","text":"<p>str     A string type cast from the decoded character.</p> Source code in <code>topostats/io.py</code> <pre><code>def read_char(open_file: io.TextIOWrapper) -&gt; str:\n    \"\"\"\n    Read a character from an open binary file.\n\n    Parameters\n    ----------\n    open_file : io.TextIOWrapper\n        An open file object.\n\n    Returns\n    -------\n    str\n        A string type cast from the decoded character.\n    \"\"\"\n    return open_file.read(1).decode(\"ascii\")\n</code></pre>"},{"location":"api/io/#topostats.io.read_gwy_component_dtype","title":"<code>read_gwy_component_dtype(open_file)</code>","text":"<p>Read the data type of a <code>.gwy</code> file component.</p> <p>Possible data types are as follows:</p> <ul> <li>'b': boolean</li> <li>'c': character</li> <li>'i': 32-bit integer</li> <li>'q': 64-bit integer</li> <li>'d': double</li> <li>'s': string</li> <li>'o': <code>.gwy</code> format object</li> </ul> <p>Capitalised versions of some of these data types represent arrays of values of that data type. Arrays are stored as an unsigned 32 bit integer, describing the size of the array, followed by the unseparated array values:</p> <ul> <li>'C': array of characters</li> <li>'I': array of 32-bit integers</li> <li>'Q': array of 64-bit integers</li> <li>'D': array of doubles</li> <li>'S': array of strings</li> <li>'O': array of objects.</li> </ul>"},{"location":"api/io/#topostats.io.read_gwy_component_dtype--parameters","title":"Parameters","text":"<p>open_file : io.TextIOWrapper     An open file object.</p>"},{"location":"api/io/#topostats.io.read_gwy_component_dtype--returns","title":"Returns","text":"<p>str     Python string (one character long) of the data type of the component's value.</p> Source code in <code>topostats/io.py</code> <pre><code>def read_gwy_component_dtype(open_file: io.TextIOWrapper) -&gt; str:\n    \"\"\"\n    Read the data type of a `.gwy` file component.\n\n    Possible data types are as follows:\n\n    - 'b': boolean\n    - 'c': character\n    - 'i': 32-bit integer\n    - 'q': 64-bit integer\n    - 'd': double\n    - 's': string\n    - 'o': `.gwy` format object\n\n    Capitalised versions of some of these data types represent arrays of values of that data type. Arrays are stored as\n    an unsigned 32 bit integer, describing the size of the array, followed by the unseparated array values:\n\n    - 'C': array of characters\n    - 'I': array of 32-bit integers\n    - 'Q': array of 64-bit integers\n    - 'D': array of doubles\n    - 'S': array of strings\n    - 'O': array of objects.\n\n    Parameters\n    ----------\n    open_file : io.TextIOWrapper\n        An open file object.\n\n    Returns\n    -------\n    str\n        Python string (one character long) of the data type of the component's value.\n    \"\"\"\n    return open_file.read(1).decode(\"ascii\")\n</code></pre>"},{"location":"api/io/#topostats.io.read_null_terminated_string","title":"<code>read_null_terminated_string(open_file, encoding='utf-8')</code>","text":"<p>Read an open file from the current position in the open binary file, until the next null value.</p>"},{"location":"api/io/#topostats.io.read_null_terminated_string--parameters","title":"Parameters","text":"<p>open_file : io.TextIOWrapper     An open file object. encoding : str     Encoding to use when decoding the bytes.</p>"},{"location":"api/io/#topostats.io.read_null_terminated_string--returns","title":"Returns","text":"<p>str     String of the ASCII decoded bytes before the next null byte.</p>"},{"location":"api/io/#topostats.io.read_null_terminated_string--examples","title":"Examples","text":"<p>with open(\"test.txt\", \"rb\") as f: ...     print(read_null_terminated_string(f), encoding=\"utf-8\")</p> Source code in <code>topostats/io.py</code> <pre><code>def read_null_terminated_string(open_file: io.TextIOWrapper, encoding: str = \"utf-8\") -&gt; str:\n    \"\"\"\n    Read an open file from the current position in the open binary file, until the next null value.\n\n    Parameters\n    ----------\n    open_file : io.TextIOWrapper\n        An open file object.\n    encoding : str\n        Encoding to use when decoding the bytes.\n\n    Returns\n    -------\n    str\n        String of the ASCII decoded bytes before the next null byte.\n\n    Examples\n    --------\n    &gt;&gt;&gt; with open(\"test.txt\", \"rb\") as f:\n    ...     print(read_null_terminated_string(f), encoding=\"utf-8\")\n    \"\"\"\n    byte = open_file.read(1)\n    value = b\"\"\n    while byte != b\"\\x00\":\n        value += byte\n        byte = open_file.read(1)\n    # Sometimes encodings cannot decode a byte that is not defined in the encoding.\n    # Try 'latin1' in this case as it is able to handle symbols such as micro (\u00b5).\n    try:\n        return str(value.decode(encoding=encoding))\n    except UnicodeDecodeError as e:\n        if \"codec can't decode byte\" in str(e):\n            bad_byte = str(e).split(\"byte \")[1].split(\":\")[0]\n            LOGGER.debug(\n                f\"Decoding error while reading null terminated string. Encoding {encoding} encountered\"\n                f\" a byte that could not be decoded: {bad_byte}. Trying 'latin1' encoding.\"\n            )\n            return str(value.decode(encoding=\"latin1\"))\n        raise e\n</code></pre>"},{"location":"api/io/#topostats.io.read_u32i","title":"<code>read_u32i(open_file)</code>","text":"<p>Read an unsigned 32 bit integer from an open binary file (in little-endian form).</p>"},{"location":"api/io/#topostats.io.read_u32i--parameters","title":"Parameters","text":"<p>open_file : io.TextIOWrapper     An open file object.</p>"},{"location":"api/io/#topostats.io.read_u32i--returns","title":"Returns","text":"<p>int     Python integer type cast from the unsigned 32 bit integer.</p> Source code in <code>topostats/io.py</code> <pre><code>def read_u32i(open_file: io.TextIOWrapper) -&gt; str:\n    \"\"\"\n    Read an unsigned 32 bit integer from an open binary file (in little-endian form).\n\n    Parameters\n    ----------\n    open_file : io.TextIOWrapper\n        An open file object.\n\n    Returns\n    -------\n    int\n        Python integer type cast from the unsigned 32 bit integer.\n    \"\"\"\n    return int(struct.unpack(\"&lt;i\", open_file.read(4))[0])\n</code></pre>"},{"location":"api/io/#topostats.io.read_yaml","title":"<code>read_yaml(filename)</code>","text":"<p>Read a YAML file.</p>"},{"location":"api/io/#topostats.io.read_yaml--parameters","title":"Parameters","text":"<p>filename : Union[str, Path]     YAML file to read.</p>"},{"location":"api/io/#topostats.io.read_yaml--returns","title":"Returns","text":"<p>Dict     Dictionary of the file.</p> Source code in <code>topostats/io.py</code> <pre><code>def read_yaml(filename: str | Path) -&gt; dict:\n    \"\"\"\n    Read a YAML file.\n\n    Parameters\n    ----------\n    filename : Union[str, Path]\n        YAML file to read.\n\n    Returns\n    -------\n    Dict\n        Dictionary of the file.\n    \"\"\"\n    with Path(filename).open(encoding=\"utf-8\") as f:\n        try:\n            yaml_file = YAML(typ=\"safe\")\n            return yaml_file.load(f)\n        except YAMLError as exception:\n            LOGGER.error(exception)\n            return {}\n</code></pre>"},{"location":"api/io/#topostats.io.save_array","title":"<code>save_array(array, outpath, filename, array_type)</code>","text":"<p>Save a Numpy array to disk.</p>"},{"location":"api/io/#topostats.io.save_array--parameters","title":"Parameters","text":"<p>array : npt.NDArray     Numpy array to be saved. outpath : Path     Location array should be saved. filename : str     Filename of the current image from which the array is derived. array_type : str     Short string describing the array type e.g. z_threshold. Ideally should not have periods or spaces in (use     underscores '_' instead).</p> Source code in <code>topostats/io.py</code> <pre><code>def save_array(array: npt.NDArray, outpath: Path, filename: str, array_type: str) -&gt; None:\n    \"\"\"\n    Save a Numpy array to disk.\n\n    Parameters\n    ----------\n    array : npt.NDArray\n        Numpy array to be saved.\n    outpath : Path\n        Location array should be saved.\n    filename : str\n        Filename of the current image from which the array is derived.\n    array_type : str\n        Short string describing the array type e.g. z_threshold. Ideally should not have periods or spaces in (use\n        underscores '_' instead).\n    \"\"\"\n    np.save(outpath / f\"{filename}_{array_type}.npy\", array)\n    LOGGER.info(f\"[{filename}] Numpy array saved to : {outpath}/{filename}_{array_type}.npy\")\n</code></pre>"},{"location":"api/io/#topostats.io.save_folder_grainstats","title":"<code>save_folder_grainstats(output_dir, base_dir, all_stats_df, stats_filename)</code>","text":"<p>Save a data frame of grain and tracing statistics at the folder level.</p>"},{"location":"api/io/#topostats.io.save_folder_grainstats--parameters","title":"Parameters","text":"<p>output_dir : Union[str, Path]     Path of the output directory head. base_dir : Union[str, Path]     Path of the base directory where files were found. all_stats_df : pd.DataFrame     The dataframe containing all sample statistics run. stats_filename : str     The name of the type of statistics dataframe to be saved.</p>"},{"location":"api/io/#topostats.io.save_folder_grainstats--returns","title":"Returns","text":"<p>None     This only saves the dataframes and does not retain them.</p> Source code in <code>topostats/io.py</code> <pre><code>def save_folder_grainstats(\n    output_dir: str | Path, base_dir: str | Path, all_stats_df: pd.DataFrame, stats_filename: str\n) -&gt; None:\n    \"\"\"\n    Save a data frame of grain and tracing statistics at the folder level.\n\n    Parameters\n    ----------\n    output_dir : Union[str, Path]\n        Path of the output directory head.\n    base_dir : Union[str, Path]\n        Path of the base directory where files were found.\n    all_stats_df : pd.DataFrame\n        The dataframe containing all sample statistics run.\n    stats_filename : str\n        The name of the type of statistics dataframe to be saved.\n\n    Returns\n    -------\n    None\n        This only saves the dataframes and does not retain them.\n    \"\"\"\n    dirs = set(all_stats_df[\"basename\"].values)\n    LOGGER.debug(f\"Statistics :\\n{all_stats_df}\")\n    for _dir in dirs:\n        LOGGER.debug(f\"Statistics ({_dir}) :\\n{all_stats_df}\")\n        try:\n            out_path = get_out_path(Path(_dir), base_dir, output_dir)\n            # Ensure \"processed\" directory exists at the stem of out_path, creating if needed\n            if out_path.stem != \"processed\":\n                out_path_processed = out_path / \"processed\"\n                out_path_processed.mkdir(parents=True, exist_ok=True)\n            all_stats_df[all_stats_df[\"basename\"] == _dir].to_csv(\n                out_path / \"processed\" / f\"folder_{stats_filename}.csv\", index=True\n            )\n            LOGGER.info(f\"Folder-wise statistics saved to: {str(out_path)}/folder_{stats_filename}.csv\")\n        except TypeError:\n            LOGGER.info(f\"No folder-wise statistics for directory {_dir}, no grains detected in any images.\")\n</code></pre>"},{"location":"api/io/#topostats.io.save_pkl","title":"<code>save_pkl(outfile, to_pkl)</code>","text":"<p>Pickle objects for working with later.</p>"},{"location":"api/io/#topostats.io.save_pkl--parameters","title":"Parameters","text":"<p>outfile : Path     Path and filename to save pickle to. to_pkl : dict     Object to be picled.</p> Source code in <code>topostats/io.py</code> <pre><code>def save_pkl(outfile: Path, to_pkl: dict) -&gt; None:\n    \"\"\"\n    Pickle objects for working with later.\n\n    Parameters\n    ----------\n    outfile : Path\n        Path and filename to save pickle to.\n    to_pkl : dict\n        Object to be picled.\n    \"\"\"\n    with outfile.open(mode=\"wb\", encoding=None) as f:\n        pkl.dump(to_pkl, f)\n</code></pre>"},{"location":"api/io/#topostats.io.save_topostats_file","title":"<code>save_topostats_file(output_dir, filename, topostats_object)</code>","text":"<p>Save a topostats dictionary object to a .topostats (hdf5 format) file.</p>"},{"location":"api/io/#topostats.io.save_topostats_file--parameters","title":"Parameters","text":"<p>output_dir : Path     Directory to save the .topostats file in. filename : str     File name of the .topostats file. topostats_object : dict     Dictionary of the topostats data to save. Must include a flattened image and pixel to nanometre scaling     factor. May also include grain masks.</p> Source code in <code>topostats/io.py</code> <pre><code>def save_topostats_file(output_dir: Path, filename: str, topostats_object: dict) -&gt; None:\n    \"\"\"\n    Save a topostats dictionary object to a .topostats (hdf5 format) file.\n\n    Parameters\n    ----------\n    output_dir : Path\n        Directory to save the .topostats file in.\n    filename : str\n        File name of the .topostats file.\n    topostats_object : dict\n        Dictionary of the topostats data to save. Must include a flattened image and pixel to nanometre scaling\n        factor. May also include grain masks.\n    \"\"\"\n    LOGGER.info(f\"[{filename}] : Saving image to .topostats file\")\n\n    if \".topostats\" not in filename:\n        save_file_path = output_dir / f\"{filename}.topostats\"\n    else:\n        save_file_path = output_dir / filename\n\n    with h5py.File(save_file_path, \"w\") as f:\n        # It may be possible for topostats_object[\"image\"] to be None.\n        # Make sure that this is not the case.\n        if topostats_object[\"image\"] is not None:\n            topostats_object[\"topostats_file_version\"] = 0.2\n            # Recursively save the topostats object dictionary to the .topostats file\n            dict_to_hdf5(open_hdf5_file=f, group_path=\"/\", dictionary=topostats_object)\n\n        else:\n            raise ValueError(\n                \"TopoStats object dictionary does not contain an 'image'. \\\n                 TopoStats objects must be saved with a flattened image.\"\n            )\n</code></pre>"},{"location":"api/io/#topostats.io.write_config_with_comments","title":"<code>write_config_with_comments(args=None)</code>","text":"<p>Write a sample configuration with in-line comments.</p> <p>This function is not designed to be used interactively but can be, just call it without any arguments and it will write a configuration to './config.yaml'.</p>"},{"location":"api/io/#topostats.io.write_config_with_comments--parameters","title":"Parameters","text":"<p>args : Namespace     A Namespace object parsed from argparse with values for 'filename'.</p> Source code in <code>topostats/io.py</code> <pre><code>def write_config_with_comments(args=None) -&gt; None:\n    \"\"\"\n    Write a sample configuration with in-line comments.\n\n    This function is not designed to be used interactively but can be, just call it without any arguments and it will\n    write a configuration to './config.yaml'.\n\n    Parameters\n    ----------\n    args : Namespace\n        A Namespace object parsed from argparse with values for 'filename'.\n    \"\"\"\n    filename = \"config\" if args.filename is None else args.filename\n    output_dir = Path(\"./\") if args.output_dir is None else Path(args.output_dir)\n    output_dir.mkdir(parents=True, exist_ok=True)\n    logger_msg = \"A sample configuration has been written to\"\n    # If no config or default is requested we load the default_config.yaml\n    if args.config is None or args.config == \"default\":\n        if args.simple:\n            config_path = resources.files(__package__) / \"simple_config.yaml\"\n        else:\n            config_path = resources.files(__package__) / \"default_config.yaml\"\n        config = config_path.read_text()\n    elif args.config == \"topostats.mplstyle\":\n        config = (resources.files(__package__) / \"topostats.mplstyle\").read_text()\n        logger_msg = \"A sample matplotlibrc parameters file has been written to\"\n    # Otherwise we have scope for loading different configs based on the argument, add future dictionaries to\n    # topostats/&lt;sample_type&gt;_config.yaml\n    else:\n        try:\n            config = (resources.files(__package__) / f\"{args.config}_config.yaml\").read_text()\n        except FileNotFoundError as e:\n            raise UserWarning(f\"There is no configuration for samples of type : {args.config}\") from e\n\n    if \".yaml\" not in str(filename) and \".yml\" not in str(filename) and \".mplstyle\" not in str(filename):\n        create_config_path = output_dir / f\"{filename}.yaml\"\n    else:\n        create_config_path = output_dir / filename\n\n    with create_config_path.open(\"w\", encoding=\"utf-8\") as f:\n        f.write(f\"# Config file generated {get_date_time()}\\n\")\n        f.write(f\"# {CONFIG_DOCUMENTATION_REFERENCE}\")\n        f.write(config)\n    LOGGER.info(f\"{logger_msg} : {str(create_config_path)}\")\n    LOGGER.info(CONFIG_DOCUMENTATION_REFERENCE)\n</code></pre>"},{"location":"api/io/#topostats.io.write_yaml","title":"<code>write_yaml(config, output_dir, config_file='config.yaml', header_message=None)</code>","text":"<p>Write a configuration (stored as a dictionary) to a YAML file.</p>"},{"location":"api/io/#topostats.io.write_yaml--parameters","title":"Parameters","text":"<p>config : dict     Configuration dictionary. output_dir : Union[str, Path]     Path to save the dictionary to as a YAML file (it will be called 'config.yaml'). config_file : str     Filename to write to. header_message : str     String to write to the header message of the YAML file.</p> Source code in <code>topostats/io.py</code> <pre><code>def write_yaml(\n    config: dict,\n    output_dir: str | Path,\n    config_file: str = \"config.yaml\",\n    header_message: str = None,\n) -&gt; None:\n    \"\"\"\n    Write a configuration (stored as a dictionary) to a YAML file.\n\n    Parameters\n    ----------\n    config : dict\n        Configuration dictionary.\n    output_dir : Union[str, Path]\n        Path to save the dictionary to as a YAML file (it will be called 'config.yaml').\n    config_file : str\n        Filename to write to.\n    header_message : str\n        String to write to the header message of the YAML file.\n    \"\"\"\n    # Save the configuration to output directory\n    output_config = Path(output_dir) / config_file\n    # Revert PosixPath items to string\n    config = path_to_str(config)\n\n    if header_message:\n        header = f\"# {header_message} : {get_date_time()}\\n\" + CONFIG_DOCUMENTATION_REFERENCE\n    else:\n        header = f\"# Configuration from TopoStats run completed : {get_date_time()}\\n\" + CONFIG_DOCUMENTATION_REFERENCE\n    output_config.write_text(header, encoding=\"utf-8\")\n\n    yaml = YAML(typ=\"safe\")\n    with output_config.open(\"a\", encoding=\"utf-8\") as f:\n        try:\n            yaml.dump(config, f)\n        except YAMLError as exception:\n            LOGGER.error(exception)\n</code></pre>"},{"location":"api/plotting/","title":"Plotting Modules","text":"<p>Plotting and summary of TopoStats output statistics.</p> <p>handler: python options: docstring_style: numpy rendering: show_signature_annotations: true</p>"},{"location":"api/plotting/#topostats.plotting.TopoSum","title":"<code>TopoSum</code>","text":"<p>Class for summarising grain statistics in plots.</p>"},{"location":"api/plotting/#topostats.plotting.TopoSum--parameters","title":"Parameters","text":"<p>df :  pd.DataFrame     Pandas data frame of data to be summarised. base_dir :  str | Path     Base directory from which all paths are relative to. csv_file :  str | Path     CSV file of data to be summarised. stat_to_sum :  str     Variable to summarise. molecule_id :  str     Variable that uniquely identifies molecules. image_id :  str     Variable that uniquely identifies images. hist :  bool     Whether to plot histograms. stat :  str     Statistic to plot on histogram 'count' (default), 'freq'. bins :  int     Number of bins to plot. kde :  bool     Whether to include a Kernel Density Estimate. cut :  float = 20,     Cut point for KDE. figsize :  tuple     Figure dimensions. alpha :  float     Opacity to use in plots. palette :  str = \"deep\"     Seaborn colour plot to use. savefig_format :  str     File type to save plots as 'png' (default), 'pdf', 'svg'. output_dir :  str | Path     Location to save plots to. var_to_label :  dict     Variable to label dictionary for automatically adding titles to plots. hue :  str     Dataframe column to group plots by.</p> Source code in <code>topostats/plotting.py</code> <pre><code>class TopoSum:\n    \"\"\"\n    Class for summarising grain statistics in plots.\n\n    Parameters\n    ----------\n    df :  pd.DataFrame\n        Pandas data frame of data to be summarised.\n    base_dir :  str | Path\n        Base directory from which all paths are relative to.\n    csv_file :  str | Path\n        CSV file of data to be summarised.\n    stat_to_sum :  str\n        Variable to summarise.\n    molecule_id :  str\n        Variable that uniquely identifies molecules.\n    image_id :  str\n        Variable that uniquely identifies images.\n    hist :  bool\n        Whether to plot histograms.\n    stat :  str\n        Statistic to plot on histogram 'count' (default), 'freq'.\n    bins :  int\n        Number of bins to plot.\n    kde :  bool\n        Whether to include a Kernel Density Estimate.\n    cut :  float = 20,\n        Cut point for KDE.\n    figsize :  tuple\n        Figure dimensions.\n    alpha :  float\n        Opacity to use in plots.\n    palette :  str = \"deep\"\n        Seaborn colour plot to use.\n    savefig_format :  str\n        File type to save plots as 'png' (default), 'pdf', 'svg'.\n    output_dir :  str | Path\n        Location to save plots to.\n    var_to_label :  dict\n        Variable to label dictionary for automatically adding titles to plots.\n    hue :  str\n        Dataframe column to group plots by.\n    \"\"\"\n\n    def __init__(\n        self,\n        df: pd.DataFrame = None,\n        base_dir: str | Path = None,\n        csv_file: str | Path = None,\n        stat_to_sum: str = None,\n        molecule_id: str = \"grain_number\",\n        image_id: str = \"image\",\n        hist: bool = True,\n        stat: str = \"count\",\n        bins: int = 12,\n        kde: bool = True,\n        cut: float = 20,\n        figsize: tuple = (16, 9),\n        alpha: float = 0.5,\n        palette: str = \"deep\",\n        savefig_format: str = \"png\",\n        output_dir: str | Path = \".\",\n        var_to_label: dict = None,\n        hue: str = \"basename\",\n    ) -&gt; None:\n        \"\"\"\n        Initialise the class.\n\n        Parameters\n        ----------\n        df :  pd.DataFrame\n            Pandas data frame of data to be summarised.\n        base_dir :  str | Path\n            Base directory from which all paths are relative to.\n        csv_file :  str | Path\n            CSV file of data to be summarised.\n        stat_to_sum :  str\n            Variable to summarise.\n        molecule_id :  str\n            Variable that uniquely identifies molecules.\n        image_id :  str\n            Variable that uniquely identifies images.\n        hist :  bool\n            Whether to plot histograms.\n        stat :  str\n            Statistic to plot on histogram 'count' (default), 'freq'.\n        bins :  int\n            Number of bins to plot.\n        kde :  bool\n            Whether to include a Kernel Density Estimate.\n        cut :  float = 20,\n            Cut point for KDE.\n        figsize :  tuple\n            Figure dimensions.\n        alpha :  float\n            Opacity to use in plots.\n        palette :  str = \"deep\"\n            Seaborn colour plot to use.\n        savefig_format :  str\n            File type to save plots as 'png' (default), 'pdf', 'svg'.\n        output_dir :  str | Path\n            Location to save plots to.\n        var_to_label :  dict\n            Variable to label dictionary for automatically adding titles to plots.\n        hue :  str\n            Dataframe column to group plots by.\n        \"\"\"\n        self.df = df if df is not None else pd.read_csv(csv_file)\n        self.base_dir = base_dir\n        self.stat_to_sum = stat_to_sum\n        self.molecule_id = molecule_id\n        self.image_id = image_id\n        self.hist = hist\n        self.bins = bins\n        self.stat = stat\n        self.kde = kde\n        self.cut = cut\n        self.figsize = figsize\n        self.alpha = alpha\n        self.palette = palette\n        self.savefig_format = savefig_format\n        self.output_dir = Path(output_dir)\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        self.var_to_label = var_to_label\n        self.hue = hue\n        self.melted_data = None\n        self.summary_data = None\n        self.label = None\n\n        # melt the data given in the init method\n        self.melted_data = self.melt_data(self.df, stat_to_summarize=self.stat_to_sum, var_to_label=self.var_to_label)\n        convert_basename_to_relative_paths(df=self.melted_data)\n        self.set_palette()\n        self._set_label(self.stat_to_sum)\n\n    def _setup_figure(self):\n        \"\"\"\n        Setup Matplotlib figure and axes.\n\n        Returns\n        -------\n        fig, ax\n            Matplotlib fig and ax objects.\n        \"\"\"\n        fig, ax = plt.subplots(1, 1, figsize=self.figsize)\n        return fig, ax\n\n    def _outfile(self, plot_suffix: str) -&gt; str:\n        \"\"\"\n        Generate the output file name with the appropriate suffix.\n\n        Parameters\n        ----------\n        plot_suffix : str\n            The suffix to append to the output file.\n\n        Returns\n        -------\n        str:\n            Concanenated string of the outfile and plot_suffix.\n        \"\"\"\n        return f\"{self.stat_to_sum}_{plot_suffix}\"\n\n    def sns_plot(self) -&gt; tuple[plt.Figure, plt.Axes] | None:\n        \"\"\"\n        Plot the distribution of one or more statistics as either histogram, kernel density estimates or both.\n\n        Uses base Seaborn.\n\n        Returns\n        -------\n        Optional[Union[Tuple[plt.Figure, plt.Axes], None]]\n            Tuple of Matplotlib figure and axes if plotting is successful, None otherwise.\n        \"\"\"\n\n        # Note: Plotting KDEs with Seaborn is not possible if all values are the same.\n        # This is because the KDE is calculated using a Gaussian kernel and if all values\n        # are the same, the standard deviation is 0 which results in a ZeroDivisionError with\n        # is caught internally but then raises a numpy linalg error.\n        # The try/catch is there to catch this error and skip plotting KDEs if all values are the same.\n\n        fig, ax = self._setup_figure()\n\n        # If histogram is requested but KDE is not, plot histogram\n        if self.hist and not self.kde:\n            outfile = self._outfile(\"hist\")\n            sns.histplot(data=self.melted_data, x=\"value\", bins=self.bins, stat=self.stat, hue=self.hue)\n        if self.kde and not self.hist:\n            outfile = self._outfile(\"kde\")\n            try:\n                sns.kdeplot(data=self.melted_data, x=\"value\", hue=self.hue)\n            except np.linalg.LinAlgError:\n                LOGGER.warning(\n                    \"[plotting] KDE plot error: Numpy linalg error encountered. This is a result of all values \\\nfor KDE plot being the same. KDE plots cannot be made as there is no variance, skipping.\"\n                )\n                return None\n        if self.hist and self.kde:\n            outfile = self._outfile(\"hist_kde\")\n            try:\n                sns.histplot(\n                    data=self.melted_data,\n                    x=\"value\",\n                    bins=self.bins,\n                    stat=self.stat,\n                    hue=self.hue,\n                    kde=True,\n                    kde_kws={\"cut\": self.cut},\n                )\n            except np.linalg.LinAlgError:\n                LOGGER.warning(\n                    \"[plotting] KDE plot error: Numpy linalg error encountered. This is a result of all values \\\nfor KDE plot being the same. KDE plots cannot be made as there is no variance, skipping.\"\n                )\n                return None\n\n        plt.ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(-3, 3))\n        plt.title(self.label)\n        self.set_xlim()\n        self.save_plot(outfile)  # pylint: disable=possibly-used-before-assignment\n\n        return fig, ax\n\n    def sns_violinplot(self) -&gt; None:\n        \"\"\"\n        Violin plot of data.\n\n        Returns\n        -------\n        fig, ax\n            Matplotlib fig and ax objects.\n        \"\"\"\n        fig, ax = self._setup_figure()\n        # Determine whether to draw a legend\n        legend = \"full\" if len(self.melted_data[self.hue].unique()) &gt; 1 else False\n        sns.violinplot(\n            data=self.melted_data,\n            x=self.hue,\n            y=\"value\",\n            hue=self.hue,\n            alpha=self.alpha,\n            legend=legend,\n        )\n        plt.title(self.label)\n        plt.xlabel(\"directory\")\n        plt.ylabel(self.label)\n        outfile = self._outfile(\"violin\")\n        self.save_plot(outfile)\n        return fig, ax\n\n    # def sns_jointplot(self, var1: str, var2: str) -&gt; None:\n    #     \"\"\"Joint distribution of two variables.\"\"\"\n    #     fig, ax = self._setup_figure()\n    #     sns.jointplot(data=self.df, x=var1, y=var2, kind=\"reg\")\n    #     outfile = f\"{'_'.join(self.stats_to_sum.keys())}_jointplot\"\n    #     # outfile = self._outfile(\"jointplot\")\n    #     self.save_plot(outfile)\n    #     return fig, ax\n\n    @staticmethod\n    def melt_data(df: pd.DataFrame, stat_to_summarize: str, var_to_label: dict) -&gt; pd.DataFrame:\n        \"\"\"\n        Melt a dataframe into long format for plotting with Seaborn.\n\n        Parameters\n        ----------\n        df : pd.DataFrame\n            Statistics to melt.\n        stat_to_summarize : str\n            Statistics to summarise.\n        var_to_label : dict\n            Mapping of variable names to descriptions.\n\n        Returns\n        -------\n        pd.DataFrame\n            Data in long-format with descriptive variable names.\n        \"\"\"\n        melted_data = pd.melt(df.reset_index(), id_vars=[\"grain_number\", \"basename\"], value_vars=stat_to_summarize)\n        melted_data[\"variable\"] = melted_data[\"variable\"].map(var_to_label)\n        LOGGER.debug(\"[plotting] Data has been melted to long format for plotting.\")\n\n        return melted_data\n\n    def set_xlim(self, percent: float = 0.1) -&gt; None:\n        \"\"\"\n        Set the range of the x-axis.\n\n        Parameters\n        ----------\n        percent : float\n            Percentage of the observed range by which to extend the x-axis. Only used if supplied range is outside the\n            observed values.\n        \"\"\"\n        range_percent = percent * (self.melted_data[\"value\"].max() - self.melted_data[\"value\"].min())\n        range_min = self.melted_data[\"value\"].min()\n        range_max = self.melted_data[\"value\"].max()\n        plt.xlim(range_min - range_percent, range_max + range_percent)\n        LOGGER.debug(f\"[plotting] Setting x-axis range       : {range_min} - {range_max}\")\n\n    def set_palette(self):\n        \"\"\"Set the color palette.\"\"\"\n        sns.set_palette(self.palette)\n        LOGGER.debug(f\"[plotting] Seaborn color palette : {self.palette}\")\n\n    def save_plot(self, outfile: Path) -&gt; None:\n        \"\"\"\n        Save the plot to the output_dir.\n\n        Parameters\n        ----------\n        outfile : str\n            Output file name to save figure to.\n        \"\"\"\n        plt.savefig(self.output_dir / f\"{outfile}.{self.savefig_format}\")\n        LOGGER.debug(\n            f\"[plotting] Plotted {self.stat_to_sum} to : \"\n            f\"{str(self.output_dir / f'{outfile}.{self.savefig_format}')}\"\n        )\n\n    def _set_label(self, var: str):\n        \"\"\"\n        Get the label based on the column name(s).\n\n        Parameters\n        ----------\n        var : str\n            The variable for which a label is required.\n        \"\"\"\n        self.label = self.var_to_label[var]\n        LOGGER.debug(f\"[plotting] self.label     : {self.label}\")\n</code></pre>"},{"location":"api/plotting/#topostats.plotting.TopoSum.__init__","title":"<code>__init__(df=None, base_dir=None, csv_file=None, stat_to_sum=None, molecule_id='grain_number', image_id='image', hist=True, stat='count', bins=12, kde=True, cut=20, figsize=(16, 9), alpha=0.5, palette='deep', savefig_format='png', output_dir='.', var_to_label=None, hue='basename')</code>","text":"<p>Initialise the class.</p>"},{"location":"api/plotting/#topostats.plotting.TopoSum.__init__--parameters","title":"Parameters","text":"<p>df :  pd.DataFrame     Pandas data frame of data to be summarised. base_dir :  str | Path     Base directory from which all paths are relative to. csv_file :  str | Path     CSV file of data to be summarised. stat_to_sum :  str     Variable to summarise. molecule_id :  str     Variable that uniquely identifies molecules. image_id :  str     Variable that uniquely identifies images. hist :  bool     Whether to plot histograms. stat :  str     Statistic to plot on histogram 'count' (default), 'freq'. bins :  int     Number of bins to plot. kde :  bool     Whether to include a Kernel Density Estimate. cut :  float = 20,     Cut point for KDE. figsize :  tuple     Figure dimensions. alpha :  float     Opacity to use in plots. palette :  str = \"deep\"     Seaborn colour plot to use. savefig_format :  str     File type to save plots as 'png' (default), 'pdf', 'svg'. output_dir :  str | Path     Location to save plots to. var_to_label :  dict     Variable to label dictionary for automatically adding titles to plots. hue :  str     Dataframe column to group plots by.</p> Source code in <code>topostats/plotting.py</code> <pre><code>def __init__(\n    self,\n    df: pd.DataFrame = None,\n    base_dir: str | Path = None,\n    csv_file: str | Path = None,\n    stat_to_sum: str = None,\n    molecule_id: str = \"grain_number\",\n    image_id: str = \"image\",\n    hist: bool = True,\n    stat: str = \"count\",\n    bins: int = 12,\n    kde: bool = True,\n    cut: float = 20,\n    figsize: tuple = (16, 9),\n    alpha: float = 0.5,\n    palette: str = \"deep\",\n    savefig_format: str = \"png\",\n    output_dir: str | Path = \".\",\n    var_to_label: dict = None,\n    hue: str = \"basename\",\n) -&gt; None:\n    \"\"\"\n    Initialise the class.\n\n    Parameters\n    ----------\n    df :  pd.DataFrame\n        Pandas data frame of data to be summarised.\n    base_dir :  str | Path\n        Base directory from which all paths are relative to.\n    csv_file :  str | Path\n        CSV file of data to be summarised.\n    stat_to_sum :  str\n        Variable to summarise.\n    molecule_id :  str\n        Variable that uniquely identifies molecules.\n    image_id :  str\n        Variable that uniquely identifies images.\n    hist :  bool\n        Whether to plot histograms.\n    stat :  str\n        Statistic to plot on histogram 'count' (default), 'freq'.\n    bins :  int\n        Number of bins to plot.\n    kde :  bool\n        Whether to include a Kernel Density Estimate.\n    cut :  float = 20,\n        Cut point for KDE.\n    figsize :  tuple\n        Figure dimensions.\n    alpha :  float\n        Opacity to use in plots.\n    palette :  str = \"deep\"\n        Seaborn colour plot to use.\n    savefig_format :  str\n        File type to save plots as 'png' (default), 'pdf', 'svg'.\n    output_dir :  str | Path\n        Location to save plots to.\n    var_to_label :  dict\n        Variable to label dictionary for automatically adding titles to plots.\n    hue :  str\n        Dataframe column to group plots by.\n    \"\"\"\n    self.df = df if df is not None else pd.read_csv(csv_file)\n    self.base_dir = base_dir\n    self.stat_to_sum = stat_to_sum\n    self.molecule_id = molecule_id\n    self.image_id = image_id\n    self.hist = hist\n    self.bins = bins\n    self.stat = stat\n    self.kde = kde\n    self.cut = cut\n    self.figsize = figsize\n    self.alpha = alpha\n    self.palette = palette\n    self.savefig_format = savefig_format\n    self.output_dir = Path(output_dir)\n    self.output_dir.mkdir(parents=True, exist_ok=True)\n    self.var_to_label = var_to_label\n    self.hue = hue\n    self.melted_data = None\n    self.summary_data = None\n    self.label = None\n\n    # melt the data given in the init method\n    self.melted_data = self.melt_data(self.df, stat_to_summarize=self.stat_to_sum, var_to_label=self.var_to_label)\n    convert_basename_to_relative_paths(df=self.melted_data)\n    self.set_palette()\n    self._set_label(self.stat_to_sum)\n</code></pre>"},{"location":"api/plotting/#topostats.plotting.TopoSum._outfile","title":"<code>_outfile(plot_suffix)</code>","text":"<p>Generate the output file name with the appropriate suffix.</p>"},{"location":"api/plotting/#topostats.plotting.TopoSum._outfile--parameters","title":"Parameters","text":"<p>plot_suffix : str     The suffix to append to the output file.</p>"},{"location":"api/plotting/#topostats.plotting.TopoSum._outfile--returns","title":"Returns","text":"<p>str:     Concanenated string of the outfile and plot_suffix.</p> Source code in <code>topostats/plotting.py</code> <pre><code>def _outfile(self, plot_suffix: str) -&gt; str:\n    \"\"\"\n    Generate the output file name with the appropriate suffix.\n\n    Parameters\n    ----------\n    plot_suffix : str\n        The suffix to append to the output file.\n\n    Returns\n    -------\n    str:\n        Concanenated string of the outfile and plot_suffix.\n    \"\"\"\n    return f\"{self.stat_to_sum}_{plot_suffix}\"\n</code></pre>"},{"location":"api/plotting/#topostats.plotting.TopoSum._set_label","title":"<code>_set_label(var)</code>","text":"<p>Get the label based on the column name(s).</p>"},{"location":"api/plotting/#topostats.plotting.TopoSum._set_label--parameters","title":"Parameters","text":"<p>var : str     The variable for which a label is required.</p> Source code in <code>topostats/plotting.py</code> <pre><code>def _set_label(self, var: str):\n    \"\"\"\n    Get the label based on the column name(s).\n\n    Parameters\n    ----------\n    var : str\n        The variable for which a label is required.\n    \"\"\"\n    self.label = self.var_to_label[var]\n    LOGGER.debug(f\"[plotting] self.label     : {self.label}\")\n</code></pre>"},{"location":"api/plotting/#topostats.plotting.TopoSum._setup_figure","title":"<code>_setup_figure()</code>","text":"<p>Setup Matplotlib figure and axes.</p>"},{"location":"api/plotting/#topostats.plotting.TopoSum._setup_figure--returns","title":"Returns","text":"<p>fig, ax     Matplotlib fig and ax objects.</p> Source code in <code>topostats/plotting.py</code> <pre><code>def _setup_figure(self):\n    \"\"\"\n    Setup Matplotlib figure and axes.\n\n    Returns\n    -------\n    fig, ax\n        Matplotlib fig and ax objects.\n    \"\"\"\n    fig, ax = plt.subplots(1, 1, figsize=self.figsize)\n    return fig, ax\n</code></pre>"},{"location":"api/plotting/#topostats.plotting.TopoSum.melt_data","title":"<code>melt_data(df, stat_to_summarize, var_to_label)</code>  <code>staticmethod</code>","text":"<p>Melt a dataframe into long format for plotting with Seaborn.</p>"},{"location":"api/plotting/#topostats.plotting.TopoSum.melt_data--parameters","title":"Parameters","text":"<p>df : pd.DataFrame     Statistics to melt. stat_to_summarize : str     Statistics to summarise. var_to_label : dict     Mapping of variable names to descriptions.</p>"},{"location":"api/plotting/#topostats.plotting.TopoSum.melt_data--returns","title":"Returns","text":"<p>pd.DataFrame     Data in long-format with descriptive variable names.</p> Source code in <code>topostats/plotting.py</code> <pre><code>@staticmethod\ndef melt_data(df: pd.DataFrame, stat_to_summarize: str, var_to_label: dict) -&gt; pd.DataFrame:\n    \"\"\"\n    Melt a dataframe into long format for plotting with Seaborn.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        Statistics to melt.\n    stat_to_summarize : str\n        Statistics to summarise.\n    var_to_label : dict\n        Mapping of variable names to descriptions.\n\n    Returns\n    -------\n    pd.DataFrame\n        Data in long-format with descriptive variable names.\n    \"\"\"\n    melted_data = pd.melt(df.reset_index(), id_vars=[\"grain_number\", \"basename\"], value_vars=stat_to_summarize)\n    melted_data[\"variable\"] = melted_data[\"variable\"].map(var_to_label)\n    LOGGER.debug(\"[plotting] Data has been melted to long format for plotting.\")\n\n    return melted_data\n</code></pre>"},{"location":"api/plotting/#topostats.plotting.TopoSum.save_plot","title":"<code>save_plot(outfile)</code>","text":"<p>Save the plot to the output_dir.</p>"},{"location":"api/plotting/#topostats.plotting.TopoSum.save_plot--parameters","title":"Parameters","text":"<p>outfile : str     Output file name to save figure to.</p> Source code in <code>topostats/plotting.py</code> <pre><code>def save_plot(self, outfile: Path) -&gt; None:\n    \"\"\"\n    Save the plot to the output_dir.\n\n    Parameters\n    ----------\n    outfile : str\n        Output file name to save figure to.\n    \"\"\"\n    plt.savefig(self.output_dir / f\"{outfile}.{self.savefig_format}\")\n    LOGGER.debug(\n        f\"[plotting] Plotted {self.stat_to_sum} to : \"\n        f\"{str(self.output_dir / f'{outfile}.{self.savefig_format}')}\"\n    )\n</code></pre>"},{"location":"api/plotting/#topostats.plotting.TopoSum.set_palette","title":"<code>set_palette()</code>","text":"<p>Set the color palette.</p> Source code in <code>topostats/plotting.py</code> <pre><code>def set_palette(self):\n    \"\"\"Set the color palette.\"\"\"\n    sns.set_palette(self.palette)\n    LOGGER.debug(f\"[plotting] Seaborn color palette : {self.palette}\")\n</code></pre>"},{"location":"api/plotting/#topostats.plotting.TopoSum.set_xlim","title":"<code>set_xlim(percent=0.1)</code>","text":"<p>Set the range of the x-axis.</p>"},{"location":"api/plotting/#topostats.plotting.TopoSum.set_xlim--parameters","title":"Parameters","text":"<p>percent : float     Percentage of the observed range by which to extend the x-axis. Only used if supplied range is outside the     observed values.</p> Source code in <code>topostats/plotting.py</code> <pre><code>def set_xlim(self, percent: float = 0.1) -&gt; None:\n    \"\"\"\n    Set the range of the x-axis.\n\n    Parameters\n    ----------\n    percent : float\n        Percentage of the observed range by which to extend the x-axis. Only used if supplied range is outside the\n        observed values.\n    \"\"\"\n    range_percent = percent * (self.melted_data[\"value\"].max() - self.melted_data[\"value\"].min())\n    range_min = self.melted_data[\"value\"].min()\n    range_max = self.melted_data[\"value\"].max()\n    plt.xlim(range_min - range_percent, range_max + range_percent)\n    LOGGER.debug(f\"[plotting] Setting x-axis range       : {range_min} - {range_max}\")\n</code></pre>"},{"location":"api/plotting/#topostats.plotting.TopoSum.sns_plot","title":"<code>sns_plot()</code>","text":"<p>Plot the distribution of one or more statistics as either histogram, kernel density estimates or both.</p> <p>Uses base Seaborn.</p>"},{"location":"api/plotting/#topostats.plotting.TopoSum.sns_plot--returns","title":"Returns","text":"<p>Optional[Union[Tuple[plt.Figure, plt.Axes], None]]     Tuple of Matplotlib figure and axes if plotting is successful, None otherwise.</p> Source code in <code>topostats/plotting.py</code> <pre><code>    def sns_plot(self) -&gt; tuple[plt.Figure, plt.Axes] | None:\n        \"\"\"\n        Plot the distribution of one or more statistics as either histogram, kernel density estimates or both.\n\n        Uses base Seaborn.\n\n        Returns\n        -------\n        Optional[Union[Tuple[plt.Figure, plt.Axes], None]]\n            Tuple of Matplotlib figure and axes if plotting is successful, None otherwise.\n        \"\"\"\n\n        # Note: Plotting KDEs with Seaborn is not possible if all values are the same.\n        # This is because the KDE is calculated using a Gaussian kernel and if all values\n        # are the same, the standard deviation is 0 which results in a ZeroDivisionError with\n        # is caught internally but then raises a numpy linalg error.\n        # The try/catch is there to catch this error and skip plotting KDEs if all values are the same.\n\n        fig, ax = self._setup_figure()\n\n        # If histogram is requested but KDE is not, plot histogram\n        if self.hist and not self.kde:\n            outfile = self._outfile(\"hist\")\n            sns.histplot(data=self.melted_data, x=\"value\", bins=self.bins, stat=self.stat, hue=self.hue)\n        if self.kde and not self.hist:\n            outfile = self._outfile(\"kde\")\n            try:\n                sns.kdeplot(data=self.melted_data, x=\"value\", hue=self.hue)\n            except np.linalg.LinAlgError:\n                LOGGER.warning(\n                    \"[plotting] KDE plot error: Numpy linalg error encountered. This is a result of all values \\\nfor KDE plot being the same. KDE plots cannot be made as there is no variance, skipping.\"\n                )\n                return None\n        if self.hist and self.kde:\n            outfile = self._outfile(\"hist_kde\")\n            try:\n                sns.histplot(\n                    data=self.melted_data,\n                    x=\"value\",\n                    bins=self.bins,\n                    stat=self.stat,\n                    hue=self.hue,\n                    kde=True,\n                    kde_kws={\"cut\": self.cut},\n                )\n            except np.linalg.LinAlgError:\n                LOGGER.warning(\n                    \"[plotting] KDE plot error: Numpy linalg error encountered. This is a result of all values \\\nfor KDE plot being the same. KDE plots cannot be made as there is no variance, skipping.\"\n                )\n                return None\n\n        plt.ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(-3, 3))\n        plt.title(self.label)\n        self.set_xlim()\n        self.save_plot(outfile)  # pylint: disable=possibly-used-before-assignment\n\n        return fig, ax\n</code></pre>"},{"location":"api/plotting/#topostats.plotting.TopoSum.sns_violinplot","title":"<code>sns_violinplot()</code>","text":"<p>Violin plot of data.</p>"},{"location":"api/plotting/#topostats.plotting.TopoSum.sns_violinplot--returns","title":"Returns","text":"<p>fig, ax     Matplotlib fig and ax objects.</p> Source code in <code>topostats/plotting.py</code> <pre><code>def sns_violinplot(self) -&gt; None:\n    \"\"\"\n    Violin plot of data.\n\n    Returns\n    -------\n    fig, ax\n        Matplotlib fig and ax objects.\n    \"\"\"\n    fig, ax = self._setup_figure()\n    # Determine whether to draw a legend\n    legend = \"full\" if len(self.melted_data[self.hue].unique()) &gt; 1 else False\n    sns.violinplot(\n        data=self.melted_data,\n        x=self.hue,\n        y=\"value\",\n        hue=self.hue,\n        alpha=self.alpha,\n        legend=legend,\n    )\n    plt.title(self.label)\n    plt.xlabel(\"directory\")\n    plt.ylabel(self.label)\n    outfile = self._outfile(\"violin\")\n    self.save_plot(outfile)\n    return fig, ax\n</code></pre>"},{"location":"api/plotting/#topostats.plotting._pad_array","title":"<code>_pad_array(profile, max_array_length)</code>","text":"<p>Pad array so that it matches the largest profile and plots are somewhat aligned.</p> <p>Centering is done based on the mid-point of longest grain and heights of zero ('0.0') are used in padding.</p>"},{"location":"api/plotting/#topostats.plotting._pad_array--parameters","title":"Parameters","text":"<p>profile : npt.NDArray     1-D Height profile. max_array_length : int     The longest height profile across a range of detected grains.</p>"},{"location":"api/plotting/#topostats.plotting._pad_array--returns","title":"Returns","text":"<p>npt.NDArray     Array padded to the same length as max_array_length.</p> Source code in <code>topostats/plotting.py</code> <pre><code>def _pad_array(profile: npt.NDArray, max_array_length: int) -&gt; npt.NDArray:\n    \"\"\"\n    Pad array so that it matches the largest profile and plots are somewhat aligned.\n\n    Centering is done based on the mid-point of longest grain and heights of zero ('0.0') are used in padding.\n\n    Parameters\n    ----------\n    profile : npt.NDArray\n        1-D Height profile.\n    max_array_length : int\n        The longest height profile across a range of detected grains.\n\n    Returns\n    -------\n    npt.NDArray\n        Array padded to the same length as max_array_length.\n    \"\"\"\n    profile_length = profile.shape[0]\n    array_diff = max_array_length - profile_length\n    pad = array_diff // 2\n    if array_diff % 2 == 0:\n        left, right = pad, pad\n    else:\n        left, right = pad, (pad + 1)\n    return np.pad(profile, (left, right))\n</code></pre>"},{"location":"api/plotting/#topostats.plotting.plot_crossing_linetrace_halfmax","title":"<code>plot_crossing_linetrace_halfmax(branch_stats_dict, mask_cmap, title)</code>","text":"<p>Plot the height-map line traces of the branches found in the 'branch_stats' dictionary, and their meetings.</p>"},{"location":"api/plotting/#topostats.plotting.plot_crossing_linetrace_halfmax--parameters","title":"Parameters","text":"<p>branch_stats_dict : dict     Dictionary containing branch height, distance and fwhm info. mask_cmap : matplotlib.colors.Colormap     Colormap for plotting. title : str     Title for the plot.</p>"},{"location":"api/plotting/#topostats.plotting.plot_crossing_linetrace_halfmax--returns","title":"Returns","text":"<p>fig, ax     Matplotlib fig and ax objects.</p> Source code in <code>topostats/plotting.py</code> <pre><code>def plot_crossing_linetrace_halfmax(\n    branch_stats_dict: dict, mask_cmap: matplotlib.colors.Colormap, title: str\n) -&gt; tuple:\n    \"\"\"\n    Plot the height-map line traces of the branches found in the 'branch_stats' dictionary, and their meetings.\n\n    Parameters\n    ----------\n    branch_stats_dict : dict\n        Dictionary containing branch height, distance and fwhm info.\n    mask_cmap : matplotlib.colors.Colormap\n        Colormap for plotting.\n    title : str\n        Title for the plot.\n\n    Returns\n    -------\n    fig, ax\n        Matplotlib fig and ax objects.\n    \"\"\"\n    fig, ax = plt.subplots(1, 1, figsize=(7, 4))\n    cmp = Colormap(mask_cmap).get_cmap()\n    total_branches = len(branch_stats_dict)\n    # plot the highest first\n    fwhms = []\n    for branch_idx, values in branch_stats_dict.items():\n        fwhms.append(values[\"fwhm\"][\"fwhm\"])\n    branch_idx_order = np.array(list(branch_stats_dict.keys()))[np.argsort(np.array(fwhms))]\n\n    for i, branch_idx in enumerate(branch_idx_order):\n        fwhm_dict = branch_stats_dict[branch_idx][\"fwhm\"]\n        if total_branches == 1:\n            cmap_ratio = 0\n        else:\n            cmap_ratio = i / (total_branches - 1)\n        heights = branch_stats_dict[branch_idx][\"heights\"]\n        x = branch_stats_dict[branch_idx][\"distances\"]\n        ax.plot(x, heights, c=cmp(cmap_ratio))  # label=f\"Branch: {branch_idx}\"\n\n        # plot the high point lines\n        plt.plot(\n            [-15, fwhm_dict[\"peaks\"][1]],\n            [fwhm_dict[\"peaks\"][2], fwhm_dict[\"peaks\"][2]],\n            c=cmp(cmap_ratio),\n            label=f\"FWHM: {fwhm_dict['fwhm']:.4f}\",\n        )\n        # plot the half max lines\n        plt.plot(\n            [fwhm_dict[\"half_maxs\"][0], fwhm_dict[\"half_maxs\"][0]],\n            [fwhm_dict[\"half_maxs\"][2], heights.min()],\n            c=cmp(cmap_ratio),\n        )\n        plt.plot(\n            [fwhm_dict[\"half_maxs\"][1], fwhm_dict[\"half_maxs\"][1]],\n            [fwhm_dict[\"half_maxs\"][2], heights.min()],\n            c=cmp(cmap_ratio),\n        )\n\n    ax.set_xlabel(\"Distance from Node (nm)\")\n    ax.set_ylabel(\"Height\")\n    ax.set_title(title)\n    ax.legend()\n    return fig, ax\n</code></pre>"},{"location":"api/plotting/#topostats.plotting.plot_height_profiles","title":"<code>plot_height_profiles(height_profiles)</code>","text":"<p>Plot height profiles.</p>"},{"location":"api/plotting/#topostats.plotting.plot_height_profiles--parameters","title":"Parameters","text":"<p>height_profiles : npt.NDArray     Single height profile (1-D numpy array of heights) or array of height profiles. If the later the profiles plot     will be overlaid.</p>"},{"location":"api/plotting/#topostats.plotting.plot_height_profiles--returns","title":"Returns","text":"<p>tuple     Matplotlib.pyplot figure object and Matplotlib.pyplot axes object.</p> Source code in <code>topostats/plotting.py</code> <pre><code>def plot_height_profiles(height_profiles: list | npt.NDArray) -&gt; tuple:\n    \"\"\"\n    Plot height profiles.\n\n    Parameters\n    ----------\n    height_profiles : npt.NDArray\n        Single height profile (1-D numpy array of heights) or array of height profiles. If the later the profiles plot\n        will be overlaid.\n\n    Returns\n    -------\n    tuple\n        Matplotlib.pyplot figure object and Matplotlib.pyplot axes object.\n    \"\"\"\n    # If we have only one profile put it in a list so we can process\n    if not isinstance(height_profiles, list):\n        height_profiles = [height_profiles]\n    # We have 1-D arrays of different sizes, we need to know the maximum length and then pad shorter ones so that the\n    # profiles will roughly align in the middle\n    max_array_length = max(map(len, height_profiles))\n\n    # Pad shorter height profiles to the length of the longest\n    padded_height_profiles = [_pad_array(profile, max_array_length) for profile in height_profiles]\n    fig, ax = plt.subplots(1, 1)\n    max_y = 0\n    for height_profile in padded_height_profiles:\n        ax.plot(np.arange(max_array_length), height_profile)\n        max_y = max_y if max(height_profile) &lt; max_y else max(height_profile) + 1\n    ax.margins(0.01, 0.1)\n    return fig, ax\n</code></pre>"},{"location":"api/plotting/#topostats.plotting.run_toposum","title":"<code>run_toposum(args=None)</code>","text":"<p>Run Plotting.</p>"},{"location":"api/plotting/#topostats.plotting.run_toposum--parameters","title":"Parameters","text":"<p>args : None     Arguments to pass and update configuration.</p> Source code in <code>topostats/plotting.py</code> <pre><code>def run_toposum(args=None) -&gt; None:\n    \"\"\"\n    Run Plotting.\n\n    Parameters\n    ----------\n    args : None\n        Arguments to pass and update configuration.\n    \"\"\"\n    if args.config_file is not None:\n        config = read_yaml(args.config_file)\n        LOGGER.info(f\"[plotting] Configuration file loaded from : {args.config_file}\")\n    else:\n        summary_yaml = (resources.files(__package__) / \"summary_config.yaml\").read_text()\n        config = yaml.safe_load(summary_yaml)\n        LOGGER.info(\"[plotting] Default configuration file loaded.\")\n    config = update_config(config, args)\n    if args.var_to_label is not None:\n        config[\"var_to_label\"] = read_yaml(args.var_to_label)\n        LOGGER.debug(\"[plotting] Variable to labels mapping loaded from : {args.var_to_label}\")\n    else:\n        plotting_yaml = (resources.files(__package__) / \"var_to_label.yaml\").read_text()\n        config[\"var_to_label\"] = yaml.safe_load(plotting_yaml)\n        LOGGER.debug(\"[plotting] Default variable to labels mapping loaded.\")\n    if args.input_csv is not None:\n        config[\"input_csv\"] = args.input_csv\n\n    # Write sample configuration if asked to do so and exit\n    if args.create_config_file:\n        write_yaml(\n            config,\n            output_dir=\"./\",\n            config_file=args.create_config_file,\n            header_message=\"Sample configuration file auto-generated\",\n        )\n        LOGGER.info(f\"A sample configuration has been written to : ./{args.create_config_file}\")\n        LOGGER.info(\n            \"Please refer to the documentation on how to use the configuration file : \\n\\n\"\n            \"https://afm-spm.github.io/TopoStats/usage.html#configuring-topostats\\n\"\n            \"https://afm-spm.github.io/TopoStats/configuration.html\"\n        )\n        sys.exit()\n    if args.create_label_file:\n        write_yaml(\n            config[\"var_to_label\"],\n            output_dir=\"./\",\n            config_file=args.create_label_file,\n            header_message=\"Sample label file auto-generated\",\n        )\n        LOGGER.info(f\"A sample label file has been written to : ./{args.create_label_file}\")\n        LOGGER.info(\n            \"Please refer to the documentation on how to use the configuration file : \\n\\n\"\n            \"https://afm-spm.github.io/TopoStats/usage.html#configuring-topostats\\n\"\n            \"https://afm-spm.github.io/TopoStats/configuration.html\"\n        )\n        sys.exit()\n\n    # Plot statistics\n    toposum(config)\n</code></pre>"},{"location":"api/plotting/#topostats.plotting.toposum","title":"<code>toposum(config)</code>","text":"<p>Process plotting and summarisation of data.</p>"},{"location":"api/plotting/#topostats.plotting.toposum--parameters","title":"Parameters","text":"<p>config : dict     Dictionary of summarisation options.</p>"},{"location":"api/plotting/#topostats.plotting.toposum--returns","title":"Returns","text":"<p>dict     Dictionary of nested dictionaries. Each variable has its own dictionary with keys 'dist' and 'violin' which     contain distribution like plots and violin plots respectively (if the later are required). Each 'dist' and     'violin' is itself a dictionary with two elements 'figures' and 'axes' which correspond to MatplotLib 'fig' and     'ax' for that plot.</p> Source code in <code>topostats/plotting.py</code> <pre><code>def toposum(config: dict) -&gt; dict:\n    \"\"\"\n    Process plotting and summarisation of data.\n\n    Parameters\n    ----------\n    config : dict\n        Dictionary of summarisation options.\n\n    Returns\n    -------\n    dict\n        Dictionary of nested dictionaries. Each variable has its own dictionary with keys 'dist' and 'violin' which\n        contain distribution like plots and violin plots respectively (if the later are required). Each 'dist' and\n        'violin' is itself a dictionary with two elements 'figures' and 'axes' which correspond to MatplotLib 'fig' and\n        'ax' for that plot.\n    \"\"\"\n    if \"df\" not in config.keys():\n        config[\"df\"] = pd.read_csv(config[\"csv_file\"])\n    if config[\"df\"].isna().values.all():\n        LOGGER.warning(\"[plotting] No statistics in DataFrame. Exiting...\")\n        return None\n    violin = config.pop(\"violin\")\n    all_stats_to_sum = config.pop(\"stats_to_sum\")\n    figures = defaultdict()\n\n    # Plot each variable on its own graph\n    for var in all_stats_to_sum:\n        if var in config[\"df\"].columns:\n            topo_sum = TopoSum(stat_to_sum=var, **config)\n            figures[var] = {\"dist\": None, \"violin\": None}\n            figures[var][\"dist\"] = defaultdict()\n            result_option: tuple | None = topo_sum.sns_plot()\n            # Handle the Optional[Tuple]\n            if result_option is not None:\n                figures[var][\"dist\"][\"figure\"], figures[var][\"dist\"][\"axes\"] = result_option\n\n            if violin:\n                figures[var][\"violin\"] = defaultdict()\n                (\n                    figures[var][\"violin\"][\"figure\"],\n                    figures[var][\"violin\"][\"axes\"],\n                ) = topo_sum.sns_violinplot()\n        else:\n            LOGGER.error(f\"[plotting] Statistic is not in dataframe : {var}\")\n\n    return figures\n</code></pre>"},{"location":"api/plottingfuncs/","title":"Plottingfuncs Modules","text":"<p>Plotting data.</p> <p>handler: python options: docstring_style: numpy rendering: show_signature_annotations: true</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.Images","title":"<code>Images</code>","text":"<p>Plots image arrays.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.Images--parameters","title":"Parameters","text":"<p>data : npt.NDarray     Numpy array to plot. output_dir : str | Path     Output directory to save the file to. filename : str     Filename to save image as. style : str | Path     Filename of matplotlibrc parameters. pixel_to_nm_scaling : float     The scaling factor showing the real length of 1 pixel in nanometers (nm). masked_array : npt.NDarray     Optional mask array to overlay onto an image. plot_coords : npt.NDArray     ??? Needs defining. title : str     Title for plot. image_type : str     The image data type, options are 'binary' or 'non-binary'. image_set : str     The set of images to process, options are 'core' or 'all'. core_set : bool     Flag to identify image as part of the core image set or not. pixel_interpolation : str, optional     Interpolation to use (default is 'None'). cmap : str, optional     Colour map to use (default 'nanoscope', 'afmhot' also available). mask_cmap : str     Colour map to use for the secondary (masked) data (default 'jet_r', 'blu' provides more contrast). region_properties : dict     Dictionary of region properties, adds bounding boxes if specified. zrange : list     Lower and upper bound to clip core images to. colorbar : bool     Optionally add a colorbar to plots, default is False. axes : bool     Optionally add/remove axes from the image. num_ticks : tuple[int | None]     The number of x and y ticks to display on the iage. save : bool     Whether to save the image. savefig_format : str, optional     Format to save the image as. histogram_log_axis : bool     Optionally use a loagrithmic y-axis for the histogram plots. histogram_bins : int, optional     Number of bins for histograms to use. savefig_dpi : str | float, optional     The resolution of the saved plot (default 'figure').</p> Source code in <code>topostats/plottingfuncs.py</code> <pre><code>class Images:\n    \"\"\"\n    Plots image arrays.\n\n    Parameters\n    ----------\n    data : npt.NDarray\n        Numpy array to plot.\n    output_dir : str | Path\n        Output directory to save the file to.\n    filename : str\n        Filename to save image as.\n    style : str | Path\n        Filename of matplotlibrc parameters.\n    pixel_to_nm_scaling : float\n        The scaling factor showing the real length of 1 pixel in nanometers (nm).\n    masked_array : npt.NDarray\n        Optional mask array to overlay onto an image.\n    plot_coords : npt.NDArray\n        ??? Needs defining.\n    title : str\n        Title for plot.\n    image_type : str\n        The image data type, options are 'binary' or 'non-binary'.\n    image_set : str\n        The set of images to process, options are 'core' or 'all'.\n    core_set : bool\n        Flag to identify image as part of the core image set or not.\n    pixel_interpolation : str, optional\n        Interpolation to use (default is 'None').\n    cmap : str, optional\n        Colour map to use (default 'nanoscope', 'afmhot' also available).\n    mask_cmap : str\n        Colour map to use for the secondary (masked) data (default 'jet_r', 'blu' provides more contrast).\n    region_properties : dict\n        Dictionary of region properties, adds bounding boxes if specified.\n    zrange : list\n        Lower and upper bound to clip core images to.\n    colorbar : bool\n        Optionally add a colorbar to plots, default is False.\n    axes : bool\n        Optionally add/remove axes from the image.\n    num_ticks : tuple[int | None]\n        The number of x and y ticks to display on the iage.\n    save : bool\n        Whether to save the image.\n    savefig_format : str, optional\n        Format to save the image as.\n    histogram_log_axis : bool\n        Optionally use a loagrithmic y-axis for the histogram plots.\n    histogram_bins : int, optional\n        Number of bins for histograms to use.\n    savefig_dpi : str | float, optional\n        The resolution of the saved plot (default 'figure').\n    \"\"\"\n\n    def __init__(\n        self,\n        data: npt.NDarray,\n        output_dir: str | Path,\n        filename: str,\n        style: str | Path = None,\n        pixel_to_nm_scaling: float = 1.0,\n        masked_array: npt.NDarray = None,\n        plot_coords: npt.NDArray = None,\n        title: str = None,\n        image_type: str = \"non-binary\",\n        image_set: str = \"core\",\n        core_set: bool = False,\n        pixel_interpolation: str | None = None,\n        cmap: str | None = None,\n        mask_cmap: str = \"jet_r\",\n        region_properties: dict = None,\n        zrange: list = None,\n        colorbar: bool = True,\n        axes: bool = True,\n        num_ticks: tuple[int | None] = (None, None),\n        save: bool = True,\n        savefig_format: str | None = None,\n        histogram_log_axis: bool = True,\n        histogram_bins: int | None = None,\n        savefig_dpi: str | float | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialise the class.\n\n        There are two key parameters that ensure whether an image is plotted that are passed in from the updated\n        plotting dictionary. These are the `image_set` which defines whether to plot 'all' images or just the `core`\n        set. There is then the 'core_set' which defines whether an individual images belongs to the 'core_set' or\n        not. If it doesn't then it is not plotted when `image_set == \"core\"`.\n\n        Parameters\n        ----------\n        data : npt.NDarray\n            Numpy array to plot.\n        output_dir : str | Path\n            Output directory to save the file to.\n        filename : str\n            Filename to save image as.\n        style : str | Path\n            Filename of matplotlibrc parameters.\n        pixel_to_nm_scaling : float\n            The scaling factor showing the real length of 1 pixel in nanometers (nm).\n        masked_array : npt.NDarray\n            Optional mask array to overlay onto an image.\n        plot_coords : npt.NDArray\n            ??? Needs defining.\n        title : str\n            Title for plot.\n        image_type : str\n            The image data type, options are 'binary' or 'non-binary'.\n        image_set : str\n            The set of images to process, options are 'core' or 'all'.\n        core_set : bool\n            Flag to identify image as part of the core image set or not.\n        pixel_interpolation : str, optional\n            Interpolation to use (default is 'None').\n        cmap : str, optional\n            Colour map to use (default 'nanoscope', 'afmhot' also available).\n        mask_cmap : str\n            Colour map to use for the secondary (masked) data (default 'jet_r', 'blu' provides more contrast).\n        region_properties : dict\n            Dictionary of region properties, adds bounding boxes if specified.\n        zrange : list\n            Lower and upper bound to clip core images to.\n        colorbar : bool\n            Optionally add a colorbar to plots, default is False.\n        axes : bool\n            Optionally add/remove axes from the image.\n        num_ticks : tuple[int | None]\n            The number of x and y ticks to display on the iage.\n        save : bool\n            Whether to save the image.\n        savefig_format : str, optional\n            Format to save the image as.\n        histogram_log_axis : bool\n            Optionally use a loagrithmic y-axis for the histogram plots.\n        histogram_bins : int, optional\n            Number of bins for histograms to use.\n        savefig_dpi : str | float, optional\n            The resolution of the saved plot (default 'figure').\n        \"\"\"\n        if style is None:\n            style = \"topostats.mplstyle\"\n        load_mplstyle(style)\n        if zrange is None:\n            zrange = [None, None]\n        self.data = data\n        self.output_dir = Path(output_dir)\n        self.filename = filename\n        self.pixel_to_nm_scaling = pixel_to_nm_scaling\n        self.masked_array = masked_array\n        self.plot_coords = plot_coords\n        self.title = title\n        self.image_type = image_type\n        self.image_set = image_set\n        self.core_set = core_set\n        self.interpolation = mpl.rcParams[\"image.interpolation\"] if pixel_interpolation is None else pixel_interpolation\n        cmap = mpl.rcParams[\"image.cmap\"] if cmap is None else cmap\n        self.cmap = Colormap(cmap).get_cmap()\n        self.mask_cmap = Colormap(mask_cmap).get_cmap()\n        self.region_properties = region_properties\n        self.zrange = zrange\n        self.colorbar = colorbar\n        self.axes = axes\n        self.num_ticks = num_ticks\n        self.save = save\n        self.savefig_format = mpl.rcParams[\"savefig.format\"] if savefig_format is None else savefig_format\n        self.histogram_log_axis = histogram_log_axis\n        self.histogram_bins = mpl.rcParams[\"hist.bins\"] if histogram_bins is None else histogram_bins\n        self.savefig_dpi = mpl.rcParams[\"savefig.dpi\"] if savefig_dpi is None else savefig_dpi\n\n    def plot_histogram_and_save(self) -&gt; tuple | None:\n        \"\"\"\n        Plot and save a histogram of the height map.\n\n        Returns\n        -------\n        tuple | None\n            Matplotlib.pyplot figure object and Matplotlib.pyplot axes object.\n        \"\"\"\n        if self.image_set == \"all\":\n            fig, ax = plt.subplots(1, 1)\n\n            ax.hist(self.data.flatten().astype(float), bins=self.histogram_bins, log=self.histogram_log_axis)\n            ax.set_xlabel(\"pixel height\")\n            if self.histogram_log_axis:\n                ax.set_ylabel(\"frequency in image (log)\")\n            else:\n                ax.set_ylabel(\"frequency in image\")\n            plt.title(self.title)\n            plt.savefig(\n                (self.output_dir / f\"{self.filename}_histogram.{self.savefig_format}\"),\n                bbox_inches=\"tight\",\n                pad_inches=0.5,\n                dpi=self.savefig_dpi,\n            )\n            plt.close()\n\n            return fig, ax\n        return None\n\n    def plot_curvatures(\n        self,\n        image: npt.NDArray,\n        cropped_images: dict,\n        grains_curvature_stats_dict: dict,\n        all_grain_smoothed_data: dict,\n        colourmap_normalisation_bounds: tuple[float, float],\n    ) -&gt; tuple[plt.Figure | None, plt.Axes | None]:\n        \"\"\"\n        Plot curvature intensity and defects of grains in an image.\n\n        Parameters\n        ----------\n        image : npt.NDArray\n            Image to plot.\n        cropped_images : dict\n            Dictionary containing cropped images of grains and the bounding boxes and padding.\n        grains_curvature_stats_dict : dict\n            Dictionary of grain curvature statistics.\n        all_grain_smoothed_data : dict\n            Dictionary containing smoothed grain traces.\n        colourmap_normalisation_bounds : tuple[float, float]\n            Tuple of the colour map normalisation bounds.\n\n        Returns\n        -------\n        tuple[plt.Figure | None, plt.Axes | None]\n            Matplotlib.pyplot figure object and Matplotlib.pyplot axes object.\n        \"\"\"\n        fig, ax = None, None\n\n        # Only plot if image_set is \"all\" (i.e. user wants all images) or an image is in the core_set\n        if self.image_set == \"all\" or self.core_set:\n            # Get the shape of the image\n\n            shape = image.shape\n            fig, ax = plt.subplots(1, 1)\n            ax.imshow(\n                image,\n                extent=(0, shape[1] * self.pixel_to_nm_scaling, 0, shape[0] * self.pixel_to_nm_scaling),\n                interpolation=self.interpolation,\n                cmap=self.cmap,\n                vmin=self.zrange[0],\n                vmax=self.zrange[1],\n            )\n\n            # For each grain, plot the points with the colour determined by the curvature value\n            # Iterate over the grains\n            for (_, grain_data_curvature), (_, grain_data_smoothed_trace), (_, grain_image_container) in zip(\n                grains_curvature_stats_dict.items(), all_grain_smoothed_data.items(), cropped_images.items()\n            ):\n\n                # Get the coordinate for the grain to accurately position the points\n                min_row = grain_image_container[\"bbox\"][0]\n                min_col = grain_image_container[\"bbox\"][1]\n\n                pad_width = grain_image_container[\"pad_width\"]\n\n                # Iterate over molecules\n                for (_, molecule_data_curvature), (\n                    _,\n                    molecule_data_smoothed_trace,\n                ) in zip(grain_data_curvature.items(), grain_data_smoothed_trace.items()):\n\n                    # Normalise the curvature values to the colourmap bounds\n                    normalised_curvature = np.array(molecule_data_curvature)\n                    normalised_curvature = normalised_curvature - colourmap_normalisation_bounds[0]\n                    normalised_curvature = normalised_curvature / (\n                        colourmap_normalisation_bounds[1] - colourmap_normalisation_bounds[0]\n                    )\n\n                    molecule_trace_coords = molecule_data_smoothed_trace[\"spline_coords\"]\n                    # pylint cannot see that mpl.cm.viridis is a valid attribute\n                    # pylint: disable=no-member\n                    cmap = mpl.cm.coolwarm\n                    for index, point in enumerate(molecule_trace_coords):\n                        color = cmap(normalised_curvature[index])\n                        if index &gt; 0:\n                            previous_point = molecule_trace_coords[index - 1]\n                            ax.plot(\n                                [\n                                    (min_col - pad_width + previous_point[1]) * self.pixel_to_nm_scaling,\n                                    (min_col - pad_width + point[1]) * self.pixel_to_nm_scaling,\n                                ],\n                                [\n                                    (image.shape[0] - (min_row - pad_width + previous_point[0]))\n                                    * self.pixel_to_nm_scaling,\n                                    (image.shape[0] - (min_row - pad_width + point[0])) * self.pixel_to_nm_scaling,\n                                ],\n                                color=color,\n                                linewidth=1,\n                            )\n\n            # save the figure\n            plt.title(self.title)\n            plt.xlabel(\"Nanometres\")\n            plt.ylabel(\"Nanometres\")\n            set_n_ticks(ax, self.num_ticks)\n            plt.axis(self.axes)\n            fig.tight_layout()\n            plt.savefig(\n                (self.output_dir / f\"{self.filename}.{self.savefig_format}\"),\n                bbox_inches=\"tight\",\n                pad_inches=0,\n                dpi=self.savefig_dpi,\n            )\n            plt.close()\n\n        return fig, ax\n\n    def plot_curvatures_individual_grains(\n        self,\n        cropped_images: dict,\n        grains_curvature_stats_dict: dict,\n        all_grains_smoothed_data: dict,\n        colourmap_normalisation_bounds: tuple[float, float],\n    ) -&gt; None:\n        \"\"\"\n        Plot curvature intensity and defects of individual grains.\n\n        Parameters\n        ----------\n        cropped_images : dict\n            Dictionary of cropped images.\n        grains_curvature_stats_dict : dict\n            Dictionary of grain curvature statistics.\n        all_grains_smoothed_data : dict\n            Dictionary containing smoothed grain traces.\n        colourmap_normalisation_bounds : tuple\n            Tuple of the colour map normalisation bounds.\n        \"\"\"\n        fig, ax = None, None\n        # Only plot if image_set is \"all\" (i.e. user wants all images) or an image is in the core_set\n        if self.image_set == \"all\" or self.core_set:\n\n            # Iterate over grains\n            for (\n                (grain_index, grain_data_curvature),\n                (_, grain_data_smoothed_trace),\n                (_, grain_image_container),\n            ) in zip(grains_curvature_stats_dict.items(), all_grains_smoothed_data.items(), cropped_images.items()):\n                grain_image = grain_image_container[\"original_image\"]\n                shape = grain_image.shape\n                fig, ax = plt.subplots(1, 1)\n                ax.imshow(\n                    grain_image,\n                    extent=(0, shape[1] * self.pixel_to_nm_scaling, 0, shape[0] * self.pixel_to_nm_scaling),\n                    interpolation=self.interpolation,\n                    cmap=self.cmap,\n                    vmin=self.zrange[0],\n                    vmax=self.zrange[1],\n                )\n\n                # Iterate over molecules\n                for (_, molecule_data_curvature), (_, molecule_data_smoothed_trace) in zip(\n                    grain_data_curvature.items(), grain_data_smoothed_trace.items()\n                ):\n\n                    molecule_trace_coords = molecule_data_smoothed_trace[\"spline_coords\"]\n\n                    # Normalise the curvature values to the colourmap bounds\n                    normalised_curvature = np.array(molecule_data_curvature)\n                    normalised_curvature = normalised_curvature - colourmap_normalisation_bounds[0]\n                    normalised_curvature = normalised_curvature / (\n                        colourmap_normalisation_bounds[1] - colourmap_normalisation_bounds[0]\n                    )\n\n                    # pylint cannot see that mpl.cm.viridis is a valid attribute\n                    # pylint: disable=no-member\n                    cmap = mpl.cm.coolwarm\n\n                    for index, point in enumerate(molecule_trace_coords):\n\n                        colour = cmap(normalised_curvature[index])\n                        if index &gt; 0:\n                            previous_point = molecule_trace_coords[index - 1]\n                            ax.plot(\n                                [\n                                    previous_point[1] * self.pixel_to_nm_scaling,\n                                    point[1] * self.pixel_to_nm_scaling,\n                                ],\n                                [\n                                    (shape[0] - previous_point[0]) * self.pixel_to_nm_scaling,\n                                    (shape[0] - point[0]) * self.pixel_to_nm_scaling,\n                                ],\n                                color=colour,\n                                linewidth=3,\n                            )\n\n                plt.title(self.title)\n                plt.xlabel(\"Nanometres\")\n                plt.ylabel(\"Nanometres\")\n                set_n_ticks(ax, self.num_ticks)\n                plt.axis(self.axes)\n                fig.tight_layout()\n                # plt.savefig(f\"./grain_{grain_index}_curvature.png\")\n                fig.savefig(\n                    (self.output_dir / f\"{grain_index}_curvature.{self.savefig_format}\"),\n                    bbox_inches=\"tight\",\n                    pad_inches=0,\n                    dpi=self.savefig_dpi,\n                )\n                plt.close()\n\n            LOGGER.debug(\n                f\"[{self.filename}] : Image saved to : {str(self.output_dir / self.filename)}.{self.savefig_format}\"\n                f\" | DPI: {self.savefig_dpi}\"\n            )\n\n    def plot_and_save(self):\n        \"\"\"\n        Plot and save the image.\n\n        Returns\n        -------\n        tuple\n            Matplotlib.pyplot figure object and Matplotlib.pyplot axes object.\n        \"\"\"\n        fig, ax = None, None\n        if self.save:\n            # Only plot if image_set is \"all\" (i.e. user wants all images) or an image is in the core_set\n            if self.image_set == \"all\" or self.core_set:\n                fig, ax = self.save_figure()\n                LOGGER.debug(\n                    f\"[{self.filename}] : Image saved to : {str(self.output_dir / self.filename)}.{self.savefig_format}\"\n                    f\" | DPI: {self.savefig_dpi}\"\n                )\n                plt.close()\n                return fig, ax\n        return fig, ax\n\n    def save_figure(self):\n        \"\"\"\n        Save figures as plt.savefig objects.\n\n        Returns\n        -------\n        tuple\n            Matplotlib.pyplot figure object and Matplotlib.pyplot axes object.\n        \"\"\"\n        fig, ax = plt.subplots(1, 1)\n        shape = self.data.shape\n        if isinstance(self.data, np.ndarray):\n            im = ax.imshow(\n                self.data,\n                extent=(0, shape[1] * self.pixel_to_nm_scaling, 0, shape[0] * self.pixel_to_nm_scaling),\n                interpolation=self.interpolation,\n                cmap=self.cmap,\n                vmin=self.zrange[0],\n                vmax=self.zrange[1],\n            )\n            if isinstance(self.masked_array, np.ndarray):\n                mask = np.ma.masked_where(self.masked_array == 0, self.masked_array)\n                ax.imshow(\n                    mask,\n                    cmap=self.mask_cmap,\n                    extent=(\n                        0,\n                        shape[1] * self.pixel_to_nm_scaling,\n                        0,\n                        shape[0] * self.pixel_to_nm_scaling,\n                    ),\n                    interpolation=self.interpolation,\n                    alpha=0.7,\n                )\n                patch = [Patch(color=self.mask_cmap(1, 0.7), label=\"Mask\")]\n                plt.legend(handles=patch, loc=\"upper right\", bbox_to_anchor=(1.02, 1.09))\n            # if coordinates are provided (such as in splines, plot those)\n            elif self.plot_coords is not None:\n                for grain_coords in self.plot_coords:\n                    ax.plot(\n                        grain_coords[:, 1] * self.pixel_to_nm_scaling,\n                        (shape[0] - grain_coords[:, 0]) * self.pixel_to_nm_scaling,\n                        c=\"c\",\n                        linewidth=1,\n                    )\n\n            plt.title(self.title)\n            plt.xlabel(\"Nanometres\")\n            plt.ylabel(\"Nanometres\")\n            set_n_ticks(ax, self.num_ticks)\n            plt.axis(self.axes)\n            if self.colorbar and self.image_type == \"non-binary\":\n                divider = make_axes_locatable(ax)\n                cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n                plt.colorbar(im, cax=cax, label=\"Height (Nanometres)\")\n            if self.region_properties:\n                fig, ax = add_bounding_boxes_to_plot(fig, ax, shape, self.region_properties, self.pixel_to_nm_scaling)\n            if not self.axes and not self.colorbar:\n                plt.title(\"\")\n                fig.frameon = False\n                plt.box(False)\n                plt.tight_layout()\n                plt.savefig(\n                    (self.output_dir / f\"{self.filename}.{self.savefig_format}\"),\n                    bbox_inches=\"tight\",\n                    pad_inches=0,\n                    dpi=self.savefig_dpi,\n                )\n            else:\n                plt.savefig((self.output_dir / f\"{self.filename}.{self.savefig_format}\"), dpi=self.savefig_dpi)\n        else:\n            plt.xlabel(\"Nanometres\")\n            plt.ylabel(\"Nanometres\")\n            self.data.show(\n                ax=ax,\n                extent=(0, shape[1] * self.pixel_to_nm_scaling, 0, shape[0] * self.pixel_to_nm_scaling),\n                interpolation=self.interpolation,\n                cmap=self.cmap,\n            )\n        plt.close()\n        return fig, ax\n</code></pre>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.Images.__init__","title":"<code>__init__(data, output_dir, filename, style=None, pixel_to_nm_scaling=1.0, masked_array=None, plot_coords=None, title=None, image_type='non-binary', image_set='core', core_set=False, pixel_interpolation=None, cmap=None, mask_cmap='jet_r', region_properties=None, zrange=None, colorbar=True, axes=True, num_ticks=(None, None), save=True, savefig_format=None, histogram_log_axis=True, histogram_bins=None, savefig_dpi=None)</code>","text":"<p>Initialise the class.</p> <p>There are two key parameters that ensure whether an image is plotted that are passed in from the updated plotting dictionary. These are the <code>image_set</code> which defines whether to plot 'all' images or just the <code>core</code> set. There is then the 'core_set' which defines whether an individual images belongs to the 'core_set' or not. If it doesn't then it is not plotted when <code>image_set == \"core\"</code>.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.Images.__init__--parameters","title":"Parameters","text":"<p>data : npt.NDarray     Numpy array to plot. output_dir : str | Path     Output directory to save the file to. filename : str     Filename to save image as. style : str | Path     Filename of matplotlibrc parameters. pixel_to_nm_scaling : float     The scaling factor showing the real length of 1 pixel in nanometers (nm). masked_array : npt.NDarray     Optional mask array to overlay onto an image. plot_coords : npt.NDArray     ??? Needs defining. title : str     Title for plot. image_type : str     The image data type, options are 'binary' or 'non-binary'. image_set : str     The set of images to process, options are 'core' or 'all'. core_set : bool     Flag to identify image as part of the core image set or not. pixel_interpolation : str, optional     Interpolation to use (default is 'None'). cmap : str, optional     Colour map to use (default 'nanoscope', 'afmhot' also available). mask_cmap : str     Colour map to use for the secondary (masked) data (default 'jet_r', 'blu' provides more contrast). region_properties : dict     Dictionary of region properties, adds bounding boxes if specified. zrange : list     Lower and upper bound to clip core images to. colorbar : bool     Optionally add a colorbar to plots, default is False. axes : bool     Optionally add/remove axes from the image. num_ticks : tuple[int | None]     The number of x and y ticks to display on the iage. save : bool     Whether to save the image. savefig_format : str, optional     Format to save the image as. histogram_log_axis : bool     Optionally use a loagrithmic y-axis for the histogram plots. histogram_bins : int, optional     Number of bins for histograms to use. savefig_dpi : str | float, optional     The resolution of the saved plot (default 'figure').</p> Source code in <code>topostats/plottingfuncs.py</code> <pre><code>def __init__(\n    self,\n    data: npt.NDarray,\n    output_dir: str | Path,\n    filename: str,\n    style: str | Path = None,\n    pixel_to_nm_scaling: float = 1.0,\n    masked_array: npt.NDarray = None,\n    plot_coords: npt.NDArray = None,\n    title: str = None,\n    image_type: str = \"non-binary\",\n    image_set: str = \"core\",\n    core_set: bool = False,\n    pixel_interpolation: str | None = None,\n    cmap: str | None = None,\n    mask_cmap: str = \"jet_r\",\n    region_properties: dict = None,\n    zrange: list = None,\n    colorbar: bool = True,\n    axes: bool = True,\n    num_ticks: tuple[int | None] = (None, None),\n    save: bool = True,\n    savefig_format: str | None = None,\n    histogram_log_axis: bool = True,\n    histogram_bins: int | None = None,\n    savefig_dpi: str | float | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialise the class.\n\n    There are two key parameters that ensure whether an image is plotted that are passed in from the updated\n    plotting dictionary. These are the `image_set` which defines whether to plot 'all' images or just the `core`\n    set. There is then the 'core_set' which defines whether an individual images belongs to the 'core_set' or\n    not. If it doesn't then it is not plotted when `image_set == \"core\"`.\n\n    Parameters\n    ----------\n    data : npt.NDarray\n        Numpy array to plot.\n    output_dir : str | Path\n        Output directory to save the file to.\n    filename : str\n        Filename to save image as.\n    style : str | Path\n        Filename of matplotlibrc parameters.\n    pixel_to_nm_scaling : float\n        The scaling factor showing the real length of 1 pixel in nanometers (nm).\n    masked_array : npt.NDarray\n        Optional mask array to overlay onto an image.\n    plot_coords : npt.NDArray\n        ??? Needs defining.\n    title : str\n        Title for plot.\n    image_type : str\n        The image data type, options are 'binary' or 'non-binary'.\n    image_set : str\n        The set of images to process, options are 'core' or 'all'.\n    core_set : bool\n        Flag to identify image as part of the core image set or not.\n    pixel_interpolation : str, optional\n        Interpolation to use (default is 'None').\n    cmap : str, optional\n        Colour map to use (default 'nanoscope', 'afmhot' also available).\n    mask_cmap : str\n        Colour map to use for the secondary (masked) data (default 'jet_r', 'blu' provides more contrast).\n    region_properties : dict\n        Dictionary of region properties, adds bounding boxes if specified.\n    zrange : list\n        Lower and upper bound to clip core images to.\n    colorbar : bool\n        Optionally add a colorbar to plots, default is False.\n    axes : bool\n        Optionally add/remove axes from the image.\n    num_ticks : tuple[int | None]\n        The number of x and y ticks to display on the iage.\n    save : bool\n        Whether to save the image.\n    savefig_format : str, optional\n        Format to save the image as.\n    histogram_log_axis : bool\n        Optionally use a loagrithmic y-axis for the histogram plots.\n    histogram_bins : int, optional\n        Number of bins for histograms to use.\n    savefig_dpi : str | float, optional\n        The resolution of the saved plot (default 'figure').\n    \"\"\"\n    if style is None:\n        style = \"topostats.mplstyle\"\n    load_mplstyle(style)\n    if zrange is None:\n        zrange = [None, None]\n    self.data = data\n    self.output_dir = Path(output_dir)\n    self.filename = filename\n    self.pixel_to_nm_scaling = pixel_to_nm_scaling\n    self.masked_array = masked_array\n    self.plot_coords = plot_coords\n    self.title = title\n    self.image_type = image_type\n    self.image_set = image_set\n    self.core_set = core_set\n    self.interpolation = mpl.rcParams[\"image.interpolation\"] if pixel_interpolation is None else pixel_interpolation\n    cmap = mpl.rcParams[\"image.cmap\"] if cmap is None else cmap\n    self.cmap = Colormap(cmap).get_cmap()\n    self.mask_cmap = Colormap(mask_cmap).get_cmap()\n    self.region_properties = region_properties\n    self.zrange = zrange\n    self.colorbar = colorbar\n    self.axes = axes\n    self.num_ticks = num_ticks\n    self.save = save\n    self.savefig_format = mpl.rcParams[\"savefig.format\"] if savefig_format is None else savefig_format\n    self.histogram_log_axis = histogram_log_axis\n    self.histogram_bins = mpl.rcParams[\"hist.bins\"] if histogram_bins is None else histogram_bins\n    self.savefig_dpi = mpl.rcParams[\"savefig.dpi\"] if savefig_dpi is None else savefig_dpi\n</code></pre>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.Images.plot_and_save","title":"<code>plot_and_save()</code>","text":"<p>Plot and save the image.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.Images.plot_and_save--returns","title":"Returns","text":"<p>tuple     Matplotlib.pyplot figure object and Matplotlib.pyplot axes object.</p> Source code in <code>topostats/plottingfuncs.py</code> <pre><code>def plot_and_save(self):\n    \"\"\"\n    Plot and save the image.\n\n    Returns\n    -------\n    tuple\n        Matplotlib.pyplot figure object and Matplotlib.pyplot axes object.\n    \"\"\"\n    fig, ax = None, None\n    if self.save:\n        # Only plot if image_set is \"all\" (i.e. user wants all images) or an image is in the core_set\n        if self.image_set == \"all\" or self.core_set:\n            fig, ax = self.save_figure()\n            LOGGER.debug(\n                f\"[{self.filename}] : Image saved to : {str(self.output_dir / self.filename)}.{self.savefig_format}\"\n                f\" | DPI: {self.savefig_dpi}\"\n            )\n            plt.close()\n            return fig, ax\n    return fig, ax\n</code></pre>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.Images.plot_curvatures","title":"<code>plot_curvatures(image, cropped_images, grains_curvature_stats_dict, all_grain_smoothed_data, colourmap_normalisation_bounds)</code>","text":"<p>Plot curvature intensity and defects of grains in an image.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.Images.plot_curvatures--parameters","title":"Parameters","text":"<p>image : npt.NDArray     Image to plot. cropped_images : dict     Dictionary containing cropped images of grains and the bounding boxes and padding. grains_curvature_stats_dict : dict     Dictionary of grain curvature statistics. all_grain_smoothed_data : dict     Dictionary containing smoothed grain traces. colourmap_normalisation_bounds : tuple[float, float]     Tuple of the colour map normalisation bounds.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.Images.plot_curvatures--returns","title":"Returns","text":"<p>tuple[plt.Figure | None, plt.Axes | None]     Matplotlib.pyplot figure object and Matplotlib.pyplot axes object.</p> Source code in <code>topostats/plottingfuncs.py</code> <pre><code>def plot_curvatures(\n    self,\n    image: npt.NDArray,\n    cropped_images: dict,\n    grains_curvature_stats_dict: dict,\n    all_grain_smoothed_data: dict,\n    colourmap_normalisation_bounds: tuple[float, float],\n) -&gt; tuple[plt.Figure | None, plt.Axes | None]:\n    \"\"\"\n    Plot curvature intensity and defects of grains in an image.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        Image to plot.\n    cropped_images : dict\n        Dictionary containing cropped images of grains and the bounding boxes and padding.\n    grains_curvature_stats_dict : dict\n        Dictionary of grain curvature statistics.\n    all_grain_smoothed_data : dict\n        Dictionary containing smoothed grain traces.\n    colourmap_normalisation_bounds : tuple[float, float]\n        Tuple of the colour map normalisation bounds.\n\n    Returns\n    -------\n    tuple[plt.Figure | None, plt.Axes | None]\n        Matplotlib.pyplot figure object and Matplotlib.pyplot axes object.\n    \"\"\"\n    fig, ax = None, None\n\n    # Only plot if image_set is \"all\" (i.e. user wants all images) or an image is in the core_set\n    if self.image_set == \"all\" or self.core_set:\n        # Get the shape of the image\n\n        shape = image.shape\n        fig, ax = plt.subplots(1, 1)\n        ax.imshow(\n            image,\n            extent=(0, shape[1] * self.pixel_to_nm_scaling, 0, shape[0] * self.pixel_to_nm_scaling),\n            interpolation=self.interpolation,\n            cmap=self.cmap,\n            vmin=self.zrange[0],\n            vmax=self.zrange[1],\n        )\n\n        # For each grain, plot the points with the colour determined by the curvature value\n        # Iterate over the grains\n        for (_, grain_data_curvature), (_, grain_data_smoothed_trace), (_, grain_image_container) in zip(\n            grains_curvature_stats_dict.items(), all_grain_smoothed_data.items(), cropped_images.items()\n        ):\n\n            # Get the coordinate for the grain to accurately position the points\n            min_row = grain_image_container[\"bbox\"][0]\n            min_col = grain_image_container[\"bbox\"][1]\n\n            pad_width = grain_image_container[\"pad_width\"]\n\n            # Iterate over molecules\n            for (_, molecule_data_curvature), (\n                _,\n                molecule_data_smoothed_trace,\n            ) in zip(grain_data_curvature.items(), grain_data_smoothed_trace.items()):\n\n                # Normalise the curvature values to the colourmap bounds\n                normalised_curvature = np.array(molecule_data_curvature)\n                normalised_curvature = normalised_curvature - colourmap_normalisation_bounds[0]\n                normalised_curvature = normalised_curvature / (\n                    colourmap_normalisation_bounds[1] - colourmap_normalisation_bounds[0]\n                )\n\n                molecule_trace_coords = molecule_data_smoothed_trace[\"spline_coords\"]\n                # pylint cannot see that mpl.cm.viridis is a valid attribute\n                # pylint: disable=no-member\n                cmap = mpl.cm.coolwarm\n                for index, point in enumerate(molecule_trace_coords):\n                    color = cmap(normalised_curvature[index])\n                    if index &gt; 0:\n                        previous_point = molecule_trace_coords[index - 1]\n                        ax.plot(\n                            [\n                                (min_col - pad_width + previous_point[1]) * self.pixel_to_nm_scaling,\n                                (min_col - pad_width + point[1]) * self.pixel_to_nm_scaling,\n                            ],\n                            [\n                                (image.shape[0] - (min_row - pad_width + previous_point[0]))\n                                * self.pixel_to_nm_scaling,\n                                (image.shape[0] - (min_row - pad_width + point[0])) * self.pixel_to_nm_scaling,\n                            ],\n                            color=color,\n                            linewidth=1,\n                        )\n\n        # save the figure\n        plt.title(self.title)\n        plt.xlabel(\"Nanometres\")\n        plt.ylabel(\"Nanometres\")\n        set_n_ticks(ax, self.num_ticks)\n        plt.axis(self.axes)\n        fig.tight_layout()\n        plt.savefig(\n            (self.output_dir / f\"{self.filename}.{self.savefig_format}\"),\n            bbox_inches=\"tight\",\n            pad_inches=0,\n            dpi=self.savefig_dpi,\n        )\n        plt.close()\n\n    return fig, ax\n</code></pre>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.Images.plot_curvatures_individual_grains","title":"<code>plot_curvatures_individual_grains(cropped_images, grains_curvature_stats_dict, all_grains_smoothed_data, colourmap_normalisation_bounds)</code>","text":"<p>Plot curvature intensity and defects of individual grains.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.Images.plot_curvatures_individual_grains--parameters","title":"Parameters","text":"<p>cropped_images : dict     Dictionary of cropped images. grains_curvature_stats_dict : dict     Dictionary of grain curvature statistics. all_grains_smoothed_data : dict     Dictionary containing smoothed grain traces. colourmap_normalisation_bounds : tuple     Tuple of the colour map normalisation bounds.</p> Source code in <code>topostats/plottingfuncs.py</code> <pre><code>def plot_curvatures_individual_grains(\n    self,\n    cropped_images: dict,\n    grains_curvature_stats_dict: dict,\n    all_grains_smoothed_data: dict,\n    colourmap_normalisation_bounds: tuple[float, float],\n) -&gt; None:\n    \"\"\"\n    Plot curvature intensity and defects of individual grains.\n\n    Parameters\n    ----------\n    cropped_images : dict\n        Dictionary of cropped images.\n    grains_curvature_stats_dict : dict\n        Dictionary of grain curvature statistics.\n    all_grains_smoothed_data : dict\n        Dictionary containing smoothed grain traces.\n    colourmap_normalisation_bounds : tuple\n        Tuple of the colour map normalisation bounds.\n    \"\"\"\n    fig, ax = None, None\n    # Only plot if image_set is \"all\" (i.e. user wants all images) or an image is in the core_set\n    if self.image_set == \"all\" or self.core_set:\n\n        # Iterate over grains\n        for (\n            (grain_index, grain_data_curvature),\n            (_, grain_data_smoothed_trace),\n            (_, grain_image_container),\n        ) in zip(grains_curvature_stats_dict.items(), all_grains_smoothed_data.items(), cropped_images.items()):\n            grain_image = grain_image_container[\"original_image\"]\n            shape = grain_image.shape\n            fig, ax = plt.subplots(1, 1)\n            ax.imshow(\n                grain_image,\n                extent=(0, shape[1] * self.pixel_to_nm_scaling, 0, shape[0] * self.pixel_to_nm_scaling),\n                interpolation=self.interpolation,\n                cmap=self.cmap,\n                vmin=self.zrange[0],\n                vmax=self.zrange[1],\n            )\n\n            # Iterate over molecules\n            for (_, molecule_data_curvature), (_, molecule_data_smoothed_trace) in zip(\n                grain_data_curvature.items(), grain_data_smoothed_trace.items()\n            ):\n\n                molecule_trace_coords = molecule_data_smoothed_trace[\"spline_coords\"]\n\n                # Normalise the curvature values to the colourmap bounds\n                normalised_curvature = np.array(molecule_data_curvature)\n                normalised_curvature = normalised_curvature - colourmap_normalisation_bounds[0]\n                normalised_curvature = normalised_curvature / (\n                    colourmap_normalisation_bounds[1] - colourmap_normalisation_bounds[0]\n                )\n\n                # pylint cannot see that mpl.cm.viridis is a valid attribute\n                # pylint: disable=no-member\n                cmap = mpl.cm.coolwarm\n\n                for index, point in enumerate(molecule_trace_coords):\n\n                    colour = cmap(normalised_curvature[index])\n                    if index &gt; 0:\n                        previous_point = molecule_trace_coords[index - 1]\n                        ax.plot(\n                            [\n                                previous_point[1] * self.pixel_to_nm_scaling,\n                                point[1] * self.pixel_to_nm_scaling,\n                            ],\n                            [\n                                (shape[0] - previous_point[0]) * self.pixel_to_nm_scaling,\n                                (shape[0] - point[0]) * self.pixel_to_nm_scaling,\n                            ],\n                            color=colour,\n                            linewidth=3,\n                        )\n\n            plt.title(self.title)\n            plt.xlabel(\"Nanometres\")\n            plt.ylabel(\"Nanometres\")\n            set_n_ticks(ax, self.num_ticks)\n            plt.axis(self.axes)\n            fig.tight_layout()\n            # plt.savefig(f\"./grain_{grain_index}_curvature.png\")\n            fig.savefig(\n                (self.output_dir / f\"{grain_index}_curvature.{self.savefig_format}\"),\n                bbox_inches=\"tight\",\n                pad_inches=0,\n                dpi=self.savefig_dpi,\n            )\n            plt.close()\n\n        LOGGER.debug(\n            f\"[{self.filename}] : Image saved to : {str(self.output_dir / self.filename)}.{self.savefig_format}\"\n            f\" | DPI: {self.savefig_dpi}\"\n        )\n</code></pre>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.Images.plot_histogram_and_save","title":"<code>plot_histogram_and_save()</code>","text":"<p>Plot and save a histogram of the height map.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.Images.plot_histogram_and_save--returns","title":"Returns","text":"<p>tuple | None     Matplotlib.pyplot figure object and Matplotlib.pyplot axes object.</p> Source code in <code>topostats/plottingfuncs.py</code> <pre><code>def plot_histogram_and_save(self) -&gt; tuple | None:\n    \"\"\"\n    Plot and save a histogram of the height map.\n\n    Returns\n    -------\n    tuple | None\n        Matplotlib.pyplot figure object and Matplotlib.pyplot axes object.\n    \"\"\"\n    if self.image_set == \"all\":\n        fig, ax = plt.subplots(1, 1)\n\n        ax.hist(self.data.flatten().astype(float), bins=self.histogram_bins, log=self.histogram_log_axis)\n        ax.set_xlabel(\"pixel height\")\n        if self.histogram_log_axis:\n            ax.set_ylabel(\"frequency in image (log)\")\n        else:\n            ax.set_ylabel(\"frequency in image\")\n        plt.title(self.title)\n        plt.savefig(\n            (self.output_dir / f\"{self.filename}_histogram.{self.savefig_format}\"),\n            bbox_inches=\"tight\",\n            pad_inches=0.5,\n            dpi=self.savefig_dpi,\n        )\n        plt.close()\n\n        return fig, ax\n    return None\n</code></pre>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.Images.save_figure","title":"<code>save_figure()</code>","text":"<p>Save figures as plt.savefig objects.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.Images.save_figure--returns","title":"Returns","text":"<p>tuple     Matplotlib.pyplot figure object and Matplotlib.pyplot axes object.</p> Source code in <code>topostats/plottingfuncs.py</code> <pre><code>def save_figure(self):\n    \"\"\"\n    Save figures as plt.savefig objects.\n\n    Returns\n    -------\n    tuple\n        Matplotlib.pyplot figure object and Matplotlib.pyplot axes object.\n    \"\"\"\n    fig, ax = plt.subplots(1, 1)\n    shape = self.data.shape\n    if isinstance(self.data, np.ndarray):\n        im = ax.imshow(\n            self.data,\n            extent=(0, shape[1] * self.pixel_to_nm_scaling, 0, shape[0] * self.pixel_to_nm_scaling),\n            interpolation=self.interpolation,\n            cmap=self.cmap,\n            vmin=self.zrange[0],\n            vmax=self.zrange[1],\n        )\n        if isinstance(self.masked_array, np.ndarray):\n            mask = np.ma.masked_where(self.masked_array == 0, self.masked_array)\n            ax.imshow(\n                mask,\n                cmap=self.mask_cmap,\n                extent=(\n                    0,\n                    shape[1] * self.pixel_to_nm_scaling,\n                    0,\n                    shape[0] * self.pixel_to_nm_scaling,\n                ),\n                interpolation=self.interpolation,\n                alpha=0.7,\n            )\n            patch = [Patch(color=self.mask_cmap(1, 0.7), label=\"Mask\")]\n            plt.legend(handles=patch, loc=\"upper right\", bbox_to_anchor=(1.02, 1.09))\n        # if coordinates are provided (such as in splines, plot those)\n        elif self.plot_coords is not None:\n            for grain_coords in self.plot_coords:\n                ax.plot(\n                    grain_coords[:, 1] * self.pixel_to_nm_scaling,\n                    (shape[0] - grain_coords[:, 0]) * self.pixel_to_nm_scaling,\n                    c=\"c\",\n                    linewidth=1,\n                )\n\n        plt.title(self.title)\n        plt.xlabel(\"Nanometres\")\n        plt.ylabel(\"Nanometres\")\n        set_n_ticks(ax, self.num_ticks)\n        plt.axis(self.axes)\n        if self.colorbar and self.image_type == \"non-binary\":\n            divider = make_axes_locatable(ax)\n            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n            plt.colorbar(im, cax=cax, label=\"Height (Nanometres)\")\n        if self.region_properties:\n            fig, ax = add_bounding_boxes_to_plot(fig, ax, shape, self.region_properties, self.pixel_to_nm_scaling)\n        if not self.axes and not self.colorbar:\n            plt.title(\"\")\n            fig.frameon = False\n            plt.box(False)\n            plt.tight_layout()\n            plt.savefig(\n                (self.output_dir / f\"{self.filename}.{self.savefig_format}\"),\n                bbox_inches=\"tight\",\n                pad_inches=0,\n                dpi=self.savefig_dpi,\n            )\n        else:\n            plt.savefig((self.output_dir / f\"{self.filename}.{self.savefig_format}\"), dpi=self.savefig_dpi)\n    else:\n        plt.xlabel(\"Nanometres\")\n        plt.ylabel(\"Nanometres\")\n        self.data.show(\n            ax=ax,\n            extent=(0, shape[1] * self.pixel_to_nm_scaling, 0, shape[0] * self.pixel_to_nm_scaling),\n            interpolation=self.interpolation,\n            cmap=self.cmap,\n        )\n    plt.close()\n    return fig, ax\n</code></pre>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.add_bounding_boxes_to_plot","title":"<code>add_bounding_boxes_to_plot(fig, ax, shape, region_properties, pixel_to_nm_scaling)</code>","text":"<p>Add the bounding boxes to a plot.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.add_bounding_boxes_to_plot--parameters","title":"Parameters","text":"<p>fig : plt.figure.Figure     Matplotlib.pyplot figure object. ax : plt.axes._subplots.AxesSubplot     Matplotlib.pyplot axes object. shape : tuple     Tuple of the image-to-be-plot's shape. region_properties : list     Region properties to add bounding boxes from. pixel_to_nm_scaling : float     The scaling factor from px to nm.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.add_bounding_boxes_to_plot--returns","title":"Returns","text":"<p>tuple     Matplotlib.pyplot figure object and Matplotlib.pyplot axes object.</p> Source code in <code>topostats/plottingfuncs.py</code> <pre><code>def add_bounding_boxes_to_plot(fig, ax, shape: tuple, region_properties: list, pixel_to_nm_scaling: float) -&gt; tuple:\n    \"\"\"\n    Add the bounding boxes to a plot.\n\n    Parameters\n    ----------\n    fig : plt.figure.Figure\n        Matplotlib.pyplot figure object.\n    ax : plt.axes._subplots.AxesSubplot\n        Matplotlib.pyplot axes object.\n    shape : tuple\n        Tuple of the image-to-be-plot's shape.\n    region_properties : list\n        Region properties to add bounding boxes from.\n    pixel_to_nm_scaling : float\n        The scaling factor from px to nm.\n\n    Returns\n    -------\n    tuple\n        Matplotlib.pyplot figure object and Matplotlib.pyplot axes object.\n    \"\"\"\n    for region in region_properties:\n        min_y, min_x, max_y, max_x = (x * pixel_to_nm_scaling for x in region.bbox)\n        # Correct y-axis\n        min_y = (shape[0] * pixel_to_nm_scaling) - min_y\n        max_y = (shape[0] * pixel_to_nm_scaling) - max_y\n        rectangle = Rectangle((min_x, min_y), max_x - min_x, max_y - min_y, fill=False, edgecolor=\"white\", linewidth=2)\n        ax.add_patch(rectangle)\n    return fig, ax\n</code></pre>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.add_pixel_to_nm_to_plotting_config","title":"<code>add_pixel_to_nm_to_plotting_config(plotting_config, pixel_to_nm_scaling)</code>","text":"<p>Add the pixel to nanometre scaling factor to plotting configs.</p> <p>Ensures plots are in nanometres and not pixels.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.add_pixel_to_nm_to_plotting_config--parameters","title":"Parameters","text":"<p>plotting_config : dict     TopoStats plotting configuration dictionary. pixel_to_nm_scaling : float     Pixel to nanometre scaling factor for the image.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.add_pixel_to_nm_to_plotting_config--returns","title":"Returns","text":"<p>dict     Updated plotting config with the pixel to nanometre scaling factor applied to all the image configurations.</p> Source code in <code>topostats/plottingfuncs.py</code> <pre><code>def add_pixel_to_nm_to_plotting_config(plotting_config: dict, pixel_to_nm_scaling: float) -&gt; dict:\n    \"\"\"\n    Add the pixel to nanometre scaling factor to plotting configs.\n\n    Ensures plots are in nanometres and not pixels.\n\n    Parameters\n    ----------\n    plotting_config : dict\n        TopoStats plotting configuration dictionary.\n    pixel_to_nm_scaling : float\n        Pixel to nanometre scaling factor for the image.\n\n    Returns\n    -------\n    dict\n        Updated plotting config with the pixel to nanometre scaling factor applied to all the image configurations.\n    \"\"\"\n    # Update PLOT_DICT with pixel_to_nm_scaling (can't add _output_dir since it changes)\n    plot_opts = {\"pixel_to_nm_scaling\": pixel_to_nm_scaling}\n    for image, options in plotting_config[\"plot_dict\"].items():\n        plotting_config[\"plot_dict\"][image] = {**options, **plot_opts}\n    return plotting_config\n</code></pre>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.dilate_binary_image","title":"<code>dilate_binary_image(binary_image, dilation_iterations)</code>","text":"<p>Dilate a supplied binary image a given number of times.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.dilate_binary_image--parameters","title":"Parameters","text":"<p>binary_image : npt.NDArray     Binary image to be dilated. dilation_iterations : int     Number of dilation iterations to be performed.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.dilate_binary_image--returns","title":"Returns","text":"<p>npt.NDArray     Dilated binary image.</p> Source code in <code>topostats/plottingfuncs.py</code> <pre><code>def dilate_binary_image(binary_image: npt.NDArray, dilation_iterations: int) -&gt; npt.NDArray:\n    \"\"\"\n    Dilate a supplied binary image a given number of times.\n\n    Parameters\n    ----------\n    binary_image : npt.NDArray\n        Binary image to be dilated.\n    dilation_iterations : int\n        Number of dilation iterations to be performed.\n\n    Returns\n    -------\n    npt.NDArray\n        Dilated binary image.\n    \"\"\"\n    binary_image = binary_image.copy()\n    for _ in range(dilation_iterations):\n        binary_image = binary_dilation(binary_image)\n\n    return binary_image\n</code></pre>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.load_mplstyle","title":"<code>load_mplstyle(style)</code>","text":"<p>Load the Matplotlibrc parameter file.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.load_mplstyle--parameters","title":"Parameters","text":"<p>style : str | Path     Path to a Matplotlib Style file.</p> Source code in <code>topostats/plottingfuncs.py</code> <pre><code>def load_mplstyle(style: str | Path) -&gt; None:\n    \"\"\"\n    Load the Matplotlibrc parameter file.\n\n    Parameters\n    ----------\n    style : str | Path\n        Path to a Matplotlib Style file.\n    \"\"\"\n    if style == \"topostats.mplstyle\":\n        plt.style.use(resources.files(topostats) / style)\n    else:\n        plt.style.use(style)\n</code></pre>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.set_n_ticks","title":"<code>set_n_ticks(ax, n_xy)</code>","text":"<p>Set the number of ticks along the y and x axes and lets matplotlib assign the values.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.set_n_ticks--parameters","title":"Parameters","text":"<p>ax : plt.Axes.axes     The axes to add ticks to. n_xy : list[int, int]     The number of ticks.</p>"},{"location":"api/plottingfuncs/#topostats.plottingfuncs.set_n_ticks--returns","title":"Returns","text":"<p>plt.Axes.axes     The axes with the new ticks.</p> Source code in <code>topostats/plottingfuncs.py</code> <pre><code>def set_n_ticks(ax: plt.Axes.axes, n_xy: list[int | None, int | None]) -&gt; None:\n    \"\"\"\n    Set the number of ticks along the y and x axes and lets matplotlib assign the values.\n\n    Parameters\n    ----------\n    ax : plt.Axes.axes\n        The axes to add ticks to.\n    n_xy : list[int, int]\n        The number of ticks.\n\n    Returns\n    -------\n    plt.Axes.axes\n        The axes with the new ticks.\n    \"\"\"\n    if n_xy[0] is not None:\n        xlim = ax.get_xlim()\n        xstep = (max(xlim) - min(xlim)) / (n_xy[0] - 1)\n        xticks = np.arange(min(xlim), max(xlim) + xstep, xstep)\n        ax.set_xticks(np.round(xticks))\n    if n_xy[1] is not None:\n        ylim = ax.get_ylim()\n        ystep = (max(ylim) - min(ylim)) / (n_xy[1] - 1)\n        yticks = np.arange(min(ylim), max(ylim) + ystep, ystep)\n        ax.set_yticks(np.round(yticks))\n</code></pre>"},{"location":"api/run_modules/","title":"Run Modules Module","text":"<p>Run TopoStats modules.</p> <p>This provide entry points for running TopoStats as a command line programme. Each function within this module is a wrapper which runs various functions from the ''processing'' module in parallel.</p> <p>handler: python options: docstring_style: numpy rendering: show_signature_annotations: true</p>"},{"location":"api/run_modules/#topostats.run_modules._log_setup","title":"<code>_log_setup(config, args, img_files)</code>","text":"<p>Log the current configuration.</p>"},{"location":"api/run_modules/#topostats.run_modules._log_setup--parameters","title":"Parameters","text":"<p>config : dict     Dictionary of configuration options. args : argparse.Namespace | None     Arguments function was invoked with. img_files : dict     Dictionary of image files that have been found.</p> Source code in <code>topostats/run_modules.py</code> <pre><code>def _log_setup(config: dict, args: argparse.Namespace | None, img_files: dict) -&gt; None:\n    \"\"\"\n    Log the current configuration.\n\n    Parameters\n    ----------\n    config : dict\n        Dictionary of configuration options.\n    args : argparse.Namespace | None\n        Arguments function was invoked with.\n    img_files : dict\n        Dictionary of image files that have been found.\n    \"\"\"\n    LOGGER.debug(f\"Plotting configuration after update :\\n{pformat(config['plotting'], indent=4)}\")\n\n    LOGGER.info(f\"Configuration file loaded from      : {args.config_file}\")\n    LOGGER.info(f\"Scanning for images in              : {config['base_dir']}\")\n    LOGGER.info(f\"Output directory                    : {str(config['output_dir'])}\")\n    LOGGER.info(f\"Looking for images with extension   : {config['file_ext']}\")\n    LOGGER.info(f\"Images with extension {config['file_ext']} in {config['base_dir']} : {len(img_files)}\")\n    if len(img_files) == 0:\n        LOGGER.error(f\"No images with extension {config['file_ext']} in {config['base_dir']}\")\n        LOGGER.error(\"Please check your configuration and directories.\")\n        sys.exit()\n    LOGGER.info(f\"Thresholding method (Filtering)     : {config['filter']['threshold_method']}\")\n    LOGGER.info(f\"Thresholding method (Grains)        : {config['grains']['threshold_method']}\")\n    LOGGER.debug(f\"Configuration after update         : \\n{pformat(config, indent=4)}\")  # noqa: T203\n</code></pre>"},{"location":"api/run_modules/#topostats.run_modules._parse_configuration","title":"<code>_parse_configuration(args=None)</code>","text":"<p>Load configurations, validate and check run steps are consistent.</p>"},{"location":"api/run_modules/#topostats.run_modules._parse_configuration--parameters","title":"Parameters","text":"<p>args : argparse.Namespace | None     Arguments.</p>"},{"location":"api/run_modules/#topostats.run_modules._parse_configuration--returns","title":"Returns","text":"<p>tuple[dict, dict]     Returns the dictionary of configuration options and a dictionary of image files found on the input path.</p> Source code in <code>topostats/run_modules.py</code> <pre><code>def _parse_configuration(args: argparse.Namespace | None = None) -&gt; tuple[dict, dict]:\n    \"\"\"\n    Load configurations, validate and check run steps are consistent.\n\n    Parameters\n    ----------\n    args : argparse.Namespace | None\n        Arguments.\n\n    Returns\n    -------\n    tuple[dict, dict]\n        Returns the dictionary of configuration options and a dictionary of image files found on the input path.\n    \"\"\"\n    # Parse command line options, load config (or default) and update with command line options\n    config = reconcile_config_args(args=args)\n\n    # Validate configuration\n    validate_config(config, schema=DEFAULT_CONFIG_SCHEMA, config_type=\"YAML configuration file\")\n\n    # Set logging level\n    _set_logging(config[\"log_level\"])\n\n    # Create base output directory\n    config[\"output_dir\"].mkdir(parents=True, exist_ok=True)\n\n    # Load plotting_dictionary and validate then update with command line options\n    plotting_dictionary = (resources.files(__package__) / \"plotting_dictionary.yaml\").read_text()\n    config[\"plotting\"][\"plot_dict\"] = yaml.safe_load(plotting_dictionary)\n    validate_config(\n        config[\"plotting\"][\"plot_dict\"], schema=PLOTTING_SCHEMA, config_type=\"YAML plotting configuration file\"\n    )\n    config[\"plotting\"] = update_config(config[\"plotting\"], args)\n\n    # Check earlier stages of processing are enabled for later.\n    check_run_steps(\n        filter_run=config[\"filter\"][\"run\"],\n        grains_run=config[\"grains\"][\"run\"],\n        grainstats_run=config[\"grainstats\"][\"run\"],\n        disordered_tracing_run=config[\"disordered_tracing\"][\"run\"],\n        nodestats_run=config[\"nodestats\"][\"run\"],\n        ordered_tracing_run=config[\"ordered_tracing\"][\"run\"],\n        splining_run=config[\"splining\"][\"run\"],\n    )\n    # Ensures each image has all plotting options which are passed as **kwargs\n    config[\"plotting\"] = update_plotting_config(config[\"plotting\"])\n    img_files = find_files(config[\"base_dir\"], file_ext=config[\"file_ext\"])\n    _log_setup(config, args, img_files)\n    return config, img_files\n</code></pre>"},{"location":"api/run_modules/#topostats.run_modules._set_logging","title":"<code>_set_logging(log_level)</code>","text":"<p>Set the logging level.</p>"},{"location":"api/run_modules/#topostats.run_modules._set_logging--parameters","title":"Parameters","text":"<p>log_level : str     String for the desired log-level.</p> Source code in <code>topostats/run_modules.py</code> <pre><code>def _set_logging(log_level: str | None) -&gt; None:\n    \"\"\"\n    Set the logging level.\n\n    Parameters\n    ----------\n    log_level : str\n        String for the desired log-level.\n    \"\"\"\n    if log_level == \"warning\":\n        LOGGER.setLevel(\"WARNING\")\n    elif log_level == \"error\":\n        LOGGER.setLevel(\"ERROR\")\n    elif log_level == \"debug\":\n        LOGGER.setLevel(\"DEBUG\")\n    else:\n        LOGGER.setLevel(\"INFO\")\n</code></pre>"},{"location":"api/run_modules/#topostats.run_modules.disordered_tracing","title":"<code>disordered_tracing(args=None)</code>","text":"<p>Load files from disk and run grainstats.</p>"},{"location":"api/run_modules/#topostats.run_modules.disordered_tracing--parameters","title":"Parameters","text":"<p>args : None     Arguments.</p> Source code in <code>topostats/run_modules.py</code> <pre><code>def disordered_tracing(args: argparse.Namespace | None = None) -&gt; None:\n    \"\"\"\n    Load files from disk and run grainstats.\n\n    Parameters\n    ----------\n    args : None\n        Arguments.\n    \"\"\"\n    config, img_files = _parse_configuration(args)  # pylint: disable=unused-variable\n    run_disordered_tracing()\n</code></pre>"},{"location":"api/run_modules/#topostats.run_modules.filters","title":"<code>filters(args=None)</code>","text":"<p>Load files from disk and run filtering.</p>"},{"location":"api/run_modules/#topostats.run_modules.filters--parameters","title":"Parameters","text":"<p>args : None     Arguments.</p> Source code in <code>topostats/run_modules.py</code> <pre><code>def filters(args: argparse.Namespace | None = None) -&gt; None:\n    \"\"\"\n    Load files from disk and run filtering.\n\n    Parameters\n    ----------\n    args : None\n        Arguments.\n    \"\"\"\n    config, img_files = _parse_configuration(args)\n    # If loading existing .topostats files the images need filtering again so we need to extract the raw image\n    if config[\"file_ext\"] == \".topostats\":\n        config[\"loading\"][\"extract\"] = \"raw\"\n    all_scan_data = LoadScans(img_files, **config[\"loading\"])\n    all_scan_data.get_data()\n\n    processing_function = partial(\n        process_filters,\n        base_dir=config[\"base_dir\"],\n        filter_config=config[\"filter\"],\n        plotting_config=config[\"plotting\"],\n        output_dir=config[\"output_dir\"],\n    )\n\n    with Pool(processes=config[\"cores\"]) as pool:\n        results = defaultdict()\n        with tqdm(\n            total=len(img_files),\n            desc=f\"Processing images from {config['base_dir']}, results are under {config['output_dir']}\",\n        ) as pbar:\n            for img, result in pool.imap_unordered(\n                processing_function,\n                all_scan_data.img_dict.values(),\n            ):\n                results[str(img)] = result\n                pbar.update()\n\n                # Display completion message for the image\n                LOGGER.info(f\"[{img}] Filtering completed.\")\n\n    # Write config to file\n    config[\"plotting\"].pop(\"plot_dict\")\n    write_yaml(config, output_dir=config[\"output_dir\"])\n    LOGGER.debug(f\"Images processed : {len(results)}\")\n    # Update config with plotting defaults for printing\n    completion_message(config, img_files, summary_config=None, images_processed=sum(results.values()))\n</code></pre>"},{"location":"api/run_modules/#topostats.run_modules.grains","title":"<code>grains(args=None)</code>","text":"<p>Load files from disk and run grain finding.</p>"},{"location":"api/run_modules/#topostats.run_modules.grains--parameters","title":"Parameters","text":"<p>args : None     Arguments.</p> Source code in <code>topostats/run_modules.py</code> <pre><code>def grains(args: argparse.Namespace | None = None) -&gt; None:\n    \"\"\"\n    Load files from disk and run grain finding.\n\n    Parameters\n    ----------\n    args : None\n        Arguments.\n    \"\"\"\n    config, img_files = _parse_configuration(args)\n    # Triggers extraction of filtered images from existing .topostats files\n    if config[\"file_ext\"] == \".topostats\":\n        config[\"loading\"][\"extract\"] = \"grains\"\n    all_scan_data = LoadScans(img_files, **config[\"loading\"])\n    all_scan_data.get_data()\n\n    processing_function = partial(\n        process_grains,\n        base_dir=config[\"base_dir\"],\n        grains_config=config[\"grains\"],\n        plotting_config=config[\"plotting\"],\n        output_dir=config[\"output_dir\"],\n    )\n    with Pool(processes=config[\"cores\"]) as pool:\n        results = defaultdict()\n        with tqdm(\n            total=len(img_files),\n            desc=f\"Processing images from {config['base_dir']}, results are under {config['output_dir']}\",\n        ) as pbar:\n            for img, result in pool.imap_unordered(\n                processing_function,\n                all_scan_data.img_dict.values(),\n            ):\n                results[str(img)] = result\n                pbar.update()\n\n                # Display completion message for the image\n                LOGGER.info(f\"[{img}] Grain detection completed (NB - Filtering was *not* re-run).\")\n\n    # Write config to file\n    config[\"plotting\"].pop(\"plot_dict\")\n    write_yaml(config, output_dir=config[\"output_dir\"])\n    LOGGER.debug(f\"Images processed : {len(results)}\")\n    # Update config with plotting defaults for printing\n    completion_message(config, img_files, summary_config=None, images_processed=sum(results.values()))\n</code></pre>"},{"location":"api/run_modules/#topostats.run_modules.grainstats","title":"<code>grainstats(args=None)</code>","text":"<p>Load files from disk and run grainstats.</p>"},{"location":"api/run_modules/#topostats.run_modules.grainstats--parameters","title":"Parameters","text":"<p>args : None     Arguments.</p> Source code in <code>topostats/run_modules.py</code> <pre><code>def grainstats(args: argparse.Namespace | None = None) -&gt; None:\n    \"\"\"\n    Load files from disk and run grainstats.\n\n    Parameters\n    ----------\n    args : None\n        Arguments.\n    \"\"\"\n    config, img_files = _parse_configuration(args)  # pylint: disable=unused-variable\n    # Triggers extraction of filtered images from existing .topostats files\n    if config[\"file_ext\"] == \".topostats\":\n        config[\"loading\"][\"extract\"] = \"grainstats\"\n    all_scan_data = LoadScans(img_files, **config[\"loading\"])\n    all_scan_data.get_data()\n    processing_function = partial(\n        process_grainstats,\n        base_dir=config[\"base_dir\"],\n        grainstats_config=config[\"grainstats\"],\n        plotting_config=config[\"plotting\"],\n        output_dir=config[\"output_dir\"],\n    )\n    with Pool(processes=config[\"cores\"]) as pool:\n        results = defaultdict()\n        height_profile_all = defaultdict()\n        with tqdm(\n            total=len(img_files),\n            desc=f\"Processing images from {config['base_dir']}, results are under {config['output_dir']}\",\n        ) as pbar:\n            for img, result, height_profiles in pool.imap_unordered(\n                processing_function,\n                all_scan_data.img_dict.values(),\n            ):\n                results[str(img)] = result\n                height_profile_all[str(img)] = height_profiles\n                pbar.update()\n\n                # Display completion message for the image\n                LOGGER.info(f\"[{img}] Grainstats completed (NB - Filtering was *not* re-run).\")\n\n    LOGGER.info(f\"Saving image stats to : {config['output_dir']}/image_stats.csv.\")\n    # Concatenate all the dictionary's values into a dataframe. Ignore the keys since\n    # the dataframes have the file names in them already.\n\n    try:\n        image_stats_all_df = pd.concat(results.values())\n        image_stats_all_df.to_csv(config[\"output_dir\"] / \"image_stats.csv\")\n    except ValueError as error:\n        LOGGER.error(\"No grains found in any images, consider adjusting your thresholds.\")\n        LOGGER.error(error)\n    # If requested save height profiles\n    if config[\"grainstats\"][\"extract_height_profile\"]:\n        LOGGER.info(f\"Saving all height profiles to {config['output_dir']}/height_profiles.json\")\n        dict_to_json(data=height_profile_all, output_dir=config[\"output_dir\"], filename=\"height_profiles.json\")\n\n    # Write config to file\n    config[\"plotting\"].pop(\"plot_dict\")\n    write_yaml(config, output_dir=config[\"output_dir\"])\n    LOGGER.debug(f\"Images processed : {len(results)}\")\n    # Update config with plotting defaults for printing\n    completion_message(config, img_files, summary_config=None, images_processed=image_stats_all_df.shape[0])\n</code></pre>"},{"location":"api/run_modules/#topostats.run_modules.nodestats","title":"<code>nodestats(args=None)</code>","text":"<p>Load files from disk and run grainstats.</p>"},{"location":"api/run_modules/#topostats.run_modules.nodestats--parameters","title":"Parameters","text":"<p>args : None     Arguments.</p> Source code in <code>topostats/run_modules.py</code> <pre><code>def nodestats(args: argparse.Namespace | None = None) -&gt; None:\n    \"\"\"\n    Load files from disk and run grainstats.\n\n    Parameters\n    ----------\n    args : None\n        Arguments.\n    \"\"\"\n    config, img_files = _parse_configuration(args)  # pylint: disable=unused-variable\n    run_nodestats()\n</code></pre>"},{"location":"api/run_modules/#topostats.run_modules.ordered_tracing","title":"<code>ordered_tracing(args=None)</code>","text":"<p>Load files from disk and run grainstats.</p>"},{"location":"api/run_modules/#topostats.run_modules.ordered_tracing--parameters","title":"Parameters","text":"<p>args : None     Arguments.</p> Source code in <code>topostats/run_modules.py</code> <pre><code>def ordered_tracing(args: argparse.Namespace | None = None) -&gt; None:\n    \"\"\"\n    Load files from disk and run grainstats.\n\n    Parameters\n    ----------\n    args : None\n        Arguments.\n    \"\"\"\n    config, img_files = _parse_configuration(args)  # pylint: disable=unused-variable\n    run_ordered_tracing()\n</code></pre>"},{"location":"api/run_modules/#topostats.run_modules.process","title":"<code>process(args=None)</code>","text":"<p>Find and process all files.</p>"},{"location":"api/run_modules/#topostats.run_modules.process--parameters","title":"Parameters","text":"<p>args : None     Arguments.</p> Source code in <code>topostats/run_modules.py</code> <pre><code>def process(args: argparse.Namespace | None = None) -&gt; None:  # noqa: C901\n    \"\"\"\n    Find and process all files.\n\n    Parameters\n    ----------\n    args : None\n        Arguments.\n    \"\"\"\n    config, img_files = _parse_configuration(args)\n\n    processing_function = partial(\n        process_scan,\n        base_dir=config[\"base_dir\"],\n        filter_config=config[\"filter\"],\n        grains_config=config[\"grains\"],\n        grainstats_config=config[\"grainstats\"],\n        disordered_tracing_config=config[\"disordered_tracing\"],\n        nodestats_config=config[\"nodestats\"],\n        ordered_tracing_config=config[\"ordered_tracing\"],\n        splining_config=config[\"splining\"],\n        curvature_config=config[\"curvature\"],\n        plotting_config=config[\"plotting\"],\n        output_dir=config[\"output_dir\"],\n    )\n    # Ensure we load the original images as we are running the whole pipeline\n    if config[\"file_ext\"] == \".topostats\":\n        config[\"loading\"][\"extract\"] = \"raw\"\n\n    all_scan_data = LoadScans(img_files, **config[\"loading\"])\n    all_scan_data.get_data()\n    # Get a dictionary of all the image data dictionaries.\n    # Keys are the image names\n    # Values are the individual image data dictionaries\n    scan_data_dict = all_scan_data.img_dict\n\n    with Pool(processes=config[\"cores\"]) as pool:\n        results = defaultdict()\n        image_stats_all = defaultdict()\n        mols_results = defaultdict()\n        disordered_trace_results = defaultdict()\n        height_profile_all = defaultdict()\n        with tqdm(\n            total=len(img_files),\n            desc=f\"Processing images from {config['base_dir']}, results are under {config['output_dir']}\",\n        ) as pbar:\n            for (\n                img,\n                result,\n                height_profiles,\n                individual_image_stats_df,\n                disordered_trace_result,\n                mols_result,\n            ) in pool.imap_unordered(\n                processing_function,\n                scan_data_dict.values(),\n            ):\n                results[str(img)] = result.dropna(axis=1, how=\"all\")\n                disordered_trace_results[str(img)] = disordered_trace_result.dropna(axis=1, how=\"all\")\n                mols_results[str(img)] = mols_result.dropna(axis=1, how=\"all\")\n                pbar.update()\n\n                # Add the dataframe to the results dict\n                image_stats_all[str(img)] = individual_image_stats_df.dropna(axis=1, how=\"all\")\n\n                # Combine all height profiles\n                height_profile_all[str(img)] = height_profiles\n\n                # Display completion message for the image\n                LOGGER.info(f\"[{img.name}] Processing completed.\")\n\n    LOGGER.info(f\"Saving image stats to : {config['output_dir']}/image_stats.csv.\")\n    # Concatenate all the dictionary's values into a dataframe. Ignore the keys since\n    # the dataframes have the file names in them already.\n    image_stats_all_df = pd.concat(image_stats_all.values())\n    image_stats_all_df.to_csv(config[\"output_dir\"] / \"image_stats.csv\")\n\n    try:\n        results = pd.concat(results.values())\n    except ValueError as error:\n        LOGGER.error(\"No grains found in any images, consider adjusting your thresholds.\")\n        LOGGER.error(error)\n\n    try:\n        disordered_trace_results = pd.concat(disordered_trace_results.values())\n    except ValueError as error:\n        LOGGER.error(\"No skeletons found in any images, consider adjusting disordered tracing parameters.\")\n        LOGGER.error(error)\n\n    try:\n        mols_results = pd.concat(mols_results.values())\n    except ValueError as error:\n        LOGGER.error(\"No mols found in any images, consider adjusting ordered tracing / splining parameters.\")\n        LOGGER.error(error)\n    # If requested save height profiles\n    if config[\"grainstats\"][\"extract_height_profile\"]:\n        LOGGER.info(f\"Saving all height profiles to {config['output_dir']}/height_profiles.json\")\n        dict_to_json(data=height_profile_all, output_dir=config[\"output_dir\"], filename=\"height_profiles.json\")\n\n    # Summary Statistics and Plots\n    if config[\"summary_stats\"][\"run\"]:\n        # Load summary plots/statistics configuration and validate, location depends on command line args or value in\n        # any config file given, if neither are provided the default topostats/summary_config.yaml is loaded\n        if args.summary_config is not None:\n            summary_config = read_yaml(args.summary_config)\n        elif config[\"summary_stats\"][\"config\"] is not None:\n            summary_config = read_yaml(config[\"summary_stats\"][\"config\"])\n        else:\n            summary_yaml = (resources.files(__package__) / \"summary_config.yaml\").read_text()\n            summary_config = yaml.safe_load(summary_yaml)\n\n        # Do not pass command line arguments to toposum as they clash with process command line arguments\n        summary_config = update_config(summary_config, config[\"plotting\"])\n\n        validate_config(summary_config, SUMMARY_SCHEMA, config_type=\"YAML summarisation config\")\n        # We never want to load data from CSV as we are using the data that has just been processed.\n        summary_config.pop(\"csv_file\")\n\n        # Load variable to label mapping\n        plotting_yaml = (resources.files(__package__) / \"var_to_label.yaml\").read_text()\n        summary_config[\"var_to_label\"] = yaml.safe_load(plotting_yaml)\n        LOGGER.info(\"[plotting] Default variable to labels mapping loaded.\")\n\n        # If we don't have a dataframe or we do and it is all NaN there is nothing to plot\n        if isinstance(results, pd.DataFrame) and not results.isna().values.all():\n            if results.shape[0] &gt; 1:\n                # If summary_config[\"output_dir\"] does not match or is not a sub-dir of config[\"output_dir\"] it\n                # needs creating\n                summary_config[\"output_dir\"] = config[\"output_dir\"] / \"summary_distributions\"\n                summary_config[\"output_dir\"].mkdir(parents=True, exist_ok=True)\n                LOGGER.info(f\"Summary plots and statistics will be saved to : {summary_config['output_dir']}\")\n\n                # Plot summaries\n                summary_config[\"df\"] = results.reset_index()\n                toposum(summary_config)\n            else:\n                LOGGER.warning(\n                    \"There are fewer than two grains that have been detected, so\"\n                    \" summary plots cannot be made for this image.\"\n                )\n        else:\n            LOGGER.warning(\n                \"There are no results to plot, either...\\n\\n\"\n                \"* you have disabled grains/grainstats etc.\\n\"\n                \"* no grains have been detected across all scans.\\n\"\n                \"* there have been errors.\\n\\n\"\n                \"If you are not expecting to detect grains please consider disabling\"\n                \"grains/grainstats etc/plotting/summary_stats. If you are expecting to detect grains\"\n                \" please check log-files for further information.\"\n            )\n    else:\n        summary_config = None\n\n    # Write statistics to CSV if there is data.\n    if isinstance(results, pd.DataFrame) and not results.isna().values.all():\n        results.reset_index(drop=True, inplace=True)\n        results.set_index([\"image\", \"threshold\", \"grain_number\"], inplace=True)\n        results.to_csv(config[\"output_dir\"] / \"all_statistics.csv\", index=True)\n        save_folder_grainstats(config[\"output_dir\"], config[\"base_dir\"], results, \"grain_stats\")\n        results.reset_index(inplace=True)  # So we can access unique image names\n        images_processed = len(results[\"image\"].unique())\n    else:\n        images_processed = 0\n        LOGGER.warning(\"There are no grainstats statistics to write to CSV.\")\n\n    if isinstance(disordered_trace_results, pd.DataFrame) and not disordered_trace_results.isna().values.all():\n        disordered_trace_results.reset_index(inplace=True)\n        disordered_trace_results.set_index([\"image\", \"threshold\", \"grain_number\"], inplace=True)\n        disordered_trace_results.to_csv(config[\"output_dir\"] / \"all_disordered_segment_statistics.csv\", index=True)\n        save_folder_grainstats(\n            config[\"output_dir\"], config[\"base_dir\"], disordered_trace_results, \"disordered_trace_stats\"\n        )\n        disordered_trace_results.reset_index(inplace=True)  # So we can access unique image names\n    else:\n        LOGGER.warning(\"There are no disordered tracing statistics to write to CSV.\")\n\n    if isinstance(mols_results, pd.DataFrame) and not mols_results.isna().values.all():\n        mols_results.reset_index(drop=True, inplace=True)\n        mols_results.set_index([\"image\", \"threshold\", \"grain_number\"], inplace=True)\n        mols_results.to_csv(config[\"output_dir\"] / \"all_mol_statistics.csv\", index=True)\n        save_folder_grainstats(config[\"output_dir\"], config[\"base_dir\"], mols_results, \"mol_stats\")\n        mols_results.reset_index(inplace=True)  # So we can access unique image names\n    else:\n        LOGGER.warning(\"There are no molecule tracing statistics to write to CSV.\")\n    # Write config to file\n    config[\"plotting\"].pop(\"plot_dict\")\n    write_yaml(config, output_dir=config[\"output_dir\"])\n    LOGGER.debug(f\"Images processed : {images_processed}\")\n    # Update config with plotting defaults for printing\n    completion_message(config, img_files, summary_config, images_processed)\n</code></pre>"},{"location":"api/run_modules/#topostats.run_modules.reconcile_config_args","title":"<code>reconcile_config_args(args)</code>","text":"<p>Reconcile command line arguments with the default configuration.</p> <p>Command line arguments take precedence over the default configuration. If a partial configuration file is specified (with '-c' or '--config-file') the defaults are over-ridden by these values (internally the configuration dictionary is updated with these values). Any other command line arguments take precedence over both the default and those supplied in a configuration file (again the dictionary is updated).</p> <p>The final configuration is validated before processing begins.</p>"},{"location":"api/run_modules/#topostats.run_modules.reconcile_config_args--parameters","title":"Parameters","text":"<p>args : argparse.Namespace     Command line arguments passed into TopoStats.</p>"},{"location":"api/run_modules/#topostats.run_modules.reconcile_config_args--returns","title":"Returns","text":"<p>dict     The configuration dictionary.</p> Source code in <code>topostats/run_modules.py</code> <pre><code>def reconcile_config_args(args: argparse.Namespace | None) -&gt; dict:\n    \"\"\"\n    Reconcile command line arguments with the default configuration.\n\n    Command line arguments take precedence over the default configuration. If a partial configuration file is specified\n    (with '-c' or '--config-file') the defaults are over-ridden by these values (internally the configuration\n    dictionary is updated with these values). Any other command line arguments take precedence over both the default\n    and those supplied in a configuration file (again the dictionary is updated).\n\n    The final configuration is validated before processing begins.\n\n    Parameters\n    ----------\n    args : argparse.Namespace\n        Command line arguments passed into TopoStats.\n\n    Returns\n    -------\n    dict\n        The configuration dictionary.\n    \"\"\"\n    default_config = read_yaml(resources.files(__package__) / \"default_config.yaml\")\n    if args is not None:\n        config_file_arg: str | None = args.config_file\n        if config_file_arg is not None:\n            config = read_yaml(config_file_arg)\n            # Merge the loaded config with the default config to fill in any defaults that are missing\n            # Make sure to prioritise the loaded config, so it overrides the default\n            config = merge_mappings(map1=default_config, map2=config)\n        else:\n            # If no config file is provided, use the default config\n            config = default_config\n    else:\n        # If no args are provided, use the default config\n        config = default_config\n\n    # Override the config with command line arguments passed in, eg --output_dir ./output/\n    if args is not None:\n        config = update_config(config, args)\n\n    return config\n</code></pre>"},{"location":"api/run_modules/#topostats.run_modules.splining","title":"<code>splining(args=None)</code>","text":"<p>Load files from disk and run grainstats.</p>"},{"location":"api/run_modules/#topostats.run_modules.splining--parameters","title":"Parameters","text":"<p>args : None     Arguments.</p> Source code in <code>topostats/run_modules.py</code> <pre><code>def splining(args: argparse.Namespace | None = None) -&gt; None:\n    \"\"\"\n    Load files from disk and run grainstats.\n\n    Parameters\n    ----------\n    args : None\n        Arguments.\n    \"\"\"\n    config, img_files = _parse_configuration(args)  # pylint: disable=unused-variable\n    run_splining()\n</code></pre>"},{"location":"api/scars/","title":"Scars Module","text":"<p>Image artefact correction functions that interpolates values filling the space of any detected scars.</p> <p>handler: python options: docstring_style: numpy rendering: show_signature_annotations: true</p>"},{"location":"api/scars/#topostats.scars._mark_if_negative_scar","title":"<code>_mark_if_negative_scar(row_col, stddev, img, marked, threshold_low, max_scar_width)</code>","text":"<p>Mark scars as negative (i.e. a dip rather than a ridge).</p> <p>Determine if the points below and including the pixel at the specified row and column are a negative scar (a dip rather than a ridge). If they are, mark them in the marked 2d npt.NDArray. Note that this only detects negative scars.</p>"},{"location":"api/scars/#topostats.scars._mark_if_negative_scar--parameters","title":"Parameters","text":"<p>row_col : tuple     A tuple containing the row and column indices of the pixel for the top of the potential scar. Note that     the first value is the row index, and the second is the column index. stddev : float     The standard deviation, or the root-mean-square value for the image. img : npt.NDArray     A 2-D image of the data to remove scars from. marked : np.ndarry     A 2-D image of pixels that stores the positions of scars marked for removal. The value of the pixel is a     floating point value that represents how strongly the algorithm considers it to be a scar.     This may or may not already contain non-zero values given that previous iterations of scar removal     may have been performed. threshold_low : float     A value that when multiplied with the standard deviation, acts as a threshold to determine if an increase     or decrease in height might constitute the top or bottom of a scar. max_scar_width : int     A value that dictates the maximum width that a scar can be. Note that this does not mean horizontal width,     rather vertical, this is because we consider scars to be laying flat, horizontally, so their width is     vertical and their length is horizontal.</p> Source code in <code>topostats/scars.py</code> <pre><code>def _mark_if_negative_scar(\n    row_col: tuple,\n    stddev: float,\n    img: npt.NDArray,\n    marked: npt.NDArray,\n    threshold_low: float,\n    max_scar_width: int,\n) -&gt; None:\n    \"\"\"\n    Mark scars as negative (i.e. a dip rather than a ridge).\n\n    Determine if the points below and including the pixel at the specified row and column are a negative scar (a\n    dip rather than a ridge). If they are, mark them in the marked 2d npt.NDArray. Note that this only detects negative\n    scars.\n\n    Parameters\n    ----------\n    row_col : tuple\n        A tuple containing the row and column indices of the pixel for the top of the potential scar. Note that\n        the first value is the row index, and the second is the column index.\n    stddev : float\n        The standard deviation, or the root-mean-square value for the image.\n    img : npt.NDArray\n        A 2-D image of the data to remove scars from.\n    marked : np.ndarry\n        A 2-D image of pixels that stores the positions of scars marked for removal. The value of the pixel is a\n        floating point value that represents how strongly the algorithm considers it to be a scar.\n        This may or may not already contain non-zero values given that previous iterations of scar removal\n        may have been performed.\n    threshold_low : float\n        A value that when multiplied with the standard deviation, acts as a threshold to determine if an increase\n        or decrease in height might constitute the top or bottom of a scar.\n    max_scar_width : int\n        A value that dictates the maximum width that a scar can be. Note that this does not mean horizontal width,\n        rather vertical, this is because we consider scars to be laying flat, horizontally, so their width is\n        vertical and their length is horizontal.\n    \"\"\"\n    # Unpack row, col\n    row = row_col[0]\n    col = row_col[1]\n\n    # If sharp enough dip\n    min_scar_value = img[row + 1, col]\n    max_border_value = img[row, col]\n    if min_scar_value - max_border_value &lt; -threshold_low * stddev:\n        # Possibly in a scar\n        for k in range(1, max_scar_width + 1):\n            if row + k + 1 &gt;= img.shape[0]:\n                # Bottom of image, break\n                LOGGER.debug(\"Bottom of image.\")\n                break\n            min_scar_value = max(min_scar_value, img[row + k, col])\n            max_border_value = min(img[row, col], img[row + k + 1, col])\n            # Check if scar ended\n            if min_scar_value - max_border_value &lt; -threshold_low * stddev:\n                while k:\n                    val = (max_border_value - img[row + k, col]) / stddev\n                    marked[row + k, col] = val\n                    k -= 1\n</code></pre>"},{"location":"api/scars/#topostats.scars._mark_if_positive_scar","title":"<code>_mark_if_positive_scar(row_col, stddev, img, marked, threshold_low, max_scar_width)</code>","text":"<p>Mark scars as positive (i.e. a ridge rather than a dip).</p> <p>Determine if the points below and including the pixel at the specified row and column are a positive scar (a ridge rather than a dip). If they are, mark them in the marked 2d npt.NDArray. Note that this only detects positive scars.</p>"},{"location":"api/scars/#topostats.scars._mark_if_positive_scar--parameters","title":"Parameters","text":"<p>row_col : tuple     A tuple containing the row and column indices of the pixel for the top of the potential scar. Note that     the first value is the row index, and the second is the column index. stddev : float     The standard deviation, or the root-mean-square value for the image. img : npt.NDArray     A 2-D image of the data to remove scars from. marked : np.ndarry     A 2-D image of pixels that stores the positions of scars marked for removal. The value of the pixel is a     floating point value that represents how strongly the algorithm considers it to be a scar.     This may or may not already contain non-zero values given that previous iterations of scar removal     may have been performed. threshold_low : float     A value that when multiplied with the standard deviation, acts as a threshold to determine if an increase     or decrease in height might constitute the top or bottom of a scar. max_scar_width : int     A value that dictates the maximum width that a scar can be. Note that this does not mean horizontal width,     rather vertical, this is because we consider scars to be laying flat, horizontally, so their width is     vertical and their length is horizontal.</p> Source code in <code>topostats/scars.py</code> <pre><code>def _mark_if_positive_scar(\n    row_col: tuple,\n    stddev: float,\n    img: npt.NDArray,\n    marked: npt.NDArray,\n    threshold_low: float,\n    max_scar_width: int,\n) -&gt; None:\n    \"\"\"\n    Mark scars as positive (i.e. a ridge rather than a dip).\n\n    Determine if the points below and including the pixel at the specified row and column are a positive scar (a\n    ridge rather than a dip). If they are, mark them in the marked 2d npt.NDArray. Note that this only detects positive\n    scars.\n\n    Parameters\n    ----------\n    row_col : tuple\n        A tuple containing the row and column indices of the pixel for the top of the potential scar. Note that\n        the first value is the row index, and the second is the column index.\n    stddev : float\n        The standard deviation, or the root-mean-square value for the image.\n    img : npt.NDArray\n        A 2-D image of the data to remove scars from.\n    marked : np.ndarry\n        A 2-D image of pixels that stores the positions of scars marked for removal. The value of the pixel is a\n        floating point value that represents how strongly the algorithm considers it to be a scar.\n        This may or may not already contain non-zero values given that previous iterations of scar removal\n        may have been performed.\n    threshold_low : float\n        A value that when multiplied with the standard deviation, acts as a threshold to determine if an increase\n        or decrease in height might constitute the top or bottom of a scar.\n    max_scar_width : int\n        A value that dictates the maximum width that a scar can be. Note that this does not mean horizontal width,\n        rather vertical, this is because we consider scars to be laying flat, horizontally, so their width is\n        vertical and their length is horizontal.\n    \"\"\"\n    # Unpack row, col\n    row = row_col[0]\n    col = row_col[1]\n\n    # If sharp enough rise\n    min_scar_value = img[row + 1, col]\n    max_border_value = img[row, col]\n    if min_scar_value - max_border_value &gt; threshold_low * stddev:\n        # Possibly in a scar\n        for k in range(1, max_scar_width + 1):\n            if row + k + 1 &gt;= img.shape[0]:\n                # Bottom of image, break\n                LOGGER.debug(\"Bottom of image.\")\n                break\n            min_scar_value = min(min_scar_value, img[row + k, col])\n            max_border_value = max(img[row, col], img[row + k + 1, col])\n            # Check if scar ended\n            if min_scar_value - max_border_value &gt; threshold_low * stddev:\n                while k:\n                    val = (img[row + k, col] - max_border_value) / stddev\n                    marked[row + k, col] = val\n                    k -= 1\n</code></pre>"},{"location":"api/scars/#topostats.scars._mark_scars","title":"<code>_mark_scars(img, direction, threshold_low, threshold_high, max_scar_width, min_scar_length)</code>","text":"<p>Mark scars within an image, returning a boolean 2D npt.NDArray of pixels that have been detected as scars.</p>"},{"location":"api/scars/#topostats.scars._mark_scars--parameters","title":"Parameters","text":"<p>img : npt.NDArray     A 2-D image of the data to detect scars in. direction : str     Options : 'positive', 'negative'. The direction of scars to detect. For example, to detect scars     that lie above the data, select 'positive'. threshold_low : float     A floating point value, that when multiplied by the standard deviation of the image, acts as a     threshold for sharp inclines or descents in pixel values and thus marks potential scars.     A lower value will make the algorithm     more sensitive, and a higher value will make it less sensitive. threshold_high : float     A floating point value that is used similarly to threshold_low, however sharp inclines or descents     that result in values in the mask higher than this threshold are automatically considered scars. max_scar_width : int     An integer that restricts the algorithm to only mark scars that are as thin or thinner than this width.     This is important for ensuring that legitimate grain data is not detected as scarred data.     Note that width here is vertical, as scars are thin, horizontal features. min_scar_length : int     An integer that restricts the algorithm to only mark scars that are as long or longer than this length.     This is important for ensuring that noise or legitimate but sharp datapoints do not get detected as scars.     Note that length here is horizontal, as scars are thin, horizontal features.</p>"},{"location":"api/scars/#topostats.scars._mark_scars--returns","title":"Returns","text":"<p>marked: npt.NDArray     Returns a 2-D image of the same shape as the data image, where each pixel's value represents     a metric for how strongly that pixel is considered to be a scar. Higher values mean more likely     to be a scar.</p> Source code in <code>topostats/scars.py</code> <pre><code>def _mark_scars(\n    img: npt.NDArray,\n    direction: str,\n    threshold_low: float,\n    threshold_high: float,\n    max_scar_width: int,\n    min_scar_length: int,\n) -&gt; npt.NDArray:\n    \"\"\"\n    Mark scars within an image, returning a boolean 2D npt.NDArray of pixels that have been detected as scars.\n\n    Parameters\n    ----------\n    img : npt.NDArray\n        A 2-D image of the data to detect scars in.\n    direction : str\n        Options : 'positive', 'negative'. The direction of scars to detect. For example, to detect scars\n        that lie above the data, select 'positive'.\n    threshold_low : float\n        A floating point value, that when multiplied by the standard deviation of the image, acts as a\n        threshold for sharp inclines or descents in pixel values and thus marks potential scars.\n        A lower value will make the algorithm\n        more sensitive, and a higher value will make it less sensitive.\n    threshold_high : float\n        A floating point value that is used similarly to threshold_low, however sharp inclines or descents\n        that result in values in the mask higher than this threshold are automatically considered scars.\n    max_scar_width : int\n        An integer that restricts the algorithm to only mark scars that are as thin or thinner than this width.\n        This is important for ensuring that legitimate grain data is not detected as scarred data.\n        Note that width here is vertical, as scars are thin, horizontal features.\n    min_scar_length : int\n        An integer that restricts the algorithm to only mark scars that are as long or longer than this length.\n        This is important for ensuring that noise or legitimate but sharp datapoints do not get detected as scars.\n        Note that length here is horizontal, as scars are thin, horizontal features.\n\n    Returns\n    -------\n    marked: npt.NDArray\n        Returns a 2-D image of the same shape as the data image, where each pixel's value represents\n        a metric for how strongly that pixel is considered to be a scar. Higher values mean more likely\n        to be a scar.\n    \"\"\"\n    image = np.copy(img)\n\n    stddev = np.std(image)\n    marked = np.zeros(image.shape)\n\n    for row in range(image.shape[0] - 1):\n        for col in range(image.shape[1]):\n            if direction == \"positive\":\n                _mark_if_positive_scar(\n                    row_col=(row, col),\n                    stddev=stddev,\n                    img=image,\n                    marked=marked,\n                    threshold_low=threshold_low,\n                    max_scar_width=max_scar_width,\n                )\n\n            elif direction == \"negative\":\n                _mark_if_negative_scar(\n                    row_col=(row, col),\n                    stddev=stddev,\n                    img=image,\n                    marked=marked,\n                    threshold_low=threshold_low,\n                    max_scar_width=max_scar_width,\n                )\n\n            else:\n                raise ValueError(f\"direction {direction} invalid.\")\n\n    _spread_scars(marked=marked, threshold_low=threshold_low, threshold_high=threshold_high)\n\n    _remove_short_scars(marked=marked, threshold_high=threshold_high, min_scar_length=min_scar_length)\n\n    return marked\n</code></pre>"},{"location":"api/scars/#topostats.scars._remove_marked_scars","title":"<code>_remove_marked_scars(img, scar_mask)</code>","text":"<p>Interpolate values covered by marked scars.</p> <p>Takes an image, and a marked scar boolean mask for that image. Returns the image where the marked scars are replaced by interpolated values.</p>"},{"location":"api/scars/#topostats.scars._remove_marked_scars--parameters","title":"Parameters","text":"<p>img : npt.NDArray     A 2-D image of the data to remove scars from. scar_mask : npt.NDArray     A boolean image of pixels that determine which values are flagged as scars and therefore should     be interpolated over in the original data image.</p> Source code in <code>topostats/scars.py</code> <pre><code>def _remove_marked_scars(img: npt.NDArray, scar_mask: npt.NDArray) -&gt; None:\n    \"\"\"\n    Interpolate values covered by marked scars.\n\n    Takes an image, and a marked scar boolean mask for that image. Returns the image where the marked scars are replaced\n    by interpolated values.\n\n    Parameters\n    ----------\n    img : npt.NDArray\n        A 2-D image of the data to remove scars from.\n    scar_mask : npt.NDArray\n        A boolean image of pixels that determine which values are flagged as scars and therefore should\n        be interpolated over in the original data image.\n    \"\"\"\n    for row, col in np.ndindex(img.shape):\n        if scar_mask[row, col] == 1.0:\n            # Determine how wide the scar is by incrementing scar_width until either the bottom\n            # of the image is reached, or a non-marked pixel is encountered.\n            scar_width = 1\n            while row + scar_width &lt; img.shape[0] and scar_mask[row + scar_width, col] == 1.0:\n                scar_width += 1\n\n            above = img[row - 1, col]\n            below = img[row + scar_width, col]\n            k = scar_width\n            while k:\n                # Linearly interpolate\n                interp_val = (k / (scar_width + 1)) * below + (1 - (k / (scar_width + 1))) * above\n                img[row + k - 1, col] = interp_val\n                scar_mask[row + k - 1, col] = 0.0\n                k -= 1\n                LOGGER.debug(\"Scar removed\")\n</code></pre>"},{"location":"api/scars/#topostats.scars._remove_short_scars","title":"<code>_remove_short_scars(marked, threshold_high, min_scar_length)</code>","text":"<p>Remove scars that are too short (horizontally), based on the minimum length.</p>"},{"location":"api/scars/#topostats.scars._remove_short_scars--parameters","title":"Parameters","text":"<p>marked : npt.NDArray     A 2-D image of pixels that stores the positions of scars marked for removal. The value of the pixel is a     floating point value that represents how strongly the algorithm considers it to be a scar.     This may or may not already contain non-zero values given that previous iterations of scar removal     may have been performed.</p> float <p>A floating point value that is used similarly to threshold_low, however sharp inclines or descents that result in values in the mask higher than this threshold are automatically considered scars.</p> int <p>A value that dictates the maximum width that a scar can be. Note that this does not mean horizontal width, rather vertical, this is because we consider scars to be laying flat, horizontally, so their width is vertical and their length is horizontal.</p> Source code in <code>topostats/scars.py</code> <pre><code>def _remove_short_scars(marked: npt.NDArray, threshold_high: float, min_scar_length: int) -&gt; None:\n    \"\"\"\n    Remove scars that are too short (horizontally), based on the minimum length.\n\n    Parameters\n    ----------\n    marked : npt.NDArray\n        A 2-D image of pixels that stores the positions of scars marked for removal. The value of the pixel is a\n        floating point value that represents how strongly the algorithm considers it to be a scar.\n        This may or may not already contain non-zero values given that previous iterations of scar removal\n        may have been performed.\n\n    threshold_high : float\n        A floating point value that is used similarly to threshold_low, however sharp inclines or descents\n        that result in values in the mask higher than this threshold are automatically considered scars.\n\n    min_scar_length : int\n        A value that dictates the maximum width that a scar can be. Note that this does not mean horizontal width,\n        rather vertical, this is because we consider scars to be laying flat, horizontally, so their width is\n        vertical and their length is horizontal.\n    \"\"\"\n    # Remove too-short scars\n    for row in range(marked.shape[0]):\n        k = 0\n        for col in range(marked.shape[1]):\n            # If greater than threshold, set value to true\n            if marked[row, col] &gt;= threshold_high:\n                marked[row, col] = 1.0\n                k += 1\n                continue\n            # If not greater than threshold,\n            # either we reached the end of the scar,\n            # or haven't found one.\n            # Check if too short. If so, remove.\n            if k and k &lt; min_scar_length:\n                while k:\n                    marked[row, col - k] = 0.0\n                    k -= 1\n            # Long enough, just not bright anymore.\n            # Reached the end of the scar that is long enough. Stop and reset.\n            marked[row, col] = 0.0\n            k = 0\n        # Reached the end of the line, so check current scar's\n        # length to see if too short and should be deleted.\n        if k and k &lt; min_scar_length:\n            while k:\n                marked[row, col - k] = 0.0\n                k -= 1\n</code></pre>"},{"location":"api/scars/#topostats.scars._spread_scars","title":"<code>_spread_scars(marked, threshold_low, threshold_high)</code>","text":"<p>Spread high-marked pixels into adjacent low-marked pixels.</p> <p>This is a smudging function that attempts to catch any pixels that are parts of scars that might not have been extreme enough to get marked above the high_threshold. Any remaining marked pixels below high_threshold are considered not to be scars and are removed from the mask.</p>"},{"location":"api/scars/#topostats.scars._spread_scars--parameters","title":"Parameters","text":"<p>marked : npt.NDArray     A 2-D image of pixels that stores the positions of scars marked for removal. The value of the pixel is a     floating point value that represents how strongly the algorithm considers it to be a scar.     This may or may not already contain non-zero values given that previous iterations of scar removal     may have been performed. threshold_low : float     A floating point value, that when multiplied by the standard deviation of the image, acts as a     threshold for sharp inclines or descents in pixel values and thus marks potential scars.     A lower value will make the algorithm     more sensitive, and a higher value will make it less sensitive. threshold_high : float     A floating point value that is used similarly to threshold_low, however sharp inclines or descents     that result in values in the mask higher than this threshold are automatically considered scars.</p> Source code in <code>topostats/scars.py</code> <pre><code>def _spread_scars(\n    marked: npt.NDArray,\n    threshold_low: float,\n    threshold_high: float,\n) -&gt; None:\n    \"\"\"\n    Spread high-marked pixels into adjacent low-marked pixels.\n\n    This is a smudging function that attempts to catch any pixels that are parts of scars that might not have been\n    extreme enough to get marked above the high_threshold. Any remaining marked pixels below high_threshold are\n    considered not to be scars and are removed from the mask.\n\n    Parameters\n    ----------\n    marked : npt.NDArray\n        A 2-D image of pixels that stores the positions of scars marked for removal. The value of the pixel is a\n        floating point value that represents how strongly the algorithm considers it to be a scar.\n        This may or may not already contain non-zero values given that previous iterations of scar removal\n        may have been performed.\n    threshold_low : float\n        A floating point value, that when multiplied by the standard deviation of the image, acts as a\n        threshold for sharp inclines or descents in pixel values and thus marks potential scars.\n        A lower value will make the algorithm\n        more sensitive, and a higher value will make it less sensitive.\n    threshold_high : float\n        A floating point value that is used similarly to threshold_low, however sharp inclines or descents\n        that result in values in the mask higher than this threshold are automatically considered scars.\n    \"\"\"\n    # Spread scars that have close to threshold edge-points\n    for row in range(marked.shape[0]):\n        # Spread right\n        for col in range(1, marked.shape[1]):\n            if marked[row, col] &gt;= threshold_low and marked[row, col - 1] &gt;= threshold_high:\n                marked[row, col] = threshold_high\n\n        # Spread left\n        for col in range(marked.shape[1] - 1, 0, -1):\n            if marked[row, col - 1] &gt;= threshold_low and marked[row, col] &gt;= threshold_high:\n                marked[row, col - 1] = threshold_high\n</code></pre>"},{"location":"api/scars/#topostats.scars.remove_scars","title":"<code>remove_scars(img, filename, removal_iterations=2, threshold_low=0.25, threshold_high=0.666, max_scar_width=4, min_scar_length=16)</code>","text":"<p>Remove scars from an image.</p> <p>Scars are long, typically 1-4 pixels wide streaks of high or low data in AFM images. They are a problem resulting from random errors in the AFM data collection process and are hard to avoid. This function detects and removes these artefacts by interpolating over them between the pixels above and below them. This method takes no parameters as it uses parameters already established as instance variables when the class was instantiated.</p>"},{"location":"api/scars/#topostats.scars.remove_scars--parameters","title":"Parameters","text":"<p>img : npt.NDArray     A 2-D image to remove scars from. filename : str     The filename (used for logging outputs only). removal_iterations : int     The number of times the scar removal should run on the image.     Running just once sometimes isn't enough to remove some of the     more difficult to remove scars. threshold_low : float     A value that when multiplied with the standard deviation, acts as a threshold to determine if an increase     or decrease in height might constitute the top or bottom of a scar. threshold_high : float     A floating point value that is used similarly to threshold_low, however sharp inclines or descents     that result in values in the mask higher than this threshold are automatically considered scars. max_scar_width : int     A value that dictates the maximum width that a scar can be. Note that this does not mean horizontal width,     rather vertical, this is because we consider scars to be laying flat, horizontally, so their width is     vertical and their length is horizontal. min_scar_length : int     An integer that restricts the algorithm to only mark scars that are as long or longer than this length.     This is important for ensuring that noise or legitimate but sharp datapoints do not get detected as scars.     Note that length here is horizontal, as scars are thin, horizontal features.</p>"},{"location":"api/scars/#topostats.scars.remove_scars--returns","title":"Returns","text":"<p>self.img     The original 2-D image with scars removed, unless the config has run set to False, in which case it     will not remove the scars.</p> Source code in <code>topostats/scars.py</code> <pre><code>def remove_scars(\n    img: npt.NDArray,\n    filename: str,\n    removal_iterations: int = 2,\n    threshold_low: float = 0.250,\n    threshold_high: float = 0.666,\n    max_scar_width: int = 4,\n    min_scar_length: int = 16,\n):\n    \"\"\"\n    Remove scars from an image.\n\n    Scars are long, typically 1-4 pixels wide streaks of high or low data in AFM images. They are a problem\n    resulting from random errors in the AFM data collection process and are hard to avoid. This function\n    detects and removes these artefacts by interpolating over them between the pixels above and below them.\n    This method takes no parameters as it uses parameters already established as instance variables when the\n    class was instantiated.\n\n    Parameters\n    ----------\n    img : npt.NDArray\n        A 2-D image to remove scars from.\n    filename : str\n        The filename (used for logging outputs only).\n    removal_iterations : int\n        The number of times the scar removal should run on the image.\n        Running just once sometimes isn't enough to remove some of the\n        more difficult to remove scars.\n    threshold_low : float\n        A value that when multiplied with the standard deviation, acts as a threshold to determine if an increase\n        or decrease in height might constitute the top or bottom of a scar.\n    threshold_high : float\n        A floating point value that is used similarly to threshold_low, however sharp inclines or descents\n        that result in values in the mask higher than this threshold are automatically considered scars.\n    max_scar_width : int\n        A value that dictates the maximum width that a scar can be. Note that this does not mean horizontal width,\n        rather vertical, this is because we consider scars to be laying flat, horizontally, so their width is\n        vertical and their length is horizontal.\n    min_scar_length : int\n        An integer that restricts the algorithm to only mark scars that are as long or longer than this length.\n        This is important for ensuring that noise or legitimate but sharp datapoints do not get detected as scars.\n        Note that length here is horizontal, as scars are thin, horizontal features.\n\n    Returns\n    -------\n    self.img\n        The original 2-D image with scars removed, unless the config has run set to False, in which case it\n        will not remove the scars.\n    \"\"\"\n    LOGGER.info(f\"[{filename}] : Removing scars\")\n\n    first_marked_mask = None\n    for i in range(removal_iterations):\n        marked_positive = _mark_scars(\n            img=img,\n            direction=\"positive\",\n            threshold_low=threshold_low,\n            threshold_high=threshold_high,\n            max_scar_width=max_scar_width,\n            min_scar_length=min_scar_length,\n        )\n        marked_negative = _mark_scars(\n            img=img,\n            direction=\"negative\",\n            threshold_low=threshold_low,\n            threshold_high=threshold_high,\n            max_scar_width=max_scar_width,\n            min_scar_length=min_scar_length,\n        )\n        # Combine the upper and lower scar masks\n        marked_both = np.bitwise_or(marked_positive.astype(bool), marked_negative.astype(bool))\n\n        if i == 0:\n            first_marked_mask = marked_both\n\n        _remove_marked_scars(img, np.copy(marked_both))\n\n        LOGGER.debug(\"Scars removed\")\n\n    return img, first_marked_mask\n</code></pre>"},{"location":"api/statistics/","title":"Statistics Modules","text":"<p>Function for calculating statistics about a whole image, for example number of grains or surface roughness.</p> <p>handler: python options: docstring_style: numpy rendering: show_signature_annotations: true</p>"},{"location":"api/statistics/#topostats.statistics.image_statistics","title":"<code>image_statistics(image, filename, pixel_to_nm_scaling, results_df)</code>","text":"<p>Calculate statistics pertaining to the whole image.</p> <p>Calculates the size of the image in pixels and metres, the root-mean-squared roughness and the grains per metre squared.</p>"},{"location":"api/statistics/#topostats.statistics.image_statistics--parameters","title":"Parameters","text":"<p>image : np.ndarray     Numpy 2D image array of the image to calculate stats for. filename : str     The name of the file being processed. pixel_to_nm_scaling : float     Float of the scaling factor between pixels and nanometres. results_df : pd.DataFrame     Pandas DataFrame of statistics pertaining to individual grains including from grainstats and     dna tracing.</p>"},{"location":"api/statistics/#topostats.statistics.image_statistics--returns","title":"Returns","text":"<p>dict     Dictionary of image statistics.</p> Source code in <code>topostats/statistics.py</code> <pre><code>def image_statistics(\n    image: np.ndarray,\n    filename: str,\n    pixel_to_nm_scaling: float,\n    results_df: pd.DataFrame,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Calculate statistics pertaining to the whole image.\n\n    Calculates the size of the image in pixels and metres, the root-mean-squared roughness and the grains per metre\n    squared.\n\n    Parameters\n    ----------\n    image : np.ndarray\n        Numpy 2D image array of the image to calculate stats for.\n    filename : str\n        The name of the file being processed.\n    pixel_to_nm_scaling : float\n        Float of the scaling factor between pixels and nanometres.\n    results_df : pd.DataFrame\n        Pandas DataFrame of statistics pertaining to individual grains including from grainstats and\n        dna tracing.\n\n    Returns\n    -------\n    dict\n        Dictionary of image statistics.\n    \"\"\"\n    image_stats = {\n        \"image\": filename,\n        \"image_size_x_m\": None,\n        \"image_size_y_m\": None,\n        \"image_area_m2\": None,\n        \"image_size_x_px\": image.shape[1],\n        \"image_size_y_px\": image.shape[0],\n        \"image_area_px2\": None,\n        \"grains_number_above\": None,\n        \"grains_per_m2_above\": None,\n        \"grains_number_below\": None,\n        \"grains_per_m2_below\": None,\n        \"rms_roughness\": None,\n    }\n\n    # Calculate dimensions of the image\n    image_stats[\"image_size_x_m\"] = image.shape[1] * pixel_to_nm_scaling * 1e-9\n    image_stats[\"image_size_y_m\"] = image.shape[0] * pixel_to_nm_scaling * 1e-9\n    image_stats[\"image_area_m2\"] = image_stats[\"image_size_x_m\"] * image_stats[\"image_size_y_m\"]\n    image_stats[\"image_area_px2\"] = image_stats[\"image_size_x_px\"] * image_stats[\"image_size_y_px\"]\n\n    # Calculate the RMS roughness of the sample on the flattened image.\n    image_stats[\"rms_roughness\"] = roughness_rms(image=image) * 1e-9\n\n    # Calculate image stats relating to grain statistics. Note that the existence of any of these stats\n    # is not guaranteed\n    try:\n        image_stats[\"grains_number_below\"] = results_df[\"threshold\"].value_counts().get(\"below\", 0)\n        image_stats[\"grains_per_m2_below\"] = image_stats[\"grains_number_below\"] / image_stats[\"image_area_m2\"]\n    except KeyError:\n        pass\n    try:\n        image_stats[\"grains_number_above\"] = results_df[\"threshold\"].value_counts().get(\"above\", 0)\n        image_stats[\"grains_per_m2_above\"] = image_stats[\"grains_number_above\"] / image_stats[\"image_area_m2\"]\n    except KeyError:\n        pass\n\n    image_stats_df = pd.DataFrame([image_stats])\n    image_stats_df.set_index(\"image\", inplace=True)\n\n    return image_stats_df\n</code></pre>"},{"location":"api/statistics/#topostats.statistics.roughness_rms","title":"<code>roughness_rms(image)</code>","text":"<p>Calculate the root-mean-square roughness of a heightmap image.</p>"},{"location":"api/statistics/#topostats.statistics.roughness_rms--parameters","title":"Parameters","text":"<p>image : np.ndarray     2-D numpy array of heightmap data to calculate roughness.</p>"},{"location":"api/statistics/#topostats.statistics.roughness_rms--returns","title":"Returns","text":"<p>float     The RMS roughness of the input array.</p> Source code in <code>topostats/statistics.py</code> <pre><code>def roughness_rms(image: np.ndarray) -&gt; float:\n    \"\"\"\n    Calculate the root-mean-square roughness of a heightmap image.\n\n    Parameters\n    ----------\n    image : np.ndarray\n        2-D numpy array of heightmap data to calculate roughness.\n\n    Returns\n    -------\n    float\n        The RMS roughness of the input array.\n    \"\"\"\n    return np.sqrt(np.mean(np.square(image)))\n</code></pre>"},{"location":"api/theme/","title":"Theme Modules","text":"<p>Custom Bruker Nanoscope colorscale.</p> <p>handler: python options: docstring_style: numpy rendering: show_signature_annotations: true</p>"},{"location":"api/theme/#topostats.theme.Colormap","title":"<code>Colormap</code>","text":"<p>Class for setting the Colormap.</p>"},{"location":"api/theme/#topostats.theme.Colormap--parameters","title":"Parameters","text":"<p>name : str     Name of colormap to use.</p> Source code in <code>topostats/theme.py</code> <pre><code>class Colormap:\n    \"\"\"\n    Class for setting the Colormap.\n\n    Parameters\n    ----------\n    name : str\n        Name of colormap to use.\n    \"\"\"\n\n    def __init__(self, name: str = \"nanoscope\"):\n        \"\"\"\n        Initialise the class.\n\n        Parameters\n        ----------\n        name : str\n            Name of colormap to use.\n        \"\"\"\n        self.name = name\n        self.cmap = None\n        self.set_cmap(self.name)\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Return string representation of object.\n\n        Returns\n        -------\n        str\n            String detailing the colormap.\n        \"\"\"\n        return f\"TopoStats Colormap: {self.name}\"\n\n    def set_cmap(self, name: str) -&gt; None:\n        \"\"\"\n        Set the ColorMap.\n\n        Parameters\n        ----------\n        name : str\n            Name of the colormap to return.\n        \"\"\"\n        if name.lower() == \"nanoscope\":\n            self.cmap = self.nanoscope()\n        elif name.lower() == \"gwyddion\":\n            self.cmap = self.gwyddion()\n        elif name.lower() == \"blue\":\n            self.cmap = self.blue()\n        elif name.lower() == \"blue_purple_green\":\n            self.cmap = self.blue_purple_green()\n        else:\n            # Get one of the matplotlib colormaps\n            self.cmap = mpl.colormaps[name]\n        LOGGER.debug(f\"[theme] Colormap set to : {name}\")\n\n    def get_cmap(self) -&gt; matplotlib.cm:\n        \"\"\"\n        Return the matplotlib.cm colormap object.\n\n        Returns\n        -------\n        matplotlib.cm\n            Matplotlib Color map object.\n        \"\"\"\n        return self.cmap\n\n    @staticmethod\n    def nanoscope() -&gt; LinearSegmentedColormap:\n        \"\"\"\n        Matplotlib compatible colormap that replicates the Bruker Nanoscope colorscale.\n\n        The colormap is implemented in Gwyddion's GwyGradient via 'Nanoscope.txt'.\n\n        Returns\n        -------\n        LinearSegmentedColormap\n            MatplotLib LinearSegmentedColourmap that replicates Bruker Nanoscope colorscale.\n        \"\"\"\n        cdict = {\n            \"red\": (\n                (0.0, 0.0, 0.0),\n                (0.124464, 0.0, 0.0),\n                (0.236052, 0.0670103, 0.0670103),\n                (0.371245, 0.253338, 0.253338),\n                (0.472103, 0.392344, 0.392344),\n                (0.611588, 0.584587, 0.584587),\n                (0.708155, 0.717678, 0.717678),\n                (0.714052, 0.725806, 0.725806),\n                (0.890558, 0.969072, 0.969072),\n                (0.933476, 0.987464, 0.987464),\n                (0.944709, 0.992278, 0.992278),\n                (0.965682, 0.995207, 0.995207),\n                (0.971401, 0.996006, 0.996006),\n                (1, 1, 1),\n            ),\n            \"green\": (\n                (0.0, 0.0, 0.0),\n                (0.124464, 0.0, 0.0),\n                (0.236052, 0.0, 0.0),\n                (0.371245, 0.0, 0.0),\n                (0.472103, 0.0721649, 0.0721649),\n                (0.611588, 0.334114, 0.334114),\n                (0.708155, 0.515464, 0.515464),\n                (0.714052, 0.527471, 0.527471),\n                (0.890558, 0.886843, 0.886843),\n                (0.933476, 0.974227, 0.974227),\n                (0.944709, 0.980523, 0.980523),\n                (0.965682, 0.992278, 0.992278),\n                (0.971401, 0.993565, 0.993565),\n                (1, 1, 1),\n            ),\n            \"blue\": (\n                (0.0, 0.0, 0.0),\n                (0.124464, 0.0, 0.0),\n                (0.236052, 0.0, 0.0),\n                (0.371245, 0.0, 0.0),\n                (0.472103, 0.0, 0.0),\n                (0.611588, 0.0, 0.0),\n                (0.708155, 0.252575, 0.252575),\n                (0.714052, 0.268, 0.268),\n                (0.890558, 0.76343, 0.76343),\n                (0.933476, 0.883897, 0.883897),\n                (0.944709, 0.915426, 0.915426),\n                (0.965682, 0.974293, 0.974293),\n                (0.971401, 0.990347, 0.990347),\n                (1, 1, 1),\n            ),\n        }\n\n        return LinearSegmentedColormap(\"nanoscope\", cdict)\n\n    @staticmethod\n    def gwyddion() -&gt; LinearSegmentedColormap:\n        \"\"\"\n        Set RGBA colour map for the Gwyddion.net colour gradient.\n\n        Returns\n        -------\n        LinearSegmentedColormap\n            The 'gwyddion' colormap.\n        \"\"\"\n        N = 4  # Number of values\n        vals = np.ones((N, 4))  # Initialise the array to be full of 1.0\n        vals[0] = [0.0, 0.0, 0.0, 1]\n        vals[1] = [168 / 256, 40 / 256, 15 / 256, 1.0]\n        vals[2] = [243 / 256, 194 / 256, 93 / 256, 1.0]\n        vals[3] = [1.0, 1.0, 1.0, 1.0]\n\n        return LinearSegmentedColormap.from_list(\"gwyddion\", vals, N=256)\n\n    @staticmethod\n    def blue() -&gt; ListedColormap:\n        \"\"\"\n        Set RGBA colour map of just the colour blue.\n\n        Returns\n        -------\n        ListedColormap\n            The 'blue' colormap.\n        \"\"\"\n        return ListedColormap([[32 / 256, 226 / 256, 205 / 256]], \"blue\", N=256)\n\n    @staticmethod\n    def blue_purple_green() -&gt; ListedColormap:\n        \"\"\"\n        RGBA colour map of just the colour blue/purple/green.\n\n        Returns\n        -------\n        ListedColormap\n            The 'blue/purple/green' colormap.\n        \"\"\"\n        return ListedColormap(\n            [[0 / 256, 157 / 256, 229 / 256], [255 / 256, 100 / 256, 225 / 256], [0 / 256, 1, 139 / 256]],\n            \"blue_purple_green\",\n            N=3,\n        )\n</code></pre>"},{"location":"api/theme/#topostats.theme.Colormap.__init__","title":"<code>__init__(name='nanoscope')</code>","text":"<p>Initialise the class.</p>"},{"location":"api/theme/#topostats.theme.Colormap.__init__--parameters","title":"Parameters","text":"<p>name : str     Name of colormap to use.</p> Source code in <code>topostats/theme.py</code> <pre><code>def __init__(self, name: str = \"nanoscope\"):\n    \"\"\"\n    Initialise the class.\n\n    Parameters\n    ----------\n    name : str\n        Name of colormap to use.\n    \"\"\"\n    self.name = name\n    self.cmap = None\n    self.set_cmap(self.name)\n</code></pre>"},{"location":"api/theme/#topostats.theme.Colormap.__str__","title":"<code>__str__()</code>","text":"<p>Return string representation of object.</p>"},{"location":"api/theme/#topostats.theme.Colormap.__str__--returns","title":"Returns","text":"<p>str     String detailing the colormap.</p> Source code in <code>topostats/theme.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Return string representation of object.\n\n    Returns\n    -------\n    str\n        String detailing the colormap.\n    \"\"\"\n    return f\"TopoStats Colormap: {self.name}\"\n</code></pre>"},{"location":"api/theme/#topostats.theme.Colormap.blue","title":"<code>blue()</code>  <code>staticmethod</code>","text":"<p>Set RGBA colour map of just the colour blue.</p>"},{"location":"api/theme/#topostats.theme.Colormap.blue--returns","title":"Returns","text":"<p>ListedColormap     The 'blue' colormap.</p> Source code in <code>topostats/theme.py</code> <pre><code>@staticmethod\ndef blue() -&gt; ListedColormap:\n    \"\"\"\n    Set RGBA colour map of just the colour blue.\n\n    Returns\n    -------\n    ListedColormap\n        The 'blue' colormap.\n    \"\"\"\n    return ListedColormap([[32 / 256, 226 / 256, 205 / 256]], \"blue\", N=256)\n</code></pre>"},{"location":"api/theme/#topostats.theme.Colormap.blue_purple_green","title":"<code>blue_purple_green()</code>  <code>staticmethod</code>","text":"<p>RGBA colour map of just the colour blue/purple/green.</p>"},{"location":"api/theme/#topostats.theme.Colormap.blue_purple_green--returns","title":"Returns","text":"<p>ListedColormap     The 'blue/purple/green' colormap.</p> Source code in <code>topostats/theme.py</code> <pre><code>@staticmethod\ndef blue_purple_green() -&gt; ListedColormap:\n    \"\"\"\n    RGBA colour map of just the colour blue/purple/green.\n\n    Returns\n    -------\n    ListedColormap\n        The 'blue/purple/green' colormap.\n    \"\"\"\n    return ListedColormap(\n        [[0 / 256, 157 / 256, 229 / 256], [255 / 256, 100 / 256, 225 / 256], [0 / 256, 1, 139 / 256]],\n        \"blue_purple_green\",\n        N=3,\n    )\n</code></pre>"},{"location":"api/theme/#topostats.theme.Colormap.get_cmap","title":"<code>get_cmap()</code>","text":"<p>Return the matplotlib.cm colormap object.</p>"},{"location":"api/theme/#topostats.theme.Colormap.get_cmap--returns","title":"Returns","text":"<p>matplotlib.cm     Matplotlib Color map object.</p> Source code in <code>topostats/theme.py</code> <pre><code>def get_cmap(self) -&gt; matplotlib.cm:\n    \"\"\"\n    Return the matplotlib.cm colormap object.\n\n    Returns\n    -------\n    matplotlib.cm\n        Matplotlib Color map object.\n    \"\"\"\n    return self.cmap\n</code></pre>"},{"location":"api/theme/#topostats.theme.Colormap.gwyddion","title":"<code>gwyddion()</code>  <code>staticmethod</code>","text":"<p>Set RGBA colour map for the Gwyddion.net colour gradient.</p>"},{"location":"api/theme/#topostats.theme.Colormap.gwyddion--returns","title":"Returns","text":"<p>LinearSegmentedColormap     The 'gwyddion' colormap.</p> Source code in <code>topostats/theme.py</code> <pre><code>@staticmethod\ndef gwyddion() -&gt; LinearSegmentedColormap:\n    \"\"\"\n    Set RGBA colour map for the Gwyddion.net colour gradient.\n\n    Returns\n    -------\n    LinearSegmentedColormap\n        The 'gwyddion' colormap.\n    \"\"\"\n    N = 4  # Number of values\n    vals = np.ones((N, 4))  # Initialise the array to be full of 1.0\n    vals[0] = [0.0, 0.0, 0.0, 1]\n    vals[1] = [168 / 256, 40 / 256, 15 / 256, 1.0]\n    vals[2] = [243 / 256, 194 / 256, 93 / 256, 1.0]\n    vals[3] = [1.0, 1.0, 1.0, 1.0]\n\n    return LinearSegmentedColormap.from_list(\"gwyddion\", vals, N=256)\n</code></pre>"},{"location":"api/theme/#topostats.theme.Colormap.nanoscope","title":"<code>nanoscope()</code>  <code>staticmethod</code>","text":"<p>Matplotlib compatible colormap that replicates the Bruker Nanoscope colorscale.</p> <p>The colormap is implemented in Gwyddion's GwyGradient via 'Nanoscope.txt'.</p>"},{"location":"api/theme/#topostats.theme.Colormap.nanoscope--returns","title":"Returns","text":"<p>LinearSegmentedColormap     MatplotLib LinearSegmentedColourmap that replicates Bruker Nanoscope colorscale.</p> Source code in <code>topostats/theme.py</code> <pre><code>@staticmethod\ndef nanoscope() -&gt; LinearSegmentedColormap:\n    \"\"\"\n    Matplotlib compatible colormap that replicates the Bruker Nanoscope colorscale.\n\n    The colormap is implemented in Gwyddion's GwyGradient via 'Nanoscope.txt'.\n\n    Returns\n    -------\n    LinearSegmentedColormap\n        MatplotLib LinearSegmentedColourmap that replicates Bruker Nanoscope colorscale.\n    \"\"\"\n    cdict = {\n        \"red\": (\n            (0.0, 0.0, 0.0),\n            (0.124464, 0.0, 0.0),\n            (0.236052, 0.0670103, 0.0670103),\n            (0.371245, 0.253338, 0.253338),\n            (0.472103, 0.392344, 0.392344),\n            (0.611588, 0.584587, 0.584587),\n            (0.708155, 0.717678, 0.717678),\n            (0.714052, 0.725806, 0.725806),\n            (0.890558, 0.969072, 0.969072),\n            (0.933476, 0.987464, 0.987464),\n            (0.944709, 0.992278, 0.992278),\n            (0.965682, 0.995207, 0.995207),\n            (0.971401, 0.996006, 0.996006),\n            (1, 1, 1),\n        ),\n        \"green\": (\n            (0.0, 0.0, 0.0),\n            (0.124464, 0.0, 0.0),\n            (0.236052, 0.0, 0.0),\n            (0.371245, 0.0, 0.0),\n            (0.472103, 0.0721649, 0.0721649),\n            (0.611588, 0.334114, 0.334114),\n            (0.708155, 0.515464, 0.515464),\n            (0.714052, 0.527471, 0.527471),\n            (0.890558, 0.886843, 0.886843),\n            (0.933476, 0.974227, 0.974227),\n            (0.944709, 0.980523, 0.980523),\n            (0.965682, 0.992278, 0.992278),\n            (0.971401, 0.993565, 0.993565),\n            (1, 1, 1),\n        ),\n        \"blue\": (\n            (0.0, 0.0, 0.0),\n            (0.124464, 0.0, 0.0),\n            (0.236052, 0.0, 0.0),\n            (0.371245, 0.0, 0.0),\n            (0.472103, 0.0, 0.0),\n            (0.611588, 0.0, 0.0),\n            (0.708155, 0.252575, 0.252575),\n            (0.714052, 0.268, 0.268),\n            (0.890558, 0.76343, 0.76343),\n            (0.933476, 0.883897, 0.883897),\n            (0.944709, 0.915426, 0.915426),\n            (0.965682, 0.974293, 0.974293),\n            (0.971401, 0.990347, 0.990347),\n            (1, 1, 1),\n        ),\n    }\n\n    return LinearSegmentedColormap(\"nanoscope\", cdict)\n</code></pre>"},{"location":"api/theme/#topostats.theme.Colormap.set_cmap","title":"<code>set_cmap(name)</code>","text":"<p>Set the ColorMap.</p>"},{"location":"api/theme/#topostats.theme.Colormap.set_cmap--parameters","title":"Parameters","text":"<p>name : str     Name of the colormap to return.</p> Source code in <code>topostats/theme.py</code> <pre><code>def set_cmap(self, name: str) -&gt; None:\n    \"\"\"\n    Set the ColorMap.\n\n    Parameters\n    ----------\n    name : str\n        Name of the colormap to return.\n    \"\"\"\n    if name.lower() == \"nanoscope\":\n        self.cmap = self.nanoscope()\n    elif name.lower() == \"gwyddion\":\n        self.cmap = self.gwyddion()\n    elif name.lower() == \"blue\":\n        self.cmap = self.blue()\n    elif name.lower() == \"blue_purple_green\":\n        self.cmap = self.blue_purple_green()\n    else:\n        # Get one of the matplotlib colormaps\n        self.cmap = mpl.colormaps[name]\n    LOGGER.debug(f\"[theme] Colormap set to : {name}\")\n</code></pre>"},{"location":"api/thresholds/","title":"Thresholds Modules","text":"<p>Functions for calculating thresholds.</p> <p>handler: python options: docstring_style: numpy rendering: show_signature_annotations: true</p>"},{"location":"api/thresholds/#topostats.thresholds._get_threshold","title":"<code>_get_threshold(method='otsu')</code>","text":"<p>Creator component which determines which threshold method to use.</p>"},{"location":"api/thresholds/#topostats.thresholds._get_threshold--parameters","title":"Parameters","text":"<p>method : str     Threshold method to use, currently supports otsu (default), mean, minimum, mean yen, and triangle.</p>"},{"location":"api/thresholds/#topostats.thresholds._get_threshold--returns","title":"Returns","text":"<p>function     Returns function appropriate for the required threshold method.</p>"},{"location":"api/thresholds/#topostats.thresholds._get_threshold--raises","title":"Raises","text":"<p>ValueError     Unsupported methods result in ValueError.</p> Source code in <code>topostats/thresholds.py</code> <pre><code>def _get_threshold(method: str = \"otsu\") -&gt; Callable:\n    \"\"\"\n    Creator component which determines which threshold method to use.\n\n    Parameters\n    ----------\n    method : str\n        Threshold method to use, currently supports otsu (default), mean, minimum, mean yen, and triangle.\n\n    Returns\n    -------\n    function\n        Returns function appropriate for the required threshold method.\n\n    Raises\n    ------\n    ValueError\n        Unsupported methods result in ValueError.\n    \"\"\"\n    if method == \"otsu\":\n        return _threshold_otsu\n    if method == \"mean\":\n        return _threshold_mean\n    if method == \"minimum\":\n        return _threshold_minimum\n    if method == \"yen\":\n        return _threshold_yen\n    if method == \"triangle\":\n        return _threshold_triangle\n    raise ValueError(method)\n</code></pre>"},{"location":"api/thresholds/#topostats.thresholds._threshold_mean","title":"<code>_threshold_mean(image, otsu_threshold_multiplier=None, **kwargs)</code>","text":"<p>Calculate the Mean threshold.</p> <p>For more information see <code>skimage.filters.threshold_mean() &lt;https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.threshold_mean&gt;</code>_.</p>"},{"location":"api/thresholds/#topostats.thresholds._threshold_mean--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D Numpy array of image for thresholding. otsu_threshold_multiplier : float     Factor for scaling (not used). kwargs : dict     Dictionary of keyword arguments to pass to 'skimage.filters.threshold_mean(kwargs)'.</p>"},{"location":"api/thresholds/#topostats.thresholds._threshold_mean--returns","title":"Returns","text":"<p>float     Threshold to be used in masking heights.</p> Source code in <code>topostats/thresholds.py</code> <pre><code>def _threshold_mean(image: npt.NDArray, otsu_threshold_multiplier: float = None, **kwargs) -&gt; float:\n    \"\"\"\n    Calculate the Mean threshold.\n\n    For more information see `skimage.filters.threshold_mean()\n    &lt;https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.threshold_mean&gt;`_.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2-D Numpy array of image for thresholding.\n    otsu_threshold_multiplier : float\n        Factor for scaling (not used).\n    **kwargs : dict\n        Dictionary of keyword arguments to pass to 'skimage.filters.threshold_mean(**kwargs)'.\n\n    Returns\n    -------\n    float\n        Threshold to be used in masking heights.\n    \"\"\"\n    return threshold_mean(image, **kwargs)\n</code></pre>"},{"location":"api/thresholds/#topostats.thresholds._threshold_minimum","title":"<code>_threshold_minimum(image, otsu_threshold_multiplier=None, **kwargs)</code>","text":"<p>Calculate the Minimum threshold.</p> <p>For more information see <code>skimage.filters.threshold_minimum() &lt;https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.threshold_minimum&gt;</code>_.</p>"},{"location":"api/thresholds/#topostats.thresholds._threshold_minimum--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D Numpy array of image for thresholding. otsu_threshold_multiplier : float     Factor for scaling (not used). kwargs : dict     Dictionary of keyword arguments to pass to 'skimage.filters.threshold_minimum(kwargs)'.</p>"},{"location":"api/thresholds/#topostats.thresholds._threshold_minimum--returns","title":"Returns","text":"<p>float     Threshold to be used in masking heights.</p> Source code in <code>topostats/thresholds.py</code> <pre><code>def _threshold_minimum(image: npt.NDArray, otsu_threshold_multiplier: float = None, **kwargs) -&gt; float:\n    \"\"\"\n    Calculate the Minimum threshold.\n\n    For more information see `skimage.filters.threshold_minimum()\n    &lt;https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.threshold_minimum&gt;`_.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2-D Numpy array of image for thresholding.\n    otsu_threshold_multiplier : float\n        Factor for scaling (not used).\n    **kwargs : dict\n        Dictionary of keyword arguments to pass to 'skimage.filters.threshold_minimum(**kwargs)'.\n\n    Returns\n    -------\n    float\n        Threshold to be used in masking heights.\n    \"\"\"\n    return threshold_minimum(image, **kwargs)\n</code></pre>"},{"location":"api/thresholds/#topostats.thresholds._threshold_otsu","title":"<code>_threshold_otsu(image, otsu_threshold_multiplier=None, **kwargs)</code>","text":"<p>Calculate the Otsu threshold.</p> <p>For more information see <code>skimage.filters.threshold_otsu() &lt;https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.threshold_otsu&gt;</code>_.</p>"},{"location":"api/thresholds/#topostats.thresholds._threshold_otsu--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D Numpy array of image for thresholding. otsu_threshold_multiplier : float     Factor for scaling Otsu threshold. kwargs : dict     Dictionary of keyword arguments to pass to 'skimage.filters.threshold_otsu(kwargs)'.</p>"},{"location":"api/thresholds/#topostats.thresholds._threshold_otsu--returns","title":"Returns","text":"<p>float     Threshold to be used in masking heights.</p> Source code in <code>topostats/thresholds.py</code> <pre><code>def _threshold_otsu(image: npt.NDArray, otsu_threshold_multiplier: float = None, **kwargs) -&gt; float:\n    \"\"\"\n    Calculate the Otsu threshold.\n\n    For more information see `skimage.filters.threshold_otsu()\n    &lt;https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.threshold_otsu&gt;`_.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2-D Numpy array of image for thresholding.\n    otsu_threshold_multiplier : float\n        Factor for scaling Otsu threshold.\n    **kwargs : dict\n        Dictionary of keyword arguments to pass to 'skimage.filters.threshold_otsu(**kwargs)'.\n\n    Returns\n    -------\n    float\n        Threshold to be used in masking heights.\n    \"\"\"\n    return threshold_otsu(image, **kwargs) * otsu_threshold_multiplier\n</code></pre>"},{"location":"api/thresholds/#topostats.thresholds._threshold_triangle","title":"<code>_threshold_triangle(image, otsu_threshold_multiplier=None, **kwargs)</code>","text":"<p>Calculate the triangle threshold.</p> <p>For more information see <code>skimage.filters.threshold_triangle() &lt;https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.threshold_triangle&gt;</code>_.</p>"},{"location":"api/thresholds/#topostats.thresholds._threshold_triangle--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D Numpy array of image for thresholding. otsu_threshold_multiplier : float     Factor for scaling (not used). kwargs : dict     Dictionary of keyword arguments to pass to 'skimage.filters.threshold_triangle(kwargs)'.</p>"},{"location":"api/thresholds/#topostats.thresholds._threshold_triangle--returns","title":"Returns","text":"<p>float     Threshold to be used in masking heights.</p> Source code in <code>topostats/thresholds.py</code> <pre><code>def _threshold_triangle(image: npt.NDArray, otsu_threshold_multiplier: float = None, **kwargs) -&gt; float:\n    \"\"\"\n    Calculate the triangle threshold.\n\n    For more information see `skimage.filters.threshold_triangle()\n    &lt;https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.threshold_triangle&gt;`_.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2-D Numpy array of image for thresholding.\n    otsu_threshold_multiplier : float\n        Factor for scaling (not used).\n    **kwargs : dict\n        Dictionary of keyword arguments to pass to 'skimage.filters.threshold_triangle(**kwargs)'.\n\n    Returns\n    -------\n    float\n        Threshold to be used in masking heights.\n    \"\"\"\n    return threshold_triangle(image, **kwargs)\n</code></pre>"},{"location":"api/thresholds/#topostats.thresholds._threshold_yen","title":"<code>_threshold_yen(image, otsu_threshold_multiplier=None, **kwargs)</code>","text":"<p>Calculate the Yen threshold.</p> <p>For more information see <code>skimage.filters.threshold_yen() &lt;https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.threshold_yen&gt;</code>_.</p>"},{"location":"api/thresholds/#topostats.thresholds._threshold_yen--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D Numpy array of image for thresholding. otsu_threshold_multiplier : float     Factor for scaling (not used). kwargs : dict     Dictionary of keyword arguments to pass to 'skimage.filters.threshold_yen(kwargs)'.</p>"},{"location":"api/thresholds/#topostats.thresholds._threshold_yen--returns","title":"Returns","text":"<p>float     Threshold to be used in masking heights.</p> Source code in <code>topostats/thresholds.py</code> <pre><code>def _threshold_yen(image: npt.NDArray, otsu_threshold_multiplier: float = None, **kwargs) -&gt; float:\n    \"\"\"\n    Calculate the Yen threshold.\n\n    For more information see `skimage.filters.threshold_yen()\n    &lt;https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.threshold_yen&gt;`_.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2-D Numpy array of image for thresholding.\n    otsu_threshold_multiplier : float\n        Factor for scaling (not used).\n    **kwargs : dict\n        Dictionary of keyword arguments to pass to 'skimage.filters.threshold_yen(**kwargs)'.\n\n    Returns\n    -------\n    float\n        Threshold to be used in masking heights.\n    \"\"\"\n    return threshold_yen(image, **kwargs)\n</code></pre>"},{"location":"api/thresholds/#topostats.thresholds.threshold","title":"<code>threshold(image, method=None, otsu_threshold_multiplier=None, **kwargs)</code>","text":"<p>Thresholding for producing masks.</p>"},{"location":"api/thresholds/#topostats.thresholds.threshold--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2-D Numpy array of image for thresholding. method : str     Method to use for thresholding, currently supported methods are otsu (default), mean and minimum. otsu_threshold_multiplier : float     Factor for scaling the Otsu threshold. **kwargs : dict     Additional keyword arguments to pass to skimage methods.</p>"},{"location":"api/thresholds/#topostats.thresholds.threshold--returns","title":"Returns","text":"<p>float     Threshold of image using specified method.</p> Source code in <code>topostats/thresholds.py</code> <pre><code>def threshold(image: npt.NDArray, method: str = None, otsu_threshold_multiplier: float = None, **kwargs: dict) -&gt; float:\n    \"\"\"\n    Thresholding for producing masks.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2-D Numpy array of image for thresholding.\n    method : str\n        Method to use for thresholding, currently supported methods are otsu (default), mean and minimum.\n    otsu_threshold_multiplier : float\n        Factor for scaling the Otsu threshold.\n    **kwargs : dict\n        Additional keyword arguments to pass to skimage methods.\n\n    Returns\n    -------\n    float\n        Threshold of image using specified method.\n    \"\"\"\n    thresholder = _get_threshold(method)\n    return thresholder(image, otsu_threshold_multiplier=otsu_threshold_multiplier, **kwargs)\n</code></pre>"},{"location":"api/utils/","title":"Utils Modules","text":"<p>Utilities.</p>"},{"location":"api/utils/#topostats.utils.ResolutionError","title":"<code>ResolutionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when the image resolution is too small for accuurate tracing.</p> Source code in <code>topostats/utils.py</code> <pre><code>class ResolutionError(Exception):\n    \"\"\"Raised when the image resolution is too small for accuurate tracing.\"\"\"\n\n    pass  # pylint: disable=unnecessary-pass\n</code></pre>"},{"location":"api/utils/#topostats.utils._get_mask","title":"<code>_get_mask(image, thresh, threshold_direction, img_name=None)</code>","text":"<p>Calculate a mask for pixels that exceed the threshold.</p>"},{"location":"api/utils/#topostats.utils._get_mask--parameters","title":"Parameters","text":"<p>image : np.array     Numpy array representing image. thresh : float     A float representing the threshold. threshold_direction : str     A string representing the direction that should be thresholded. (\"above\", \"below\"). img_name : str     Name of image being processed.</p>"},{"location":"api/utils/#topostats.utils._get_mask--returns","title":"Returns","text":"<p>npt.NDArray     Numpy array of image with objects coloured.</p> Source code in <code>topostats/utils.py</code> <pre><code>def _get_mask(image: npt.NDArray, thresh: float, threshold_direction: str, img_name: str = None) -&gt; npt.NDArray:\n    \"\"\"\n    Calculate a mask for pixels that exceed the threshold.\n\n    Parameters\n    ----------\n    image : np.array\n        Numpy array representing image.\n    thresh : float\n        A float representing the threshold.\n    threshold_direction : str\n        A string representing the direction that should be thresholded. (\"above\", \"below\").\n    img_name : str\n        Name of image being processed.\n\n    Returns\n    -------\n    npt.NDArray\n        Numpy array of image with objects coloured.\n    \"\"\"\n    if threshold_direction == \"above\":\n        LOGGER.debug(f\"[{img_name}] : Masking (above) Threshold: {thresh}\")\n        return image &gt; thresh\n    LOGGER.debug(f\"[{img_name}] : Masking (below) Threshold: {thresh}\")\n    return image &lt; thresh\n</code></pre>"},{"location":"api/utils/#topostats.utils.bound_padded_coordinates_to_image","title":"<code>bound_padded_coordinates_to_image(coordinates, padding, image_shape)</code>","text":"<p>Ensure the padding of coordinates points does not fall outside of the image shape.</p> <p>This function is primarily used in the dnaTrace.get_fitted_traces() method which aims to adjust the points of a skeleton to sit on the highest points of a traced molecule. In order to do so it takes the ordered skeleton, which may not lie on the highest points as it is generated from a binary mask that is unaware of the heights, and then defines a padded boundary of 3nm profile perpendicular to the backbone of the DNA (which at this point is the skeleton based on a mask). Each point along the skeleton therefore needs padding by a minimum of 2 pixels (in this case each pixel equates to a cell in a NumPy array). If a point is within 2 pixels (i.e. 2 cells) of the border then we can not pad beyond this region, we have to stop at the edge of the image and so the coordinates is adjusted such that the padding will lie on the edge of the image/array.</p>"},{"location":"api/utils/#topostats.utils.bound_padded_coordinates_to_image--parameters","title":"Parameters","text":"<p>coordinates : npt.NDArray     Coordinates of a point on the mask based skeleton. padding : int     Number of pixels/cells to pad around the point. image_shape : tuple     The shape of the original image from which the pixel is obtained.</p>"},{"location":"api/utils/#topostats.utils.bound_padded_coordinates_to_image--returns","title":"Returns","text":"<p>tuple     Returns a tuple of coordinates that ensure that when the point is padded by the noted padding width in     subsequent calculations it will not be outside of the image shape.</p> Source code in <code>topostats/utils.py</code> <pre><code>def bound_padded_coordinates_to_image(coordinates: npt.NDArray, padding: int, image_shape: tuple) -&gt; tuple:\n    \"\"\"\n    Ensure the padding of coordinates points does not fall outside of the image shape.\n\n    This function is primarily used in the dnaTrace.get_fitted_traces() method which aims to adjust the points of a\n    skeleton to sit on the highest points of a traced molecule. In order to do so it takes the ordered skeleton, which\n    may not lie on the highest points as it is generated from a binary mask that is unaware of the heights, and then\n    defines a padded boundary of 3nm profile perpendicular to the backbone of the DNA (which at this point is the\n    skeleton based on a mask). Each point along the skeleton therefore needs padding by a minimum of 2 pixels (in this\n    case each pixel equates to a cell in a NumPy array). If a point is within 2 pixels (i.e. 2 cells) of the border then\n    we can not pad beyond this region, we have to stop at the edge of the image and so the coordinates is adjusted such\n    that the padding will lie on the edge of the image/array.\n\n    Parameters\n    ----------\n    coordinates : npt.NDArray\n        Coordinates of a point on the mask based skeleton.\n    padding : int\n        Number of pixels/cells to pad around the point.\n    image_shape : tuple\n        The shape of the original image from which the pixel is obtained.\n\n    Returns\n    -------\n    tuple\n        Returns a tuple of coordinates that ensure that when the point is padded by the noted padding width in\n        subsequent calculations it will not be outside of the image shape.\n    \"\"\"\n    # Calculate the maximum row and column indexes\n    max_row = image_shape[0] - 1\n    max_col = image_shape[1] - 1\n    row_coord, col_coord = coordinates\n\n    def check(coord: npt.NDArray, max_val: int, padding: int) -&gt; npt.NDArray:\n        \"\"\"\n        Check coordinates are within the bounds of the padding.\n\n        Parameters\n        ----------\n        coord : npt.NDArray\n            Coordinates (length = 2).\n        max_val : int\n            Maximum width in the dimension being checked (max_row or max_col).\n        padding : int\n            Padding used in the image.\n\n        Returns\n        -------\n        npt.NDArray\n            Coordinates adjusted for padding.\n        \"\"\"\n        if coord - padding &lt; 0:\n            coord = padding\n        elif coord + padding &gt; max_val:\n            coord = max_val - padding\n        return coord\n\n    return check(row_coord, max_row, padding), check(col_coord, max_col, padding)\n</code></pre>"},{"location":"api/utils/#topostats.utils.convert_path","title":"<code>convert_path(path)</code>","text":"<p>Ensure path is Path object.</p>"},{"location":"api/utils/#topostats.utils.convert_path--parameters","title":"Parameters","text":"<p>path : str | Path     Path to be converted.</p>"},{"location":"api/utils/#topostats.utils.convert_path--returns","title":"Returns","text":"<p>Path     Pathlib object of path.</p> Source code in <code>topostats/utils.py</code> <pre><code>def convert_path(path: str | Path) -&gt; Path:\n    \"\"\"\n    Ensure path is Path object.\n\n    Parameters\n    ----------\n    path : str | Path\n        Path to be converted.\n\n    Returns\n    -------\n    Path\n        Pathlib object of path.\n    \"\"\"\n    return Path().cwd() if path == \"./\" else Path(path).expanduser()\n</code></pre>"},{"location":"api/utils/#topostats.utils.convolve_skeleton","title":"<code>convolve_skeleton(skeleton)</code>","text":"<p>Convolve skeleton with a 3x3 kernel.</p> <p>This produces an array where the branches of the skeleton are denoted with '1', endpoints are denoted as '2', and pixels at nodes as '3'.</p>"},{"location":"api/utils/#topostats.utils.convolve_skeleton--parameters","title":"Parameters","text":"<p>skeleton : npt.NDArray     Single pixel thick binary trace(s) within an array.</p>"},{"location":"api/utils/#topostats.utils.convolve_skeleton--returns","title":"Returns","text":"<p>npt.NDArray     The skeleton (=1) with endpoints (=2), and crossings (=3) highlighted.</p> Source code in <code>topostats/utils.py</code> <pre><code>def convolve_skeleton(skeleton: npt.NDArray) -&gt; npt.NDArray:\n    \"\"\"\n    Convolve skeleton with a 3x3 kernel.\n\n    This produces an array where the branches of the skeleton are denoted with '1', endpoints are denoted as '2', and\n    pixels at nodes as '3'.\n\n    Parameters\n    ----------\n    skeleton : npt.NDArray\n        Single pixel thick binary trace(s) within an array.\n\n    Returns\n    -------\n    npt.NDArray\n        The skeleton (=1) with endpoints (=2), and crossings (=3) highlighted.\n    \"\"\"\n    conv = convolve(skeleton.astype(np.int32), np.ones((3, 3)))\n    conv[skeleton == 0] = 0  # remove non-skeleton points\n    conv[conv == 3] = 1  # skelly = 1\n    conv[conv &gt; 3] = 3  # nodes = 3\n    return conv\n</code></pre>"},{"location":"api/utils/#topostats.utils.coords_2_img","title":"<code>coords_2_img(coords, image, ordered=False)</code>","text":"<p>Convert coordinates to a binary image.</p>"},{"location":"api/utils/#topostats.utils.coords_2_img--parameters","title":"Parameters","text":"<p>coords : np.ndarray     An array of 2xN integer coordinates. image : np.ndarray     An MxL array to assign the above coordinates onto. ordered : bool, optional     If True, increments the value of each coord to show order.</p>"},{"location":"api/utils/#topostats.utils.coords_2_img--returns","title":"Returns","text":"<p>np.ndarray     An array the same shape as 'image' with the coordinates highlighted.</p> Source code in <code>topostats/utils.py</code> <pre><code>def coords_2_img(coords, image, ordered=False) -&gt; np.ndarray:\n    \"\"\"\n    Convert coordinates to a binary image.\n\n    Parameters\n    ----------\n    coords : np.ndarray\n        An array of 2xN integer coordinates.\n    image : np.ndarray\n        An MxL array to assign the above coordinates onto.\n    ordered : bool, optional\n        If True, increments the value of each coord to show order.\n\n    Returns\n    -------\n    np.ndarray\n        An array the same shape as 'image' with the coordinates highlighted.\n    \"\"\"\n    comb = np.zeros_like(image)\n    if ordered:\n        comb[coords[:, 0].astype(np.int32), coords[:, 1].astype(np.int32)] = np.arange(1, len(coords) + 1)\n    else:\n        coords = coords[\n            (coords[:, 0] &lt; image.shape[0]) &amp; (coords[:, 1] &lt; image.shape[1]) &amp; (coords[:, 0] &gt; 0) &amp; (coords[:, 1] &gt; 0)\n        ]\n        comb[np.floor(coords[:, 0]).astype(np.int32), np.floor(coords[:, 1]).astype(np.int32)] = 1\n    return comb\n</code></pre>"},{"location":"api/utils/#topostats.utils.create_empty_dataframe","title":"<code>create_empty_dataframe(column_set='grainstats', index_col='grain_number')</code>","text":"<p>Create an empty data frame for returning when no results are found.</p>"},{"location":"api/utils/#topostats.utils.create_empty_dataframe--parameters","title":"Parameters","text":"<p>column_set : str     The name of the set of columns for the empty dataframe. index_col : str     Column to set as index of empty dataframe.</p>"},{"location":"api/utils/#topostats.utils.create_empty_dataframe--returns","title":"Returns","text":"<p>pd.DataFrame     Empty Pandas DataFrame.</p> Source code in <code>topostats/utils.py</code> <pre><code>def create_empty_dataframe(column_set: str = \"grainstats\", index_col: str = \"grain_number\") -&gt; pd.DataFrame:\n    \"\"\"\n    Create an empty data frame for returning when no results are found.\n\n    Parameters\n    ----------\n    column_set : str\n        The name of the set of columns for the empty dataframe.\n    index_col : str\n        Column to set as index of empty dataframe.\n\n    Returns\n    -------\n    pd.DataFrame\n        Empty Pandas DataFrame.\n    \"\"\"\n    empty_df = pd.DataFrame(columns=COLUMN_SETS[column_set])\n    return empty_df.set_index(index_col)\n</code></pre>"},{"location":"api/utils/#topostats.utils.get_mask","title":"<code>get_mask(image, thresholds, img_name=None)</code>","text":"<p>Mask data that should not be included in flattening.</p>"},{"location":"api/utils/#topostats.utils.get_mask--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2D Numpy array of the image to have a mask derived for. thresholds : dict     Dictionary of thresholds, at a bare minimum must have key 'below' with an associated value, second key is     to have an 'above' threshold. img_name : str     Image name that is being masked.</p>"},{"location":"api/utils/#topostats.utils.get_mask--returns","title":"Returns","text":"<p>npt.NDArray     2D Numpy boolean array of points to mask.</p> Source code in <code>topostats/utils.py</code> <pre><code>def get_mask(image: npt.NDArray, thresholds: dict, img_name: str = None) -&gt; npt.NDArray:\n    \"\"\"\n    Mask data that should not be included in flattening.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2D Numpy array of the image to have a mask derived for.\n    thresholds : dict\n        Dictionary of thresholds, at a bare minimum must have key 'below' with an associated value, second key is\n        to have an 'above' threshold.\n    img_name : str\n        Image name that is being masked.\n\n    Returns\n    -------\n    npt.NDArray\n        2D Numpy boolean array of points to mask.\n    \"\"\"\n    # Both thresholds are applicable\n    if \"below\" in thresholds and \"above\" in thresholds:\n        mask_above = _get_mask(image, thresh=thresholds[\"above\"], threshold_direction=\"above\", img_name=img_name)\n        mask_below = _get_mask(image, thresh=thresholds[\"below\"], threshold_direction=\"below\", img_name=img_name)\n        # Masks are combined to remove both the extreme high and extreme low data points.\n        return mask_above + mask_below\n    # Only below threshold is applicable\n    if \"below\" in thresholds:\n        return _get_mask(image, thresh=thresholds[\"below\"], threshold_direction=\"below\", img_name=img_name)\n    # Only above threshold is applicable\n    return _get_mask(image, thresh=thresholds[\"above\"], threshold_direction=\"above\", img_name=img_name)\n</code></pre>"},{"location":"api/utils/#topostats.utils.get_thresholds","title":"<code>get_thresholds(image, threshold_method, otsu_threshold_multiplier=None, threshold_std_dev=None, absolute=None, **kwargs)</code>","text":"<p>Obtain thresholds for masking data points.</p>"},{"location":"api/utils/#topostats.utils.get_thresholds--parameters","title":"Parameters","text":"<p>image : npt.NDArray     2D Numpy array of image to be masked. threshold_method : str     Method for thresholding, 'otsu', 'std_dev' or 'absolute' are valid options. otsu_threshold_multiplier : float     Scaling value for Otsu threshold. threshold_std_dev : dict     Dict of above and below thresholds for the standard deviation method. absolute : tuple     Dict of below and above thresholds. kwargs :     Dictionary passed to 'topostats.threshold(kwargs)'.</p>"},{"location":"api/utils/#topostats.utils.get_thresholds--returns","title":"Returns","text":"<p>dict     Dictionary of thresholds, contains keys 'below' and optionally 'above'.</p> Source code in <code>topostats/utils.py</code> <pre><code>def get_thresholds(  # noqa: C901\n    image: npt.NDArray,\n    threshold_method: str,\n    otsu_threshold_multiplier: float = None,\n    threshold_std_dev: dict = None,\n    absolute: dict = None,\n    **kwargs,\n) -&gt; dict:\n    \"\"\"\n    Obtain thresholds for masking data points.\n\n    Parameters\n    ----------\n    image : npt.NDArray\n        2D Numpy array of image to be masked.\n    threshold_method : str\n        Method for thresholding, 'otsu', 'std_dev' or 'absolute' are valid options.\n    otsu_threshold_multiplier : float\n        Scaling value for Otsu threshold.\n    threshold_std_dev : dict\n        Dict of above and below thresholds for the standard deviation method.\n    absolute : tuple\n        Dict of below and above thresholds.\n    **kwargs :\n        Dictionary passed to 'topostats.threshold(**kwargs)'.\n\n    Returns\n    -------\n    dict\n        Dictionary of thresholds, contains keys 'below' and optionally 'above'.\n    \"\"\"\n    thresholds = defaultdict()\n    if threshold_method == \"otsu\":\n        thresholds[\"above\"] = threshold(image, method=\"otsu\", otsu_threshold_multiplier=otsu_threshold_multiplier)\n    elif threshold_method == \"std_dev\":\n        try:\n            if threshold_std_dev[\"below\"] is not None:\n                thresholds[\"below\"] = threshold(image, method=\"mean\") - threshold_std_dev[\"below\"] * np.nanstd(image)\n            if threshold_std_dev[\"above\"] is not None:\n                thresholds[\"above\"] = threshold(image, method=\"mean\") + threshold_std_dev[\"above\"] * np.nanstd(image)\n        except TypeError as typeerror:\n            raise typeerror\n    elif threshold_method == \"absolute\":\n        if absolute[\"below\"] is not None:\n            thresholds[\"below\"] = absolute[\"below\"]\n        if absolute[\"above\"] is not None:\n            thresholds[\"above\"] = absolute[\"above\"]\n    else:\n        if not isinstance(threshold_method, str):\n            raise TypeError(\n                f\"threshold_method ({threshold_method}) should be a string. Valid values : 'otsu' 'std_dev' 'absolute'\"\n            )\n        if threshold_method not in [\"otsu\", \"std_dev\", \"absolute\"]:\n            raise ValueError(\n                f\"threshold_method ({threshold_method}) is invalid. Valid values : 'otsu' 'std_dev' 'absolute'\"\n            )\n    return thresholds\n</code></pre>"},{"location":"api/utils/#topostats.utils.update_config","title":"<code>update_config(config, args)</code>","text":"<p>Update the configuration with any arguments.</p>"},{"location":"api/utils/#topostats.utils.update_config--parameters","title":"Parameters","text":"<p>config : dict     Dictionary of configuration (typically read from YAML file specified with '-c/--config '). args : Namespace     Command line arguments."},{"location":"api/utils/#topostats.utils.update_config--returns","title":"Returns","text":"<p>dict     Dictionary updated with command arguments.</p> Source code in <code>topostats/utils.py</code> <pre><code>def update_config(config: dict, args: dict | Namespace) -&gt; dict:\n    \"\"\"\n    Update the configuration with any arguments.\n\n    Parameters\n    ----------\n    config : dict\n        Dictionary of configuration (typically read from YAML file specified with '-c/--config &lt;filename&gt;').\n    args : Namespace\n        Command line arguments.\n\n    Returns\n    -------\n    dict\n        Dictionary updated with command arguments.\n    \"\"\"\n    args = vars(args) if isinstance(args, Namespace) else args\n\n    config_keys = config.keys()\n    for arg_key, arg_value in args.items():\n        if isinstance(arg_value, dict):\n            update_config(config, arg_value)\n        else:\n            if arg_key in config_keys and arg_value is not None:\n                original_value = config[arg_key]\n                config[arg_key] = arg_value\n                LOGGER.debug(f\"Updated config config[{arg_key}] : {original_value} &gt; {arg_value} \")\n    if \"base_dir\" in config.keys():\n        config[\"base_dir\"] = convert_path(config[\"base_dir\"])\n    if \"output_dir\" in config.keys():\n        config[\"output_dir\"] = convert_path(config[\"output_dir\"])\n    return config\n</code></pre> <p>handler: python options: docstring_style: numpy rendering: show_signature_annotations: true</p>"},{"location":"api/utils/#topostats.utils.update_plotting_config","title":"<code>update_plotting_config(plotting_config)</code>","text":"<p>Update the plotting config for each of the plots in plot_dict.</p> <p>Ensures that each entry has all the plotting configuration values that are needed.</p>"},{"location":"api/utils/#topostats.utils.update_plotting_config--parameters","title":"Parameters","text":"<p>plotting_config : dict     Plotting configuration to be updated.</p>"},{"location":"api/utils/#topostats.utils.update_plotting_config--returns","title":"Returns","text":"<p>dict     Updated plotting configuration.</p> Source code in <code>topostats/utils.py</code> <pre><code>def update_plotting_config(plotting_config: dict) -&gt; dict:\n    \"\"\"\n    Update the plotting config for each of the plots in plot_dict.\n\n    Ensures that each entry has all the plotting configuration values that are needed.\n\n    Parameters\n    ----------\n    plotting_config : dict\n        Plotting configuration to be updated.\n\n    Returns\n    -------\n    dict\n        Updated plotting configuration.\n    \"\"\"\n    main_config = plotting_config.copy()\n    for opt in [\"plot_dict\", \"run\"]:\n        main_config.pop(opt)\n    LOGGER.debug(\n        f\"Main plotting options that need updating/adding to plotting dict :\\n{pformat(main_config, indent=4)}\"\n    )\n    for image, options in plotting_config[\"plot_dict\"].items():\n        main_config_temp = main_config.copy()\n        LOGGER.debug(f\"Dictionary for image : {image}\")\n        LOGGER.debug(f\"{pformat(options, indent=4)}\")\n        # First update options with values that exist in main_config\n        # We must however be careful not to update the colourmap for diagnostic traces\n        if (\n            not plotting_config[\"plot_dict\"][image][\"core_set\"]\n            and \"mask_cmap\" in plotting_config[\"plot_dict\"][image].keys()\n        ):\n            main_config_temp.pop(\"mask_cmap\")\n        plotting_config[\"plot_dict\"][image] = update_config(options, main_config_temp)\n        LOGGER.debug(f\"Updated values :\\n{pformat(plotting_config['plot_dict'][image])}\")\n        # Then combine the remaining key/values we need from main_config that don't already exist\n        for key_main, value_main in main_config_temp.items():\n            if key_main not in plotting_config[\"plot_dict\"][image]:\n                plotting_config[\"plot_dict\"][image][key_main] = value_main\n        LOGGER.debug(f\"After adding missing configuration options :\\n{pformat(plotting_config['plot_dict'][image])}\")\n        # Make it so that binary images do not have the user-defined z-scale\n        # applied, but non-binary images do.\n        if plotting_config[\"plot_dict\"][image][\"image_type\"] == \"binary\":\n            plotting_config[\"plot_dict\"][image][\"zrange\"] = [None, None]\n\n    return plotting_config\n</code></pre>"},{"location":"api/validation/","title":"Validation Module","text":"<p>Validation of configuration.</p> <p>handler: python options: docstring_style: numpy rendering: show_signature_annotations: true</p>"},{"location":"api/validation/#topostats.validation.validate_config","title":"<code>validate_config(config, schema, config_type)</code>","text":"<p>Validate configuration.</p>"},{"location":"api/validation/#topostats.validation.validate_config--parameters","title":"Parameters","text":"<p>config : dict     Config dictionary imported by read_yaml() and parsed through clean_config(). schema : Schema     A schema against which the configuration is to be compared. config_type : str     Description of of configuration being validated.</p> Source code in <code>topostats/validation.py</code> <pre><code>def validate_config(config: dict, schema: Schema, config_type: str) -&gt; None:\n    \"\"\"\n    Validate configuration.\n\n    Parameters\n    ----------\n    config : dict\n        Config dictionary imported by read_yaml() and parsed through clean_config().\n    schema : Schema\n        A schema against which the configuration is to be compared.\n    config_type : str\n        Description of of configuration being validated.\n    \"\"\"\n    try:\n        schema.validate(config)\n        LOGGER.info(f\"The {config_type} is valid.\")\n    except SchemaError as schema_error:\n        raise SchemaError(\n            f\"There is an error in your {config_type} configuration. \"\n            \"Please refer to the first error message above for details\"\n        ) from schema_error\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>This document describes how to contribute to the development of this software.</p>"},{"location":"contributing/#contribution-workflow","title":"Contribution Workflow","text":""},{"location":"contributing/#create-an-issue","title":"Create an Issue","text":"<p>Before starting please search for and review the existing issues (both <code>open</code> and <code>closed</code>) and pull requests to see if anyone has reported the bug or requested the feature already or work is in progress. If nothing exists then you should create a new issue using one of the templates provided.</p>"},{"location":"contributing/#cloning-the-repository","title":"Cloning the repository","text":"<p>If you wish to make changes yourself you will have to fork the repository to your own account and then clone that if you are not a member of AFM-SPM Organisation. If you are a member then you can clone the repository and make contributions directly.</p> <pre><code># Member of AFM-SPM Organisation\ngit clone git@github.com:AFM-SPM/TopoStats.git\n# Non-member of AFM-SPM cloning fork\ngit clone git@github.com:&lt;YOUR_GITHUB_USERNAME&gt;/TopoStats.git\n</code></pre>"},{"location":"contributing/#install-additional-dependencies","title":"Install Additional Dependencies","text":"<p>If you are going to contribute you should install the additional dependencies for undertaking such work. There are three groups of additional dependencies, <code>dev</code>, <code>docs</code> and <code>tests</code> and you should install all three using <code>pip</code> as shown below.</p> <pre><code>cd TopoStats\npip install \".[dev,docs,tests]\"\n</code></pre>"},{"location":"contributing/#creating-a-branch","title":"Creating a branch","text":"<p>Typically you will now create a branch to work on the issue you wish to address. It is not compulsory but we try to use a consistent nomenclature for branches that shows who has worked on the branch, the issue it pertains to and a short description of the work. To which end you will see branches with the form <code>&lt;GITHUB_USERNAME&gt;/&lt;GITHUB_ISSUE&gt;-&lt;DESCRIPTION&gt;</code>. Some examples are shown below...</p> Branch User Issue Description <code>ns-rse/259-contributing</code> <code>ns-rse</code> 259 <code>contributing</code> is short for the issue subject Add contributing section to documentation. <code>SylviaWhittle/204-nanometre-scaling</code> <code>SylviaWhittle</code> 204 <code>nanometre-scaling</code> is short for the issue subject Colour scale in nanometers not pixels. <p>How you create a branch depends on how you use Git, some use the integration provided by their IDE, others dedicated clients such as GitKraken and some may use the command line interface. These instructions use the later but you are of course free to use your chosen method of managing Git and GitHub.</p> <p>In this example we branch from <code>dev</code> and create a new branch called <code>ns-rse/000-fix-an-issue</code>.</p> <pre><code># Ensure you are up-to-date on the main branch\ngit checkout main\ngit pull\n# Create and checkout a branch in one step\ngit checkout -b ns-rse/000-fix-an-issue\n# Create and checkout a branch in two steps\ngit branch dev ns-rse/000-fix-an-issue\ngit checkout ns-rse/000-fix-an-issue\n</code></pre> <p>You can now start working on your issue and making regular commits, but please bear in mind the following section on Coding Standards.</p>"},{"location":"contributing/#software-development","title":"Software Development","text":"<p>To make the codebase easier to maintain we ask that you follow the guidelines below on coding style, linting, typing, documentation and testing. These entail a number of additional dependencies that can be installed with the following command.</p> <pre><code>pip install -e .[dev,tests,docs]\n</code></pre> <p>This will pull in all the dependencies we use for development (<code>dev</code>), tests (<code>tests</code>) and writing documentation (<code>docs</code>)</p>"},{"location":"contributing/#coding-stylelinting","title":"Coding Style/Linting","text":"<p>Using a consistent coding style has many benefits (see Linting : What is all the fluff about?). For this project we aim to adhere to PEP8 - the style Guide for Python Code and do so using the formatting linters black and ruff. Ruff implements the checks made by Flake8, isort and pydocstyle and has some overlap with both Black and Pylint.</p> <p>We also like to ensure the code passes pylint which helps identify code duplication and reduces some of the code smells that we are all prone to making. A <code>.pylintrc</code> is included in the repository. Currently this isn't strictly applied but it is planned for part of the CI/CD pipeline and so we would be grateful if you could lint your code before making Pull Requests.</p> <p>Many popular IDEs such as VSCode, PyCharm, Spyder and Emacs all have support for integrating these linters into your workflow such that when you save a file the linting/formatting is automatically applied.</p>"},{"location":"contributing/#pre-commit","title":"Pre-commit","text":"<p>pre-commit is a powerful and useful tool that runs hooks on your code prior to making commits. For a more detailed exposition see pre-commit : Protecting your future self.</p> <p>The repository includes <code>pre-commit</code> as a development dependency as well as a <code>.pre-commit-config.yaml</code>. To use these locally you should have already installed all the <code>dev</code> dependencies in your virtual environment. You then need to install <code>pre-commit</code> configuration and hooks (NB this will download specific virtual environments that <code>pre-commit</code> uses when running hooks so the first time this is run may take a little while).</p> <pre><code>pre-commit install --install-hooks\n</code></pre> <p>Currently there are hooks to remove trailing whitespace, check YAML configuration files and a few other common checks as well as hooks for <code>black</code> and <code>ruff</code>. If these fail then you will not be able to make a commit until they are fixed. The <code>black</code> hook will automatically format failed files so you can simply <code>git add</code> those and try committing straight away. <code>flake8</code> does not correct files automatically so the errors will need manually correcting.</p> <p>If you do not enable and resolve issues reported by <code>pre-commit</code> locally before making a pull request you will find the <code>pre-commit.ci</code> GitHub Action will fail, preventing your Pull Request from being merged. You can shorten the feedback loop and speed up the resolution of errors by enabling <code>pre-commit</code> locally and resolving issues before making your commits.</p>"},{"location":"contributing/#typing","title":"Typing","text":"<p>Whilst Python is a dynamically typed language (that is the type of an object is determined dynamically) the use of Type Hints is strongly encouraged as it makes reading and understanding the code considerably easier for contributors. For more on Type Hints see PEP483 and PEP484</p>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>All classes, methods and functions should have Numpy Docstrings defining their functionality, parameters and return values and pylint will note and report the absence of docstrings by way of the <code>missing-function-docstring</code> condition.</p> <p>Further, when new methods are incorporated into the package that introduce changes to the configuration they should be documented under Parameter Configuration. pre-commit has the markdownlint-cli2 hook enabled to lint all Markdown files and will where possible automatically fix things, but some issues need resolving manually.</p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>New features should have unit-tests written and included under the <code>tests/</code> directory to ensure the functions work as expected. The pytest framework is used for running tests along with a number of plugins (pytest-regtest for regression testing; pytest-mpl for testing generated Matplotlib images).</p> <p>In conjunction with pre-commit we leverage pytest-testmon to run tests on each commit, but as the test suite is large and can take a while to run <code>pytest-testmon</code> restricts tests to only files that have changed (code or tests) or changes in environment variables and dependencies. You will need to create a database locally on first run and so should run the following before undertaking any development.</p> <pre><code>pytest --testmon\n</code></pre> <p>This will create a database (<code>.testmondata</code>) which tracks the current state of the repository, this file is ignored by Git (via <code>.gitignore</code>) but keeps track of the state of the repository and what has changed so that the <code>pre-commit</code> hook <code>Pytest (testmon)</code> only attempts to run the tests when changes have been made to files that impact the tests.</p>"},{"location":"contributing/#debugging","title":"Debugging","text":"<p>To aid with debugging we include the snoop package. The package is disabled by default, but when you have a class, method or function you wish to debug you should add <code>snoop.install(enabled=True)</code> to the file you wish to debug and use the <code>@snoop</code> decorator around the function/method you wish to debug.</p>"},{"location":"contributing/#configuration","title":"Configuration","text":"<p>As described in Parameter Configuration options are primarily passed to TopoStats via a YAML configuration file. When introducing new features that require configuration options you will have to ensure that the default configuration file (<code>topostats/default.yaml</code>) is updated to include your options.</p> <p>Further the <code>topostats.validation.validate.config()</code> function, which checks a valid configuration file with all necessary fields has been passed when invoking <code>topostats</code> sub-commands, will also need updating to include new options in the Schema against which validation of configuration files is made.</p>"},{"location":"contributing/#ide-configuration","title":"IDE Configuration","text":"<p>Linters such as <code>black</code>, <code>flake8</code> and <code>pylint</code> can be configured to work with your IDE so that say Black and/or formatting is applied on saving a file or the code is analysed with <code>pylint</code> on saving and errors reported. Setting up and configuring IDEs to work in this manner is beyond the scope of this document but some links to articles on how to do so are provided.</p> <ul> <li>Linting Python in Visual Studio Code</li> <li>Code Analysis \u2014 Spyder for <code>pylint</code> for Black see How to use   code formatter Black with Spyder.</li> <li>Code Quality Assistance Tips and Tricks, or How to Make Your Code Look Pretty? |   PyCharm</li> <li>Reformat and rearrange code | PyCharm</li> </ul>"},{"location":"contributing/adding_modules/","title":"Adding Modules","text":""},{"location":"contributing/adding_modules/#basic-functionality","title":"Basic Functionality","text":"<p>This should reside in <code>topostats/</code> or optionally <code>topostats/&lt;sub_dir&gt;</code></p> <p>Unit tests should be written for each function, classes and method and integration tests to ensure the overall functionality is as expected now and in the future should refactoring be undertaken.</p>"},{"location":"contributing/adding_modules/#adding-configuration","title":"Adding configuration","text":"<p>Configuration options live in <code>topostats/default_config.yaml</code> you should create a nested object for the options corresponding to your module. The configuration nomenclature should match exactly the options of your modules class/function as this allows the <code>**kwargs</code> to be used to pass the options from the loaded dictionary to the function without having to explicitly map them to the class/function arguments. This might seem fickle or excessive but it saves you and others work in the long run.</p>"},{"location":"contributing/adding_modules/#modularity","title":"Modularity","text":"<p>TopoStats is a command line program (for now at least!) and the main command <code>topsotats</code> has sub-commands which allow individual steps of the processing to be undertaken, making it faster to test out the impact of different options. For example once loaded and saved as <code>.topostats</code> files the <code>filter</code> stage could be re-run to improve flattening. Once flattening is complete changes in configuration could be made to detect different grains or features using the already flattened images.</p> <p>Once you have a module that works it should ideally be included in this pipeline. Here we described how to include it.</p>"},{"location":"contributing/adding_modules/#processing","title":"Processing","text":"<p>Each module needs a processing function. This is defined the <code>topostats/processing.py</code> module and should be called from the <code>process_all()</code> function to include it in the end to end pipeline.</p>"},{"location":"contributing/adding_modules/#process_all","title":"<code>process_all</code>","text":"<p>All of these modules are run in order to process individual images in parallel and this is achieved via the <code>process_all()</code> function which has a parameter for a single image and the configuration dictionary and calls each module in turn.</p> <p>This is run in parallel using the <code>functools.partial()</code> and <code>Pool</code>. The former takes the <code>process_all()</code> function as an argument along with all other configuration options. This is combined with a list of images to be processed and run through the <code>Pool</code> class (see examples below).</p> <p>To add your functionality to this pipeline you should add the calls to your class and its method to the <code>process_all()</code> function.</p>"},{"location":"contributing/adding_modules/#modular-analyses","title":"Modular Analyses","text":"<p>It is however useful to be able to call the function in isolation, this means we can add in sub-commands to <code>topostats</code> so that we can experiment with different configurations without having to run the whole pipeline for all images in one big batch job.</p> <p>As an example we will look at the <code>Filter</code> class and how it is added as a sub-command.</p> <p>The <code>topostats.processing.run_filters()</code> command is the processing command that takes in the various options, instantiates an instance of the <code>Filters()</code> class and runs the various methods required to process the image. There are other classes such as <code>Grains()</code>, <code>Grainstats()</code>, <code>Tracing()</code> which form part of the pipeline.</p>"},{"location":"contributing/adding_modules/#adding-sub-command-arguments","title":"Adding Sub-Command Arguments","text":"<p>You need to add a sub-parser for your module to run it in isolation. To do this entries need to be made to <code>topostats/entry_point.py</code> which sets up <code>argparse</code>. At the top level the <code>create_parser()</code> function is defined where the <code>parser</code> has the main options shown by <code>topostats --help</code> are defined. Each sub-command has its own parser, the most commonly used is <code>process_parser</code> which defines the arguments to and the help shown by <code>topostats process --help</code>. A <code>filter_parser</code> subparser is added which defines the arguments and help shown by <code>topostats filter</code> and this has various arguments added to it with <code>.add_argument()</code>. Note it is important to ensure that the <code>dest</code> for each added argument matches the name used in the <code>default_config.yaml</code> as these values are used to update the loaded dictionary. If the names don't match the values do not get updated (and/or an error will occur).</p> <pre><code># Filter\nfilter_parser = subparsers.add_parser(\n    \"filter\",\n    description=\"Load and filter images, saving as .topostats files for subsequent processing.\",\n    help=\"Load and filter images, saving as .topostats files for subsequent processing.\",\n)\nfilter_parser.add_argument(\n    \"--row-alignment-quantile\",\n    dest=\"row_alignment_quantile\",\n    type=float,\n    required=False,\n    help=\"Lower values may improve flattening of larger features.\",\n)\nfilter_parser.add_argument(\n    \"--threshold-method\",\n    dest=\"threshold_method\",\n    type=str,\n    required=False,\n    help=\"Method for thresholding Filtering. Options are otsu, std_dev, absolute.\",\n)\nfilter_parser.add_argument(\n    \"--otsu-threshold-multiplier\",\n    dest=\"otsu_threshold_multiplier\",\n    type=float,\n    required=False,\n    help=\"Factor for scaling the Otsu threshold during Filtering.\",\n)\nfilter_parser.add_argument(\n    \"--threshold-std-dev-below\",\n    dest=\"threshold_std_dev_below\",\n    type=float,\n    required=False,\n    help=\"Threshold for data below the image background for std dev method during Filtering.\",\n)\n...\nfilter_parser.add_argument(\n    \"--scars-max-scar-length\",\n    dest=\"scars_max_scar_length\",\n    type=int,\n    required=False,\n    help=\"Maximum length of scars in pixels\",\n)\n# Run the relevant function with the arguments\nfilter_parser.set_defaults(func=run_modules.filters)\n</code></pre> <ol> <li>Create a subparser with <code>&lt;module_name&gt;_parser = subparsers.add_parser(...)</code>.</li> <li> <p>Add arguments to subparser with <code>&lt;module_name&gt;_parser.add_argument(...)</code>, include...</p> </li> <li> <p>Single letter flag (optional).</p> </li> <li>Longer flag (required).</li> <li><code>dest</code> the destination to which the variable will be saved. This should match the corresponding value in the   <code>default_config.yaml</code> which makes updating the configuration options straight-forward and will occur automatically   (the code is in place you don't need to add anything, just ensure the names match).</li> <li><code>type</code> should ideally be included as this helps define the type of the stored variable, particularly useful if for   example paths are provided which should be stored as <code>Path</code> pathlib objects.</li> <li><code>default</code> a sensible default value, typically <code>None</code> though so that the value in <code>default_config.yaml</code> is used.</li> <li><code>help</code> a useful description of what the configuration option changes along with possible options.</li> </ol> <ol> <li>Set the default function that will be called with <code>&lt;module_name&gt;_parser.set_defaults(func=run_modules.&lt;function&gt;)</code> which will call the function you have defined in <code>topostats/run_modules.py</code> which runs your module.</li> </ol> <p>NB In the above substitute <code>&lt;module_name&gt;</code> for the meaningful name you have created for your module.</p>"},{"location":"contributing/adding_modules/#running-in-parallel","title":"Running in Parallel","text":"<p>One of the main advantages of TopoStats is the ability to batch process images. As modern computers typically have multiple cores it means the processing can be done in parallel making the processing faster. To achieve this we use wrapper functions in <code>topostats/run_modules.py</code> that leverage the <code>Pool</code> multiprocessing class.</p> <p>Your function should first load the <code>.topostats</code> files you wish to process that are found from the user specified path (default being the current directory <code>./</code>).</p> <p>You then need to define a <code>partial()</code> function with the <code>topostats/processing.py&lt;your_module_processing_function&gt;</code> as the first argument and the remaining configuration options. These will typically be a subset/list from the <code>default_config.yaml</code> where the configuration options use the exact same names as the arguments of the function you defined your <code>topostats/processing.py</code>. As mentioned above keeping configuration names consistent between configuration files and functions means <code>**kwargs</code> can be used when passing options to functions.</p> <p>Continuing with our example let's look at the [<code>topostats.processing.run_filters()</code>][topostats_entry_point_filters] function.</p> <pre><code>def run_filters(\n    unprocessed_image: npt.NDArray,\n    pixel_to_nm_scaling: float,\n    filename: str,\n    filter_out_path: Path,\n    core_out_path: Path,\n    filter_config: dict,\n    plotting_config: dict,\n) -&gt; npt.NDArray | None:\n    \"\"\"\n    Filter and flatten an image. Optionally plots the results, returning the flattened image.\n\n    Parameters\n    ----------\n    unprocessed_image : npt.NDArray\n        Image to be flattened.\n    pixel_to_nm_scaling : float\n        Scaling factor for converting pixel length scales to nanometres.\n        ie the number of pixels per nanometre.\n    filename : str\n        File name for the image.\n    filter_out_path : Path\n        Output directory for step-by-step flattening plots.\n    core_out_path : Path\n        General output directory for outputs such as the flattened image.\n    filter_config : dict\n        Dictionary of configuration for the Filters class to use when initialised.\n    plotting_config : dict\n        Dictionary of configuration for plotting output images.\n\n    Returns\n    -------\n    npt.NDArray | None\n        Either a numpy array of the flattened image, or None if an error occurs or\n        flattening is disabled in the configuration.\n    \"\"\"\n    if filter_config[\"run\"]:\n        filter_config.pop(\"run\")\n        LOGGER.debug(f\"[{filename}] Image dimensions: {unprocessed_image.shape}\")\n        LOGGER.info(f\"[{filename}] : *** Filtering ***\")\n        filters = Filters(\n            image=unprocessed_image,\n            filename=filename,\n            pixel_to_nm_scaling=pixel_to_nm_scaling,\n            **filter_config,\n        )\n        filters.filter_image()\n        # Optionally plot filter stage\n        if plotting_config[\"run\"]:\n            plotting_config.pop(\"run\")\n            LOGGER.info(f\"[{filename}] : Plotting Filtering Images\")\n            if plotting_config[\"image_set\"] == \"all\":\n                filter_out_path.mkdir(parents=True, exist_ok=True)\n                LOGGER.debug(\n                    f\"[{filename}] : Target filter directory created : {filter_out_path}\"\n                )\n            # Generate plots\n            for plot_name, array in filters.images.items():\n                if plot_name not in [\"scan_raw\"]:\n                    if plot_name == \"extracted_channel\":\n                        array = np.flipud(array.pixels)\n                    plotting_config[\"plot_dict\"][plot_name][\"output_dir\"] = (\n                        core_out_path\n                        if plotting_config[\"plot_dict\"][plot_name][\"core_set\"]\n                        else filter_out_path\n                    )\n                    try:\n                        Images(\n                            array, **plotting_config[\"plot_dict\"][plot_name]\n                        ).plot_and_save()\n                        Images(\n                            array, **plotting_config[\"plot_dict\"][plot_name]\n                        ).plot_histogram_and_save()\n                    except AttributeError:\n                        LOGGER.info(\n                            f\"[{filename}] Unable to generate plot : {plot_name}\"\n                        )\n            plotting_config[\"run\"] = True\n        # Always want the 'z_threshed' plot (aka \"Height Thresholded\") but in the core_out_path\n        plot_name = \"z_threshed\"\n        plotting_config[\"plot_dict\"][plot_name][\"output_dir\"] = core_out_path\n        Images(\n            filters.images[\"gaussian_filtered\"],\n            filename=filename,\n            **plotting_config[\"plot_dict\"][plot_name],\n        ).plot_and_save()\n        LOGGER.info(f\"[{filename}] : Filters stage completed successfully.\")\n        return filters.images[\"gaussian_filtered\"]\n    # Otherwise, return None and warn that initial processing is disabled.\n    LOGGER.error(\n        \"You have not included running the initial filter stage. This is required for all subsequent \"\n        \"stages of processing. Please check your configuration file.\"\n    )\n    return None\n</code></pre> <p>This instantiates (creates) the object <code>filters</code> of the class <code>Filters</code> with the supplied options and then runs the <code>filter_image()</code> method to perform the filtering. The rest of the code determines what images to plot based on the configuration. At the end the <code>gaussian_filtered</code> image is returned.</p> <p>This function only processes a single image. As mentioned we use the <code>functools.partial()</code> function to define a function with the command we want to run, in this case <code>topostats.processing.run_filters()</code> (imported as just <code>filters()</code>) as the first argument and then all of the parameters we would normally pass in to <code>filters()</code> as the remainder arguments. This is then used with the <code>Pool</code> class and given a list of the images that are to be processed and the <code>partial</code>ly defined function is run with each image.</p> <p>In our example the <code>run_modules.filters()</code> this looks like the following.</p> <pre><code>def filters(args: argparse.Namespace | None = None) -&gt; None:\n    \"\"\"\n    Load files from disk and run filtering.\n\n    Parameters\n    ----------\n    args : None\n        Arguments.\n    \"\"\"\n    config, img_files = _parse_configuration(args)\n    # If loading existing .topostats files the images need filtering again so we need to extract the raw image\n    if config[\"file_ext\"] == \".topostats\":\n        config[\"loading\"][\"extract\"] = \"raw\"\n    all_scan_data = LoadScans(img_files, **config[\"loading\"])\n    all_scan_data.get_data()\n\n    processing_function = partial(\n        process_filters,\n        base_dir=config[\"base_dir\"],\n        filter_config=config[\"filter\"],\n        plotting_config=config[\"plotting\"],\n        output_dir=config[\"output_dir\"],\n    )\n\n    with Pool(processes=config[\"cores\"]) as pool:\n        results = defaultdict()\n        with tqdm(\n            total=len(img_files),\n            desc=f\"Processing images from {config['base_dir']}, results are under {config['output_dir']}\",\n        ) as pbar:\n            for img, result in pool.imap_unordered(\n                processing_function,\n                all_scan_data.img_dict.values(),\n            ):\n                results[str(img)] = result\n                pbar.update()\n\n                # Display completion message for the image\n                LOGGER.info(f\"[{img}] Filtering completed.\")\n\n    # Write config to file\n    config[\"plotting\"].pop(\"plot_dict\")\n    write_yaml(config, output_dir=config[\"output_dir\"])\n    LOGGER.debug(f\"Images processed : {len(results)}\")\n    # Update config with plotting defaults for printing\n    completion_message(\n        config, img_files, summary_config=None, images_processed=sum(results.values())\n    )\n</code></pre> <p>The files that are to be processed are first loaded to give the list of images that need processing and the <code>partial()</code> function is defined as <code>processing_function</code> with all of the arguments before running in parallel using <code>Pool</code>. The <code>tqdm</code> package is leverage to give a progress bar and after completion the configuration file is written to file before a completion message is run.</p>"},{"location":"contributing/adding_modules/#results","title":"Results","text":"<p>Before we start the parallel processing we create a dictionary <code>results = defaultdict()</code> which will have the results of processing added to. Some steps in processing return more than one object, for example <code>grainstats</code> returns statistics for the image along with height profiles. In such cases we need to instantiate a dictionary to hold each set of results across images and included a holder in the <code>for ... in pool.imap_unordered(...):</code> to store the results before adding the results to the dictionary. For <code>run_modules.grainstats()</code> this looks like the below code. We create two dictionaries <code>results</code> and <code>height_profile_all</code> and in our call for <code>for</code> we have <code>img</code> (a string representing the image name), <code>result</code> (the returned Pandas DataFrame of grain statistics for the given image) and <code>height_profiles</code> (the height profile dictionary for the grains in that image).</p> <pre><code>with Pool(processes=config[\"cores\"]) as pool:\n    results = defaultdict()\n    height_profile_all = defaultdict()\n    with tqdm(\n        total=len(img_files),\n        desc=f\"Processing images from {config['base_dir']}, results are under {config['output_dir']}\",\n    ) as pbar:\n        for img, result, height_profiles in pool.imap_unordered(\n            processing_function,\n            all_scan_data.img_dict.values(),\n        ):\n            results[str(img)] = results\n            height_profile_all[str(img)] = height_profiles\n            pbar.update()\n\n            # Display completion message for the image\n            LOGGER.info(\n                f\"[{img}] Grainstats completed (NB - Filtering was *not* re-run).\"\n            )\n</code></pre> <p>Note that your <code>processing.process_&lt;stage&gt;</code> function which is used in the call to <code>processing_function</code> should return a tuple, the first item of which is the <code>topostats_object[\"filename\"]</code> (which will be stored in <code>img</code> and used as dictionary keys), the remaining items are the results that you expect to be returned.</p>"},{"location":"contributing/adding_modules/#conclusion","title":"Conclusion","text":"<p>Adding functionality is useful but it has to integrate into the workflow and ideally be accessible as a stand alone step in the process. Hopefully the above helps demystify the steps required to achieve this.</p>"},{"location":"usage/","title":"Getting Started","text":"<p>After having installed TopoStats you are ready to run it. For convenience TopoStats provides a command line interface <code>topostats</code> that will load a default configuration file and process all images with reasonable default configuration options.</p> <p>However, because the location of your image files can not be known in advance you must make a copy of the default configuration and modify it to work with your files. This guide will hopefully take you through the process of running TopoStats and customising the configuration file with which it is run. If you encounter any problems please ask questions in the Discussions. If you think you have encountered a bug or have a feature suggestion please create an Issue.</p>"},{"location":"usage/#organising-scans","title":"Organising Scans","text":"<p>You should place all files you wish to batch process in a single directory. They can be nested in separate folders as TopoStats will scan for all images within this directory but currently it will only process one scan type at a time (i.e. <code>.spm</code> or <code>.jpk</code> or <code>.asd</code>). This may change in the future.</p>"},{"location":"usage/#command-line-navigation","title":"Command Line Navigation","text":"<p>TopoStats currently runs as a command-line programme. To use it you will have to use a \"prompt\" or \"terminal\" (they're essentially the same thing). What you use will depend on your operating system, but the following are some simple commands on navigation. If you use Windows then for consistency it is recommended to install and use PowerShell.</p> <p>At the command line you use <code>cd</code> to <code>c</code>hange <code>d</code>irectory to the location of your files. For example if your scans are on the C-drive in <code>C:\\User\\me\\work\\spm\\2022-12-08\\scans</code> then you would</p> <pre><code>cd c:/User/me/work/spm/2022-12-08/scans\n</code></pre> <p>If you are on a Linux or OSX system then paths are not prefixed with letters and your files may be saved to <code>/home/me/work/spm/2022-12-08/scans</code>. To change directory there you would...</p> <pre><code>cd /home/me/work/spm/2022-12-08/scans\n</code></pre> <p>NB - Always use a forward-slash (<code>/</code>) when typing directory paths. Windows will display back-slash (<code>\\</code>) but understands forward-slash. Under Linux and OSX they mean different things and so you should always use forward-slash (<code>/</code>).</p> <p>You can always find out what location you are at in the command line using the <code>pwd</code> command (<code>p</code>rint <code>w</code>orking <code>d</code>irectory) and it will print out the directory you are currently at.</p> <pre><code>pwd\n/home/me/work/spm/2022-12-08/scans\n</code></pre> <p>To navigate up one directory level use <code>cd ..</code>. These can be chained together and directories separated with <code>/</code>.</p> <pre><code># Move up a single directory level\ncd ..\npwd\n/home/me/work/spm/2022-12-08\n# Move up another two directory levels\ncd ../../\npwd\n/home/me/\n</code></pre> <p>You can list the files in a directory using the <code>ls</code> command.</p> <pre><code>ls\nsample_image_scan_2022-12-08-1204.spm\n</code></pre> <p>To learn more about the command line see the Introduction to the Command Line for Genomics.</p>"},{"location":"usage/#running-topostats","title":"Running TopoStats","text":"<p>The default location that TopoStats looks for scans is the directory from which it is invoked. Once you start your shell/terminal you will therefore need to do two things.</p> <ol> <li>Navigate to the location of the scans you wish to process using <code>cd /path/to/where/scans/are/located</code>.</li> <li>Activate the virtual environment under which you installed TopoStats (refer to installed if unsure).</li> </ol> <p>You can now run topostats by invoking <code>topostats process</code> and you should start to see some output similar to that below.</p> <pre><code>cd /path/to/where/scans/are/located\ntopostats process\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Configuration is valid.\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Plotting configuration is valid.\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Configuration file loaded from      : None\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Scanning for images in              : /home/neil/work/projects/topostats/TopoStats\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Output directory                    : output\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Looking for images with extension   : .spm\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Images with extension .spm in /home/neil/work/projects/topostats/TopoStats : 32\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Thresholding method (Filtering)     : std_dev\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Thresholding method (Grains)        : std_dev\n...\n</code></pre> <p>On a successful completion you should see a message similar to the following which indicates various aspects of the run along with information about how to give feedback, report bugs and cite the software.</p> <pre><code>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n  _______      _____      __ __       _____     ______    _______      _____      _______    ______\n/\\_______)\\   ) ___ (    /_/\\__/\\    ) ___ (   / ____/\\ /\\_______)\\   /\\___/\\   /\\_______)\\ / ____/\\\n\\(___  __\\/  / /\\_/\\ \\   ) ) ) ) )  / /\\_/\\ \\  ) ) __\\/ \\(___  __\\/  / / _ \\ \\  \\(___  __\\/ ) ) __\\/\n  / / /     / /_/ (_\\ \\ /_/ /_/ /  / /_/ (_\\ \\  \\ \\ \\     / / /      \\ \\(_)/ /    / / /      \\ \\ \\\n ( ( (      \\ \\ )_/ / / \\ \\ \\_\\/   \\ \\ )_/ / /  _\\ \\ \\   ( ( (       / / _ \\ \\   ( ( (       _\\ \\ \\\n  \\ \\ \\      \\ \\/_\\/ /   )_) )      \\ \\/_\\/ /  )____) )   \\ \\ \\     ( (_( )_) )   \\ \\ \\     )____) )\n  /_/_/       )_____(    \\_\\/        )_____(   \\____\\/    /_/_/      \\/_/ \\_\\/    /_/_/     \\____\\/\n\n\n[Thu, 14 Nov 2024 09:40:56] [INFO    ] [topostats]\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ COMPLETE ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n  Base Directory              : /home/neil/work/projects/topostats/TopoStats\n  File Extension              : .spm\n  Files Found                 : 1\n  Successfully Processed      : 1 (100.0%)\n  Configuration               : output/config.yaml\n  All statistics              : output/all_statistics.csv\n  Distribution Plots          : output/summary_distributions\n\n  Email                       : topostats@sheffield.ac.uk\n  Documentation               : https://afm-spm.github.io/topostats/\n  Source Code                 : https://github.com/AFM-SPM/TopoStats/\n  Bug Reports/Feature Request : https://github.com/AFM-SPM/TopoStats/issues/new/choose\n  Citation File Format        : https://github.com/AFM-SPM/TopoStats/blob/main/CITATION.cff\n\n  If you encounter bugs/issues or have feature requests please report them at the above URL\n  or email us.\n\n  If you have found TopoStats useful please consider citing it. A Citation File Format is\n  linked above and available from the Source Code page.\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre>"},{"location":"usage/#help-options","title":"Help Options","text":"<p>The main <code>topostats</code> programme has a number of flags which can be specified to change the behaviour of how the programme runs. You can view the possible options by supplying the <code>-h</code> or <code>--help</code> flag.</p> <pre><code>\u2771 topostats --help\nusage: topostats [-h] [-v] [-c CONFIG_FILE] [-s SUMMARY_CONFIG] [--matplotlibrc MATPLOTLIBRC] [-b BASE_DIR] [-o OUTPUT_DIR] [-l LOG_LEVEL] [-j CORES] [-f FILE_EXT] [--channel CHANNEL] {process,load,filter,grains,grainstats,disordered-tracing,nodestats,ordered-tracing,splining,summary,create-config,create-matplotlibrc} ...\n\nRun various programs relating to AFM data. Add the name of the program you wish to run.\n\noptions:\n  -h, --help            show this help message and exit\n  -v, --version         Report the current version of TopoStats that is installed\n  -c CONFIG_FILE, --config-file CONFIG_FILE\n                        Path to a YAML configuration file.\n  -s SUMMARY_CONFIG, --summary-config SUMMARY_CONFIG\n                        Path to a YAML configuration file for summary plots and statistics.\n  --matplotlibrc MATPLOTLIBRC\n                        Path to a matplotlibrc file.\n  -b BASE_DIR, --base-dir BASE_DIR\n                        Base directory to scan for images.\n  -o OUTPUT_DIR, --output-dir OUTPUT_DIR\n                        Output directory to write results to.\n  -l LOG_LEVEL, --log-level LOG_LEVEL\n                        Logging level to use, default is 'info' for verbose output use 'debug'.\n  -j CORES, --cores CORES\n                        Number of CPU cores to use when processing.\n  -f FILE_EXT, --file-ext FILE_EXT\n                        File extension to scan for.\n  --channel CHANNEL     Channel to extract.\n\nprogram:\n  Available programs, listed below:\n\n  {process,load,filter,grains,grainstats,disordered-tracing,nodestats,ordered-tracing,splining,summary,create-config,create-matplotlibrc}\n    process             Process AFM images. Additional arguments over-ride defaults or those in the configuration file.\n    load                Load and save all images as .topostats files for subsequent processing.\n    filter              WIP DO NOT USE - Load and filter images, saving as .topostats files for subsequent processing.\n    grains              WIP DO NOT USE - Load filtered images from '.topostats' files and detect grains.\n    grainstats          WIP DO NOT USE - Load images with grains from '.topostats' files and calculate statistics.\n    disordered-tracing  WIP DO NOT USE - Skeletonise and prune objects to disordered traces.\n    nodestats           WIP DO NOT USE - Calculate node statistics and disentangle molecules.\n    ordered-tracing     WIP DO NOT USE - Ordered traces of pruned skeletons.\n    splining            WIP DO NOT USE - Splining of traced molecules to produce smooth curves.\n    summary             Plotting and summary of TopoStats output statistics.\n    create-config       Create a configuration file using the defaults.\n    create-matplotlibrc\n                        Create a Matplotlibrc parameters file using the defaults.\n</code></pre> <p>The global flags/options for modifying behaviour are listed. You then need to provide the name of the programme you wish to run which are listed at the bottom of the output along with a description.</p> <p>Each sub-programme has its own specific set of options too which can be specified to override the settings in the configuration file that is loaded (either the default or the user specified configuration). To view these again use the <code>-h</code> or <code>--help</code> flag. For a more detailed description of the options see the configuration page.</p> <pre><code> \u2771 topostats create-config --help\nusage: topostats create-config [-h] [-f FILENAME] [-o OUTPUT_DIR] [-c CONFIG] [-s]\n\nCreate a configuration file using the defaults.\n\noptions:\n  -h, --help            show this help message and exit\n  -f FILENAME, --filename FILENAME\n                        Name of YAML file to save configuration to (default 'config.yaml').\n  -o OUTPUT_DIR, --output-dir OUTPUT_DIR\n                        Path to where the YAML file should be saved (default './' the current directory).\n  -c CONFIG, --config CONFIG\n                        Configuration to use, currently only one is supported, the 'default'.\n  -s, --simple          Create a simple configuration file with only the most common options.\n</code></pre> <p>NB The <code>process</code> programme has a lot of options as it runs the processing pipeline in full.</p>"},{"location":"usage/#reducing-output","title":"Reducing Output","text":"<p>If you find the output too verbose or of no use you can reduce it by setting the <code>log_level</code> to either <code>error</code> or <code>warning</code>. This can be done either in the configuration file (see Configuration below) or using the <code>-l</code>/<code>--log-level</code> flag for example <code>topostats process --log_level warning</code>.</p>"},{"location":"usage/#configuring-topostats","title":"Configuring TopoStats","text":"<p>Configuration of TopoStats is done through a YAML file and a full description of the fields used can be found under the configuration section.</p> <p>Here we will go through generating a configuration file to edit and some of the common changes that you are likely to want to make to the default configuration and how to make them.</p>"},{"location":"usage/#generating-configuration-file","title":"Generating Configuration File","text":"<p>TopoStats will use some reasonable default parameters by default, but typically you will want to customise the parameters that are used. This is achieved using a configuration file. This is a YAML file that contains parameters for different settings. For convenience you can generate a sample configuration file in your current working directory using the <code>topostats create-config</code> sub-command. It takes a single argument, the name of the file to save the configuration to (e.g. <code>config.yaml</code> or <code>settings.yaml</code>), and it will write the current default configuration to that file.</p> <pre><code>topostats create-config --filename my_config.yaml\nls -l\nmy_config.yaml\nsample_image_scan_2022-12-08-1204.spm\n</code></pre> <p>You can now edit and/or rename the <code>my_config.yaml</code>. It can be called anything you want, e.g. <code>todays_first_run_configuration.yaml</code> is a valid name.</p>"},{"location":"usage/#editing-configyaml","title":"Editing <code>config.yaml</code>","text":"<p>IMPORTANT This file is an ASCII text file and you should use NotePad (Windows), TextEdit (OSX) or Nano/Emacs/Vim (GNU/Linux) or any other text editor. Do not use Microsoft Word or any other Word Processor to edit this file.</p> <p>You can now start customising the configuration you are going to run TopoStats with. All fields have defaults but the ones you may want to change are....</p> <ul> <li><code>base_dir</code> (default: <code>./</code>) the directory in which to search for scans. By default this is <code>./</code> which represents the   directory from which <code>topostats process</code> is called and it is good practice to have one configuration file per batch of   scans that are being processed.</li> <li><code>output_dir</code> (default: <code>output</code>) the location where the output is saved, by default this is the directory <code>output</code>   which will be created if it doesn't exist. If you wish for the output to be somewhere else specify it here. If you   want <code>Processed</code> directories to sit within the directories that images are found then simply set the <code>output_dir</code> to   the same value as <code>base_dir</code>.</li> <li><code>log_level</code> (default: <code>info</code>) the verbosity of output to the console and log file, the options in order of verbosity   are <code>debug</code> &gt; <code>info</code> &gt; <code>warning</code> &gt; <code>error</code>. If you want less output set to <code>warning</code> or <code>error</code>. If you encounter   errors please set to <code>debug</code> and run again and include the log in your bug   report.</li> <li><code>cores</code> (default: <code>2</code>) the number of parallel processes to run processing of all found images. Set this to a maximum   of one less than the number of cores on your computers CPU. If unsure leave as is, but chances are you can increase   this to at least <code>4</code> quite safely.</li> <li><code>file_ext</code> (default: <code>.spm</code>) the file extension of scans to search for within the current directory. The default is   <code>.spm</code> but other file format support is in the pipeline.</li> <li><code>plotting</code> : <code>image_set</code> (default <code>core</code>) specifies which steps of the processing to plot images of. The value <code>all</code>   gets images for all stages, <code>core</code> saves only a subset of images.</li> </ul> <p>Most of the other configuration options can be left on their default values for now. Once you have made any changes save the file and return to your terminal.</p>"},{"location":"usage/#running-topostats-with-my_configyaml","title":"Running TopoStats with <code>my_config.yaml</code>","text":"<p>To use your new configuration file you need to inform <code>topostats process</code> to use that file rather than the defaults, this is done using the <code>--config config.yaml</code> file.</p> <p>NB this assumes that you are in the same directory as your scans where you have saved the <code>my_config.yaml</code> file that you edited. That doesn't have to be the case but it makes life easier for if you are not familiar with absolute and relative paths.</p> <pre><code>topostats --config my_config.yaml process\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Configuration is valid.\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Plotting configuration is valid.\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Configuration file loaded from      : None\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Scanning for images in              : /home/neil/work/projects/topostats/TopoStats\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Output directory                    : output\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Looking for images with extension   : .spm\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Images with extension .spm in /home/neil/work/projects/topostats/TopoStats : 1\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Thresholding method (Filtering)     : std_dev\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Thresholding method (Grains)        : std_dev\n...\n</code></pre> <p>On successful completion you should see the same message noted above.</p>"},{"location":"usage/#output","title":"Output","text":"<p>The output from running TopoStats is saved in the location defined in the configuration file by <code>output_dir</code>. The default is the directory <code>output</code> within the directory from which <code>topostats process</code>. This may differ if you have used your own customised configuration file (specifically if you have modified the <code>output_dir:</code> option).</p> <p>At the top level of the output directory are a few files produced:</p> <ul> <li><code>config.yaml</code> : a copy of the configuration used to process the images.</li> <li><code>all_statistics.csv</code> : a Comma Separated Variable ASCII plain-text file of the grain statistics.</li> <li><code>all_disordered_segment_statistics.csv</code> : a Comma Separated Variable ASCII plain-text file of the branched skeleton   statistics.</li> <li><code>all_mol_statistics.csv</code> : a Comma Separated Variable ASCII plain-text file of the molecule statistics.</li> </ul> <p>Note: - If all grains / branch segments of a column have a <code>None</code> or <code>NaN</code> value, the column will not be present in the output <code>.csv</code> file.</p> <p>The remaining directories of results is contingent on the structure of files within the <code>base_dir</code> that is specified in the configuration. If all files are in the top-level directory (i.e. no nesting) then you will have just a <code>Processed</code> directory. If there is a nested structure then there will be a <code>Processed</code> directory in each folder that an image with the specified <code>file_ext</code> has been found. This is perhaps best illustrated by way of example.</p> <p>If you have the following three <code>.spm</code> files within your current directory, one at the top level, one under <code>level1</code> and one under <code>level1/a</code>...</p> <pre><code>[4.0K Nov 15 13:55]  .\n|-- [4.0K Nov 15 13:54]  ./level1\n|   |-- [4.0K Nov 15 13:54]  ./level1/a\n|   |-- [ 32M Nov 15 13:54]  ./level1/a/minicircle.spm\n|   |-- [ 32M Nov 15 13:54]  ./level1/minicircle.spm\n|-- [ 32M Nov 15 13:54]  ./minicircle.spm\n</code></pre> <p>...then under <code>output</code> (the default for<code>output_dir</code>) you will see the following directory structure.</p> <pre><code>[4.0K Nov 15 14:06]  output\n|-- [ 381 Nov 15 14:06]  output/all_statistics.csv\n|-- [ 733 Nov 15 14:06]  output/all_disordered_tracing_statistics.csv\n|-- [ 254 Nov 15 14:06]  output/all_mol_statistics.csv\n|-- [7.4K Nov 15 14:06]  output/config.yaml\n|-- [ 222 Nov 15 14:06]  output/image_stats.csv\n|-- [4.0K Nov 15 14:06]  output/level1\n|   |-- [4.0K Nov 15 14:06]  output/level1/a\n|   |   |-- [4.0K Nov 15 14:06]  output/level1/a/Processed\n|   |-- [4.0K Nov 15 14:06]  output/level1/Processed\n|-- [4.0K Nov 15 14:06]  output/Processed\n</code></pre> <p>...where there is one <code>Processed</code> directory at the sub-directory level that each image was found.</p> <p>NB If you want <code>Processed</code> directories to sit within the directories that images are found then simply set the <code>output_dir</code> to the same value as <code>base_dir</code>.</p> <p>Within each <code>Processed</code> directory is a directory for each file found with the specified <code>file_ext</code> and within these are the resulting images from processing scans. If the <code>plotting</code> : <code>image_set</code> is <code>core</code> then there is a single image for each. If this option is <code>all</code> then there is also a sub-directory for each image found within which there are the directories <code>filters</code>, <code>grains/below</code> and <code>grains/above</code> which contain additional images from the processing stages and an accompanying histogram for each image showing the distribution of pixel heights for that image.</p>"},{"location":"usage/#summary-plots","title":"Summary Plots","text":"<p>By default TopoStats will take the data that has been summarised across all files and generate a series of plots, histograms with Kernel Density Estimates (KDE) overlaid and Violin plots. The default location of these if no custom configuration file is used is <code>output/summary_distributions</code>. If you have used a custom configuration file it will be the sub-directory <code>summary_distributions</code> nested under the directory specified for the <code>output</code>, e.g. if you used the current directory as output you will have a <code>summary_distributions</code> directory present.</p> <p>Sometimes you may have a <code>all_statistics.csv</code> from a run and wish to plot distributions of additional statistics that were not already plotted. This can be achieved using the command line programme <code>toposum</code> which is included.</p> <p>NB Because of the inherent complexity of plots this script is, by design, limited in the scope to which plots can be configured. It uses the plotting library Seaborn (which is built on top of Matplotlib) to produce basic plots, which are not intended for publication. If you want to tweak or customise plots it is recommended to load <code>all_statistics.csv</code> into a Jupyter Notebook and generate the plots you want there. A sample notebook is included to show how to do this.</p>"},{"location":"usage/#configuring-summary-plots","title":"Configuring Summary Plots","text":"<p>Configuration of summary plots is also via a YAML configuration file a description of the fields can be found under configuration page. You can generate a sample configuration by invoking the <code>--create-config-file</code> option to <code>toposum</code></p> <pre><code>toposum --create-config-file custom_summary_config.yaml\n</code></pre> <p>The file <code>custom_summary_config.yaml</code> can then be edited to change what plots are generated, where they are saved to and so forth. Typically you will only want to adjust a few settings such as toggling the types of plots (<code>hist</code>, <code>kde</code> and <code>violin</code>), the number of <code>bins</code> in a histogram or the statistic to plot in histograms (<code>count</code>, <code>frequency</code> etc.). You can change the <code>palette</code> that is used by Seaborn and crucially toggle which statistics are summarised by commenting and uncommenting the statistic names under <code>stats_to_sum</code>.</p>"},{"location":"usage/#labels","title":"Labels","text":"<p>Labels for the plots are generated from the file <code>topostats/var_to_label.yaml</code> which provides a dictionary that maps the variable name as the dictionary <code>key</code> to its description stored in the dictionary <code>value</code>. If you wish to customise these you can do so and pass it to <code>toposum</code> using the <code>--plotting_dictionary</code> which takes as an argument the path to the file you have created.</p>"},{"location":"usage/#pickles","title":"Pickles","text":"<p>The option <code>pickle_plots: True</code> will save to the specified <code>output_dir</code> the file <code>distribution_plots.pkl</code> which is a binary format that saves the plots that have been generated and saved in nested dictionaries so that they can be loaded again. The Notebook <code>notebooks/02-Summary-statistics-and-plots.ipynb</code> shows how to load these and make simple modifications to the the plots.</p>"},{"location":"usage/configuration/","title":"Configuration","text":"<p>Configuration for TopoStats is done using a YAML configuration file that is specified on the command line when invoking. If no configuration file is provided this default configuration is loaded automatically and used.</p> <p>The current configuration file is provided in the TopoStats repository at <code>topostats/default_config.yaml</code> but please be aware this may not work with your installed version, particularly if you installed from PyPI.</p>"},{"location":"usage/configuration/#generating-a-configuration","title":"Generating a configuration","text":"<p>You can always generate a configuration file appropriate for the version you have installed (bar v2.0.0 as this option was added afterwards). This writes the default configuration to the specified filename (i.e. it does not have to be called <code>config.yaml</code> it could be called <code>spm-2023-02-20.yaml</code>). There are a few options available (use <code>topostats create-config --help</code> for further details).</p> <pre><code>topostats create-config\n</code></pre>"},{"location":"usage/configuration/#partial-configurations","title":"Partial configurations","text":"<p>TopoStats supports using a partial configuration, where you specify only the fields you wish to override. This is useful if you only want to change a few parameters from the default configuration or would like to use a configuration file that is smaller and easier to read.</p> <p>To create a partial configuration file, simply create a new config file and delete anything you don't want to override.</p> <p>TopoStats will take the partial configuration file and merge it with the default configuration file, with the partial configuration taking precedence. This means that any fields you specify in the partial configuration will override the default configuration, while any fields you don't specify will be taken from the default configuration. Command-line arguments will override both the default and partial configurations.</p> <p>For example, you could use a configuration as simple as:</p> <pre><code>base_dir: ./mydata/\noutput_dir: ./myoutput/\nfilter:\n  remove_scars:\n    run: true\ngrains:\n  threshold_method: absolute\n  threshold_absolute:\n    above: 1.2\n  absolute_area_threshold:\n    above: [400, 1000]\n</code></pre>"},{"location":"usage/configuration/#using-a-custom-configuration","title":"Using a custom configuration","text":"<p>If you have generated a configuration file you can modify and edit a configuration it to change the parameters (see fields below). Once these changes have been saved, you can run TopoStats with this configuration file as shown below.</p> <pre><code>topostats --config my_config.yaml process\n</code></pre> <p>On completion a copy of the configuration that was used is written to the output directory so you have a record of the parameters used to generate the results you have. This file can be used in subsequent runs of TopoStats.</p>"},{"location":"usage/configuration/#yaml-structure","title":"YAML Structure","text":"<p>YAML files have key and value pairs, the first word, e.g. <code>base_dir</code> is the key this is followed by a colon to separate it from the value that it takes, by default <code>base_dir</code> takes the value <code>./</code> (which means the current directory) and so the entry in the file is a single line with <code>base_dir: ./</code>. Other data structures are available in YAML files including nested values and lists.</p> <p>A list in YAML consists of a key (e.g. <code>above:</code>) followed by the values in square brackets separated by commas such as <code>above: [ 500, 800 ]</code>. This means the <code>above</code> key is a list of the values <code>500</code> and <code>800</code>. Long lists can be split over separate lines as shown below</p> <pre><code>above:\n  - 100\n  - 200\n  - 300\n  - 400\n</code></pre>"},{"location":"usage/configuration/#fields","title":"Fields","text":"<p>Aside from the comments in YAML file itself the fields are described below.</p> Section Sub-Section Data Type Default Description <code>base_dir</code> string <code>./</code> Directory to recursively search for files within. (See Absolute v Relative Paths) <code>output_dir</code> string <code>./output</code> Directory that output should be saved to. (See Absolute v Relative Paths) <code>log_level</code> string <code>info</code> Verbosity of logging, options are (in increasing order) <code>warning</code>, <code>error</code>, <code>info</code>, <code>debug</code>. <code>cores</code> integer <code>2</code> Number of cores to run parallel processes on. <code>file_ext</code> string <code>.spm</code> File extensions to search for. <code>loading</code> <code>channel</code> string <code>Height</code> The channel of data to be processed, what this is will depend on the file-format you are processing and the channel you wish to process. <code>extract</code> string <code>raw</code> The array to extract when loading from <code>.topostats</code> images. <code>filter</code> <code>run</code> boolean <code>true</code> Whether to run the filtering stage, without this other stages won't run so leave as <code>true</code>. <code>threshold_method</code> str <code>std_dev</code> Threshold method for filtering, options are <code>ostu</code>, <code>std_dev</code> or <code>absolute</code>. <code>otsu_threshold_multiplier</code> float <code>1.0</code> Factor by which the derived Otsu Threshold should be scaled. <code>threshold_std_dev</code> dictionary <code>10.0, 1.0</code> A pair of values that scale the standard deviation, after scaling the standard deviation <code>below</code> is subtracted from the image mean to give the below/lower threshold and the <code>above</code> is added to the image mean to give the above/upper threshold. These values should always be positive. <code>threshold_absolute</code> dictionary <code>-1.0, 1.0</code> Below (first) and above (second) absolute threshold for separating data from the image background. <code>gaussian_size</code> float <code>0.5</code> The number of standard deviations to build the Gaussian kernel and thus affects the degree of blurring. See skimage.filters.gaussian and <code>sigma</code> for more information. <code>gaussian_mode</code> string <code>nearest</code> <code>filter</code>  \u221f <code>remove_scars</code> <code>run</code> bool <code>true</code> Whether to run scar removal. <code>removal_iterations</code> int <code>2</code> The number of times to run scar removal. More iterations can improve scar removal by tidying up remaining artefacts after removal, though will cause more data distortion. <code>threshold_low</code> float <code>0.250</code> The threshold determining whether to further assess if a pixel is a scar. This is the first check, and lowering it will allow more pixels to undergo further analysis in determining if they are scars. <code>threshold_high</code> float <code>0.666</code> The threshold above which a pixel ridge is automatically determined to be a scar. Lowering this value will increase the number of pixels that are flagged as scars with no additional checks. <code>max_scar_width</code> int <code>4</code> The maximum thickness of scars in pixels, along their short axis, ie vertical distance in an AFM image. This parameter can be reduced to only allow marking of thin scars or increased to allow thicker regions to be marked as scars. Be careful - if this value in pixels approaches the thickness of DNA, then it will start deleting regions of DNA (or other relevant data). <code>min_scar_length</code> int <code>16</code> The minimum length of scars in pixels, along their long axis, ie horizontal distance in an AFM image. This parameter can be reduced to allow shorter ridges to be marked as scars, or increased to only allow longer regions to be marked. This can be used to attempt to avoid marking data such as DNA from being marked as a scar, as it may be unlikely that you have a section of DNA that is straight and more than 16 pixels long. <code>grains</code> <code>run</code> boolean <code>true</code> Whether to run grain finding. Options <code>true</code>, <code>false</code> <code>row_alignment_quantile</code> float <code>0.5</code> Quantile (0.0 to 1.0) to be used to determine the average background for the image. below values may improve flattening of large features. <code>smallest_grain_size_nm2</code> int <code>100</code> The smallest size of grains to be included (in nm^2), anything smaller than this is considered noise and removed. NB must be <code>&gt; 0.0</code>. <code>threshold_method</code> float <code>std_dev</code> Threshold method for grain finding. Options : <code>otsu</code>, <code>std_dev</code>, <code>absolute</code> <code>otsu_threshold_multiplier</code> <code>1.0</code> Factor by which the derived Otsu Threshold should be scaled. <code>threshold_std_dev</code> dictionary <code>10.0, 1.0</code> A pair of values that scale the standard deviation, after scaling the standard deviation <code>below</code> is subtracted from the image mean to give the below/lower threshold and the <code>above</code> is added to the image mean to give the above/upper threshold. These values should always be positive. <code>threshold_absolute</code> dictionary <code>-1.0, 1.0</code> Below (first), above (second) absolute threshold for separating grains from the image background. <code>direction</code> <code>above</code> Defines whether to look for grains above or below thresholds or both. Options: <code>above</code>, <code>below</code>, <code>both</code> <code>smallest_grain_size</code> int <code>50</code> Catch-all value for the minimum size of grains. Measured in nanometres squared. All grains with area below than this value are removed. <code>absolute_area_threshold</code> dictionary <code>[300, 3000], [null, null]</code> Area thresholds for above the image background (first) and below the image background (second), which grain sizes are permitted, measured in nanometres squared. All grains outside this area range are removed. <code>remove_edge_intersecting_grains</code> boolean <code>true</code> Whether to remove grains that intersect the image border. Do not change this unless you know what you are doing. This will ruin any statistics relating to grain size, shape and DNA traces. <code>grains</code>  \u221f <code>unet_config</code> <code>path_to_model</code> str <code>null</code> The path to the U-Net model to override traditional segmentation. Supply a path to a tensorflow U-net model to use, else U-Net segmentation will be skipped. <code>grain_crop_padding</code> int <code>0</code> The amount of padding to be applied to grain crops before they are passed to the U-Net model. Increasing this value within reason may reduce edge-anomalies within the crops. Additionally, models are usually trained assuming the grain will take up a certain proportion of the image. If segmentation is poor, try increasing this. <code>upper_norm_bound</code> float <code>5.0</code> The upper normalisation bound for normalising grain crops before sending to the segmentation model. The model will have been trained with particular normalisation bounds, use those. If in doubt, talk to the person who trained the model or use a sensible range, eg if DNA is expected between 0 and 2nm, try using -1 to 3 as normalisation bounds. <code>lower_norm_bound</code> float <code>-1</code> The lower normalisation bound for normalising grain crops before sending to the segmentation model. The model will have been trained with particular normalisation bounds, use those. If in doubt, talk to the person who trained the model or use a sensible range, eg if DNA is expected between 0 and 2nm, try using -1 to 3 as normalisation bounds. <code>grains</code>  \u221f <code>vetting</code> <code>class_region_number_thresholds</code> list[tuple[int, int, int]] <code>null</code> Class region number thresholds, list of lists, <code>[[class, low, high]]</code>, eg: <code>[[1, 2, 4], [2, 1 ,1]]</code> for class 1 to have 2-4 regions and class 2 to have 1 region. Can use Noneto not set an upper/lower bound. <code>class_conversion_size_thresholds</code> list[tuple[tuple[int, int, int], tuple[int, int]]] <code>null</code> Class conversion size thresholds, list of tuples of 3 integers and 2 integers, ie <code>list[tuple[tuple[int, int, int], tuple[int, int]]]</code> eg <code>[[[1, 2, 3], [5, 10]]]</code> for each region of class 1 to convert to 2 if smaller than 5 nm^2 and to class 3 if larger than 10 nm^2. <code>class_size_thresholds</code> list[tuple[int, int, int]] null Class size thresholds (nm^2), list of tuples of 3 integers, ie <code>[[class, low, high],]</code> eg <code>[[1, 100, 1000], [2, 1000, None]]</code> for class 1 to have 100-1000 nm^2 and class 2 to have 1000-any nm^2. Can use None to not set an upper/lower bound. <code>nearby_conversion_classes_to_convert</code> list[tuple[tuple[int, int], tuple[int, int]]] <code>null</code> Class conversion for nearby regions, list of tuples of two-integer tuples, eg <code>[[[1, 2], [3, 4]]]</code> to convert class 1 to 2 and 3 to 4 for small touching regions <code>class_touching_threshold</code> int <code>5</code> Number of dilation steps to use for detecting touching regions, higher value will mean further away regions will be considered touching <code>keep_largest_labelled_regions_classes</code> list[int] <code>null</code> Classes to keep only the largest labelled regions for, list of integers eg <code>[1, 2]</code> to keep only the largest labelled regions for classes 1 and 2 <code>class_connection_point_thresholds</code> list[tuple[tuple[int, int] tuple[int, int]]] <code>null</code> Class connection point thresholds, <code>[[[class_1, class_2], [min, max]]]</code> eg <code>[[[1, 2], [1, 1]]]</code> for class 1 to have 1 connection point with class 2 <code>grainstats</code> <code>run</code> boolean <code>true</code> Whether to calculate grain statistics. Options : <code>true</code>, <code>false</code> <code>cropped_size</code> float <code>40.0</code> Force cropping of grains to this length (in nm) of square cropped images (can take <code>-1</code> for grain-sized box) <code>edge_detection_method</code> str <code>binary_erosion</code> Type of edge detection method to use when determining the edges of grain masks before calculating statistics on them. Options : <code>binary_erosion</code>, <code>canny</code>. <code>disordered_tracing</code> <code>run</code> boolean <code>true</code> Whether to run the Disordered Traces pipeline. Options : true, false <code>min_skeleton_size</code> int <code>10</code> The minimum number of pixels a skeleton should be for statistics to be calculated on it. Anything smaller than this is dropped but grain statistics are retained. <code>pad_width</code> str <code>1</code> Padding for individual grains when tracing. This is sometimes required if the bounding box around grains is too tight and they touch the edge of the image. <code>disordered_tracing</code>  \u221f <code>mask_smoothing_params</code> <code>gaussian_sigma</code> float <code>2</code> Amount of smoothing by a gaussian kernel. This will compete with <code>dilation_iteration</code> to see which changes the grain mask least, ensuring quality over different scan sizes. <code>dialtion_iterations</code> int <code>2</code> The the number of dilations to perform to smooth. This will compete with <code>gaussian_sigma</code> to see which changes the grain mask least, ensuring quality over different scan sizes. <code>holearea_min_max</code> list <code>[0, null]</code> As smoothing fill holes in the mask, this replaces those within a size range (in nm^2). <code>disordered_tracing</code>  \u221f <code>skeletonisation_params</code> <code>method</code> str <code>topostats</code> The Skeletonisation method to use, possible options are <code>zhang</code>, <code>lee</code>, <code>thin</code> (from Scikit-image Morphology module) or the original bespoke TopoStats (height-biasing) method topostats. <code>height_bias</code> float <code>0.6</code> The percentage of lowest pixels to remove during each skeletonisation iteration of the <code>topostats</code> method. <code>disordered_tracing</code>  \u221f <code>pruning_params</code> <code>max_length</code> float <code>-1</code> The length in nanometres below which to prune branches. Default is <code>-1</code>, meaning 15% of the total length. <code>height_threshold</code> float <code>null</code> The height threshold in nanometres below which to prune branches. <code>method_values</code> str <code>mid</code> The method that determines how branch height is calculated. Options: <code>min</code>, <code>median</code>, <code>mid</code> (middle). <code>method_outliers</code> str <code>mean_abs</code> How to compare the threshold and branch heights to remove low branches. Options are; the inter-quartile range <code>iqr</code>, the height_threshold as an absolute value <code>abs</code>, or the mean of all branches minus the height_threshold value <code>mean_abs</code>. <code>nodestats</code> <code>run</code> boolean <code>true</code> Whether to quantify the crossings in an image. Required for over/under tracing through crossings. Options : true, false <code>node_joining_length</code> float <code>7.0</code> The distance (nm) over which to join nearby crossing points as the skeletonisation will not always force crossing points to connect. <code>node_extend_list</code> float <code>14.0</code> The distance (nm) over which to join nearby odd-branched nodes. <code>branch_pairing_length</code> float <code>nodestats</code> The length (nm) from the crossing point to pair the emainating branches and trace along to obtain the over/under distinguishing full-width half-maximum (FWHM's) values. <code>pair_odd_branches</code> boolean <code>true</code> Whether to try and pair branches at odd-branch crossing regions and leave one hanging branch, or to leave all branches hanging here. Options: <code>true</code> or <code>false</code>. <code>pad_width</code> str <code>1</code> Padding for individual grains when tracing. This is sometimes required if the bounding box around grains is too tight and they touch the edge of the image. <code>ordered_tracing</code> <code>run</code> boolean <code>true</code> Whether to order the pruned skeletons of Disordered Traces. Options : true, false <code>ordering_method</code> str <code>nodestats</code> The method of ordering the disordered traces either using the nodestats output or solely the disordered traces. Options: <code>nodestats</code> or <code>topostats</code>. <code>pad_width</code> int 10 Padding for individual grains when tracing. This is sometimes required if the bounding box around grains is too tight and they touch the edge of the image. <code>splining</code> <code>run</code> boolean <code>true</code> Whether to run ordered trace splining to generate smooth traces. Options : true, false <code>method</code> int <code>rolling_window</code> The method used to smooth out the ordered traces. Options: <code>rolling_window</code> or <code>spline</code>. <code>rolling_window_size</code> int <code>20.0e-9</code> The length (in meters) of the coordinate averaging window to smooth the ordered trace. <code>spline_step_size</code> int <code>7.0e-9</code> The The sampling length of the spline (in meters) to obtain an average of splines. <code>spline_linear_smoothing</code> int <code>5.0</code> The amount of smoothing to apply to linear molecule splines. <code>spline_circular_smoothing</code> int <code>5.0</code> The amount of smoothing to apply to circular molecule splines. <code>spline_degree</code> int <code>3</code> The polynomial degree of the spline. Smaller, odd degrees work best SciPy - slprep. <code>plotting</code> <code>run</code> boolean <code>true</code> Whether to run plotting. Options : <code>true</code>, <code>false</code> <code>style</code> str <code>topostats.mplstyle</code> The default loads a custom matplotlibrc param file that comes with TopoStats. Users can specify the path to their own style file as an alternative. <code>save_format</code> string <code>null</code> Format to save images in, <code>null</code> defaults to <code>png</code> see matplotlib.pyplot.savefig <code>savefig_dpi</code> string / float <code>null</code> Dots Per Inch (DPI), if <code>null</code> then the value <code>figure</code> is used, for other values (typically integers) see [#further-customisation] and Matplotlib. Low DPI's improve processing time but can reduce the plotted trace (but not the actual trace) accuracy. <code>pixel_interpolation</code> string <code>null</code> Interpolation method for image plots. Recommended default 'null' prevents banding that occurs in some images. If interpolation is needed, we recommend <code>gaussian</code>. See matplotlib imshow interpolations documentation for details. <code>image_set</code> string <code>all</code> Which images to plot. Options : <code>all</code>, <code>core</code> (flattened image, grain mask overlay and trace overlay only). <code>zrange</code> list <code>[0, 3]</code> Low (first number) and high (second number) height range for core images (can take [null, null]). NB <code>low &lt;= high</code> otherwise you will see a <code>ValueError: minvalue must be less than or equal to maxvalue</code> error. <code>colorbar</code> boolean <code>true</code> Whether to include the colorbar scale in plots. Options <code>true</code>, <code>false</code> <code>axes</code> boolean <code>true</code> Whether to include the axes in the produced plots. <code>num_ticks</code> null / int <code>null</code> Number of ticks to have along the x and y axes. Options : <code>null</code> (auto) or an integer &gt;1 <code>cmap</code> string <code>null</code> Colormap/colourmap to use. Defaults to 'nanoscope' if null (defined in <code>topostats/topostats.mplstyle</code>). Other options are 'afmhot', 'viridis' etc., see Matplotlib : Choosing Colormaps. <code>mask_cmap</code> string <code>blu</code> Color used when masking regions. Options <code>blu</code>, <code>jet_r</code> or any valid Matplotlib colour. <code>histogram_log_axis</code> boolean <code>false</code> Whether to plot hisograms using a logarithmic scale or not. Options: <code>true</code>, <code>false</code>. <code>summary_stats</code> <code>run</code> boolean <code>true</code> Whether to generate summary statistical plots of the distribution of different metrics grouped by the image that has been processed. <code>config</code> str <code>null</code> Path to a summary config YAML file that configures/controls how plotting is done. If one is not specified either the command line argument <code>--summary_config</code> value will be used or if that option is not invoked the default <code>topostats/summary_config.yaml</code> will be used."},{"location":"usage/configuration/#summary-configuration","title":"Summary Configuration","text":"<p>Plots summarising the distribution of metrics are generated by default. The behaviour is controlled by a configuration file. The default example can be found in <code>topostats/summary_config.yaml</code>. The fields of this file are described below.</p> Section Sub-Section Data Type Default Description <code>output_dir</code> <code>str</code> <code>./output/</code> Where output plots should be saved to. <code>csv_file</code> <code>str</code> <code>null</code> Where the results file should be loaded when running <code>toposum</code> <code>file_ext</code> <code>str</code> <code>png</code> File type to save images as. <code>var_to_label</code> <code>str</code> <code>null</code> Optional YAML file that maps variable names to labels, uses <code>topostats/var_to_label.yaml</code> if null. <code>molecule_id</code> <code>str</code> <code>molecule_number</code> Variable containing the molecule number. <code>image_id</code> <code>str</code> <code>image</code> Variable containing the image identifier. <code>hist</code> <code>bool</code> <code>True</code> Whether to plot a histogram of statistics. <code>bins</code> <code>int</code> <code>20</code> Number of bins to plot in histogram. <code>stat</code> <code>str</code> <code>count</code> What metric to plot on histogram valid values are <code>count</code> (default), <code>frequency</code>, <code>probability</code>, <code>percent</code>, <code>density</code> <code>kde</code> <code>bool</code> <code>True</code> Whether to include a Kernel Density Estimate on histograms. NB if both <code>hist</code> and <code>kde</code> are true they are overlaid. <code>violin</code> <code>bool</code> <code>True</code> Whether to generate Violin Plots. <code>figsize</code> <code>list</code> <code>[16, 9]</code> Figure size (x then y dimensions). <code>alpha</code> <code>float</code> <code>0.5</code> Level of transparency to use when plotting. <code>palette</code> <code>str</code> <code>bright</code> Seaborn color palette. Options <code>colorblind</code>, <code>deep</code>, <code>muted</code>, <code>pastel</code>, <code>bright</code>, <code>dark</code>, <code>Spectral</code>, <code>Set2</code> <code>stats_to_sum</code> <code>list</code> <code>str</code> A list of strings of variables to plot, comment (placing a <code>#</code> at the start of the line) and uncomment as required. Possible values are <code>area</code>, <code>area_cartesian_bbox</code>, <code>aspect_ratio</code>, <code>banding_angle</code>, <code>contour_length</code>, <code>end_to_end_distance</code>, <code>height_max</code>, <code>height_mean</code>, <code>height_median</code>, <code>height_min</code>, <code>radius_max</code>, <code>radius_mean</code>, <code>radius_median</code>, <code>radius_min</code>, <code>smallest_bounding_area</code>, <code>smallest_bounding_length</code>, <code>smallest_bounding_width</code>, <code>volume</code>"},{"location":"usage/configuration/#validation","title":"Validation","text":"<p>Configuration files are validated against a schema to check that the values in the configuration file are within the expected ranges or valid parameters. This helps capture problems early and should provide informative messages as to what needs correcting if there are errors.</p>"},{"location":"usage/configuration/#matplotlib-style","title":"Matplotlib Style","text":"<p>TopoStats generates a number of images of the scans at various steps in the processing. These are plotted using the Python library Matplotlib. A custom <code>matplotlibrc</code> file is included in TopoStats which defines the default parameters for generating images. This covers all aspects of a plot that can be customised, for example we define custom colour maps <code>nanoscope</code> and <code>afmhot</code>. By default the former is configured to be used. Other parameters that are customised are the <code>font.size</code> which affects axis labels and titles.</p> <p>If you wish to modify the look of all images that are output you can generate a copy of the default configuration using <code>topostats create-matplotlibrc</code> command which will write the output to <code>topostats.mplstyle</code> by default (NB there are flags which allow you to specify the location and filename to write to, see <code>topostats create-matplotlibrc --help</code> for further details).</p> <p>You should read and understand this commented file in detail. Once changes have been made you can run TopoStats using this custom file using the following command (substituting <code>my_custom_topostats.mplstyle</code> for whatever you have saved your file as).</p> <pre><code>topostats --matplotlibrc my_custom_topostats.mplstyle process\n</code></pre> <p>NB Plotting with Matplotlib is highly configurable and there are a plethora of options that you may wish to tweak. Before delving into customising <code>matplotlibrc</code> files it is recommended that you develop and build the style of plot you wish to generate using Jupyter Notebooks and then translate them to the configuration file. Detailing all of the possible options is beyond the scope of TopoStats but the Matplotlib documentation is comprehensive and there are some sample Jupyter Notebooks (see <code>notebooks/03-plotting-scans.ipynb</code>) that guide you through the basics.</p>"},{"location":"usage/configuration/#further-customisation","title":"Further customisation","text":"<p>Whilst the overall look of images is controlled in this manner there is one additional file that controls how images are plotted in terms of filenames, titles and image types and whether an image is part of the <code>core</code> subset (flattened image, grain mask overlay and trace overlay) that are always generated or not.</p> <p>This is the <code>topostats/plotting_dictionary.yaml</code> which for each image stage defines whether it is a component of the <code>core</code> subset of images that are always generated, sets the <code>filename</code>, the <code>title</code> on the plot, the <code>image_type</code> (whether it is a binary image), the <code>savefig_dpi</code> which controls the Dots Per Inch (essentially the resolution). Each image has the following structure.</p> <pre><code>z_threshed:\n  title: \"Height Thresholded\"\n  image_type: \"non-binary\"\n  savefig_dpi: 100\n  core_set: true\n</code></pre> <p>Whilst it is possible to edit this file it is not recommended to do so.</p> <p>The following section describes how to override the DPI settings defined in this file and change the global <code>cmap</code> (colormap/colourmap) used in plotting and output format.</p>"},{"location":"usage/configuration/#dpi","title":"DPI","text":"<p>During development it was found that setting high DPI globally for all images had a detrimental impact on processing speeds, slowing down the overall processing time. The solution we have implemented is to use the <code>topostats/plotting_dictionary.yaml</code> file and set the <code>savefig_dpi</code> parameter on a per-image basis.</p> <p>If you wish to change the DPI there are two options, you can change the value for all images by modifying the setting in your a custom configuration by modifying the <code>savefig_dpi</code> from <code>null</code> to your desired value. The example below shows a section of the configuration file you can generate and setting this value to <code>400</code>.</p> <pre><code>plotting:\n  run: true # Options : true, false\n  style: topostats.mplstyle # Options : topostats.mplstyle or path to a matplotlibrc params file\n  savefig_format: null # Options : null (defaults to png) or see https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html\n  savefig_dpi: 400 # Options : null (defaults to format) see https://afm-spm.github.io/TopoStats/main/configuration.html#further-customisation and https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html\n</code></pre> <p>The value in the configuration file (or the default if none is specified) can also be configured at run-time using the <code>--savefig-dpi ###</code> option to the <code>topostats process</code>. This will over-ride both the default or any value specified in a custom configuration you may have set. The following sets this to <code>400</code></p> <pre><code>topostats process --savefig-dpi 400\n</code></pre> <p>NB Changing the DPI in this manner will apply to all images and may significantly reduce processing speed as it takes longer to write images with high DPI to disk.</p> <p>If you wish to have fine grained control over the DPI on a per-image basis when batch processing then your only recourse is to change the values in <code>topostats/plotting_dictionary.yaml</code>. Where this is depends on how you have installed TopoStats, if it is from a clone of the Git repository then it can be found in <code>TopoStats/topostats/plotting_dictionary.yaml</code>. If you have installed from PyPI using <code>pip install topostats</code> then it will be under the virtual environment you have created e.g. <code>~/.virtualenvs/topostats/lib/python3.11/site-packages/topostats/topostats/plotting_dictionary.yaml</code> if you are using plain virtual environments or <code>~/miniconda3/envs/topostats/lib/python3.11/site-packages/topostats/topostats/plotting_dictionary.yaml</code> if you are using Conda environments and chose <code>~/miniconda3</code> as the base directory when installing Conda.</p> <p>If you have installed TopoStats from the cloned Git repository the file will be under <code>TopoStats/topostats/plotting_dictionary.yaml</code>.</p> <p>NB The exact location will be highly specific to your system so the above are just guides as to where to find things.</p>"},{"location":"usage/configuration/#colormap","title":"Colormap","text":"<p>The colormap used to plot images is set globally in <code>topostats/default_config.yaml</code>. TopoStats includes two custom colormaps <code>nanoscope</code> and <code>afmhot</code> but any colormap recognised by Matplotlib can be used (see the Matplotlib Colormap reference for choices).</p> <p>If you want to modify the colormap that is used you have two options. Firstly you can generate a configuration file and modify the field <code>cmap</code> to your choice. The example below shows changing this from <code>null</code> (which defaults to <code>nanoscope</code> as defined in <code>topostats.mplstyle</code>) to <code>rainbow</code>.</p> <pre><code>plotting:\n  ...\n  cmap: rainbow # Colormap/colourmap to use (default is 'nanoscope' which is used if null, other options are 'afmhot', 'viridis' etc.)\n</code></pre> <p>Alternatively it is possible to specify the colormap that is used on the command line using the <code>--cmap</code> option to <code>topostats process</code>. This will over-ride both the default or any value specified in a custom configuration you may have set. The following sets this to <code>rainbow</code>.</p> <pre><code>topostats process --cmap rainbow\n</code></pre>"},{"location":"usage/configuration/#saved-image-format","title":"Saved Image format","text":"<p>Matplotlib, and by extension TopoStats, supports saving images in a range of different formats including <code>png</code> (Portable Network Graphic), <code>svg</code> (Scalable Vector Graphics), <code>pdf</code> (Portable Document Format), and <code>tif</code> (Tag Image File Format). The default is <code>png</code> but, as with both DPI and Colormap, these can be easily changed via a custom configuration file or command line options to change these without having to edit the Matplotlib Style file. If using <code>tif</code> it is worth being aware that although the image will be saved, this will be without metadata since this is not supported for <code>tif</code> files (see the note under <code>metadata</code> of Matplotlib savefig).</p> <p>If you want to modify the output file format that is used you have two options. Firstly you can generate a configuration file and modify the field <code>savefig_format</code> to your choice. The example below shows changing this from <code>null</code> (which defaults to <code>png</code> as defined in <code>topostats.mplstyle</code>) to <code>svg</code>.</p> <pre><code>plotting:\n  ...\n  savefig_format: svg # Options : null (defaults to png) or see https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html\n</code></pre> <p>Alternatively it is possible to specify the output image format that is used on the command line using the <code>--savefig-format</code> option to <code>topostats process</code>. This will over-ride both the default or any value specified in a custom configuration you may have set. The following sets this to <code>svg</code>.</p> <pre><code>topostats process --savefig-format svg\n</code></pre> <p>NB Note that these options are not mutually exclusive and can therefore be combined along with any of the other options available to <code>topostats process</code>. The following would use a DPI of <code>400</code>, set the colormap to <code>rainbow</code> and the output format to <code>svg</code> when running Topostats and would over-ride options in any custom configuration file or matplotlib style file.</p> <pre><code>topostats process --savefig-dpi 400 --cmap rainbow --savefig-format svg\n</code></pre>"},{"location":"usage/configuration/#absolute-v-relative-paths","title":"Absolute v Relative paths","text":"<p>When writing file paths you can use absolute or relative paths. On Windows systems absolute paths start with the drive letter (e.g. <code>c:/</code>) on Linux and OSX systems they start with <code>/</code>. Relative paths are started either with a <code>./</code> which denotes the current directory or one or more <code>../</code> which means the higher level directory from the current directory. You can always find the current directory you are in using the <code>pwd</code> (<code>p</code>rint <code>w</code>orking <code>d</code>irectory). If your work is in <code>/home/user/path/to/my/data</code> and <code>pwd</code> prints <code>/home/user</code> then the relative path to your data is <code>./path/to/my/data</code>. The <code>cd</code> command is used to <code>c</code>hange <code>d</code>irectory.</p> <pre><code>pwd\n/home/user/\n# Two ways of changing directory using a relative path\ncd ./path/to/my/data\npwd\n/home/user/path/to/my/data\n# Using an absolute path\ncd /home/user/path/to/my/data\npwd\n/home/user/path/to/my/data\n</code></pre>"},{"location":"usage/data_dictionary/","title":"Data Dictionary","text":"<p>Output from TopoStats includes two sets of statistics in ASCII text <code>.csv</code> files. The tables below detail the columns of these files, the data types, a description and their units where appropriate.</p>"},{"location":"usage/data_dictionary/#all_statisticscsv","title":"<code>all_statistics.csv</code>","text":"<p>The <code>all_statistics.csv</code> file contains details on each grain that has been detected and traced and has the following fields.</p> Column / field / feature Description Type Units <code>image</code> Filename (minus extension) of scan. <code>str</code> N/A <code>threshold</code> Whether grain is <code>above</code> or <code>below</code> a threshold. <code>str</code> N/A <code>grain_number</code> Number of found grain (starts at <code>0</code>) <code>int</code> N/A <code>centre_x</code> x coordinate of grain centre. <code>float</code> m <code>centre_y</code> y coordinate of grain centre. <code>float</code> m <code>radius_min</code> minimum distance from the centroid to edge of the grain. <code>float</code> m <code>radius_max</code> maximum distance from the centroid to edge of the grain. <code>float</code> m <code>radius_mean</code> mean distance from the centroid to the edge of the grain. <code>float</code> m <code>radius_median</code> median distance from the centroid to the edge of the grain. <code>float</code> m <code>height_min</code> Minimum height of grain. <code>float</code> m <code>height_max</code> Maximum height of grain. <code>float</code> m <code>height_median</code> Median height of grain. <code>float</code> m <code>height_mean</code> Mean height of grain. <code>float</code> m <code>volume</code> Volume of the grain calculated as the number of pixels multiplied by each height and scaled to metres. <code>float</code> m^3 <code>area</code> Area of the grain itself calculated as the number of pixels scaled to metres. <code>float</code> m^2 <code>area_cartesian_bbox</code> Area of the bounding box for the grain along the cartesian axes. (Not the smallest bounding box). <code>float</code> m^2 <code>smallest_bounding_width</code> Width of the smallest bounding box for the grain (not along cartesian axes). <code>float</code> m <code>smallest_bounding_length</code> Length of the smallest bounding box for the grain (not along cartesian axes). <code>float</code> m <code>smallest_bounding_area</code> Area of the smallest bounding box for the grain (not along cartesian axes). <code>float</code> m^2 <code>aspect_ratio</code> Aspect ratio of the grain (length / width), always &gt;= 1. <code>float</code> N/A <code>max_feret</code> Longest length of the grain (see Feret diameter). <code>float</code> m <code>min_feret</code> Shortest width of the grain (see Feret diameter). <code>float</code> m <code>basename</code> Directory in which images was found. <code>str</code> N/A <code>grain_endpoints</code> The number of pixels designated as endpoints (only 1 neighbour) in the pruned skeleton. NB molecules with zero end-points are circular/closed loops. <code>integer</code> N/A <code>grain_junctions</code> The number of pixels designated as junctions (&gt;2 neighbours) in the pruned skeleton. <code>integer</code> N/A <code>total_branch_length</code> The sum of all branch lengths in the pruned skeleton. <code>float</code> m <code>grain_width_mean</code> The mean width of the grain. <code>float</code> m <code>num_crossings</code> The number of crossing regions found in the grain. Note: this will be equal to or lower than the number of junctions explained in the previous section. <code>integer</code> N/A <code>avg_crossing_confidence</code> The average of all pseudo crossing confidences. Used to estimate quality of predictions. <code>float</code> N/A <code>min_crossing_confidence</code> The minimum of all pseudo crossing confidences. Used to estimate quality of predictions. <code>float</code> N/A <code>num_molecules</code> The number of molecules found by following the tracing paths. Note: This will always be 1 for the TopoStats method. <code>integer</code> N/A <code>writhe_string</code> The writhe sign (+/-) which describes the crossing directionality. If a crossing contains &gt; 2 crossing branches, the single crossing region is split into pairs and the writhe calculated in brackets i.e. \"+(-++)\". <code>str</code> N/A <code>total_contour_length</code> The total length along the splined trace of all identified molecules. <code>float</code> m <code>average_end_to_end_distance</code> The average distance from two endpoints of the spline of all identified linear molecules. <code>float</code> m"},{"location":"usage/data_dictionary/#image_statscsv","title":"<code>image_stats.csv</code>","text":"<p>The <code>image_stats.csv</code> summarises the metrics</p> Column / field / feature Description Type Units <code>image</code> Filename of image statistics pertain to. <code>str</code> N/A <code>image_size_x_m</code> Width of image. <code>float</code> m <code>image_size_y_m</code> Height of image. <code>float</code> m <code>image_area_m2</code> Area of image (width x height). <code>float</code> m^2 <code>image_size_x_px</code> Width of image in pixels. <code>int</code> N/A <code>image_size_y_px</code> Height of image in pixels. <code>int</code> N/A <code>image_area_px2</code> Area of image in pixels squared. <code>int</code> N/A <code>grains_number_above</code> Number of grains found above threshold. <code>int</code> N/A <code>grains_per_m2_above</code> Density of grains above upper threshold. <code>int</code> N/A <code>grains_number_below</code> Number of grains found below threshold. <code>int</code> N/A <code>grains_per_m2_below</code> Density of grains below lower threshold. <code>int</code> N/A <code>rms_roughness</code> Root Mean Square Roughness, the square root of the mean squared heights across the surface (Surface Roughness; Surface roughness (Wikipedia)) <code>float</code> N/A"},{"location":"usage/data_dictionary/#all_disordered_segment_statisticscsv","title":"<code>all_disordered_segment_statistics.csv</code>","text":"<p>Please refer to the specific sections on output from running Disordered Segment Statistics Tracing section of the Disordered Tracing page for the data dictionary of the <code>all_disordered_segment_statistics.csv</code> output.</p>"},{"location":"usage/installation/","title":"Installation","text":"<p>NB - If you have trouble installing TopoStats please do checkout the discussion for possible solutions. If your problem isn't covered then please do not hesitate to ask a question.</p> <p>TopoStats is a Python package designed to run at the command line. If you are using Microsoft Windows you should use Powershell. You may have Python installed on your system but should use a Python Virtual Environment such as Miniconda and install and use TopoStats under the Virtual Environment. The versions of Python supported are Python &gt;=3.8 and so when creating your virtual environment you should specify this <code>3.8</code> as the minimum.</p>"},{"location":"usage/installation/#setting-up-conda","title":"Setting up Conda","text":"<p>Once you have downloaded and installed Miniconda you can create a virtual environment for installing TopoStats for installing and running TopoStats. We will call this environment <code>topostats</code> (specified with the <code>--name topostats</code> option) and use Python 3.10 (the option <code>python=3.10</code>). After creating it we can, as per the instructions printed out, activate the environment.</p> <pre><code>conda create --name topostats python=3.10\nconda activate topostats\n</code></pre> <p>You are now ready to install TopoStats.</p> <p>NB If you are using an Apple M1 Macbook then you need to install Anaconda &gt;= 2022.05.</p>"},{"location":"usage/installation/#installing-topostats","title":"Installing TopoStats","text":"<p>There are two options for installing TopoStats depending on your usage</p> <ol> <li>Python Package Index - appropriate if you are just using TopoStats and don't need to dig into    the code.</li> <li>Cloning the GitHub Repository - if you want to look at the code, contribute to it, debug errors or perhaps test a new    feature before a release.</li> </ol>"},{"location":"usage/installation/#pypi-installation","title":"PyPI Installation","text":"<p>After activating your <code>topostats</code> Conda environment you can install TopoStats from PyPI using the following command.</p> <pre><code>pip install topostats\n</code></pre> <p>This will install TopoStats under your virtual environment and the command <code>topostats</code> will be available at the command line. It has a number of sub-commands which can be displayed by invoking it without any options. You can upgrade <code>topostats</code> by using the <code>--upgrade</code> flag...</p> <pre><code>pip install --upgrade topostats\n</code></pre> <p>You can always install a specific version from PyPI</p> <pre><code>pip install topostats==2.0.0\n</code></pre> <p>For more information on using <code>pip</code> to install and manage packages please refer to the pip documentation.</p>"},{"location":"usage/installation/#installing-from-github","title":"Installing from GitHub","text":"<p>You may wish to consider cloning and installing TopoStats from GitHub if...</p> <ul> <li>You wish to try out new features that have been developed since the last release (if you find problems please create   an issue).</li> <li>If you have found an issue in a released version and want to see if it has been fixed in the unreleased version.</li> <li>If you wish to develop and extend TopoStats with new features yourself.</li> </ul> <p>There are two options to install from GitHub, which you use will depend on what you want to do.</p> <ol> <li>Using PyPI to install directly.</li> <li>Clone the repository and install from there.</li> </ol> <p>If all you want to do is use the development version of TopoStats then you can use option 1. If you wish to change the underlying code you should use option 2.</p>"},{"location":"usage/installation/#installing-from-github-using-pypi","title":"Installing from GitHub using PyPI","text":"<p><code>pip</code> supports installing packages from GitHub. To install the <code>main</code> branch of TopoStats use the following in your Virtual Environment.</p> <pre><code>pip install git+https://github.com/AFM-SPM/TopoStats.git@main\n</code></pre> <p>You can install any branch on GitHub by modifying the last argument (<code>@main</code>) to the branch you wish to install, e.g. <code>@another_branch</code> would install the <code>another_branch</code> (if it existed).</p>"},{"location":"usage/installation/#cloning-the-repository-and-installing","title":"Cloning the Repository and installing","text":"<p>If you do not have Git already installed please see Git Installation. If you intend to contribute to the development of TopoStats please read through the contributing section. If you are familiar with the command line then you can clone and install TopoStats with the following after activating your virtual environment. By installing in editable mode (with the <code>-e</code> flag) switching branches will make the branch available.</p> <pre><code>cd ~/where/to/clone\ngit clone git@github.com:AFM-SPM/TopoStats.git\ncd TopoStats\npip install -e .\n</code></pre> <p>If you plan to contribute to development by adding features or address an existing issue please refer to the contributing section and pay particular attention to the section about installing additional dependencies.</p> <p>We include notebooks which show how to use different aspects of TopoStats. If you wish to try these out the Jupyter Noteooks then you can install the dependencies that are required from the cloned TopoStats repository using...</p> <pre><code>pip install \".[notebooks]\"\n</code></pre>"},{"location":"usage/installation/#cloning-using-gitkraken","title":"Cloning Using GitKraken","text":"<p>If you are using GitKraken you can clone the repository by selecting \"Clone\" and then \"GitHub.com\" and typing <code>TopoStats</code> into the box next to \"Repository to Clone\" and you should be presented with the option of selecting \"TopoStats\" from the AFM-SPM organisation. Once cloned follow the above instructions to install with <code>pip</code> under your virtual environment.</p>"},{"location":"usage/installation/#tests","title":"Tests","text":"<p>One of the major changes in the refactoring is the introduction of unit tests. These require certain packages to be installed which are not installed to your virtual environment by setuptools in the above steps. If you are intending to modify or contribute to the development of TopoStats or make changes to the code base you will likely want to be able to run the tests. Install the necessary dependencies to do so with...</p> <pre><code>cd TopoStats\ngit checkout dev\npip install \".[tests]\"\npytest\n</code></pre>"},{"location":"usage/installation/#git","title":"Git","text":"<p>Git is a version control system for managing software development and is required to be installed on your computer in order to clone the TopoStats repository. Instructions on installing Git can be found at Git Guides - install git.</p> <p>A nice Graphical User Interface for working with Git is GitKraken which includes everything you need.</p>"},{"location":"usage/matplotlib-style/","title":"Matplotlib Style","text":"<p>TopoStats includes its own Matplotlib style file . This resides at <code>topostats/topostats.mplstyle</code> (see also GitHub repository).</p> <p>If you wish to customise the style of plots you can create a copy of this using <code>topostats create-matplotlibrc</code>. For more information see</p> <pre><code>topostats create-matplotlibrc --help\n</code></pre> <p>Once you have modified and saved the file you can run your analyses with it using...</p> <pre><code>topostats --matplotlibrc &lt;filename&gt;\n</code></pre> <p>Alternatively you can change the parameters in a custom configuration file to point to the newly created style file.</p>"},{"location":"usage/matplotlib-style/#color-maps","title":"Color Maps","text":"<p>Several custom colormaps for plotting data are also included. These are defined within the <code>topostats.themes.Colormap</code> class. For full details refer to the API.</p> <ul> <li><code>nanoscope</code> colormap is provided and used by default.</li> <li><code>gwyddion</code> colormap is provided that matches the colormap used by default in the Gwyddion</li> <li><code>blue</code> colormap is used for masks by default.</li> <li><code>blue_purple_green</code> colormap is available and is used when plotting traces of overlapping molecules.</li> </ul>"},{"location":"usage/notebooks/","title":"Notebooks","text":"<p>A series of Jupyter Notebooks are provided that demonstrate how to use the TopoStats package in a more interactive manner, calling individual steps. This is useful as it allows the user to explore interactively and with rapid feedback the parameters that may need adjusting in order to process a batch of scans. The notebooks can be found in the <code>notebook/</code> directory after cloning the GitHub repository.</p> Notebook Description <code>00-Walkthrough-minicircle.ipynb</code> Step-by-step walkthrough of processing <code>minicircle.spm</code> from the <code>tests/resources/</code> directory. <code>01-Walthrhgouh-interactive.ipynb</code> Work in Progress As above but uploading a single scan. Will be deployed in Google Colab/Binder for interactive use. <code>02-Summary-statistics-and-plots.ipynb</code> Plotting statistics interactively. <code>03-Plotting-scans.ipynb</code> Plotting NumPy arrays of scans from different stages of processing."},{"location":"usage/notebooks/#installation","title":"Installation","text":"<p>To be able to run the Notebooks you need some additional Python packages installed. You will have to clone the repository from GitHub (see installation) and then install the Notebook dependencies with the following commands under your Virtual Environment (e.g. Conda)...</p> <pre><code>cd TopoStats\npip install \".[notebooks]\"\n</code></pre>"},{"location":"usage/notebooks/#running-notebooks","title":"Running Notebooks","text":"<p>Start a Jupyter server under the Virtual Environment you have installed the dependencies from and a web-browser page will open from which you can choose which notebook to launch.</p> <pre><code>cd TopoStats/notebooks\njupyter notebook\n</code></pre> <p>For more on Jupyter Notebooks please refer to the official documentation.</p>"},{"location":"usage/workflow/","title":"Workflow","text":"<p>This section gives a broad overview of the workflow and how the different modules interact.</p> graph TB     subgraph Input         IF[Input Files]         IO[\"Input/Output Layer\"]:::io     end      subgraph Configuration         CM[\"Configuration Management\"]:::config         VL[\"Validation Layer\"]:::validation     end      subgraph \"Core Processing\"         PL[\"Processing Layer\"]:::processing         FM[\"Filtering Module\"]:::filter     end      subgraph \"Analysis Layer\"         GA[\"Grain Analysis\"]:::analysis         SM[\"Statistics Module\"]:::analysis          subgraph \"Tracing System\"             TS[\"Tracing Subsystem\"]:::tracing             OT[\"Ordered Tracing\"]             DT[\"Disordered Tracing\"]             NS[\"Node Statistics\"]             SP[\"Splining\"]             DC[\"DNA Curvature\"]         end     end      subgraph \"Measurement System\"         GM[\"Geometry\"]:::measure         CM2[\"Curvature\"]:::measure         HP[\"Height Profiles\"]:::measure         FA[\"Feret Analysis\"]:::measure     end      subgraph \"Visualization\"         PS[\"Plotting System\"]:::viz         TM[\"Theme Management\"]:::viz         OUT[\"Output Generation\"]     end      IF --&gt; IO     IO --&gt; PL     CM --&gt; VL     VL --&gt; PL     PL --&gt; FM     FM --&gt; GA     FM --&gt; SM     GA --&gt; TS     SM --&gt; TS      TS --&gt; OT     TS --&gt; DT     OT --&gt; NS     DT --&gt; NS     NS --&gt; SP     SP --&gt; DC      GA --&gt; GM     GA --&gt; CM2     GA --&gt; HP     GA --&gt; FA      GM --&gt; PS     CM2 --&gt; PS     HP --&gt; PS     FA --&gt; PS     TS --&gt; PS     PS --&gt; TM     TM --&gt; OUT      classDef io fill:#90EE90     classDef config fill:#A9A9A9     classDef processing fill:#87CEEB     classDef filter fill:#87CEEB     classDef analysis fill:#FFA500     classDef tracing fill:#FFA500     classDef measure fill:#DDA0DD     classDef viz fill:#9370DB     classDef validation fill:#A9A9A9      click IO \"https://github.com/AFM-SPM/TopoStats/blob/main/topostats/io.py\"     click PL \"https://github.com/AFM-SPM/TopoStats/blob/main/topostats/processing.py\"     click FM \"https://github.com/AFM-SPM/TopoStats/blob/main/topostats/filters.py\"     click GA \"https://github.com/AFM-SPM/TopoStats/blob/main/topostats/grains.py\"     click SM \"https://github.com/AFM-SPM/TopoStats/blob/main/topostats/statistics.py\"     click TS \"https://github.com/AFM-SPM/TopoStats/tree/main/topostats/tracing/\"     click CM \"https://github.com/AFM-SPM/TopoStats/blob/main/topostats/default_config.yaml\"     click VL \"https://github.com/AFM-SPM/TopoStats/blob/main/topostats/validation.py\"     click GM \"https://github.com/AFM-SPM/TopoStats/blob/main/topostats/measure/geometry.py\"     click CM2 \"https://github.com/AFM-SPM/TopoStats/blob/main/topostats/measure/curvature.py\"     click HP \"https://github.com/AFM-SPM/TopoStats/blob/main/topostats/measure/height_profiles.py\"     click FA \"https://github.com/AFM-SPM/TopoStats/blob/main/topostats/measure/feret.py\"     click PS \"https://github.com/AFM-SPM/TopoStats/blob/main/topostats/plotting.py\"     click TM \"https://github.com/AFM-SPM/TopoStats/blob/main/topostats/theme.py\"  <p>Generated using GitDiagram</p>"}]}